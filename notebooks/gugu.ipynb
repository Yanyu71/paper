{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import os, sys\n",
    "import openai\n",
    "from tenacity import (retry, stop_after_attempt, wait_random_exponential)\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=60, max=70), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return openai.ChatCompletion.create(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['å…¨å›½é¦–åº—/è¥¿è´æ——ä¸‹æ–°å“ç‰Œä¸»æ‰“â€œä¸­å¼æ±‰å ¡â€çš„è´¾å›½é¾™é…’é…¿ç©ºæ°”é¦å…¨å›½é¦–åº—äº®ç›¸åŒ—äº¬ã€‚é¦–åº—ä½äºä¸­å…³æ‘Eä¸–ç•Œåœ°ä¸‹ä¸€å±‚ï¼Œå†…éƒ¨æ•´ä½“é£æ ¼ç®€çº¦å¼§çº¿ä¸ºä¸»ï¼Œæ•´ä½“ç©ºé—´æ„Ÿå—å¼€é˜”èˆ’é€‚ï¼Œè¿™ä¸ªä¸»æ‰“çº¢çƒ§è‚‰å¤¹é¦ã€å¤è‚¥è‚ å¤¹é¦ç­‰ä¸­å¼å¤¹é¦çš„å…¨æ–°å“ç‰Œï¼Œæœªæ¥å°†ä¼šå¼€å¯åŠ ç›Ÿã€‚å•å“åˆ°å¥—é¤ä»·æ ¼å’Œä¸»æµè¥¿å¼å¿«é¤å¥—é¤ä»·æ ¼ç›¸å·®æ— å‡ \\n', 'æ¯”å¦‚çº¢çƒ§è‚‰å¤¹é¦åŠ é”…å·´åœŸè±†åŠ èŒ¶é¥®å¥—é¤ä»·æ ¼33å…ƒï¼Œå¦å¤–è¿˜æœ‰å„ç±»ä¸­å¼å°åƒè‡­è±†è…ã€çƒ¤é¸¡çˆªã€çƒ¤é¸¡æ¶ç­‰ï¼Œè¿˜æœ‰ç‰¹è‰²æ±¤ç±»åŠé…¸å¥¶ç­‰ï¼Œå½“ç„¶å¯ä¹å’–å•¡ä¹Ÿæ˜¯æœ‰çš„ï¼Œå·¥ä½œæ—¥ä¸‹åˆå°±é¤é¡¾å®¢å¹¶ä¸å¤šï¼Œæ­£åœ¨è¿›è¡Œå…¥ç¾¤å…è´¹é€å’–å•¡æ´»åŠ¨ã€‚\\n', 'è¥¿è´è¿‘å¹´æ¥æ–°å“ç‰Œä¸æ–­ï¼ŒåŒ…æ‹¬è¥¿è´ç‡•éº¦å·¥åŠã€è¥¿è´è¶…çº§è‚‰å¤¹é¦ã€è¥¿è´é…¸å¥¶å±‹ã€å¼“é•¿å¼ ç­‰ï¼ŒåŒ…æ‹¬è¿˜åœ¨è¿è¥çš„è´¾å›½é¾™åŠŸå¤«èœï¼Œå¤§å¤šè¿è¥å¹¶ä¸æˆåŠŸï¼Œæ­¤æ¬¡æ–°å“ç‰Œå¸‚åœºæ¥å—åº¦å¦‚ä½•å€¼å¾—å…³æ³¨ã€‚\\n', '\\n', 'é¸¡æ¶æœ€å¥½åƒçœŸçš„å¥½åƒä¸é”™æ¯”è¾ƒå…¥å‘³æˆ‘è·Ÿå–œæ¬¢ï¼Œä¸€ç«¯ä¸Šæ¥å°±ç‰¹åˆ«é¦™ï¼æœ‰ç‚¹åƒå¥¥å°”è‰¯çš„å£å‘³\\n', 'å…¨åœºæœ€å¥½åƒçš„æ˜¯é‚£ä¸ªé¸¡æ¶ï¼ŒçœŸçš„ã€‚\\n', 'å¯èƒ½æˆ‘ä¸ªäººè¿˜æ˜¯æ²¡åŠæ³•æ¥å—æŠŠçº¢çƒ§è‚‰å¤¹åœ¨é¢åŒ…é‡Œé¢åƒå§ï¼Œè€Œä¸”è¿™ä¸ªçº¢çƒ§è‚‰çœŸçš„å¾ˆè‚¥å¾ˆè‚¥ã€‚çŒªæ’çš„æ¯”è¾ƒå¥½åƒã€‚\\n', 'é¸¡æ¶çœŸçš„å¾ˆé¦™ï¼Œæˆ‘æ˜¯çœŸçš„å–œæ¬¢é‚£ä¸ªé¸¡æ¶ã€‚è¿˜ç‚¹äº†çº¢è–¯æ¡å’Œè–¯æ¡ï¼Œæ„Ÿè§‰çº¢è–¯æ¡ä¸æ˜¯ç‰¹åˆ«å¥½åƒï¼Œè¿˜æ˜¯æ›´å–œæ¬¢è–¯æ¡ã€‚\\n', 'çœŸçš„è¿˜æ˜¯å–œæ¬¢éº¦å½“å½“å¤šä¸€ç‚¹å‘€\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "f=open('../data/ä¸­å›½å ¡.txt',encoding='utf-8')\n",
    "txt=[]\n",
    "for line in f:\n",
    "    txt.append(line.strip('\"'))\n",
    "f.close()\n",
    "print(txt[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['å¤–å©†èœé¸¡è›‹å ¡yydsï¼Œå¥½å–œæ¬¢ï¼Œè¿ç»­åƒäº†å¥½å‡ æ¬¡ã€‚è¿™ä¸ªæ±‰å ¡æ–™æ¯”è¾ƒè¶³ï¼Œå¤–å©†èœå’Œé¸¡è›‹å¡çš„æ»¡æ»¡çš„ï¼Œé¸¡è›‹è¶…çº§å«©ã€‚æ„Ÿè§‰åƒå®Œæ¯”çº¢çƒ§è‚‰çš„è¦æ»¡è¶³ã€‚\\n', 'ğŸ«“å‘³é“ï¼š\\n', 'QQé¸¡å— 13.5å…ƒ\\n', 'ã€Œæ²™æ£˜å†°æ·‡æ·‹ã€ã€Œè“è“é…¸å¥¶å†°æ·‡æ·‹ã€é…¸å¥¶å†°æ·‡æ·‹æ˜¯çœŸçš„é…¸ï¼Œè€Œä¸”ä¸ä¼šåŒ–ï¼Œæˆ‘æ‹¿å›å»ä¸€ä¸ªå¤šå°æ—¶æ‰åƒç«Ÿç„¶è¿˜æ˜¯å®Œå¥½çš„ã€‚\\n', 'å¥—é¤é‡Œçš„é¸¡æ¶æ˜¯çƒ¤çš„ï¼Œå‘³é“ä¹Ÿä¸é”™\"\\n', 'å¯ä»¥åœ¨æ¡Œä¸Šæ‰«ç ç‚¹é¤ï¼Œå‡ºé¤åæœåŠ¡å‘˜ä¼šå¸®å¿™é€è¿‡æ¥ã€‚\\n', 'å»ºè®®å¤–å–é‡Œçš„é¥®å“å¯ä»¥è‡ªå·±æŒ‘é€‰ï¼Œå¥½æƒ³å–å†·é¥®ï¼Œç»“æœéƒ½æ˜¯ä¹Œé¾™èŒ¶\\n', 'ç¯å¢ƒå¹²å‡€æ•´æ´ï¼›å¢™ä¸ŠæŒ‚çš„äº§å“çš„KTæ¿â€¦â€¦ä¸ªäººè§‰å¾—å¾ˆlowï¼ˆå¯ä»¥æ¢ä¸€ä¸ªæ›´å¥½çš„å‘ˆç°æ–¹å¼ï¼‰\\n', 'åœ°æ–¹ä¸æ˜¯å¾ˆå¥½æ‰¾ ï¼Œæ˜¯åœ¨å†™å­—æ¥¼ä¸­åº­çš„åœ°ä¸‹ï¼Œç»•äº†ä¸€åœˆé—®äº†ä¿å®‰æ‰æ‰¾åˆ°ã€‚ä½œä¸ºç®€é¤è¿˜ä¸é”™ï¼Œç‚¹äº†ä¸€ä»½å¥—é¤å¯ä»¥åƒé¥±ã€‚é¥¼çš®æœ‰ç‚¹ç±»ä¼¼äºå‘ç³•æˆ–ç™½ç³–ç³•çš„å£æ„Ÿï¼Œå¾®å¾®æœ‰ç‚¹é…’é…¿çš„é…¸ç”œå‘³ã€‚å†…é¦…æœ‰è¯•è¿‡æ‰£è‚‰ã€å°ç‚’é»„ç‰›è‚‰å’Œé¸¡æ’çš„ï¼Œéƒ½è¿˜ä¸é”™ã€‚å€¼å¾—æ¨èçš„æ˜¯ä»–å®¶çš„è–¯æ¡ å…¨æ˜¯ç°ç‚¸çš„ï¼Œä¸Šæ¥æ—¶å€™è¿˜çƒ«æ‰‹çš„çƒ­ä¹ä¹ï¼Œé…¥é…¥è„†è„†çš„å¾ˆä¸é”™ã€‚\\n', 'æŠ±ç€è¯•è¯•çœ‹çš„å¿ƒæ€æ¥å°å°ç©ºæ°”é¦ï¼Œä¸€è¿›é—¨åº—å†…è£…ä¿®å¹²å‡€æ•´æ´ï¼ŒæœåŠ¡éƒ½å¾ˆçƒ­æƒ…ï¼Œæ‰«ç ç‚¹é¤ï¼Œæ–°æ³¨å†Œä¼šå‘˜è¿˜é€äº†å¾ˆå¤šä¼˜æƒ åˆ¸ï¼Œç¬¬ä¸€é¤åƒçš„ç›¸å½“å®æƒ ã€‚æ ·å­åƒæ±‰å ¡ï¼Œä½†æ˜¯å‘³é“æ¯”è¾ƒé€‚åˆå›½äººï¼Œé¢é¥¼å®£è½¯ï¼Œé¦…æ–™ä¸°å¯Œï¼Œå½“æˆä¸€é¡¿ç®€é¤åƒæ˜¯ä¸é”™çš„é€‰æ‹©\\n']\n"
     ]
    }
   ],
   "source": [
    "temp=txt[:9]\n",
    "# å»æ‰txtä¸­å’Œtempç›¸åŒçš„å…ƒç´ \n",
    "txt=list(set(txt).difference(set(temp)))\n",
    "print(txt[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™ä¸ªæ˜¯å¼ºè°ƒå…ˆåä¿®æç¤º\n",
    "system_content = '''You are a helpful assistant that \n",
    "                 extract knowledge points and the concept prerequisite relations between knowledge points from contents below,\n",
    "                 returning in the form of json. \n",
    "                 the value of \"en\" should be the english translation of the \"title\".\n",
    "                 the value of \"type\" should represent relationship between \"source\" to \"target\" in 'Communication Theory' area.\n",
    "                 all values are better to be in Chinese apart from \"en\".\n",
    "                 {\n",
    "                    \"knowledge_points\": [{\"title\": \"\", \"en\": \"\"},{\"title\": \"\",  \"en\": \"\"}, ...],\n",
    "                    \"relations\": [{\"source\": \"\", \"target\": \"\", \"type\": \"\"}, {\"source\": \"\", \"target\": \"\", \"type\": \"\"}, ...]\n",
    "                 }\n",
    "                 '''\n",
    "user_content = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™ä¸ªæ˜¯å¼ºè°ƒå…ˆåä¿®æç¤º\n",
    "system_content = '''ä½ ç°åœ¨æ˜¯ä¸€ä¸ªæ•°æ®å¤„ç†ä¸“å®¶ï¼Œæˆ‘ä¼šä¸ºä½ æä¾›ä¸€äº›é¡¾å®¢çš„è¯„è®ºï¼Œé‡Œé¢ä¼šæ¶‰åŠåˆ°é¡¾å®¢å¯¹èœå“çš„è¯„ä»·ã€‚\n",
    "                    æˆ‘å¸Œæœ›ä½ å°†ä¸åŒé¡¾å®¢å¯¹ç›¸åŒèœå“çš„è¯„ä»·å½’ç±»å¯¹å…·ä½“ç›¸åº”èœå“çš„è¯„ä»·ä¸­ï¼ŒåŒæ—¶å¯¹è¯„ä»·è¿›è¡Œä¸€ä¸ªæ€»ç»“ï¼Œæ¯”å¦‚è¯´ï¼šå¥½ã€åã€ä¸­æ€§ã€‚\n",
    "                    éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæœ‰äº›èœå“æ˜¯ç”¨ã€ã€‘æˆ–è€…[]æ ‡å‡ºæ¥ï¼Œæœ‰çš„åˆ™æ²¡æœ‰ï¼Œæ‰€ä»¥éœ€è¦ä½ è¯†åˆ«å‡ºç›¸å…³çš„èœå“ï¼Œæ¯”å¦‚'è¿˜æœ‰ç¾å‘³çš„èƒ¡è¾£æ±¤ï¼Œé…¸è¾£æ±¤ï¼Œè¿˜æœ‰è‡­è±†è…'ä¸­éœ€è¦ä½ è¯†åˆ«å‡ºèœå“èƒ¡è¾£æ±¤ã€é…¸è¾£æ±¤ã€è‡­è±†è…ï¼Œå¹¶ä¸”è¯„ä»·éƒ½æ˜¯å¥½ï¼Œå› ä¸ºéƒ½å¾ˆç¾å‘³ã€‚\n",
    "                    æˆ‘å¸Œæœ›ä½ çš„è¾“å‡ºæ ¼å¼æ˜¯ï¼š\n",
    "                    {å…·ä½“èœå“1çš„è¯„ä»·ï¼š[[å•ä¸ªè¯„è®ºçš„æ€»ç»“ï¼ŒåŸå› ],[å•ä¸ªè¯„è®ºçš„æ€»ç»“ï¼ŒåŸå› ]],\n",
    "                    å…·ä½“èœå“2çš„è¯„ä»·ï¼š[[å•ä¸ªè¯„è®ºçš„æ€»ç»“ï¼ŒåŸå› ],[å•ä¸ªè¯„è®ºçš„æ€»ç»“ï¼ŒåŸå› ]],\n",
    "                    å…·ä½“èœå“3çš„è¯„ä»·ï¼š[[å•ä¸ªè¯„è®ºçš„æ€»ç»“ï¼ŒåŸå› ],[å•ä¸ªè¯„ä»·çš„æ€»ç»“ï¼ŒåŸå› ]]...}ã€‚\n",
    "                 '''\n",
    "user_content = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™ä¸ªæ˜¯å¼ºè°ƒå…ˆåä¿®æç¤º\n",
    "system_content = '''As a specialist in data processing, \n",
    "                  you'll be given a series of customer reviews that contain evaluations of various dishes. \n",
    "                  Your task is to categorize the reviews of different customers for the same dish, \n",
    "                  and then summarize these evaluations as either good, bad, or neutral. \n",
    "                  It's important to note that some dishes are indicated with ã€ã€‘ or [], while others are not. \n",
    "                  Therefore, you need to identify the relevant dishes. \n",
    "                  For instance, in the phrase \"delicious hot and sour soup, sour and spicy soup, and stinky tofu,\" \n",
    "                  you should recognize the dishes hot and sour soup, sour and spicy soup, and stinky tofu, and classify their evaluations as good because they are described as delicious. \n",
    "                  All outputs should be in Chinese form.\n",
    "                  The desired output format is: \n",
    "                  {Evaluation of specific dish 1: [[a summary of a review, reason], [a summary of a review, reason]], \n",
    "                  evaluation of specific dish 2: [[a summary of a review, reason], [a summary of a review, reason]], \n",
    "                  evaluation of specific dish 3: [[a summary of a review, reason], [a summary of the overall evaluation, reason]],...}\n",
    "                 '''\n",
    "user_content = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "lines=[]\n",
    "temp_line=''\n",
    "for line in txt:\n",
    "    if len(temp_line)<1500:\n",
    "        temp_line=temp_line+'\\n'+line\n",
    "    else:\n",
    "        lines.append(temp_line)\n",
    "        temp_line=''\n",
    "lines.append(temp_line) # æ·»åŠ æœ€åä¸€è¡Œæ²¡æœ‰åˆ°3300çš„\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022727272727272728\n",
      "0.045454545454545456\n",
      "0.06818181818181818\n",
      "0.09090909090909091\n",
      "0.11363636363636363\n",
      "0.13636363636363635\n",
      "0.1590909090909091\n",
      "0.18181818181818182\n",
      "0.20454545454545456\n",
      "0.22727272727272727\n",
      "0.25\n",
      "0.2727272727272727\n",
      "0.29545454545454547\n",
      "0.3181818181818182\n",
      "0.3409090909090909\n",
      "0.36363636363636365\n",
      "0.38636363636363635\n",
      "0.4090909090909091\n",
      "0.4318181818181818\n",
      "0.45454545454545453\n",
      "0.4772727272727273\n",
      "0.5\n",
      "0.5227272727272727\n",
      "0.5454545454545454\n",
      "0.5681818181818182\n",
      "0.5909090909090909\n",
      "0.6136363636363636\n",
      "0.6363636363636364\n",
      "0.6590909090909091\n",
      "è¶…è¿‡4096äº†\n",
      "1.1363636363636365\n",
      "1.1590909090909092\n",
      "1.1818181818181819\n",
      "1.2045454545454546\n",
      "è¶…è¿‡4096äº†\n",
      "1.5909090909090908\n",
      "1.6136363636363635\n",
      "1.6363636363636365\n",
      "1.6590909090909092\n",
      "1.6818181818181819\n",
      "1.7045454545454546\n",
      "1.7272727272727273\n",
      "1.75\n",
      "1.7727272727272727\n",
      "1.7954545454545454\n",
      "1.8181818181818181\n"
     ]
    }
   ],
   "source": [
    "index1=1\n",
    "for line in lines:\n",
    "    print(index1/len(lines))\n",
    "    response = completion_with_backoff(\n",
    "        # model=\"text-davinci-003\",\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": line},\n",
    "        ],\n",
    "        top_p=0.1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    if int(response['usage']['total_tokens'])<4096:\n",
    "        completion = response['choices'][0][\"message\"][\"content\"]\n",
    "        with open(\"../output/ä¸­å›½å ¡.txt\", 'a', encoding=\"utf-8-sig\") as f:\n",
    "            f.write(completion)\n",
    "    else:\n",
    "        print(\"è¶…è¿‡4096äº†\")        \n",
    "        temp_lines= line.split(\"\\n\")\n",
    "        length=len(temp_lines)\n",
    "        temp_line1=''\n",
    "        temp_line2=''\n",
    "        index1=0\n",
    "        for i in temp_lines:\n",
    "            if index1 < int(length/2):\n",
    "                temp_line1=temp_line1+'\\n'+i\n",
    "            else:\n",
    "                temp_line2=temp_line2+'\\n'+i\n",
    "            index1+=1\n",
    "        response = completion_with_backoff(\n",
    "            # model=\"text-davinci-003\",\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": temp_line1},\n",
    "            ],\n",
    "            top_p=0.1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "        completion = response['choices'][0][\"message\"][\"content\"]\n",
    "        with open(\"../output/ä¸­å›½å ¡.txt\", 'a', encoding=\"utf-8-sig\") as f:\n",
    "            f.write(completion)\n",
    "        response = completion_with_backoff(\n",
    "            # model=\"text-davinci-003\",\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\"role\": \"user\", \"content\": temp_line2},\n",
    "            ],\n",
    "            top_p=0.1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "        completion = response['choices'][0][\"message\"][\"content\"]\n",
    "        with open(\"../output/ä¸­å›½å ¡.txt\", 'a', encoding=\"utf-8-sig\") as f:\n",
    "            f.write(completion)\n",
    "    # print(f\"completion:{completion}\")\n",
    "    index1+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤„ç†è¾“å‡ºçš„æ•°æ®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
