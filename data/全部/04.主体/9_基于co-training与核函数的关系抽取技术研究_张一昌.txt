第一章绪论
1.1引言
自然语言一直蕴含着非常重要的信息，尤其是自然语言在描述事情的过程中 起着无与伦比的作用。人们平时接触到的，或者使用搜索引擎返回的大部分信息 也是以自然语言的形式反馈的。相对于其他形式的信息，对于自然语言内容的挖 掘和理解有至关重要的作用。在人工智能的早起，图灵就提出了著名的图灵测试, 通过人和未知的另一端以界面语言交互的方式来判定另一端是人还是机器，图灵 测试认为，如果机器能够骗过人类，那么就认为机器具有了智能。图灵测试蕴含 了机器对于语言的深层次理解，只有理解了文字，机器才能在后续做出模仿人类 的回应。
同时，在当今社会随着互联网的飞速发展，信息总量的急剧增加。传统的搜 索引擎技术已经不能很好地满足人们快速、便捷获取信息的需求了⑴。人们常用 的百度、360等搜索引擎，一般都是通过使用自己的爬虫对于互联网上能够访问 到的页面进行抓取，将Web文档分析和切分并进行索引、查询的方式，得到的 结果相关的链接。但是人们面对一个个链接背后的网页仍然会出现浪费大时间， 效率低下的情况。
现在的搜索引擎技术己经不能够充分满足人们要求快速、便捷获取信息的需求，以自然语言为研究对象的技术越来越受到重视。通过对自然语言的结构化信 息进行分析，其处理问题的角度是浅层的，表面的。人们需要的是将非结构化的 自然语言进行深入剖析，利用模式识别的技术，挖掘其内在规律和模式，从而更 深刻的理解自然语言的内涵，在人们搜索的时候简单快捷的返回最需要的信息。
以上提到的人工智能相关以及信息检索问题的解决都需要一项核心的技术， 也就是信息抽取技术。信息抽取(IE, Information Extraction)的指的是从自然语言 信息中抽取出符合预先设定的实体、关系、事件等信息，并将这些信息进行结构 化文本处理技术⑵，该技术的目的是让计算机能够更加理解信息，更方便处理信 息⑶。作为信息抽取技术的核心技术之一，关系抽取(RE, Relation Extraction)技 术Ml的核心研究点在于判定某句子中某对实体是否具有指定关系。
信息抽取技术研究的重点是从文本中抽取出一定的事实信息，这里的事实信 息指的是文本中有表述的信息。本文研究的主体是英文的自然语言，抽取内容为 实体之间的关系。实体，在本文中指的是人物(PERSON)、时间(TIME)、地点 (LOACATION)、年龄(AGE)、组织结构(ORGANIZATION)、头衔(TITLE)、血统 (ORIGIN).信仰(RELIGION)等等。关系指的是实体之间存在的特定关系，如出 生地、死亡地、居住的城市、头衔、子公司、母公司、总部所在地等。本文以人 名和组织机构名这两类实体为主，研究他们与其他实体之间的不同关系。例如， 给出一篇文章之后，本文从中提取出某个人物的头衔，生日、年龄、所属公司、 孩子以及配偶等信息；或者提取岀关于文中某个组织机构名的总部 (HEADQUARTERS)所在地、子公司的名字、员工数、网站等信息。
本文目前以文本分析会议(TAC, Text Analysis Conference)的相关任务为依 据，只研究二元关系，因为如果是多元关系，也可以将其转化成二元关系。对于 关系抽取技术，除了关系实体的确定、实体的关系外，还包括关系实体的指代等 内容。但是本文中，实体的确定和共指关系不是重点，实际操作中会使用其他现 成的技术来解决此类问题。
目前，通过使用常用的搜索引擎，本文发现，百度、Google、360、搜狗等 搜索引擎，都已经将信息抽取技术应用于搜索和Query分析之中，使搜索引擎更 加智能化，而微软的搜索引擎Bing还没有应用这项技术，具体情况见图1-1至 图 l -4o
Bai<S百度奥巴马岀生地	'
网页际通 feae 整這音矛 恿片 H5® 姆图 十產更多》


图1-1百度查询奥巴马出生地
Gl? 奥巴马出生地

美国夏威.夷州檀香山

图1-2 Google查询奥巴马出生地
2
BSC 厂*新闻阕萸问答视频 囹片音乐地图百科购物更多

簡C	奥巴马的岀生地：
Lt美国夏威夷州檀香山
| 贝拉克侯赛因奥巴马二世(英语:Barack Hus-s^ir- Qbama :， be m khu： i nou ba fn项，1961年8月4曰 详蟠
图1-3 360搜索引擎查询奥巴马出生地
"网页 图片 视频，.网與 地图 1衆讯w 押與".影响力、更多 -




奥巴马岀生他 P
單尸竺涛抵山牛氐为了济诱八圭国大学旬円马下…一党网新闻
2014-5-30 英国《每曰郵报》E月27曰报道，美国房地产大亭川普质疑总统奥EH马出生 地，一再要求后者出示出生证明，此人近期就'出生证门'又抛出呂一个理论——聽巴马 n^s.e23.cn ? ME :国际會 2014-5-30
丰杞亨伟定二"二至为卜k学号垢二二、言.万弥 ^AEB
2Q14-5-2S 美国房地产大亨，川普质疑总统奥巴马出生地，一再要求后者出示出生证明、此 人近期就甘生证门'又抛出另一个理论•一一奥巴马为7SOX.美国大字，谎称自己
sc.people.ccsm cn ：•人民网，丄..民网四川頻道:-新闻中心 国际赍讯 寸 d上-29
图1-4 Bing查询奥巴马出生地
由上图本文注意到，如果能够直接在使用搜索引擎的时候如果能够应用信息 抽取技术，则会大大的提升用户体验，节约用户时冋、提高查询效率，关系抽取 技术在学术界和工业界都很有前景。
1.2关系抽取的历史
实体关系抽取技术的冃的是从文本中抽取出两个或者多个实体之间语义关 系(SR, Semantic Relationship),是信息抽取的子任务。历史中，关系抽取技术致 力于研究篇章中所有实体之间的关系，目前则主要研究关于具有特定关系的实体 对。
从1987年开始，得益于消息理解会议(MUC , Message Understanding Conference)的召开，信息抽取技术开展起来。从1987年开始到1997年，美国国
防高级研兖计划委员会(DARPA, the Defense Advanced Research Projects Agency) 资助MUC举行了七届。该会议的前五届是英文，后两届扩展到中文，其主要任 务或者是信息抽取的核心技术或者对于信息抽取有巨大的作用。MUC在信息检 索指标基础上，提出了衡量信息抽取系统性能的两个重要指标：准确率(Precision) 和召回率(Recall)o正是MUC系列会议使信息抽取发展成为自然语言处理领域一 个重要分支，让人们认识到了信息抽取的重要作用，并一直推动这一领域的研究 向前发展。
随着MUC会议的停办，美国国家标准技术研究院(NIST, National Institute of Standards and Technology)组织了 自动 内 容抽 取(ACE , Automatic Content Extraction)会议，从〔999年开始继续进行信息抽取方面的评测，井于2009, ACE 变成了 TAC 的一项子任务。TAC-KBP(KBP, Knowledge Base Population)主要是 研究实体链接和关系抽取。本课题就是以其中的Slot Filling为平台进行分析和研 究。图1-4是信息抽取技术的中具有重大意义会议列表。
时间	评测阶段	f〔务	涪料
1987-1993	MUC1-MUC5	命名实休识别，共指消解，模板 关系抽取等等	限定领域文本(海箪军 駐情报、恐怖袭击)
1995-1997	MUC6-MUC7	棋板填充、命名实体识别、共指 为系确定等	限定领域乂本(人事职 位变动、飞机央率)
1999	ACE-Pilot-ACE-l	命名实体i!(别	新艸涪料
2002	ACt2	命名实体识别、关系识别与描述 等	新闻语料
2003-2007	ACE2003-ACE2007	命名实体识别、关系识别"J描述、 时间表达式识别、羿件抽取等	新闻语料、对话诺料
2009-2014	TAC1-TAC6	次体链接、属性抽取	新闻语料、Web贝而、 论坛语料
图1-4信息抽取技术的中具有重大意义会议列表

1.3关系抽取研究现状
关系抽取技术从开始研究到现在经历了很多的演变,从起初的抽取文本中所 有实体的关系，到现在只是专注于指定关系的抽取技术。目前，关系抽取技术的 研究主要有两个主流的研究方向,它们是半监督或弱监督⑸的迭代式学习方法和 有监督学习方法。
第一类方法是利用少量的实体对出发，在较大规模的文本中通过一定的方法 得到可以标定此种关系的模板，然后利用模板在文本集中匹配出新的实体对，循 环往复的迭代这个过程，最终的得到一系列的模板和新的实体对。
第二类方法则是通过将句子拆解成一个平行或者有结构的特定表示，这些表 示之间可以计算距离或者相似度，通过大量的训练的数据集和一定的模型进行训 练，从而在统计意义上得到一个模型和相应的参数来确定两个实体是否具有某关 系。
1.3.1有监督的方法
对于一般的模式识别问题，最直观的思想就是将需要待识别的目标进行向量 化，从而能够将实际卽问题映射到一个输入空间。如果人们抽取特征的方式是合 理且有效的，那么就可以认为，只需要届理好输入空间，这个问题就能被解决了。 在过去，核函数出现以前，很多的研究者使用各种自然语言处理技术，以此构建 一个平面特征的向量。研究者认为，这个向量能够涵盖部分输入数据的信息。此 方法通常显示的使用各种语言学特征，包括词汇特征、语法特征(依存树特征、 语法树特征等等)以及次序特征表达成特征向量，采用最大炳模型［6】(ME, Maximum Entropy)或者支撑向量机［7］(SVM, Support Vector Machine)进行学习。 在一段时间内，这种方法被广泛应用于关系抽取的研究领域，而且也取得了一定 的成果，其性能指标F值约为70%冏。后来，人们发现这种方法在性能上遇到了 瓶颈，并且存在了一些不可克服的缺点。首先，这种方法严重依赖特征抽取和特 征选择，只有对于信息抽取的领域具有深刻的理解，人们才能得到较好的效果， 这样一来本来应该依靠数据和模型从而解决的问题变成了依靠专家选择和抽取 有效特征。其次，原本的文本数据是有一个序列，并且存在一定结构，而这种方 法将输入数据向量化后就丢失了这些信息，这也就使得此方法必然存在了性能瓶 颈。这两点是将关系抽取问题看成分类问题，并使用无结构的向量进行表示吋的 固有缺陷，除此之外，作为有监督学习算法，需要大量的数据进行训练，而获得 大量的标注数据是十分困难的事情。
在核函数図出现后，很多有监督学习算法的研究者对核函数应用到关系抽取 算法进行了很多的实验。在应用了核函数后，上面提到的第一个问题得到了一定 的缓解，而第二个问题基本上得到了解决，但并不能有效避免有监督算法需要大 量标注数据的缺陷。由于基于核函数的有监督算法更能代表目前的研究方向，本 文将主要介绍目前学术界对于此类方法的研究进展。
在实际研究中，有大量的研究者采取了各种各样的核函数。Haussler等人㈣ 就提出了离散结构上的核函数，其中离散结构指的是如树形结构和字符串等非实 值型的结构。由于自然语言本身就是具有离散化的性质，所以在这之后有些研究 者，如Lodhi等人［⑴在文本分类等研究领域使用了字符串核函数。
Zelenkoel.等人卩刀提出了定义了一种建立在句法分析树上的核，这种核函数 能够层次上从顶至下的匹配句法分析树。这种方法从根节点上开始，只有从根节 点到该节点的路径完全相同的同层节点才能匹配。作者在相对容易的两种关系， 即 organization-location 和 person-affiliation 上进行了 实验，其 F1 值超过了 80%。
Culotta和Sorensen等人［⑶在Zelenko等人的基础上提出了考虑句子依存关 系的核函数，有研究表示依存关系对于处理关系抽取具有天然的优势。他们的实 验将关系抽取分为关系检测和分类两部分，并应用依存树核和子序列核组成的一 种复合核，其中依存核要求两棵树的节点必须在相同的高度，并且从根节点到该 节点的路径也必须完全相同。这种定义的核函数能够保证较高的准确率(在ACE RDR 2003语料库上准确率大于0.67),但是召回率却比较低(同样的语料库上召 回率低于O.35)o
BunescuR. C.和Mooney等人提出了亠种最短路径依赖核。这种最短路径 依赖核主要考察待判定关系的实体对之间的最短依存路径，他们认为对关系抽取 有效果的结构化信息主要存在于最短依存路径之中。这个核函数是一种简单的核 函数，但是其在效果上达到了准确率0.655,召回率0.438, F值为0.525,效果 优于Culotta和Sorensen^］。这说明最短依存路径中确实蕴含了有效信息且减小 了噪声。
在核函数逐渐发展壮大的时候，有很多研究者将目光投向了传统基于特征提 取的机器学习方法和核函数结合起来的新领域。混合核(Composite Kernel)的研究 受到重视，研究者们做了很多富有成效的工作，下面简要介绍混合核的相关工作。
Zhao Shubin和Grishman［15］定义了特征空间覆盖不同语言学领域的混合核， 这种混合核在ACE RDR 2004语料上，其F值达到了 0.704□ Zhang Mingtl6］等人 利用最短路径封闭树(SPT, Shortest Path enclosed Tree)和多样的结构化信息，定义 了卷积树核(CTK, Convolution Tree Kernel),这种混合核表现良好，论文中实验 环境下在ACE RDR 2004语料上取得了 F值0.677的成绩。Zhou Guodong等人卩刀 在Zhang Ming等人工作的基础上对于最短路径封闭树进行改造并加入了上下文 信息，构建了 CS-SPT。由于上下文信息的加入，实验中ACE RDR 2004语料的 7种关系上其F值达到了 0.732O CS-SPT只能加入有限的上下文信息，而且在加 入上下文信息时噪声也随之加入，这是此方法的一个缺点。Qian和Zhou等人卩'I 在他们的工作里提出了可以动态确定CS-SPT扩展范围的方法处理上述Zhou Guodong等人卩刀的一些缺点，通过选择性的保留上下文的重要信息，其实验效果 在ACE RDR 2004语料的7中关系上取得了 F值0.771的好成绩。
目前为止，基于平面特征，核方法以及混合核的研究在有监督关系抽取技术 领域做了很多切实有效的工作，取得了很多令人瞩目的成绩，为后续的研究和其 他相关工作的借鉴提供了宝贵丰富的资源。
1.3.2半监督方法
ACE RDR 2004语料有自己的一些限制，对于将关系抽取技术应用到实际的 工业界，并形成相应的产品来说还有很多的不足。首先，语料的规模较小，领域 涵盖也相对不足，另外对于实际应用来说，ACE本身标注的语料太少，即使研 究方法是非常有效的，为了训练模型人们仍然要进行大量的标注工作，这会导致 人力、财力的消耗，并且对于领域的迁移来说，标注工作并不能做到一劳永逸。 在这种背景下，上面提到的基于传统机器学习进行特征抽取的方法、基于核函数 以及混合核等技术将会受到极大的限制，这就要求研究者充分的挖掘无监督、半 监督技术来解决关系抽取问题。所以，近些年来有很多研究者将研究重点放在无 监督、半监督的领域，希望能够找到相应的解决方案。
半监督的关系抽取技术有DIPRE系统卩9】，它首先找到表示某种关系的句子， 然后剔除掉这些句子中相应的实体对，这样就构成了一个三元组的序列模板（句 子中剔除掉两个实体后形成的三段，恰巧为空的字符串也作为一段）。DIPRE系 统认为，这个序列模板包含了表达这个关系的所有信息，利用这个模板在海量的 语料库中能够找到符合该模板的其他句子，这时新的句子在相应位置上的实体对 就符合这个关系。在取得新的实体对之后，DIPRE系统能够检索出包含这个实 体对的句子。通过反复迭代上面由句子找到实体对以及由实体对找至句子的过程 就能处理关系抽取问题。这个系统其序列模板过于苛刻，导致其覆盖率太低，所 以依赖于拥有海量的语料库，事实上DIPRE系统是基于Internet的。
Rosenfeld 和 Feldman[20]构造了 URES（an Unsupervised Web Relation Extraction System）系统，这是一个基于半监督方法的关系抽取系统。该系统从实 体关系对出发，使用软序列模板和实体关系信息进行提取和匹配，获得了很高的 准确率。
James R. Curran等人刖提出了使用少量语料同样能够处理关系抽取问题的 解决方案。该作者认识到在减少序列模板的信息时，还需要保证序列模板的准确 性，因此提出了一种互斥的Bootstrapping算法，该算法中可以同时处理多种关 系，并且提到在迭代过程中，每一个实体对和序列模板必须是对应唯一关系类型， 否则将实体对和序列模板的所属关系类型设为其他，通过这种策略，此半监督抽 取系统得到了较高的准确率和召回率。
SnowBall系统冋则使用另外一种方法解决了 DIPRE系统的一些缺陷。该系 统注意到DIPRE系统的序列模板包含了大量的噪声信息，这些非必要的信息使 得每个模板的泛化能力很弱。所以SnowBall系统将原有系统中的3元组变为包 括句子的前、中、后三部分以及实体对的类型（例如PERSON> ORGANIZATION
等)的5元组。除此之外，SnowBall系统还对5元组序列模板进行了聚类处理， 这是非常有用的一项工作。
在图1-4中提到的TAC会议同样存在了很多富有成效的解决思路。纽约大 学〔23][24]利用依存树替代了 dipre系统中的单词序列，以及SnowBall中的5元组。 这种做法具有很好地效果，因为依存树本身包含了关系抽取中的有效的结构化的 信息，并且能够剔除掉很多的噪声，这使得此种序列模板能够有更好的泛化能力。 在Yan Li和Chen Lijia[25]使用的基于最短依存树的Bootstrapping算法中取得2012 年的第一名，F1值达到了 0.5以上，这对于半监督学习来说是非常高的好成绩。
Blohm和Cimiano等人啓〕研究基于Bootstrapping的关系抽取算法时，发现 这类方法具有语义漂移问题。由此，研究如何对于获取的序列模板和实体关系对 进行过滤，从而避免将噪声信息引入到迭代过程中，造成噪声弥散，以至于降低 系统的性能成为了一个问题。在很多的研究者注意到这个问题后采取了使用一个 序列模板和实体关系对的评价函数(或者称为过滤函数)，从而根据一定的阈值剔 除掉尽可能多的噪声信息。
Feiyu Xu等人[27K28][29]和德国的研究机构DFKI对于基于Bootstrapping算法 进行深入细致的研究和实现，他们的系统DARE(Domain Adaptive Relation Extraction based on Seeds)中对很多不同的领域进行了相应的实验。Feiyu Xu等人 对于关系抽成进行了大量研究并形成有很多资料文档，这对于研究人员对于相关 方面的算法具有非常好的借鉴意义。
除了以上典型的半监督关系抽取技术外，还有-•些非常著名的关系抽取系 统。Etzioni和Cafarella等人啊根据co-training技术构建了著名的KonwItAll信 息抽取系统。KowItAll系统能够自动的，领域无关从WEB上抽取事实信息。该 系统确切的说领域知识抽取系统，但是KnowItAll仍然有很好的借鉴意义。
1.4论文主要工作及研究成果
本文对于关系抽取的两个主要策略进行了探索性的改进和实验，主要的工作 和研究成果如下：
(1)设计并实现了防止语义漂移的co-training关系抽取改进算法。本文增 加了防止语义漂移公式，使得算法能够进行更多轮的迭代，并且F1值提升了 0.09,效果较为明显。
(2)提出了基于word embedding的co-training关系抽取算法，包括增加语 言学信息、词向量以及将以前模板之间非此及彼的匹配关系改造成进行相似度计 算的匹配方法，这样大大丰富了增加召回率的策略，实验结果F1值比单纯的最 短路径实验提高了 O.lOo
(3)提岀了基于核函数的co-training关系抽取算法。本文通过利用半监督 算法充分挖掘数据集中信息，反复迭代产生大量的标注数据，然后再利用有监督 算法进行训练得到训练模型，最后使用模型进行分类，得出最终实验结果。这种 方法能够比关系抽取中的co-training算法更进一步的利用模板之间的共性，F1 值提升了 0.05,并且为半监督和有监督结合提供了新的思路。
(4)本文研究了文本分析会议的相应任务，并利用官方的数据集和标注结 果打造了一个便于进行关系抽取研究的实验系统，方便了研究。
1.5论文结构安排
本文的主要研究内容是英文语料的自然语言关系抽取技术，在调研过程中， 作者发现有监督和半监督这两类主要的方法都有自身的不足，在对半监督学习算 法提出改进的同时，研究了两者结合的可能性，并找到了一个切实可行的方法。 本文包括对于半监督算法的实现、相关改进以及有监督核函数的研究都取得了不 错的效果。除此之外，通过将co-training算法和核函数的有机结合，有效的利用 了有监督机器学习的优点弥补半监督算法的不足。
本文的内容安排如下：
第一章是绪论，主要介绍了本文的研究背景、目的、研究意义、关系抽取技 术的两个研究方向、优缺点以及当前的研究进展，最后提出了本文的主要研究内 谷。
第二章介绍干监督关系抽取的相关技术和理论，主要说明关系抽取的形式化 定义和优化方向。同时，本章详细说明了为什么关系抽取问题可以使用半监督方 法去解决，半监督方法本身的语义漂移问题。最后则给出了本文实验使用的语料 集和实验评价标准。
第三章主要说明了本文设计并实现的防止语义漂移的co-training关系抽取 改进算法，包括算法流程的设计，主要函数的逻辑，以及关于语义漂移的解决办 法。最后的实验分析显示F1值提高了 0.090
第四章提出了基于word embedding的co-training关系抽取算法。本章详细 说明word embedding技术的技术背景与理论研究，并在co-training算法的相应 过程中加入word embedding技术。经过实验验证，改进算法比完全不加入任何 语言学信息F1值提高了 0.10,比不加入word embedding的算法Fl值提高了 0.03。
第五章是关于使用核函数以及有监督和半监督结合处理关系抽取问题的研 究。本章证明了加入word embedding信息的核函数是有效的，然后提出了基于 核函数的co-training关系抽取算法，设计对比实验，并对实验效果进行分析和说 明。核函数的引进使得实验效果提升了 0.05。
第六章搭建了一个应用于KBP关系抽取任务的实验与研究系统。该章介绍 和分析了这项任务的相关信息，搭建了结合检索、抽取相关文本、前期处理、关 系抽取以及后处理等满足KBP任务的研究系统，应用于这个不断改进的系统， 本文作者连续三年参加了 KBP评测，并取得较好成绩。
第七章则是总结本文研究内容并展望半监督系统需要继续研究和改进的地 方。
10
第二章半监督关系抽取的相关技术与理论
目前，半监督关系抽取主要是利用少量的种子，然后通过实体对和模板之间 的互补关系，反复进行迭代，从而尽可能的挖掘出语料集中的有用信息。本章将 详细介绍半监督相关技术和理论。
2.1关系抽取理论研究
2.1.1关系抽取的形式化定义
对于自然语言的关系抽取技术的相关说明和定义已经在绪论中有较为详细 的说明和介绍，这里本文将这个问题形式化为一个数学表达式，从数学的角度进 行问题的剖析。
对于给定句子S,本文需要判断其中的实体耳和％是否满足关系7?。下式 中，函数L代表属于关系月的概率，而函数歹(S)代表对s进行特征提取形成一 个向量。
Tr(F(S),Ei，E2)	(2-1)
根据以上的表达式，本文了解到其中最为关键的两个部分就是对于句子的特 征抽取和对抽取后得到特征的判别处理。在处理特征抽取中，根据机器学习的观 点，必须要做到尽可能少的损失有用信息，并且抽取的特征应该尽可能的简单。 而在判别是否属于关系&时，一般釆取的策略是釆取分类的方法，也就是找到属 于关系R的共性。
2.1.2关系抽取的优化思路
通过研究和分析关系抽取的理论和特点，根据基本的机器学习观点，本文认 为优化的方向有两个，他们是：
第一，增强有效特征及其表示能力；
第二，加强模型对于数据的共性识别。
对于第一点，当前研究现状己经进行了大量研究，但是随着深度学习的兴起 和word embedding技术的研究，有了更多有力的工具帮助研究人员加强特征。 而且，从第一章介绍的关系抽取历史中，本文也注意到，随着技术的进步越来越 多的相关技术推动者关系抽取的发展与进步。从最初的DIPRE系统中非常简陋
11
的特征提取、后期的平面特征一直到最近的核函数，这些进步均是在第一点上有 比较重大的突破和进步。
对于第二点，这是机器学习的核心问题。很多时候学者研究机器学习模型都 是只考察给定的数据，重点关注模型对于数据的处理。在李航博士的《统计学习 方法》"中明确提到了不考虑特征提取问题。机器学习的相关研究人员平时使 用的线性回归、逻辑回归、支撑向量机以及梯度提升决策树等模型时主要考察的 就是模型对于数据的拟合程度。如果找到一种方法能够充分利用标注数据的信息 对实体关系类别进行区分，这样文便完成了任务。
一般来说，上面两点指明了优化的方向，深度学习和词向量技术则提供了切 实可行的方案。
2.2半监督关系抽取技术
上一个小节基本上说明了关系抽取的问题，但是关系抽取问题还有一些其他 的特点，也正是因为这个特点，本文才能使用半监督算法处理这个问题。自然语 言处理中，对实体对以及表征实体对关系模板的抽取任务是独立且互补的，可以 认为完成第一个任务有助于完成第二个任务，而同时完成第二个任务有助于完成 第一个任务。
自然语言中，实体关系对的模板和实体对是多对多关系的，每对实体可以被 不同的模板所表征，同时每个模板也能表征不同的实体二寸，如图2-1。正是因为 如此，co-training算法能够应用于关系抽取问题中。
<query_entityl, fiHer_entityl> 	pattern 1
<query_entity2, filler_entity2>^^^\ 昇 pattern2
<query_entity3, fiHer_entity3>^^	patterns
: 		:
: / :
图2-1实体对和模板之间对应关系
2.2.1Co-training 半监督算法
Co-training 是由 Avrim Blum 和 Tom Mitchell[32]在 1998 年提出的，一种使用 少量标注数据和大量未标注数据的机器学习算法。Co-training算法需要以两个角 度去观察数据。它假定每个角度使用的训练集是不同的，互补的信息，这样的话， 我们就能够使用其中的一个角度预测符合第二视角的数据，反之亦然。如果我们
12 能够保证每个视角下训练出的分类器是能够很好地预测岀另一个视角卜的训练 集，那么co-training算法就能够得到较好的效果。
可以认为，能够使用co-training的条件就是能够从两个（或者是至少两个） 角度去观看数据，而这些角度看到的结果是互补的。假定只有两个视角，下面给 岀一定的解释。假设从分类器A能够从语料集中得到数据集合a,从数据集合a 中可以得到训练出分类器B；若有训练好的分类器B能够从语料集中区分出数据 集合b,数据集合b能够训练得出分类器A。这样就得到了一个循环，从而得到 逐渐增强的分类器A和B以及两个越来越大的数据集合B,见图2-2。

图2-2 co-training算法框架

2.2.2Co-training 与关系抽取
下面，本文分析一下关系抽取技术的过程分解。假设，最开始有一些种子对, 这些种子对S是满足关系R,可以抽取出包含这些种子对的句子，这些句子也就 蕴含了关系人，从句子中提取出一些模板户的话，这些模板一样是满足关系人的； 接下来找到其他的句子，如果这些句子中包含模板户，那么这些句子同样满足关 系于此同时可以找到这个句子中符合模板的实体对S,这样，就形成了一 个类似于上面框架的流程，见图2-3。
13

图2-3关系抽取拆解流程

对比图2-2和图2-3,可以观察出如果将分类器类比为种子对，将数据集合 类比为句子集合，二者具有惊人的相似性。其中不同之处在于图2-3的分类过程 没有利用机器学习而是利用匹配规则，而训练过程则对应抽取过程。对于分类器 来说，可以设计成以统计机器学习为基础的有监督分类器，也可以设计成基于规 则的分类器，因此分类过程可以在图2-3中釆用规则匹配方法。同样的，通过训 练生成分类器可以采用统计方法训练得到，也可以迎过抽取方法得到。上述是使 用co-training算法进行关系抽取的基础。
2.2.3Co-training关系抽取的语义漂移
图2-2中，co-training通过构建两个分类器进行反复迭代，从而挖掘出语料 集屮的信息。但是如果构建的分类器性能不高，则co-training算法因为构建的训 练集质量比较低导致分类器效果变差，而分类器效果较差之后，会继续导致分类 器得出的训练集质量进一步变差。这样，co-training算法是不具备无限制迭代能 力的。
".文描述的co-training算法性能下降的现象是一种噪声扩散现象，当出现- 个噪声时，这个噪声将会随着迭代次数的增加而引进越来越多的噪声，从而算法 性能下降会比较厉害。
在关系抽取中，使用co-training算法时出现的这种现象叫做语义漂移。指的 就是最开始时满足关系R的实体对或模板随着送代次数的增加，其中不满足关 系R的内容越来越多，从而语义出现了漂移。想要克服这种现象，在co-training 中，最重要的是保证分类器的质量，而关系抽取中则是评估迭代产生的实体对和 模板集合是不是已经发生了漂移，从而过滤出蕴含关系R的实体对和模板。这 部分内容会在第三章进行详细说明和处理。
2.3语料集和评价标准
2.3.1语料集
本文使用TAC会议KBP任务中2009至2013年语料和标注答案，构建了一 个基础的实验环境，这是后续第三、四、五章实验的基础。2013年KBP中Slot Filling任务需要参赛机构对官方提出的50个人名实体(PERSON)和50个组织机 构实体(ORGANIZATION)进行关系抽取。其中，语料是LDC2012E45,包括新闻 语料、网页语料和论坛语料三部分，总共约200W篇文档。本文主要研究的是规 范的自然语言，而网页语料和论坛语料具有大量的特殊字符并且存在很多非自然 语言格式的情况，所以使用的主要是比较干净、规范的新闻语料。
本文主要使用2013年的TAC会议Slot Filling任务作为测试数据，而2009 年至2012年的数据作为训练研究使用。其中，表2-1汇总了这四年产生的训练 集大小。
表2-1训练集详细信息
种子对数	关系类型个数	平均每个关系种子对数
1885	41	46
2.3.2评价标准

本文设计的关系抽取系统是以TAC会议Slot Filling任务为基础的，所以评 价的标准就是这个任务的评价标准，也就是考察准确率、召回率以及F1值。
关系抽取任务的准确率和召回率与一般意义上的分类系统的准确率和召回 率不同。对于一般意义上的分类，其准确率和召回率是考察测试集所有实例，其 准确率定义为式(2-2),召回率定义为式(2-3)。
p ..=某类被正确分类的实例数
reClSl°n _分类器判定为某类的实例数	(2-2)
n	〃一某类被正确分类的实例数
心-某类的所有实例数	(2-3)
而当前任务下的准确率、召回率都有所不同，Slot Filling任务只考察抽取出 结果后排名最靠前的不重复的答案。举例说明一下，假设有一个句子包含了答案，
15
但是没有被抽取出来，按照一般意义上的评价指标是会影响性能的，不过在本文 的系统里面如果该句子抽取的答案被其他句子同样抽取到了，那么这个答案会出 现在最终结果里，导致不影响系统性能。
因为影响系统性能指标的一般都是比较困难的实体，所以本系统的评价方法 将会得到比传统评价方法更低的性能。同时语料库规模不是很大，这些就导致了 该任务下的性能指标普遍偏低。本文中系统的评价方法与上面公式略有不同，见 式(2-4)与式(2-5) o
N R
££(前n,且阈值大于代，被正确分类的答案个数)
Precision =日，土 “ %		 24)
££(前n,且阈值大于/的实例个数)	'’
i—\ r=I
N R
££(前n,.且阈值大于代.且正确分类的答案个数)
Recall = -!~i - ~	(2-5)
££(人工标注答案个数)	1
1*1 r=l
可以看出来，评价方法近似一致，但是上述两个式子的稍微复杂一些，其中 式中N代表需要进行关系抽取的实体个数，而択则代表关系数，括号中的描述 则表示在给定实体及关系下的相应指标。
最后，因为了综合评价系统性能的好坏，本文采取计算准确率和召回率调和 平均值的大小，见式(2-6)。其中“代表准确率以及召回率的相对权重，大于1 且越大准确率就越重要，而"小于1则召回率更重要。本系统认为二者同等重要， 故“值取1。
F _ (俨 +1) * {Precision * Recall)
(俨 * Precision) + Recall	(2-6)
2.4本章小结
本章详细介绍了关系抽取问题的形式化定义以及性能提升的两个方向。然后 介绍了半监督机器学习技术co-training并说明这项技术适用于解决关系抽取问 题。最后，本章给出了后续实验的数据集和评价标准。
16
第三章 防止语义漂移的co-training关系抽取改进算法
本章设计了一套防止语义漂移的co-training关系抽取改进算法，通过观察语 义漂移现象，提出了一个有效解决语义漂移现象的公式。虽然不能彻底的解决掉 这个问题，但是根据对比实验发现，改进算法的F1值提高了 0.09。
3.1算法分析与流程
3.1.1训练过程
Co-training算法在进行关系抽取时是一个反复迭代的过程，但是这只是一个 框架。本节实现的算法中，种子是实体关系对，而模板则是基于依存树构建的最 短路径。
在给定一个实体关系对< E{,E2 > ,如< Obama,Honolulu > ,这代表着Obama 的出生地是Honolulu,然后抽取出表征这个种子对的模板，完成之后再利用模板 抽取出新的实体关系对，如此反复迭代。这就是co-training关系抽取算法的概要 步骤。
由于研究的关系具有很多种，而每次进行训练的时候只能处理一个关系，所 以系统的主要流程图只针对一个关系，其他关系类似，流程图如图3-1所示，其 中深色部分加入了防卄漂移的公式。

图3-1 co-training关系抽取算法流程图

以人和出生地关系为例，co-training关系抽眼算法过程如下：
(1 )种子对：这是指算法最开始的实体对，$0 < Obama,Honolulu >
< Michelle ,Chicago >等等。种子对相当于是co-training的起始状态。
17
(2)检索相关文档：由于实体在文档集中的分布概率比较低，所以需要对 实体对进行检索，返回仇"个相关文档，相关文档是sgml格式的，如图3-2。
<DCC id="XIN_ENG_20101C=30.0049"	>
<HEADLINE>
Roundup: Afghan election body has yet tc anno nr： ce election i rsult
■:- although 6 weeks on
</HEADLINE>
<TEZT>
<F>
By Farid Behfoua
■- </P>
•. <P>
KABUL, Oct. 30 (Xinhua) -- Even though six have passsa from Sept. IS when
willicns of v;ai-weary Afghans dared Taliban threats and cast their ballots in the country's 3=cond parliamentary election, the final requite have yct tc come -out.
</p>
图3-2新闻语料文档原始格式
(3)处理分析文档：使用CoreNLP对文档进行分句、词性标注、命名实体 识别以及句法分析等相关处理，处理后的文档格式如图3-3所示。
<roct>
〈document〉
<docDate>2010-lC-30</dGcDa te>
<sentences>
^sentence
<tokens>
<token ia=,'l,,>
<word>Roundup</wcrd>
< 1 ernma > P.oun ^up< / l&nira«>
:GharacterCf f3etEegiii>5S</CharacterGff s^tBegin>
<CharactercffsetEnd>c5</Chai3cterCff'?tEnd>
<pcs>r-r<p</fros>
<M£R>O<yNER>
</'token>
<token id=,'2n>
<wora>:</word>
<lemma>:</leiriina>
<CharacterCffsetBegin>65</criar«cterCffsetSegin>
<CharacterCffsetEnd>66</€haracterCffsetEnd>
<PCS>：</POS>
<NERX)</NEP.>
图3-3处理分析后的文档
处理分析后的句子会产出很多信息，如上图所示包括词形还原、偏移量、词 性标注以及命名实体识别等°CoreNLP官方网站还给出了一个可视化的句子分析 图，如对句子：The preliminary results of Afghanistan's second parliamentary elections since the collapse of Taliban regime in late 2001, held amid tight security was announced on Oct. 20 with surfacing over 50 percent new faces.
对其进行分析可得到可视化的效果，如图3-4至图3-6：
Pan-of-Speech:
®J JJ O IN 雖 O JJ JJ	® IN iffi IN
The p>rehn->nary results of Afghanistan s second parhamentary	chons since the coHapse of
W： IN JJ 侦—顾 III JJ M VBD VBN	IN ®' CD IN VBG IN
Taliban regime in late 2001. held am：cl tight security was announced on Oct. 20 witn surfacing over a ® jj醵注
50 percent new faces.
图3-4 CoreNLP处理后词性标注结果
18

Named Entity Recognition:

ORDINAL	館袞
The preliminary results of Afghanistan s second pariianrentary ejections since the coUapse of Tahban
(DflLte'i	[Datej
regime in late 2001, hesd mmd tight sec□■ •ty was announ<:ed on Oct. 20 with surfac ng over
Percent
50 percent new faces.
图3-5 CoreNLP处理后命名实体标注结果



pobj

poss		 ；. , 	vmod	；	►
/	det		/	/		amod 	、&	pobj —♦
^f.-possessive-*-^ jj，	prep>IK [町&t-
The preb mi nary results	u? Afghanistan rs second parliamentary elections smce the
:	 vmod	:	•、
—pobj-、	—pobj—、	/—pobj—^、	\	-—pobj—、
—攝-、职 pr*p Fl 抵-pmp pN. 」\砌【‘心》邛	jjfod•谕	VKL f 5"
of Taliban regime in laze 2001, held amid tight security was


\	/	p°bj	\
\ I	,• •	num
>		prep	 .	/ / ，	nn	 a
''VBHfWAiNE捎」—niF num—m *IH pcomp-prep-IN/ gf 曲‘ 叫一孙边描氐
announced on Oct. 20 surfacing over 50 percent new faces.
图3-6 CoreNLP处理后依存树结果
(4)抽取模板：首先，将句子中的实体对找到，如果有多对则选择距离最 近的一对。然后，根据依存树标注结果，采用单源点最短路径算法抽取出实体对 之间的路径，并保存。
(5)过滤出高质量模板：指定一个评价模板质量的函数，并以此来判定模 板的质量，其中模板长度大小限制在勾以内，这是出于对算法效率以及距离过 滤的考虑。由于差的模板会造成语义漂移，所以将每一伦迭代的产岀的新模板进 行排序，选择满足模板质量大于阈值a的前％个模板存储，并丢弃其他模板。
(6)使用模板抽取实体对：对于当前相关文档集的所有句子进行分析，如 果其中具有满足命名实体条件的句子，则判定该实体对之间的最短路径与己有模 板相似度是否大于阈值人，如果满足条件，则存储这对实体。当模块分析完所有 句子，会得到大量的新增实体对。
(7)过滤出高质量实体对：与过滤出高质量模板的目的一样，同时使用的 也是类似的评价函数，只是会选取质量大于阈值"的前倪个实体对，丢弃其他 的实体对。
到此为止，完成一轮迭代，后面则按照流程图继续上面的过程，使用新产生 的实体对进行检索相关文档。如此往复，直到达到指定迭代次数上线7V,nax o
19
3.1.2使用过程
上一节已经清楚地阐述了使用半监督co-training算法进行关系抽取的训练 流程。上述过程中产出的实体对集合与模板集合都是完成了一定的自然语言处理 任务。不过，训练完成本文只需要使用产出的模板去匹配出种子对就可以了，为 了满足任务需求，按照匹配出实体对的模板质量给实体对打分，然后排序选取答 案。使用过程是基本上是训练过程的一部分，这里不再赘述。
3.2算法设计
这一节主要介绍算法流程中的核心模块及函数，并加上一些例子辅以说明， 帮助更好地阐述算法。
假设本文还是抽取姓名-出生地这个关系，为便于分析简单，初始种子对为
< Obama, Honolulu > ,检测到一个句子：Barack Obama was bom in Honolulu.
通过这个句子，本文就能够得到表征原始种子对的模板，伪代码，见图3-7。
Containing Relation Extraction Procedure：
in: seeds S
in: all sentences Sent (retrieve after each iteration) . out: patterns P out: entity pairs EP add S to EP
1.While( iteration < N暗瞅)
2.foreach s e EP do
3.foreach sent € Sent do
4.patterns.add(GeneratePattern(s,sent))
5.foreach pattern e patterns do
6.p_score - EvaluatePatternfpattern, EP)
7.sort patterns by p_$core
8.add top np to P where p_score > 8窘
9.foreach p € P do
10.foreach sent e SeiU do
11.seeds,add(GenerateSeed(p,sent)}
12.foreach seed e seeds do
13.s_score= EvaluateSeedfseed, P)
14.sort seed by s_score
15.add top 井4 to EP where s_score > S,
图3-7核心算法伪代码
伪代码里面有很多的细节没有进行说明，包括如何匹配实体字符序列，如确
20
定CoreNLP不进行命名实体识别的字符序列，以及系统中需要使用的依存树最 短路算法。
3.2.1命名实体增强
有些类型的实体CoreNLP并不能有效识别，而识别这些实体对于任务的完 成确实至关重要的，所以本文会采取其他的方法来进行识别他们。
本文的做法是手工筛选出这些类型的实体列表，然后通过WordNet进行扩 展以增加召回率，最后通过规则的方法将这些列表标注在CoreNLP的分析结果 上。
除此之外，第二章提到的地名等需要进一步细分为国家名、州名或者省名以 及城市名，也是采取了名字列表，然后在抽取完成后判断抽取的地名属于哪一类。
3.2.2实体匹配
实体匹配函数是完成匹配句子中实体的功能，一般而言，一个实体很有可能 是具有多个单词构成的序列，这样的话，本文需要找到这个实体的位置，并进行 标示。
每一个句子中的单词，程序上都给按顺序表上序号，同时艮据对后续使用依 存树时方便，本文取实体序列的最后一个单词作为这个实体序列的标识。因为， 实验观察到一个实体序列的最后一个单词是这个序列的中心词，实体序列作为一 个单元的话只有中心词会与其他词具有依存关系。这样，本文设计出返回实体标 识的函数，见图3-8。
其中，entity是实体，而last代表从什么位置开始计算，这样是为了方便一 个句子中包含多份实体。
sub GetEntitylndex(entityJast)
index*rlast
for word seq in reversef sentencef :last]) do
if sentence[len(entity )r index] = entity
return index
return -1
图3-8获取实体位置序号
另外，当给出一个数字，需要有一个机制找到个数字代表的实体序列，为 此，本文需要设计出一个相应的反函数，伪代码见图3-9。
21
sub GetlndexEntity (index,ner) for word in reverse(sentence[:index]) do if word.ner = ner
entity, a ppend( word)
else
return entity.reverse()	-
return entity.reverse()
图3-9获取指定位置实体
3.2.3最短路径匹配
上述章节中有人指出，使用最短路径依存树，在关系抽取中具有很好地表现, 并提出了依存关系对于关系抽取的重要作用。这里说明一下最短路径的抽取方 法。
根据依存关系的定义，任何一个单词都不是孤立的，必须依存于其他的单词， 并且根据依存关系的构造过程.，可以得知一个句子中所有的单词是连通的，这样， 本文就能够保证了一定有最短依存路径存在。
根据上一小节，如果能够得到一个实体的中心词，而这个中心词是与外部联 系的，所以实验中可以把这个中心词作为源点或者终点。单源点最短路径算法 ——Djistra算法是一个带权重的最短路径算法，而对于不带权最短路径时会退化 为广度优先遍历。本算法中的单源点最短路径使用的就是广度优先遍历算法，构 造BFS函数。
另外，由于一个句子通常不会特别长，所以构成的图一般比较小，系统使用 的邻接矩阵法表示图。算法比较简单通用，这里就不在赘述了。
3.2.4共指消解
CoreNLP能够得到一篇文章中所有指向同一实体的单词序列集合，也就是共 指链。通过观察数据，以及人们的经验都可以得到这样一个事实：对于多次描述 的实体，一般只有在第一次是全称，其余情况是简写或者是代指。这样，如果只 是匹配实体词，则很难保证召回率。
另外，因为在介绍实体时总是优先介绍该实体的重要信息，从而导致不重要 的信息大多数都是包含在代词的句子里，所以，本文必须使用共指消解。
共指消解函数就是简单地将一篇文章里所有和给定实体等价处理，也就是说
22
实体对中的两个实体之一可能是代词或其他序列。之所以没有将两个实体都做共 指消解替换是因为共指消解也是有一定的错误率，在保证增加召回率的情况下同 样要保证准确率。
3.2.5模板匹配与实体对匹配函数
这两个函数是规则匹配的重要部分，给定句子和种子对，模板生成函数找到 种子对的两个实体之间的最短依存路径；种子对生成函数则根据模板和句子，判 段句子中是否存在该模板，如存在则返回实体对，不存在则返回NIL,伪代码参 见图3-10和图3-llo
Sub GeneratePatteni(seiiten£«,seed)
srcidGetEntityIndex(sentence,seed.entity 1) desid GetEntityIndex(sentence3eed*entity2) pattern BFS(sentence,src_id,des_id) return pattern
图3-10模板生成函数
Sub GenerateSeed(sentence,pattem)
for seed in sentence do
path <— getSPT(sentence,seed) if match(path,pattern) return seed
return NIL
图3-11种子对生成函数
3.3防止语义漂移公式
每一轮迭代都会产生大量的模板和实体对，但是这些生成的结果如果不加以 限制的话极有可能发生一些问题，导致出现语义偏移。如，实体对之间的模板并 没有描述这个实体对应有的关系，而是描述了另外的关系，这样的话错误的模板 就产生了 0例如根据实体对＜ Jordan^Brooklyn ＞匹配出的句子：Jordan likes to live in Brooklyn.这个句子的依存关系见图3-12。显而易见的是，如果本文使用了这
23
个句子，则抽取出模板〈(Rnsubjpass),likes,(1,xomp),〃ve,(1,prep),in,(1,pobj) ＞。 然而，这个模板抽取的并不是出生地，而是喜欢某地的关系。这个例子体现的就 是典型的语义漂移问题。

图 3-12 '"Jordan likes to live in Brooklyn."的依存关系图

通过分析这个问题，可以发现新增的模板并不能保证满足多数的实体对，因 为这个关系和原始的出生地关系还是有很大的区别的。假设同样的抽取到了一个 Kobe在Brooklyn打球的例子，那这个关系将与出生地关系相差更大。根据这个 结论，本文提出了一个给模板打分的公式，参见式(3-l)o
# match seed.old
p score =	=	 zn 1 \
—	# match _ seed.new+# match _ seed.old	2一丄丿
公式中p_score表示模板的得分，#match_seed.old指的是当前模板能够匹 配的原有实体对的个数，而#match seed.new则表示当前模板匹配的不在原有实 体对集合中的实体对个数。这样当新增的模板匹配了太多的新实体对，而对于原 有实体对中匹配的比较少，本文会认为新增的实体对质量不高，很可能发生了语 义漂移，从而给出较低的分数。
同样的，对于新增的实体对，在实验中也需要进行评估，根据迭代过程的对 偶性，实体对的评估方法与式(3-1)基本一致，只是做了一下对偶，参见式(3-2).
# match pattern .old
—	# match _pattem ,new + # match _pattem .old	乙丿
其中s_score代表种子对的得分，其他的符号与式(3-1)类似，不再赘述。
24
不过，需要指出的一个问题是，第一次得到模板后，这个模板的得分需要在 使用模板的时候才能给出，而如果使用后发现模板分数偏低，则根据规则剔除掉 这个模板。
3.4实验设计
算法设计的时候已经将评价算法的原理描述清楚，现在只设计对比实验的算 法。对比实验的算法比较简単，直接去除对于模板和实体对的评价，而每轮迭代 产生的新增内容不加甄别的进入下一轮迭代。流程伪代码只需要将图3-7中的相 应逻辑，如第5-8行以及第12-15行去除就可以了。
本文两个实验为无过滤实验和有过滤实验，下面给出系统中参数，见表3-1.
表3-1有过滤实验的参数说明和设置
参数	说明	大小
膈	返回的相关文档个数	150
模板长度限制	9
nP	每轮迭代新增模板个数	5
模板的质量阈值	0.2
ns	每轮迭代新增实体对个数	5
a、	实体对质量阈值	0.2
8	模板相似度阈值	0.6
nr	关系r选取答案个数	单值关系为1,多值为5
<Pr	答案质量阈值	0.4
N林	迭代次数	7
对于无过滤实验，其中只有〃疽8p, ns,名不存在，答案的排序则根据答 案的重复次数进行处理。

表3-2质量评估对比实验结果
无过滤实验	有过滤实验
迭代次数	Precision	Recall	F	Precision	Recall	　　　F
1	0.51	0.20	0.29	0.62	0.09	　　0.16
2	0.43	0.28	0.34	0.59	0.17	　　0.26
3	0.32	0.35	0.33	0.56	0.22	　　0.32
4	0.21	0.41	0.28	0.54	0.29	　　0.38
5	0.10	0.48	0.17	0.52	0.36	　　0.43
6	0.05	0.57	0.09	0.48	0.37	　　0.42
7	0.03	0.62	0.06	0.45	0.38	　　0.41
25
3.5实验结果分析
质量评估函数防止语义漂移实验，可以看到实验中准确率随着迭代逐渐降 低，而召回率升高，但是无过滤实验准确率下降的极为明显，而召回率则没有上 升特别快。这个现象反映了这个实验的语义漂移现象非常严重，通过观察实验结 果发现，每轮迭代产出的模板集合和种子对集合质量都在下降。还是以〈人名， 出生地＞这个关系为例，最开始的种子都是正确的，但是当迭代一轮之后就会发 现出现了一些其他关系的实体对混杂了进来，如出现＜Obama, New York〉或者 ＜Michelle, Beijing〉，这可能是出现过 Obama 访问 New York,而 Michelle 来过 Beijing,并不是出生地的关系。上面提到的这个例子就是典型的语义漂移。
另外，无过滤实验的F值在第2轮迭代的时候达到顶峰，有过滤的实验则在 第5轮迭代的时候到达顶峰。观察实验结果，本文发现如果考察F值的话，随着 迭代次数增加这是一个单峰的形状；如果考察Precision的话，其规律是单调下 降的，召回率的变化规律与准确率相反。
这个规律的内在原因是语义漂移现象是没有完全避免的，否则准确率不会下 降；而且虽然有语义漂移现象，但是还是能够提高召回率。通过这个现象可以得 知，如果有足够的语料，可以通过少迭代而提高准确率，同时召回率也不会太低； 而如果语料比较少，则可以多迭代几次，否则召回率会过低，导致F值下降。
3.6本章小结
本章首先详细描述了算法的流程，对整体框架进行了分析与说明，明确了系 统的流程，并详细的说明了其中主要函数的思路以及逻辑,部分核心函数还附有 伪代码。同时本章设计了一组实验，通过实验的对比以及观察迭代次数影响系统 性能的变化，进而分析实验中模板以及实体对的评价公式对于防止语义漂移是有 效的。
26
第四章 基于word embedding的co-training关系抽取算法
本章提出了一种基于word embedding的co-training关系抽取改进算法。根 据co-training关系抽取算法的演进流程中可以看到，研究者们非常关注如何增强 模板的表现力，从最开始的DIPRE系统到基于最短依存路径的Bootstrapping算 法。如果能够找到一种有效地表达方式将句子中蕴含关系的特征表示出来，那么 不论是半监督系统还是有监督算法，关系抽取的性能指标都能够有所提升，本章 基于深度学习在自然语言处理技术中的一项重大进展 word embedding，构造 了一种包含更多信息的模板形式，并取得了比较好的效果。
4.1Word embedding 与关系抽取
4.1.1Word embedding技术背景与理论研究
Word embedding1331技术是深度学习技术在自然语言处理领域的一个应用，随 着其开源代码〔34］的出现，目前在学术界和工业界都有很大的影响力。Word embedding技术源自于神经网络技术在近年来的突飞猛进。随着神经网络模型进 一步发展为现在的深度神经网络，深度学习技术在包括图像识别、语音处理、文 本挖掘、自然语言处理等等领域有了长足的发展，并打开了观察数据，理解数据 的一个新视角。
词向量方法在深度学习的基础上创造性的利用了自然语言的冗余性，通过周 围单词预测中间单词(CBOW)或者中间单词预测周围单词(Skip-gram)的方法将单 词之间的相关性记录了下来，如图4-1。其中，冗余性思想类似于英语中的完形 填空，所以虽然研究者把这种计算词向量的方法称作为非监督方法，但是实际上 却是一种有监督的方法，只不过标注数据来自于人们的使用且不需要花费新的劳 动力而己。

CBOW	Skip-gram
图4-1词向量使用的预测模型

27
在上述基本的思想上，加入典型的信息论思想，也就是通过一层神经元保证 信息不丢失以及数字的误差代表信息误差的能量观点，这就构成了词向量思想的 理论基础。
从数学意义上可以认为，词向量将自然语言中的符号——单词，映射到了欧 式空间中的一个点。目前，研究者都认为这个映射关系保存了原有自然语言符号 的大部分信息。但是，从图4-1的物理结构上，本文认为词向量包含的信息是通 过单词的顺序、频率等信息为基础描述单词的，也就说是，其中的语义信息来自 于结构上的信息。
4.1.2 Word embedding应用于关系抽取
Word embedding之所以为学术界和工业界所认可，其最主要的原因就是传 统上处理自然语言时，很难有一种方法能够将自然语言符号转化为数字，从而使 用数学工具进行分析和处理，而词向量做到了。现在的机器学习技术实际上是数 学模型与最优化算法在大量数据上的应用。
在上一节，提到了进一步优化关系抽取的方向，所以借助word embedding 技术，本文就能克服对于以前各种特征提取时自言语言符号难以量化的问题。比 如，传统的自然语言处理技术很难分辨cat和dog的关系，而且，即使使用了 WordNet[40],人们仍然只知道他们都是动物。这种情况还是无法进行量化，而且 cat和dog的关系过于狭隘，显然不能满足自言语言处理的需求。下面给出词向 量如何理解cat和dog这两个单词，见图4-2。通过计算余弦相似度，实验得到 dog和cat的相似度为0.8817。
如果词向量的信息是有效的，那么通过使用词向量增加特征信息，必然能够 提升一定的性能。由于特征提取属于基础工作，所以本文通过加入word embedding对于co-training关系抽取算法做了改进并进行了实验。
画亀蝴災0.2酹231 •如焼。禮	龄 S.5586伸・0.聽5也 ■凱旳就0.2淞的4 •就林3B孔的831
餘 9,网3机晦队29U獭转.。料7询準京25781麝；织33跆76 6*272403	-«.9«3743 132126 9.247474
臥gSGfi ",炒Bl G.229565 -£1.190422 0.1438^$ e.154292 W.734339 ^.109074 «0<276475 9.639774 *01102691 -
G.3&52^$ *0.294^56.0.081592：9.G.629S42 -0.86«833 0.419^29 -0.818011 0.191024 Q.1S1812 0.22M4S 鋤？
337•軌528：160 ：。.397双 臥监44丄8 •矶457W	46249"	•	•	.	•	.
(a)
也询779 連.295鮭《 .flLpeCTM..飢胳864&	:峯務E2 •.皿4G2 .尊・25心9	觐72 ••."12
蘭诲.192977 9.H4S36 -0.29282S 碗蜘 023弟39 -0.497942 9.2228S3 9.161793 -0.878479 0»1«1813 0.163«35 。•勢2m.Y.133a4S 牝gg •或涌264 •就213443 e.31dW ・0.44$498 -0.143CS8 .«.12712t 9.69321B •亀 198973 • &打7炀 •&够娅7 縛.043194 ^3S927B e4^15932 9.1HM7 弟歯7722 &669148 0.39111» 9.9664S7 0.037416 0.4148 检妍9.蘭3每S043W “滴般團* •况59痫14。	・.	：;" 代 泠"£
(b)
图 4-2 (a) dog, (b) cat 的词向量
28
4.2 Word Embedding 的应用
4.2.1模板生成函数改造
GeneratePattem函数通过句子和实体对产生模板，这是co-training关系抽取 算法产出的两个最重要的结果之一。对于关系抽取任务来说，最重要的就是产生 高质量、高泛化能力的模板。下面详细介绍这一部分的逻辑。
对于句子：Barack Obama was bom in Honolulu.对其进行分析后将得到卜面 的结果，其中包括表4-1.
表4-1系统解析的侍征结果
Id	Word	Lemma	POS	NER	Word
Embedding
1	Barack	Barack	NNP	PERSON	50 numbers
2	Obama	Obama	NNP	PERSON	50 numbers
3	was	be	VBD	0	50 numbers
4	bom	bear	VBN	0	50 numbers
5	in	in	IN	0	50 numbers
6	Honolulu	Honolulu	NNP	LOCATION	50 numbers
7				0	50 numbers
本文使用的是最短依存路径，但是并不是只包含依存路径，而且包含路径中 每个节点的信息，这种依存路径在前面介绍的核函数时提到过。下面给出句子的 依存树，并表示出最短路径，如图4-3。

图 4-3 "Barack Obama was bom in Honolulu."的依存关系图

图中深色连接箭头代表依存路径，黄色节点代表依存路径中的节点.而连接 线中的文字代表连接类型，箭头方向代表连接方向。其中，图中的源地Obama 和终点Honolulu不算是路径的一部分。
只要把依存路径和表3-1中的特征联合在一起就构成了模板，这个模板就是
29
GeneratePattem的返回值，伪代码见图4-4,任何一个最短路径模板本文总可以 表示为下面这种形式<(direct,rela),,,(direct,rela)2,(direct,rela)n+1 > ,其中 direct为0代表符号 <—,而direct为1则代表符号T , rela代表依存关系,w代 表单词的所有信息，包括单词本身、词形还原、词性标注、命名实体、词向量。 按照这个通用的模板，当前实例下的模板则可以表示为 < (0, nsubjpass},born, (l,prep), in, (l,pobj) >。
Sub GeneratePattem(sentence,seed)
src_id	GetEntityIndcx(sentence^seed.entity 1)
d 嘴 _id s GetEntityIndex(seatcncefseed.entity2) pattern 4- BFS(sentence,src_id,des_id) pattem.add(node information)
return pattern
图4-4模板生成函数
4.2.2 Word embedding 与相似度
Word embedding是一种连续、向量化表示单词的一种方式，通过计算两个 词向量之间的余弦值，就能得到它们的相似度。在这里本文将词向量置于模板里, 相似度计算的这个过程就体现在了实体对生成函数GenerateSeed中。
实体对是co-training关系抽取系统的另外一个重要产出，虽然不能直接应用 于给定实体的关系抽取系统，但是实体对和模板是相辅相成的，任何一部分的产 出策略都影响着对方的质量，这部分也是系统的核心。
实体对生成函数可以釆用两种经典的策略：
第一种就是给定一个实体，然后从这个点出发，一直到走到路径的尽头，查 看终点的类型是否为指定类型，在当前的出生地关系里，终点应该是地名。这样， 如果当前句子具有这个路径，且路径终点相一致，则这个实体对就是正确的实体 对，可以被抽取出来。这里面如果句子是共指的句子，则把共指的单词序列替换 为原实体。
第二种则是找到所有的找到所有满足关系的实体对，然后抽取实体对之间的 最短路径，如果最短路径和模板完全匹配，则这个实体对被抽取。
根据对数据的观察，以及方案实现是否方便，这里选择第二个策略。因为一 个句子里面符合的实体对比较少，另外就是最短路径的函数己经实现，可以直接 调用接口。
30
第二个方案的具体流程是这样的，当本文从模板列表中取出一个模板，如上 面提到的< (0,nsubjpass),born, (1,prep),in, (l,pobj) > ,通过这个模板可以匹配出很 多的实体对。假设有句子：Jordan was bom in Brooklyn.这个句子的句式和Barack Obama was bom in Honolulu.完全一样，见图4-5,具有相同的模板，这时本文就
可以抽取出实体对〈Jordan, Brooklyn > ,这就是实体对生成函数的工作。具体逻 辑见图4-5。

图 4-5 "Jordan was bom in Brooklyn?5的依存关系图

使用模板进行匹配的时候，为了保证召回率，本文使用的是软匹配模式，即 种子对之间的最短路径和模板之间的相似度不是非0即1的离散值，而是一个连 续值。连续值会有很多的好处，通过利用word embedding,系统增强了泛化能力， 假设本文找到了 模板 < (0,nsubjpass),born,(1,prep),in,(1,pobj),province,(1,nn) > , 那么，根据词向量，本文实验得出province、city> country以及state的余弦相似 度比较高，这样，下面的四个模板，如图4-6,就会非常接近。因此，即使最终 只是找到了一个模板，本文也能抽取出这些类似模板的实体对。
这个匹配函数很简单，就是计算两个模板(其中一个模板是当前抽取出来的 最短路径)，然后计算公式(4-1).
<(0, nsubjpass), born, (1, prep), in, (1, pobj), province, (1, nn) >
<(0, nsubjpass), born, (1, prep), in, (1, pobj), city, (1,nn) >
<(0, nsubjpass),feorw, (l,prep),m, (l,pobj),sto/e,(l,nn) >
<(0, nsubjpass), born, (1, prep), in, (1, pobj), country, (1, nn) >
图4-6相似度很高的模板
31

式(4-1)需要考虑最短路径是否长度一致，只有一致的才能计算，否则记为相 似度为0.其中首先计算节点的相似度，奇数节点相似度计算方法为式(4-2)：



而当节点为偶数时，相似度的计算方法为式(4-4).
顷(x,y) = ： »(x”y,)+cos(")
其中，sz初。(x,y)表示奇数节点X与节点7的相似度，花为节点所具有的子元

子元素，也就是词向量之间的余弦相度。考虑到整个模板，则模板之间的相似 度计算公式为式(4-5)。
%
sMPx,py) = sim0 (xk况)x	sim0(x2M,y1M)xsime(x2i,y2i)	(4.5)
式(4-5)中的阵表示链各个不同的模板，左则表示模板的节点个数，如模 板 < (O,nsubjpass),Z>orn, (l,prep),zw, (l,pobj),province, (l,nn) > 则包含 7 个节点，即 k=7,而［团代表对,4进行下取整。本文中将阈值设为模板匹配相似度低 于S的实体对丢弃。
32


4.3实验设计
对比实验需要考察新增的各种信息的有效性，需要设计很多不同的实验，鉴 于本文的重点是新增了单词的语言学信息和词向量信息，故只设计额外的两个实 验，加上本文原有设计的实验一共三个，分别命名为最短路径实验，扩展型实验 以及词向量实验。
实验的参数和表3-1给出的基本一致，只有模板的相似度阈值3不同。其中 第一个实验的阈值$为1,代表完全匹配；扩展型实验的少值根据人工设定，选 取最优，实验结果显示3为0.8；词向量实验的$按照同样的方法进行处理，3的 值为0.6。最后，还会给出词向量实验下随着S的不同取值，系统性能变化的情 况，以此来进一步验证本实验的效果，见图4-7。
根据分析，可以给出最短路径实验使用的模板，见公式(4-6),以及扩展 型实验使用的模板，见公式(4-7),以及实验结果，见表4-2。
direct rela
direct
〉
rela
direct
direct
(4-6)

rela
rela
x[wor(7]x
x---x[yvorJ]x
(4-7)

表4-2特征信息对比实验结果
图4-7词向量实验系统指标曲线
33








































图4-7中的横坐标是模板匹配相似度阈值，而纵坐标是Precision. Recall以 及F值等系统性能指标。
4.4结果分析
该实验体现了增加足够多的语言学以及word embedding信息能够提高召回 率，不过根据实验结果可以看到，增强的实验并没有提高准确率，原因有两个方 面，其一是本文增加了更多的信息，但是实际上这些信息还是蕴含在单词之中的， 只不过本文通过其他的手段将这些信息独立出来，以增强泛化能力；第二就是这 部分研究的目的就是希望提高召回率。利用模板匹配的方法准确率比较高是正常 的。如果实验中不使用依存树作为模板而是直接将字符串作为模板，准确率会更 高，如DIPRE系统，但是这时召回率将变的非常低。所以，表4-2所展示的结 果完全符合预期，证实了按照第二章提出的改进思路是正确的。
另外关于加入词向量之后调整模板匹配阈值的实验，观察图4-7,本文发现 随着阈值的增加准确率上升，召回率下降，而F值则形成单峰的图形，峰值在阈 值为0.6时出现。这个规律与迭代次数变化时非常相近，其原理是词向量影响着 匹配的精度，当单词完全匹配的时候词向量的余弦相似度是1,形成类似最短路 径的硬匹配，这时准确率最高而召回率最低；而当词向量余弦相似度较低的时候 则召回率会有所上升而准确率略有下降，这个现象同样符合预期。
34
第五章 基于核函数的co-training关系抽取算法
找到数据之间的共性能够提升关系抽取的性能，而找到实例之间的则需要使 用有监督的分类思想。由于关系抽取构造的表征句子中实体关系的特征在本文中 就是结构化的模板，而且使用核函数配合SVM等模型能有效利用模板信息，所 以，本章选用核函数进行实验。
本章首先详细说明核函数的有点，进行核函数的实验，验证增加的特征信息 是有效的；然后介绍半监督与核函数结合的可能性，并给出co-training关系抽取 算法与基于核函数的SVM分类器级联逻辑，最后进行实验。实验数据说明二者 结合能够提高算法性能。
5.1核函数的模型建立
本文最开始就提出了关于半监督算法和有监督算法在关系抽取问”题上的研 究工作，上一章主要介绍了基于半监督算法的关系抽取系统，但是半监督算法是 建立在训练集不容易获取的基础上的。为了做好有监督学习的实验，本节设计一 个实验进行验证。
本章需要进行手工标注增加训练集以满足有监督训练的要求。通过检索原始 语料库，对〈人名，出生地＞这个关系进行手工标注500个正例和500个负例， 最后采用十折交叉验证并给出性能指标。
最后，本节的主要内容是通过实验说明使用词向量信息改造的核函数是有效 的，并为后面半监督与半监督的方法结合做准备。
5.1.1核函数介绍
基于核函数的方法齐］［36］是基于特征提取的机器学习方法的一个切实有效的 替代方案，在这里，核函数可以有效的利用具有结构化关系的信息，避免过多的 信息丢失。
在一个空间X上的核函数(Kernel Method), K是一个二元函数。假设X是 输入空间(欧式空间R”的子集或离散集合)，又H为特征空间(希尔伯特空间)，如 果存在一个从X到H的映射：(p(x):XfH，使得所有的x,y&X ,函数K(x,y) 满足条件：K(x,y) = g}(x)-(p(y),则称为核函数，cp(x)为映射函数，式中 ?3)•『3)为9(x)和9(y)的内积。二元函数K定义了一个从x,y^X到它们的相 似度K(x,y)的映射，核函数必须满足对称条件和半正定条件。
35
核函数的想法是，在学习和预测时只定义核函数K(x,y),而不显示的定义 映射函数0。通常直接计算核函数K(x,y)比较容易，而通过伊(对和但。)计算 K(x,y)并不容易。通过核函数的方法计算数据事例之间相似度的函数，与通过 映射的方法相比除了计算量方面的优势外，还能将原有的数据映射到更高维的空 间，从而在高维空间中解决问题。参照Fukunaga[37]和Cortes and Vapnik。'】等人的 工作，本文注意到目前支撑向量机和最近邻[39](NN, Nearest Neighbor)是使用核函 数的经典案例。
5.1.2 SVM实验策略
SVM具有很深的理论基础，是目前为止应用广泛且效果最好的分类技术之 一。这里选用SVM作为分类器的主要就是因为它支持核函数。在第一章里面提 到的关于关系抽取的相关研究都提到基于核函数的技术比基于传统特征向量的 技术性能优越且有更好的发展前景。同样的，在这里本文同样不得不使用核函数, 因为模板变成特征向量的话会有很多难以解决的问题，如本文需要将单词、词性 标注、词形还原这些都进行量化，这个工作是难以有效完成的，并且很有可能造 成维数灾难。现在通过将计算模板相似度的函数视为核函数，则相当于将高维空 间的问题规避掉了。
本章使用的SVM模型使用的是libSVM〔4°],并修改libSVM的源代码以适应 新的核函数。本节主要设计两个核函数，分别是最短路径依赖核以及增强型词向 量最短路径依赖核。这两个核函数已经在第三章提到过，具体参见公式(4-1)至式 (4-5)o其中最短路径依赖核函数，也即是Bunescu.C.R和Mooney等人冋提出核 函数，其模板参见式(4-7),而其核函数则可根据相应公式推导得出。
现在自行构造的训练集的评价方法与半监督评价方法已经不一样了，人们可 以直接使用标准的分类器评价方法进行计算Precision、Recall以及F值。由于正 负样本是均衡的，所以关注正样本的或负样本没有区别，这里釆取关注正样本的 相应指标。实验结果参见表5-1。
表5-1 SVM实验结果
实验名称	Precision	Recall	F值
最短路径依赖核	0.82	0.63	0.71
增强型词向量最短路径依赖核	0.89	0.76	0.82
5.1.3实验结果分析

通过表5-1本文看到，这两个有监督方法的性能指标都远胜半监督方法，这
也是因为有监督方法使用了更多的标注数据。另外，本文实现的最短路径依赖核
36
函数性能指标也超过原作者的实验结果，原因有两点：一是选取的关系类型〈人 名，出生地＞是比较简单的；二是正负样本相对均衡。
5.2有监督与co-training关系抽取算法结合
5.2.1算法结合的可行性
在关系抽取中，有监督算法和半监督算法是能够结合在一起的，而且有很多 种结合的方法，其中包括：
(1)利用co-training关系抽取算法设计完全匹配的模板时，系统的准确率很 高而召回率较低，所以本文可以将待判别的实例先经过半监督算法处理，保证准 确率。然后在利用有监督算法处理没有被分入正例的实例以保证召回率。
(2)不利用co-training算法进行分类，而只是利用其迭代多次产生足够多的
正样本，然后从其他类别中选出等量的负样本，这样构成训练集。最后使用有监 督的方法进行训练，从而得到一个新的分类器。	.
上述两个方法，第一个方法想法直观，效果也比较直观且易于理解，但是这 种级联的方法将半监督和有监督进行结合有一个缺点，那就是有监督的训练不够 充分，还是需要大量的训练集进行训练。第二个方法的则相对不是很直观，因为 釆取使用co-training关系抽取算法迭代产出的训练集必然受限于半监督算法的 影响，具体能不能提高系统性能有待考察。但是，根据第三章的实验结果，本文 发现，其实半监督迭代产出的内容还是包含了很多有效信息，只不过使用模板匹 配的方法没有真正挖掘出模板之间的共性。正例的模板的共性和负例模板的共性 应该是有区别，这里只有使用一些统计机器学习的技术才能充分挖掘模板之间的 共性。第二个方法其实是第二章提到的第二种优化思路的一种体现，其中训练集 的标注工作由半监督方法完成。
综上所述，半监督方法与有监督方法的结合具有很高的可行性。为了验证结 合两大类机器学习算法的有效性，下面设计一下算法流程。
5.2.2算法流程设计
为了验证将有监督算法和半监督算法进行有机结合后其效果优于二者分别 解决关系抽取问题，则本文需要设计三个实验，包括：单纯的半监督算法进行关 系抽取、单纯的有监督算法处理关系抽取问题以及二者有机结合的方法在相同问 题上进行实验。
为了保证实验具有说服力，在这里必须确保三个实验中使用的算法都是相同
37
的算法，且使用的数据也要完全一致。这一节将采用第三章的co-training半监督 关系抽取实验中词向量扩展的实验作为第一个实验。第二个和第三个实验需要本 节另行设计，这两个实验也都用了词向量进行扩展，其核函数与co-training的相 关实验参数见第三章，下面给出三个实验的算法流程，见图5-1至5-3。

图5-1半监督关系抽取实验流程



图5-2有监督关系抽取实验流程

38


图5-3半监督与有监督结合的关系抽取实验流程

第一个实验的流程和第三个实验的流程比较接近，而在本实验里使用的有监 督分类方法都只考虑模板上的特征，这部分代码的编写工作在上一节已经处理完 毕。
关于第一个实验的实验结果在第四章的表4-2已经给出，为了查阅方便，现 在把三个实验的结果列在下面，参见表5-2。
表5-2对比实验结果
实验	Precision	Recall	Fl值
半监督实验	0.52	0.36	0.43
有监督实验	0.09	0.57	0.16
结合实验	0.54	0.43	0.48

5.3实验结果分析
上述实验结果体现了半监督算法和有监督算法进行有机结合是切实有效的， 验证了第二章提出的分析，符合实验预期。在表5-2中，还有一些有趣的实验现 象，下面详细分析实验结果。
半监督的实验对比有监督的实验中，半监督实验结果的F1值远远超过有监 督实验的结果，这完全体现了在关系抽取领域研究半监督学习方法的必要性。并 不是说有监督效果不好，恰恰相反，如果有足够的训练集有监督算法的效果会非 常的好，就像本章第一节所展示的那样。自然语言本身的信息冗余度非常高，这 才导致了本文实现的co-training关系抽取算法挖掘出了语料集本身的有效信息。
39
如果还有其他的方法能够挖掘标注样本集的信息，那么这个方法应该也是可以得 到较好的效果。机器学习不能只关注于有标注的数据，更要关注无标注数据的内 部规律，毕竟无标注数据占了数据总量的绝大部分。
半监督实验对比co-training与核函数结合的实验，实验给出的结果是意料之 中的，也是比较有意义的。确切的来说，改进算法的基础是半监督学习，而这样 将半监督和有监督结合的实验从本质上来说还是半监督算法。因为有监督部分并 没有得到更多的信息，且这个实验的性能上限是由半监督实验决定的。改进算法 能够表现出比半监督学习更好效果的原因就是第三章实现的co-training关系抽 取算法只是利用了模板匹配，但并没有真正的挖掘出模板之间的关系。这正是体 现了第二章中提到的第二个优化方向。事实上，挖掘出信息之间的共性才是机器 学习的核心，而挖掘出任务可能需要的特征则是模式识别理论中特征提取和特征 选择的工作内容。因此，在半监督学习之后加入有监督的算法才能够真正的将性 能指标进一步提升。
最后，有监督实验和改进实验对比，这个结论很简单，那就是有监督实验必 须有足够的训练集才能得到较好的效果，否则实验结果会非常不理想，这也是机 器学习理论中提到的欠拟合。
5.4本章小结
本章就关系抽取问题进行了进一步的研究，其中对于第三章提出的模板之间 相似度函数转化为核函数进行有监督算法的实验，并验证加入大量语言学信息和 word embedding信息对于有监督的算法同样有效。与此同时，本文根据半监督算 法和有监督算法的各自特点设计了有监督与co-training进行有机结合的策略。虽 然从本质上来说这是一个半监督的算法，但是通过有监督的过程进一步的提炼出 模板之间的共性，从而提升了第三章中co-training关系抽取算法的实验性能。本 章设计的三个实验互相对比，验证了本文提出的思路是正确的，虽然现在只是在 TAC会议的数据集进行了验证，但是得出的一些结论对于后续的继续研究是有 一定帮助的。
40
第六章KBP关系抽取系统搭建，
6.1关系抽取任务介绍
本章以TAC会议KBP任务下的Slot Filling任务为研究对象，该任务是一个 定义翔实、规则细致、问题严谨的任务，其各方面经过数年的摸索已经逐步标准 化，是研究关系抽取问题的良好平台。但是由于问题标准化后会有一定的复杂性， 包括数据的来源、定义、关系的定义都需要进行说明。
6.1.1任务介绍
Slot Filling任务旨在判断指定的实体是不是存在于知识库中，并通过在语料 库中的信息来完善、更新一个新的或者已经存在的知识库。一般而言，Slot Filling 任务会指定抽取固定的关系，但是从2009年值2013年，每年需要抽取的关系都 略有差别。
2013年Slot Filling任务需要参赛机构对官方提岀的50个人名实体(PERSON) 和50个组织机构实体(ORGANIZATION)进行关系抽取。其中，语料是 LDC2012E45,包括新闻语料、网页语料和论坛语料三部分，总共约200W篇文 档。本文主要研究的是规范的自然语言，而网页语料和论坛语料具有大量的特殊 字符并且存在很多非自然语言格式的情况，所以构建研窕平台时使用的主要是比 较干净、规范的新闻语料。
Slot Filling任务中对于不同的实体类型定义了不同的关系，2013年时人名实 体和组织机构名实体分别具有25种和16种关系。每种关系需要抽取的答案根据 内容的不同可以分为三类：名字、值和字符串；而根据抽取答案数量的不同则可 以分为两种：单值型和多值型，具体情况参见官方说明。
任务中，上述所有关系抽取的来自未来、假设、虚构和隐喻的答案都被认为 错误的。另外，上表中提到的单值的关系只能提供一个答案，也就是即使系统排 序后的第二个备选答案是正确的，但是官方不会受理这个答案，对于准确率以及 召回率不能产生影响。
官方提供的任务介绍以及规则明细里面明确的提及了每个空在什么情况是 正确的，什么情况是正确的、错误的、不明确的等等情况，为了后续实验环节能 够准确描述出相关概念，在这里仅举一为例，如果需要切实研咒这个任务的相关 情况可以参考官方文档，此处只为后续内容介绍方便进行相关简要说明。
41
别名(Alternate Names)所需填写的实体必须是名字类型的，也就是一般所说 的命名实体，且这个关系允许参赛者填写多个答案。这个关系的具体描述指的是 一个相对独立的官方名字，可以包括化名、艺名、不完全一致名字(如Mike和 Michael)>缩写、绰号以及乳名。下面举一些具体的例子，比如从Barack Hussein Obama中得到的字符串Barack Hussein除非曾单独的出现在文档中，否则不能认 为是一个别名。另外，通常来讲一个人除去姓的名字除非能够毫无歧义的指明了 这个人，否则不能作为别名，即使这个名字单独在文档中出现过。这样的例子在 官方文档中有很多，从这里可以注意到，虽然Slot Filling任务的平台非常的规范， 但是里面的规则相当的细致，这给研究带来了一定的困难。
在抽取过程中，某些实体的部分关系是没有答案的，比如Obama的死亡时 间，这时候，参赛者只需要在答案出填写NIL就可以了。另外，官方还需要参 与的机构提供每个答案的相关信息，包括：答案的偏移量、答案所在短句的偏移 量、给定查询的偏移量等等信息。
6.1.2关系的层次分类
任务本身需要填写的41个关系是具有层次结构的，这在后续的处理时也有 体现。比如在上面提到的出生国家(Country of Birth),出生所在州或省份(State or Province of Birth) > 出生城市(City of Birth)以及死亡国家(Country of Death) > 死亡 所在州或省份(State or Province of Death)死亡城市(City of Death),本文简单的 将这些作为出生地(Place of Birth)和死亡地(Place of Death)-这两组关系的信息冗 余度较高，并且在实际处理问题的时候本文发现，这两组关系所在句子的句式结 构完全一样。于此同时，很多的句子会在一句里面将岀生地或死亡地的三个关系 信息同时给出，这说明提取信息的时候两组类别的三种关系就有一定的等价性。 除此之外，本文还对其他的一些关系进行不同层次的归类，便更方便的处理关系 抽取问题。
在提到出生地/死亡地的时候，文中忽略了如何区分每组类别的三种关系， 在实际处理中，一般的做法是找到相应国家名列表、城市或者州名列表以及城市 名列表。通过使用这些列表去匹配上面抽取出来的每个实体，进而对抽取出的实 体进行分类以达到完成任务的目的。实际操作时，很多的地名是不规范的，具体 如何处理这些不规范的地名可以使用Word Net和一些其他的处理方法，不属于 本文的研究内容，此处不予说明。
下面，着重介绍一下上面人刍的25种关系以及组织机构名的16种关系进行 分类的情况。其中文中只阐述可以归类的关系，对于不能归类的关系则不予表示。
对于人名实体的25种关系：
42
出生地：出生国家(Country of Birth) ＞出生所在州或省份(State or Province of Birth) ＞ 岀生城市(City of Birth)；
死亡地：死亡国家(Country of Death) ＞死亡所在州或省份(State or Province of Death)、死亡城市(City of Death)；
居住地：居住国家(Countries of Residence)＞死亡所在州或省份(States or Provinces of Residence)、死亡城市(Cities of Residence)； 上面三种分为一类的原因已经阐述清楚，不在赘述。
父母、孩子：孩子(Children)、父母(Parents),这两种关系具有非常高的内在 联系，处理过程中得到的孩子/父母类关系的实体时，需要进一步判断是不是找 到了父母/孩子类关系的实体。
人际关系：其他家庭成员(Other Family)和同胞(Siblings),这两个关系的冗余 度也比较大，需要在填写的时候仔细辨别。
对于组织机构类实体的16种关系：
总部所在地：总部所在国家(Country of Headquarters) ＞总部所在州或省(State or Province of Headquarters) ＞ 总部所在城市(City of Headquarters),这三个关系所 组成的类别与上面提到的出生地和死亡地是类似的。
组织机构隶属关系：隶属于(Member of)、母公司(Parents),成员(Members)＞ 子公nJ (Subsidiaries),这四个关系中前两个和后两个各自互为相反的关系，而前 两个和后两个之间的界限又相对比较模糊，所以在实际处理这个问题时，需要增 加额外逻辑判定对于给定实体所抽取出的答案应该属于什么关系。
对于人名类实体和组织结构类实体，别名这个关系在一般论述里会有较为固 定的格式出现，如，在某实体后加上一个括号，而括号内则是这个实体的别名。 为了保证文中技术的通用性，在本文里并没有釆用这类人工构造的规则对别名关 系进行抽取。
6.1.3任务中其他的自然语言处理问题
相关研究人员都知道ACE RDR 2004语料的标注是非常完善的，但是TAC 的相关语料在2009年至2013年期间一直是只给出了带有简单标签的自然语言原 文，这对于实际处理关系抽取问题是不够的。因为，对于一个实体而言，根据一 般的用语习惯，只有在第一次提及的时候会使用全称，后面的诸多提及都会使用 简称或者代词，而很多符合要求的答案实体就蕴含在这些简称或者代词所在的句 子之中。
信息抽取中，如果进行篇章级抽取，其中必不可少的一部分就是共指消解。 只有能够准确无误的找到给定实体在文章中的共指链，本文才能在准确率和召回
43
率上都有较大的提高。除了前文提到的TAC会议制定的规范过于严谨导致Slot Filling任务比较难之外，这是第二个导致TAC关系抽取任务的性能指标一直没 有像ACE RDR 2004语料库上表现出优越性能的原因。
为了尽可能的做好关系抽取任务，本文使用的来自斯坦福大学的自然语言处 理工具包CoreNLP",事实上，这个工具包具有分词、分句、词性标注、专有 名词标注、句法树分析、依存树分析、共指消解等多项功能。本文主要的研究重 点是关系抽取技术，所以在实验过程中需要的基础自然语言处理技术都是借助 CoreNLP进行处理，具体处理的重点逻辑将在下一个小节介绍。
6.2 KBP关系抽取系统搭建
上一个小结主要介绍了 KBP任务的相关事宜，但是TAC官方只是提供了相 应的数据和规范，并没有形成方便进行关系处理研究的平台，为了能够便于研究， 本文利用相应技术处理了索引、查询、数据分析、结果评判和分析反馈多个模块。
其中建立索引的原因是为了快速的在语料中检索出符合条件的文本，而不是 在所有语料中进行遍历，而且对于文本的分析非常耗时，经过检索后本文能够只 处理少量的相关文档。
本文主要使用2013年的TAC会议Slot Filling任务作为测试数据，而2009 年至2012年的数据作为训练研究使用。其中，表6-1汇总了这四年产生的训练 集大小。
表6-1训练集详细信息
种子对数	关系类型个数	平均每个关系种子对数
1885	41	46
KBP任务中关系抽取任务是只提供了一个关系抽取的研究平台，并没有提 供任何关于系统的建议和支持。这里，本文构建一个利用该平台数据以及规则的 关系抽取系统，系统流程如图6-1所示。

44


图6-1 KBP关系抽取系统流程图

流程图中的调用co-training关系抽取算法以及调优等部分已经在前面的章 节详细介绍，另外包括清洗数据、评估打分等流程比较简单，这里将不再详细说 明。
6.2.1索引与查询
免费的搜索引擎有很多，比如LuceneW】，Indri[43], Xapin[44],由于Indri主 要面向学术界，所以在构建平台的时候使用的是Indri进行索引的建立和査询。
在本平台里，为了后续可能进行研究的便利和考虑到Indri支持跨索引查询， 2009至2013年的语料分年份单独的进行建立索引工作。建立索引时，Indri需要
45
提供一份建立索引的配置文件，除了索引时考虑了词干化，本平台则使用了最默 认的配置文件。
关于查询，由于TAC官方给出的实体信息不一定大量存在于语料集中，而 根据往年的经验，对于给定实体进行模糊查询，如果能够匹配，则同样认为是该 实体，所以实验中的查询语言〔的使用间隔最多为3个单词的查询语句。为了保 证数据的充足且有效，根据经验值，设定每个给定实体至多返回150篇相关文档。
6.2.2预处理
对于检索出来的相关文档，本平台自动使用斯坦福的自然语言处理工具包进 行分析处理，并撰写程序将分句、词性标注等工作完成后的文档进行分析处理。
工具包CoreNLP具有十分强大的功能，能够满足本平台所需要使用的所有 自然语言处理技术，并进行一定的可视化工作。不仅如此，CoreNLP能够生成多 种类型的依存树，对于句子：Bills on ports and immigration were submitted by Senator Brownback, Republican of Kansa. CoreNLP 能够生成下面的如图 6-2 所示 的依存关系。预处理过程中，系统能够得到除去word embedding的所有特征信 息。



图6-2 (a)基本依存关系,(b)斯坦福依存关系
6.2.3词向量训练
Mikolov"提供的word embedding工具包word2vec具有多种可选择的参数, 和两个训练的模型。通过实验来看，模型方面使用skip-gram模型效果更好一些, 而其他参数在实验过程中并没有黑'别明显地影响，所以这里的词向量是通过将 word2vec工具包使用skip-gram模型并采用维度50维，其他参数默认训练得到 的结果。训练集使用的是去除标签，但是没有去除停用词后的KBP语料，语料
46
大小约为2G
6.2.4后处理
后处理部分是去除噪声，保证系统效果的重要环节，主要包括：
(1)将模型的到的数据结果规范化成KBP官方要求提交的格式；
(2)将具有层次化的关系进行匹配和其他方式的处理，以保证能够符合官方 要求；
(3)将明显是错误的答案去掉，如年龄大于200或者10岁以下以及非整数 等情况；
(4)确定实体对，句子的偏移量。
6.3系统成果与总结
本章所搭建的基于TAC会议KBP评测的关系抽取研究系统，包含了一整套 的检索、预处理、中间过程检测以及标准的评估逻辑。本系统能够方便研究者快 速实现关于co-training关系抽取算法的改进思路，并验证效果，是一个便利的研 究半监督关系抽取的系统。
本文作者在2012、2013、2014连续三年参加了 TAC会议KBP评测，并逐 渐完善系统。在参赛期间，一直取得非常好的成果，其中在2012年取得了第一 名，F值在0.5以上。
47
第七章总结和展望
7.1成果总结
本文针对文本分析会议所提出的关系抽取问题进行了详细的研究，切实分析文 本内容的重点，不考虑含有大量噪声，且不符合语言语法的语料。本文的做法更有 助于人们专注在自然语言的处理与理解，而且努力解决这个本质的问题后，处理网 页语料或者其他半结构化语料以及研究人类的语言特性都有很大的帮助。
关于实体关系抽取，前人巳经做了很多重要且卓有成效的工作，本文充分调研 了当前主流的思想和方法，并结合自身理解，选取合适的研究平台作为切入点，进 一步做了一些探索和实验。
首先，本文设计并实现了改进语义漂移的co-training关系抽取系统，并对该系 统的流程，逻辑以及部分核心操作的详细设计都做了充分的说明。本文设计的防止 语义漂移逻辑，通过每轮迭代都过滤出质量比较高的内容，从而规避掉一些可能的 漂移现象。这一部分做了一个对比实验，效果是显著的。
其次，本文提出了基于word embedding的co training关系抽取算法。本文根据 增加有效信息的思路，新增了语言学信息以及word embedding信息，构建増强狙的 模板，并设计了模板之间相似度的计算公式，而这个公式可以认为是核函数。为了 证明这样的改进是有效果的，本文设计了一组对比实验，实验结果验证了最初的猜 '想，F1值提高了 O.lOo
再次，本文提出了基于核函数的co-training关系抽取算法。本文验证半监督和 有监督算法相结合的可能性，并以半监督算法为基础得到大量的训练集。然后，使 用SVM为分类模型进行训练，并最终得出用于分类的模型文件。这样，利用训练 好的模型进行关系抽取，对比于单纯的co-training算法和SVM分类器，实验结果 有明显的提升，F1值提升0.05o
最后，本文根据文本分析会议的关系抽取任务制定了一套从检索到语言分析的 研究系统，并充分应用该任务的评价方法进行成果检测和优化依据。
综上所述，本文进行了大量的探索和实验，取得了一定的研究成果，达到了预 期的目的。
48
7.2不足与展望
本文在做实验的时候由于时间、研究水平的限制，实验中存在了一些的不足。 其中，co-training关系抽取算法中预防语义漂移的公式没有充分利用数据本身的信 息，其中给岀的公式属于启发式思维，这不符合机器学习的思想。其次，在进行 co-training算法实验设计的时候，有很多参数都没有经过充分的调优，并且这些参 数并不能通过数据进行自动调整，这同样是不符合依靠数据说话的机器学习思想。 同时，实验中只是验证了自身算法的有效性，但是并没有进行足够多的对照，从而 具体分析出每一步增加特征会有什么样的性能提升。这样做的原因，一是本文的主 要目的就是为了验证自身实验的有效性；二是过于细致的实验可能失去了普遍适用 性。当然本文所做的实验可能也是在KBP任务的数据集中效果明显，在跨度比较大 的领域，如微博等语料集，效果可能不是特别理想。除上述不足外，本文在有监督 和半监督结合的方案中理论研究不够，实验结果提高确实是可喜的，但是其中应该
:窓
有深厚的理论基础，还需继续研究。	1
自然语言的关系抽取技术研究不仅能够从理论上进一步理解自然语言，为自动 问答和人工智能提供一些支撑，而且就眼前来看基于模板的关系抽取技术可以与其 他技术结合，并形成语义关系的检索系统，以满足更多的需求，从而人们对于信息 的获取能够更加的便利。
参考文献
[1]李保利，陈玉忠.信息抽取研究综述[J].计算机工程与应用，2003, 39(10): 1-5.
[2]Grishman R. Information extraction: Techniques and challenges[M]//Infbrmation Extraction A Multidisciplinary Approach to an Emerging Information Technology. Springer Berlin Heidelberg, 1997: 10-27.
[3]Wu F, Weld D S. Open information extraction using Wikipedia[C]//Proceedings of the 48th Annual Meeting of the Association fbr Computational Linguistics. Association for Computational Linguistics, 2010: 118-127.
[4]Grishman R. Information extraction]J]. The Handbook of Computational Linguistics and Natural Language Processing, 2003: 515-530.
[5]Semi-supervised leaming[M]. Cambridge: MIT press, 2006.
[6]Berger A L, Pietra V J D, Pietra S A D. A maximum entropy approach to natural language processing[J]. Computational linguistics, 1996, 22(1): 39-71.
[7]Suykens J A K, Vandewalle J. Least squares support vector machine classifiers]J], Neural processing letters, 1999, 9(3): 293-300.
[8]黄瑞红，孙乐，冯元勇，等.基于核方法的中文实体关系抽取研究[皿中文信息学报,2008, 22(5): 102-108.
[9]Aitchison J, Aitken C G G. Multivariate binary discrimination by the kernel method[J]. Biomet:'ka, 1976, 63(3):413-420.
[10]Haussler D. Convolution kernels on discrete structures[R]. Technical report, Department of Computer Science, University of California at Santa Cruz, 1999.
[11]Lodhi H, Saunders C, Shawe-Taylor J, et at Text classification using string kernels[J]. The Journal of Machine Learning Research, 2002,2: 419-444.
[12]D. Z elenko and C.A.A. Richardella, Kernel methods fbr relation extraction. Journal of Machine Learning Research, 2003. 3(6): p. 1083-1106.
[13]A. Culotta and J. Sorensen. Dependency tree kernels fbr relation extraction. In Proceedings of the 42nd Annual Meeting of the Association of Computational Linguistics (ACL-2004), Barcelona, Spain, 2004:423-439.
[14]Bunescu, C. Razvan, J. Raymond and Mooney. A Shortest Path Dependency Kernel fbr Relation Extraction. In Proceedings of the Human Language Technology Conference and Conference on Em pirical Methods in Natural Language Processi ng (EMNLP-2005), Vancover, B.C. 2005:724-731.
[15]S .B. Zhao and R . Grishman. ExfractKg relations with integrated information using kernel methods. In Proceedings of the 43rd Annual Meeting of the Association of Computational Linguis tics (ACL-2005), Ann Arbor, USA. 2005:419-426.
50
[16]Zhang M, Zhang J, Su J, et aL A composite kernel to extract relations between entities with both flat and structured features[C]//Proceedings of the 2lst International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics. Association fbr Computational Linguistics, 2006: 825-832.
[17]ZHOU G D, Zhang M, Ji D H, et al. Tree kernel-based relation extraction with context-sensitive structured parse tree infbrmation[J]. EMNLP-CoNLL 2007, 2007: 728.
[18]Qian L, Zhou G, Kong F, et al. Exploiting constituent dependencies fbr tree kernel-based semantic relation extraction[C]//Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1. Association fbr Computational Linguistics, 2008: 697-704.
[19]Brin S. Extracting patterns and relations from the world wide web[M]. The World Wide Web and Databases. Springer Berlin Heidelberg, 1999.
[20]B . Rosenfeld and R . Feldman. URES: an unsupervised web relation extraction system. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, Sydney. Australia . 2006: 667-674.
[21]aCurran J R, Murphy T, Scholz B. Minimising semantic drift with mutual exclusion bootstrapping[A]. Proceedings of the 10th Conference of the Pacific Association fbr Computational LinguisticsfC]. 2007. 172-180.
[22]Agichtein E, Gravano L. Snowball: Extracting relations from large plain-text collections]A]. Proceedings of the fifth ACM conference on Digital libraries[C]. ACM, 2000. 85-94.
[23]Yarowsky D. Unsupervised word sense disambiguation rivaling supervised methods [A]. Proceedings of the 33rd annual meeting on Association fbr Computational Linguistics[C]. Association fbr Computational Linguistics, 1995: 189-196.
[24]Grishman R, Min B. New york university kbp 2010 slot-filling system]A]. Proc. TAC 2010 Workshop[C]. 2010.
[25]Sijia C, Yan L, Guang C. Reducing semantic drift in bootstrapping fbr entity relation extraction[C]//,Mechatronic Sciences, Electric Engineering and Computer (MEC), Proceedings 2013 International Conference on. IEEE, 2013: 1947-1950.
[26]D. P. T. Nguyen, Y , Matsuo and M. Ishizuka . Relation Extraction from Wikipedia Using Subtree Mining. Proceedings of the 22nd Conference of the Association for the Advancement of Artificial Intelligence (AAAL200 7), 2007:1414-1420.
[27]Xu F, Uszkoreit H, Li H. A seed-driven bottom-up machine learning framework for extracting relations of various complexity[C]//ACL. 2007, 7: 584-591.
[28]Xu F, Kurz D, Piskorski J, et al. A Domain Adaptive Approach to Automatic Acquisition of Domain Relevant Terms and their Relations with Bootstrapping[C]//LREC. 2002.
[29]Xu F, Uszkoreit H, Li H. Automatic event and relation detection with seeds of varying complexity[C]//PrGceedings of the AAAI workshop event extraction and synthesis. 2006: 12-17.
[j0] Etzioni O, Cafarella M, Downey D, et al. Unsupervised named-entity extraction from the web: An experimental study[J], Artificial Intelligence, 2005, 165(1): 91-134.
[31]李航.统计学习方法[J]. 2012.
51
[32]Blum A, Mitchell T. Combining labeled and unlabeled data with co-training[C] // Proceedings of the eleventh annual conference on Computational learning theory' ACM, 1998: 92-100.
[33]Mikolov T, Chen K, Corrado G, et al. Efficient estimation of word representations in vector space[J]. arXiv preprint arXiv: 1301.3781, 2013.
[34]https://code.google.eom/p/word2vec/
[35]VVapnik. Statistical Learning Theory. John Wiley, 1998 :1 - 28.
[36]Lodhi H, Saunders C, Shawe-Taylor J, et al. Text classification using string kemelsfJ]. The Journal of Machine Learning Research, 2002,2: 419-444.
[37]K. Fukunaga. Introduction to Statistical Pattern Recognition . Second Edition. Academic Press, 1990:4-37
[38]C . Cortes and V. Vapnik. 1995. Support- Vector networks. Machine Learning, 20(3):273-297
[39]Cover T, Hart P. Nearest neighbor pattern classification]J]. Information Theory, IEEE Transactions on, 1967, 13(1): 21-27.
[4G] http://www.csie.ntu.edu.tw/-cjlin/libsvm/index.html
[41]http://nlp.stanfdrd.edu/software/corenlp.shtml
[42]http://lucerne.apachc.org/
[43]http://www.lemurproject.org/indri.php
[44]http://xapian.org/
[45]http://sourceforge.net/p/lemur/wiki/Indri%20Query%20Language%20Reference/
52
