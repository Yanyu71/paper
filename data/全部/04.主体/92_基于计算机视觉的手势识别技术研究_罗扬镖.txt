第一章绪论
1.1研究背景及意义
科学技术的进步带来了人机交互的发展，各种人机交互的方式百花齐放。键 盘和鼠标作为人机交互的重要产品，早已渗透在人们的日常生活之中，触摸屏也 已在手机、平板电脑以及个人电脑等设备上广为使用，为人机交互带来了极佳的 用户体验。语音识别技术也伴随着人工智能时代的到来让人们可以用声音控制设 备，苹果公司的Siri,微软的Cortana,小米的小爱同学，都让智能语音技术充分 展示了其技术实力和发展潜力。
在机器化的大时代背景下，人机交互更是成为了最重要的技术之一，人们也 越来越多的关注到智能和自然的人机交互逻辑。其中，人体动作识别成为最有效、 最便捷的人机交互方式，其迅速从工业控制等领域转向了人们的日常生活。比如 在游戏控制方面，任天堂公司的WII以及微软的Xbox360体感游戏机中均含有 利用人体动作识别来进行交互的功能。手势识别的人机交互与人体动作识别具有 非常相似的技术特点，都是通过人体或人体的某个部位经过空间移动产生光学信 息，经过机器自动化处理来产生机器指令，控制设备进一步操作的智能技术。在 早期，手势识别技术受限于特定的设备，例如数据手套、戒指和腕带等繁琐且昂 贵的物理设备，或通过肌电等形式的数据输入作为手部的动作信息，进而控制终 端物理设备。近几年对手势识别技术的研究则更多地聚焦于利用计算机视觉等新 兴技术对手势动作进行智能化的识别，利用当前应用非常广泛的手机镜头、终端 设备中的深度立体镜头等常见设备来获取手势信息，对手势动作进行静态或动态 的智能识别给机器发出相应指令。例如快手公司就在去年推出了其在手机应用中 的手势识别技术，让使用者可以利用其手势来控制设备拍照、以及视频的自动化 渲染等。
随着人类社会的发展以及计算机视觉技术的日新月异，手势识别技术已经从 传统工业界走向了增强现实(AugmentedReality,AR)、虚拟现实(VirtualReality, VR)和机器人等新兴领域。特别是在2017年，苹果和谷歌相继发布了其增强现 实工具(ARKit)和增强现实核心(ARCore),增强现实领域的应用也开始逐渐 走向成熟，增强现实技术的发展也有了明确的方向。手势识别技术是环境感知的 关键技术之一，其可以用于自动驾驶、运动监测、行为分析等多个智能化的现实 场景。以下列举几个手势识别技术常见且极具发展力的应用领域：
(1) 手语翻译
手势识别中一个很重要的应用就是手语识别。很多聋哑人可以用手语进行交 流，但生活中却有很多人不懂手语，这成为了聋哑人与其他人正常交流的一个巨 大阻碍。对聋哑人的手语进行翻译，转化为文字语言,再通过语音技术读取播放， 可以为聋哑人的生活带来极大的便利，科技对于所有人都应该是平等和友好的。
(2) 智能家居
手势识别智能家居系统，区别于市面上现有的一些智能家居系统，它摒弃了 控制板或者遥控器等实体按键来操纵家电的方法，采用手势识别控制设备的技术, 让机器自动识别人类做出的手势动作，根据识别结果控制家电的下一步操作。
(3) AR、VR
目前手势识别、手形重建等技术在AR、VR领域非常活跃，原因在于AR、 VR领域有很多人机交互、人机互动的需求，将人手重建后的三维模型放到智能 场景中进行展示，根据手势进行人机互动及设备控制，成为了这些领域对手势识 别的迫切需求。目前大多数VR产品中都配备了手势识别的功能。
(4) 生活娱乐
在生活中娱乐往往是不可缺少的，目前市面上的一些游戏厅已经配备了手势 识别与追踪的项目，比如把“水果忍者”这款游戏搬到荧幕前，人们用手臂与手 的挥动便可以把水果切成两半。另外，一些终端设备厂商也在尝试将手势识别技 术应用到家庭娱乐设备中，比如家庭影院切歌、暂停以及播放等功能。
可见，手势识别技术在众多领域中都有着重要的应用，该技术不仅能够帮助 听觉障碍人士便利沟通，还能为人们的日常生活提供诸多可能性。由于手势识别 技术是涉及计算机、机器学习、计算机图形学等多方面的复杂技术，该技术仍存 在着很多的难题需要解决，这也是本课题的研究意义所在。最近几年，各种终端 芯片的开发都加入了神经网络加速模块，使得机器学习技术得以在用户的终端设 备上大放光彩，神经网络技术成为了切实可行的终端形态。本文基于计算机视觉 技术，研究神经网络在手势识别技术中的具体应用。
1.2手势识别研究现状
随着计算机设备在人们生活中普及，人机交互也加速成为了近几年最热门的 研究课题，大量研究专注于建立新的智能交互系统来达成新的人机交互目标，这 一目标的最终要求是桥接机器与人类行为最自然的对应关系。在这个背景下，手 势识别致力于分析并解释特定的人类动作成为了研究热点。手势识别大都基于特 定的场景，捕捉整个人体或者特定手部的肢体移动行为。因此基于视觉的手势识 别成为了最自然、最符合人类直觉的方式之一，特别是在某些复杂的场景下，物理或者语音方式变得不再适用，视觉成为了最简易且最方便的交互逻辑，由于手 势识别的重要性，该领域吸引了学术界及工业界的大量关注。
计算机视觉算法仅依赖于视觉信息识别手势动作，近年来发展了很多种多模 式传感器(例如微软公司的Microsoft Kinect设备)可以同时获得红绿蓝三通道 (Red Green Blue, RGB)图像数据和手势深度信息，结合RGB和深度(Red Green Blue and Depth, RGB-D)两种数据模态的优势发展出了很多新的识别算法，极大 地推动了手势识别技术的研究积极性及技术发展。深度信息可提供丰富的3D(空 间三维)立体结构特征，对照明变化更不敏感，降低了对于服装及肤色的要求， 成为了常规RGB图像数据的实质性补充。虽然在手势识别领域已经有了大量的 研究工作，但准确地识别出无条件限制的视频手势仍然是一项极具挑战性的工作, 主要面对的难题是视点变化，视频背景复杂，遮挡，类内、类间差异以及噪声的 影响等，其他困难包括不同表演者不完全一致的手势演示行为，以及在时空尺度 上手势的复杂变化等。
与依赖静态图片的其他视觉分类任务不同，动态手势提供了信息更加丰富的 时空特征，包括视觉空间维度以及视频中手势运动的时序信息。因此，提取有效 的时空特征来捕捉手势动作在不同尺度上的时空演变对于完成动态手势的识别 至关重要，从建模的角度来看，三维数据结构带来了极具挑战性的复杂人体运动 分析。根据Tran团队山和Zhang Liang等人⑵的工作，有效提取手势的时空特征 必须包括以下的几点要求：(1)健壮性，(2)计算效率高，(3)易于实现。到目 前为止，构建完全满足这些要求的智能手势识别系统仍然非常困难。
毫无疑问，已经有很多的研究工作致力于实现这样的手势识别系统。传统方 法卩,4,5,6,7,8］尝试构造非常有效的手工特征去挖掘视频数据中的空间及时序特征表 示，通过提取的手工特征送入判别型的分类器例如支持向量机(Support Vector Machine, SVM)、主成分分析(Principal Component Analysis, PCA)、朴素贝叶斯 等分类器实现手势的识别与分类。通常，手工提取特征的功能建立在像素级别上， 也可以从感兴趣的区域中进行密集采样或提取［9】，使得它们对物体的空间几何变 形表现得更加健壮。然而，除了计算量大之外，大多数现有的手工特征都对数据 集本身有着极强的依赖性，这使得它们很难从一个场景迁移到另一个场景，在切 换应用场景时需要专家重新设计新的手工特征，高昂的人力成本也使得他们无法 一一适配更多的真实场景。
近年来，手势识别技术中更为常见且先进的一类特征表示方法是深度神经网 络模型(Deep Neural Networks, DNN) ［10L DNN具有很强的非线性学习能力， 在端到端的训练过程中随着层次的加深进一步学习复杂的特征抽象表示。随着大 规模训练数据集的收集，深度神经网络迅速成为许多计算机视觉和模式识别任务的基础模型【11,213,14,15]。作为深度神经网络的重要分支，卷积神经网络(Convolutional NerualNetwork, CNN)【均通过在原始输入中应用可训练的卷积核使得局部 的特征表示具有了更高阶的抽象，成为了一种非常有效的深度图像学习模型。在 计算机视觉领域，研究者们也将CNN深度学习技术应用在手势识别上，并且获 得了比效果最好的手工特征手势识别方法更高的识别准确率。
将卷积神经网络技术应用于动态手势识别的切入点是在单帧图像上应用二 维卷积，再通过其帧间关系融合动态手势的时序特征U&1920],这种方法可以很容 易地利用大规模的图像数据集进行预训练和迁移图像知识。虽然这种方法在模型 的预训练上具有优势，但二维图像卷积特征在模型训练提取过程中并未融入动态 手势的时序编码，每帧图像的特征是相互独立的，空间特征的时序融合忽略了视 频图像帧的帧间时序关系，增加了动态手势识别的经验性风险。另一种方法是将 二维卷积网络扩展至三维卷积，利用三维卷积以及三维池化的操作方式融合时序 上手势的运动特征[B2I，22,23],大量方法证明了三维卷积网络结构对复杂时空建模 的有效性。然而，三维卷积具有的大量的学习参数导致这一神经网络模型仍然是 一个具有挑战性的训练任务，特别是在具有较长时间序列的视频结构中。同时， 由于三维卷积通常是直接在原始视频上进行的计算，生活场景中的复杂背景以及 噪声也对其产生了较大影响。第三种手势识别的策略是基于运动信息作为输入的 手势识别02526],运动信息例如光流会在输入深度神经网络之前进行计算，从这 种预先计算好的运动信息中训练机器学习模型可以使其暗含手势的时序关系，更 好地融合手势视频中的时空特征，并且由于光流作为运动信息的输入，在某些场 景下可以过滤掉静态视频背景的干扰，但该方法的缺点在于相邻帧的运动表示在 视频的长期时序编码过程中会导致时序关系的丢失。第四种方法是利用循环卷积 神经网络(Recurrent Neural network, RNN)模型及其变体，如长短期记忆网络 (Long Short-Tenn Memory, LSTM)建模视频中的长短期时序关系【27,28,29]。LSTM 通过信息单元来存储、修改以及访问时序的内部状态，通过门结构来实现网络的 记忆功能，因此LSTM可以很好地融合视频中长期及短期的时空特征。然而， LSTM内部使用全连接的神经网络结构，则无法很好地整合手势视频中的空间信 息。基于此缺陷，发展出了一种以LSTM网络为基础，结合卷积神经网络优势的 适应于时空结构输入的循环神经网络变体，即卷积长短期记忆网络(ConvLSTM) [3叫与二维卷积神经网络扩展至三维卷积增加了时间维度卷积的思路类似， ConvLSTM也在提取时序特征的基础上扩充了特征的空间维度，使其适应三维结 构的数据输入。然而，简单地扩充循环神经网络的空间维度并不能有效地提取手 势视频的空间特征，卷积长短期记忆网络的卷积门结构设计在空间维度上也进行 了过多的特征像素级记忆。
当前已有的研究中各种手势识别算法无法对手势的时空特征进行很好的融 合。在前人研究的基础上，本文针对动态手势视频中的RGB视频和深度视频信 息两种模态进行了深入研究，为了有效提取并融合动态手势的时空特征，提出了 一种时空多尺度特征高效融合的“3DCNN&T-Dilated + ConvGRU + 2DCNN”算 法结构，结合了三维卷积神经网络以及门控循环单元各自在特征提取上的优势， 提高了动态手势的识别精度。同时，本文还对手势识别的RGB-D两种模态进行 了双模态手势识别技术的研究，引入用于动态手势视频前置数据处理的时空注意 力机制，加入了空间维度注意力模型以及时序压缩激励网络(TemporalSqueeze- Excitation Network, TSENet), 实现端到端的手势识别。同时本文还利用迁移学习 的技术提升动态手势识别的整体效果，其通过迁移领域知识提升手势单模态及双 模态的识别精度。
1.3论文结构安排
本文的各章节安排如下：
第一章为绪论，介绍了本课题的研究背景，分析手势识别技术研究中的实际 应用以及本课题的研究意义，同时本章还调查了国内外关于手势识别技术的研究 进展以及技术概述，提出本文的研究重点及论文的整体结构安排。
第二章为手势识别的相关技术研究，特别是对与本课题研究相关的技术细节 做了详细介绍。本章首先介绍了传统机器学习方法在手势识别技术中的应用进展, 介绍了手工特征提取在手势识别中的具体模式。接着介绍了深度学习卷积神经网 络在手势识别技术中的技术细节，探究了传统二维卷积神经网络以及具有时间维 度卷积的三维卷积神经网络的具体实现，阐述了仅使用卷积神经网络作为手势特 征提取模型的缺点。随后本章介绍了著名的时序关系模型循环神经网络及其变体 结构在动态手势识别中的具体应用，探究循环神经网络的技术细节及其优缺点， 介绍了卷积循环神经网络在手势识别技术中的应用形式。最后对本章内容进行了 总结，概括本章的主要内容。
第三章为本文提出的基于时空多尺度特征融合的动态手势识别模型。首先对 串行的网络结构进行了概括性的介绍，提出网络的整体框架。其次在本章对应的 几个小节中分别介绍了本章算法的具体模块设计、数据增强方法以及输入数据的 规范化方法等，并对本章算法的整体结构进行了具体描述。同时，本章还具体介 绍了动态手势识别算法中的预训练微调学习方法，在大规模数据集上进行预训练 并微调学习其他的数据集模型，通过实验分析并验证本章算法各个模块的有效性 及算法的整体表现。最后对本章内容进行了总结，概括时空多尺度特征融合算法 的相关结论。
第四章为基于注意力机制的手势识别算法研究。首先分析了手势识别应用的 一般流程，提出将计算机视觉技术中的注意力机制应用于动卷手势识别第一阶段, 代替手部检测以及视频关键帧提取的具体方法。接着详细介绍了本章时空注意力 模型的技术细节以及将二维残差注意力模型应用于三维手势视频中的具体结构， 并结合压缩激励网络(Squeeze-Excitation Network, SENet)提出了本章用于代替 视频关键帧提取操作的时序压缩激励网络TSENet。同时本章还对RGB-D手势 双模态视频数据的两种手势模型进行了多任务迁移学习训练，进一步提升RGB 视频和深度视频两种独立模态的手势识别精度，并对手势的双模态融合识别进行 研究，对比其他手势识别方法验证了本章注意力模型结构的有效性，最后对本章 的内容进行了总结。
第五章为总结与展望。对本文的研究内容以及研究成果进行了总结和讨论， 概括本文研究的亮点并为课题的下一步研究指明方向。
第二章手势识别相关技术研究
2.1引言
近年来基于计算机视觉的机器学习算法取得了长足的进步，从传统的机器学 习模型如支持向量机SVM、决策树以及集成方法等统计形式，到后来快速发展 的深度学习模型，机器学习在计算机视觉领域发挥了重要的作用，深度学习算法 更是接连取得了具有突破性的进展。残差网络的提出在很大程度上解决了深层次 网络训练退化的问题，来自变换器网络结构的双向编码器表征量模型(Bidirectional Encoder Representations from Transformer, BERT )在自然语言处理的各 种任务上带来了全面的性能提升，深度学习方法大放光彩。在基于传统统计学的 机器学习方法中，逻辑回归方法与神经网络技术异曲同工，将输入特征进行线性 和非线性的数学变换，计算当前模型的预测误差并反向传播，不断迭代更新学习 参数实现统计意义上的机器学习目的。不同的是，传统机器学习方法常利用提取 手工特征的方法来提取数据的可解释性特征，而在深度学习中，通过改变模型的 结构则可以自动提取数据更为有效的隐藏特征来代替繁琐的手工特征提取，且结 构的不同往往带来完全不同的机器学习效果。例如有的网络结构在图像的局部特 征提取任务上十分有效，有的结构则适用于连续时间的序列特征建模，不同的算 法结构有着不同的优势及劣势。因此本章首先简要介绍与手势识别有关的一些传 统机器学习特征及方法，接着详细介绍与连续图像序列识别有关的深度学习手势 识别方法，分析各种不同学习算法的优缺点。
2.2特征及机器学习方法
2.2.1视频的基本特征
视频数据相比于图像数据，是由连续的图像序列组成的，其等同于在图像数 据的基础上添加时间维度，因此数据量是图像数据的数倍。本小节首先介绍手势 视频中图像的基础特征，接着介绍视频数据所特有的动态特征，下一小节将介绍 基础特征用于传统手势识别的机器学习方法。
在手势识别技术中所使用的图像特征通常包含以下几种：
(1)颜色特征
颜色特征在图像检索中的应用非常广泛，原因在于颜色往往和图像中所包含 的物体或具体场景有着很强的相关性，属于全局性特征。在自然界，不同物体所具有的颜色特征一般相差较大。相比于形状、方向、视角等物体特征，颜色是最 简单的区分性特征，在很多场景下也具有较高的识别稳定性。然而，颜色特征非 常容易受到图片背景以及光照的影响，在图像背景颜色与物体较为接近的情况下 容易发生误判，且现代社会中物品的颜色也与自然界有着较大的差别。
(2) 纹理特征
纹理特征是一种反映图像及其局部区域内物体表面性质的特征，也是一种全 局性的特征，例如手部的正面与反面就有着不同的纹理表现。而由于纹理是物体 表面的一种基础特征，不能完全反映整个物体的本质属性，因此仅利用纹理特征 无法准确获取物体的高层次隐藏特征。与颜色特征不同，纹理特征并不基于图像 的全部像素点进行统计运算，而是分别计算每个像素点周围空间的灰度分布。在 模式匹配中，这种区域性的纹理特征也具有较高的识别稳定性，不会因为局部的 物理偏差而导致无法匹配。与颜色特征相似，纹理特征也有可能受到光照及其反 射条件的影响。
(3) 形状特征
形状特征定义的是物体表面轮廓的结构特征，不同的物体通常具有完全不同 的形状。当前研究中基于形状的物体检测还比较缺乏完善的数学模型，当物体发 生形变时检测的结果可能发生很大改变，其特征相似性与人类视觉系统感受到的 相似性也有所差别。另外，从现实3D物体到某一方向上的2D映射并不能很好 地反映出物体的真实形状，不同角度的观察结果可能会带来各种失真问题。
手势动态特征通常包括以下两种：
(1)光流
光流是空间中运动物体在观察成像平面上运动的瞬时速度，其粒度为像素级, 是一种利用图像序列间相邻帧像素点的相关性来计算当前帧与前一帧图像对应 像素点的空间移动关系的方法。一般而言，光流是由视觉场景中物体本身的移动、 摄相机的运动，或者两者的共同运动所产生的。当人的眼睛在观察运动物体时， 物体的反射光在人眼的视网膜上形成了一系列连续变化的物体成像，这一系列连 续变化的运动信息不断“流过”视网膜，即形成了视觉上的物体图像平面，因此 被称之为光流。光流表达了视频中物体所发生的变化，由于它同时包含了目标物 体在三维空间中具体的运动信息，因此可被用于确定目标物体的运动情况。如图 2-1所示是目标物体在三维空间中运动而产生的二维光流矢量，所有视觉成像像 素点运动产生的光流矢量即构成了整体的光流场，光流场是一种矢量场，其具有 横轴和纵轴两个方向，图中(u,v)代表了物体运动的两个方向。光流场利用视频 中的相邻帧进行计算，其计算的前提是物体的瞬时光照条件在相邻两帧的时间间 隔内保持不变，即同一物体的像素值在运动的两帧之间具有一致性。

图2-1物体三维运动产生的二维光流矢量
(2)运动表示
运动表示特征(Motion Representation)是人体行为识别技术中的重要应用⑶］, 是表示人体动作的一种形式，试图对整个视频序列中物体运动进行整体结构性表 示，是替代光流特征的一种可能方向。基于光流和RGB原始图像特征的双流网 络是目前比较繁琐的一种多模态模型结构，该方法需要对原始RGB视频独立提 取光流信息进行识别。因此如何利用类似光流的思路简便地获取到物体的运动信 息是比较重要的时序表示方法。运动表示就是这样一种有效的光流替代方案，该 方法是通过视频相邻帧像素点的计算在全域上表示的所有物体的运动信息，跟光 流不同的是，运动表示特征代替了繁琐的图像梯度计算，因此可以很方便地得到 视频中像素点的运动表示。视频的运动表示特征也有RGB和深度信息两种形式， 可以从RGB图像的运动表示模型(Motion History Image, MHI)卩刀和深度信息的 运动表示模型(Depth Motion Map, DMM)卩习中看到，图像的运动信息表示只需 要计算视频相邻帧对应像素点的像素值变化，而不需要精确计算物体的移动方向, 从而可以轻易地利用矩阵方法进行快速运算。它们的基础公式如式2-1和2-2所 示，其中I和D分别代表RGB图像和深度信息两种图像的像素输入值，加是运 动表示特征的基础单元，5是衡量RGB图像像素值变化的阈值控制，用来减弱 光照等其他因素变化带来的不良影响，/和/+1表示视频中的相邻两帧，x和丁表 示图像的每个像素位置。人体行为识别论文［34］中使用了视频的深度信息计算 DMM运动表示特征来对人体行为进行识别。

2.2.2基于手工特征的传统机器学习方法
传统机器学习方法对手工特征的提取具有很强的依赖性。针对不同场景的手 势识别数据，专业人员利用其专业知识提取手势的有效特征表示，通过训练学习 模型可以实现很高的识别精度。在传统的机器学习算法中，HOG+SVM技术卩5］ 常用于识别静态手势，而DTWR61技术则可以更好地应用于动态手势识别。
⑴ HOG+SVM
HOG (Histogram of Oriented Gradient)即图像方向梯度直方图，是一种在计 算机视觉图像处理中用来检测物体提取物体成像特征的描述算子。HOG方法通 过统计图像每个局部区域上梯度方向的直方图构成图像特征，利用该图像特征训 练一个SVM模型或者其他有效的机器学习分类器对静态手势进行识别。静态手 势识别中还有其他有效的学习方法，例如卷积网络的多特征加权融合方法⑶】。
(2) DTW
DTW (Dynamic Time Warping)即动态时间规整，是一种衡量两个不同长度 时间序列相似度的方法，通过扭曲原始数据在时间上的维度，在时间轴上进行局 部的缩放平移，使得两个序列的形态尽可能地趋于一致，得到其最大可能的时序 相似度。在动态手势视频中，每个表演者完成相同的手势动作所需要的完成演示 时间具有不同长度，有的表演者移动速度快一些，而另一些表演者的移动速度则 相对缓慢，DTW算法在此类动态手势识别数据中具有良好的识别作用。
2.3卷积神经网络
人工神经网络(Artificial Neural Network, ANN)是20世纪80年代以来机器 学习领域兴起的研究热点，是最基础的深度学习方法。1958年，Rosenblatt先生 首次提出了感知机模型［附，但由于硬件条件限制，当时的神经网络模型并没有取 得很好的效果。而后BP神经网络模型【39］的出现，训练多层神经网络结构成为了 现实。如图2-2所示是一个多层连接的神经网络模型结构，其中包含了输入层、 输出层以及单个的隐藏层结构。为了使模型训练结果具备非线性功能，层与层之 间通常会叠加非线性的激活函数，以此达到更好的学习效果。卷积神经网络由于 其良好的局部特征分辨能力被广泛应用于计算机视觉领域，其可以直接在原始图 像上进行应用，省去了诸多人工图像处理的流程。

输	隐	输
入	藏	出
层	层	层

图2-2 —个简单的多层连接的神经网络结构
2.3.1卷积结构
卷积神经网络的基本模块包含三个串行的连接层：卷积层、激活函数层以及 池化层，如图2-3所示。

图2-3卷积神经网络
卷积层通过一个卷积核提取图像上每个局部的特征，得到一个具有线性映射 关系的卷积图像特征图，每处的局部特征都接受了一个卷积核大小的输入。激活 函数层则是通过激活函数使线性图像特征产生了非线性变换，使模型能够学到非 线性的特征表示。最后的池化层进一步调整特征图的大小，减少模型的训练参数。
(1)卷积层
卷积是信息处理中一种非常常见的操作，其中一维卷积可以用如式2-3的微 积分公式表示：
s(f) = | x(t — a)w(a)da
其离散公式如2-4表示为：

其矩阵形式为式2-5：

其中*表示一维向量的卷积操作，s(t)为一维卷积的结果输出，x和w分别代 表原始数据输入和卷积核的学习参数。以上是关于一维向量卷积的数据操作，而 卷积神经网络则是进一步将一维卷积扩展到了二维卷积，用于对图像等二维数据 进行特征提取，卷积神经网络中的二维卷积操作如式2-6所示：

其中s代表二维卷积输出，*表示了原始图像和卷积核的卷积操作。该公式并 非严格数学意义上的卷积，但其与式2-3至2-5中的一维卷积过程十分相似，因 此业界也将其称之为卷积神经网络结构。
在卷积神经网络的卷积结构中，一个神经元只与其部分邻接的神经元相连。 在CNN的一个卷积层输出中，通常包含了数个特征平面（fbatureMap）,每个特 征平面由矩形结构排列的神经元组成，同一个特征平面的每个神经元即局部特征 具有共享权值的操作，即共享同一个卷积核的学习参数，特征平面的每处局部都 使用同一个卷积核参数进行计算，这种稀疏的连接方式就是卷积神经网络和普通 神经网络的最大差别。通过这样的权值共享机制，卷积神经网络可以大大减少所 需要的机器学习参数量。卷积核参数一般以一定的分布例如0均值高斯分布的随 机小数来对模型参数进行初始化，在网络的训练过程中通过损失误差的反向传播 迭代更新卷积核参数，找到最优的机器学习模型。
典型的卷积层操作可以用图2-4的步骤来表示，其中，输入是一个5*5*3大 小的原始输入，最后的维度3代表了输入具有的3个通道，在二维图像中可以理 解为RGB三种颜色或者其他颜色格式表示的不同图像风格。为了便于表示卷积 过程，本文使用了其中一个通道作为示例对图像进行卷积操作的表示。其中，常 规卷积神经网络中的卷积核除了拥有3*3表示卷积核的大小之外,还具有和输入 数据相同通道数的多个单层卷积核用于对输入的每个通道分别卷积并求和。
图2-4卷积层操作
卷积运算的特点为神经网络提供了重要思路，其共享权值的模式不仅减少了 机器学习所需要的参数量，还进一步提高了神经网络模型的泛化能力。卷积神经 网络的共享权值机制与普通全连接神经网络之间的主要区别在于是否进行局部 运算，如图2-5表示，卷积神经网络的每个神经元只与与其相连的卷积核大小的 局域输入相乘，而全连接的神经网络则对每个输入值都进行相乘的操作。

图2-5全连接神经网络（左）与卷积神经网络的局部连接（右）
（2）激活函数层
由卷积函数的公式可以看出，卷积操作是一层层线性的特征变换。但样本的 分布却常常是线性不可分的，例如简单的异或关系（XOR）,就需要输入数据之 间进行相乘的与非操作，因此需要通过激活函数来引入模型的非线性学习功能， 拟合非线性的数据输入，解决线性变换所不能解决的机器学习问题。另外，激活 函数还具有控制数据变化范围的功能，多层神经元的输出层逐层乘积可能导致输 出结果过大或过小，中间数据过大及过小均有可能导致模型的反向传播失效，模 型的学习参数无法继续回归到合理的数值范围，因此需要使用激活函数控制神经 网络每个层次的数据输出值。在深度学习网络中经常使用的激活函数包括S型 （Sigmoid）函数、正值滤波（ReLU）函数以及双曲正切（Tanh）函数几种。
S型函数：S型函数是机器学习中最早使用的一种激活函数，在深度学习技 术开始流行之前，S型函数就已经作为逻辑回归的计算方法广泛应用于传统的机 器学习中。它的公式定义如式2-7所示，其形状如图2-6所示。可见，S型函数 可以将输出控制在0到1之间，这使得它天然适合于二分类的机器学习任务，并 且由于S型函数与对数损失函数具有非常一致的非线性函数形式，因此在机器 学习早期的研究中，S型函数就经常被用于各种场景下的机器学习研究。但同时， 由于其导函数值被限制在0到0.25之间，在多层的神经网络反向传播时容易导 致梯度相乘消失的现象。
(2-7)

由式可知正值滤波函数是将输出小于0的部分映射为0,而大于0的部分则 维持正值不变，通过该函数可以很轻易地实现一些与或非的逻辑功能；正值滤波
13 函数将小于0的输出置0,不仅起到了非线性函数的功能，还具有稀疏化机器学 习参数的作用，即训练过程中将一部分学习参数永久置零，可以在一定程度上提 高机器学习模型的泛化能力。其缺点在于训练初期机器学习的中间层输出可能并 不稳定，正值滤波函数有可能过早导致机器学习参数无法更新，以至于过度稀疏， 即神经元“坏死”的现象。因此，后续的学者们提出了很多关于正值滤波函数的 变种，例如倾斜正值滤波(leaklyReLU)函数、高斯误差线性单元等。
双曲正切函数：Tanl)函数与S型函数具有非常相似的非线性函数功能，其 公式如式2-9所示，形状如图2-7。双曲正切函数将模型的输出限制在-1到1之 间，具有更丰富的非线性变换功能。

池化函数通常包括最大池化(Max pooling)和平均池化(Average pooling) 两种。由图2-8可以很形象地表示出来，其与卷积层操作类似，对每个局部进行 运算，输出其方块内的最大值或平均值来对特征图进行池化。


图2-8最大池化
池化层有两个主要的作用：减小特征图、减弱模型的过拟合影响。池化层配 合卷积神经网络使用具有平移不变性的作用。其池化操作就是图像的去冗余，例 如一张狗的图像缩小了一半依然能够被机器或人类辨别出这是一张狗的照片，这 说明这张缩小后的图像中仍保留着狗的重要特征，因此池化层只是去除了一部分 的冗余信息，而留下的信息则是更关键的尺度不变性特征，能够代表原图像中具

有辨别性的特征。同时，去冗余操作也在一定程度上有利于机器学习的泛化，改 善模型的判别效果。值得说明的是，在神经网络池化层的反向传播中，平均池化 会将某个神经元得到的梯度平均分成n等份向上传递给上一层神经元，保证池化 操作前后的梯度之和不变，并同步更新池化函数连接的所有局部学习参数；最大 池化则是在前向传播时记录下池化操作中最大值的位置，而在反向传播时仅将梯 度传递给该位置上的神经元，其他神经元的更新梯度则置为0。
三维卷积神经网络：以上关于卷积神经网络的介绍中，都是以二维图像中的 卷积作为例子进行介绍的，卷积神经网络在二维图像上的性能表现十分优越，具 体表现在图像分类、目标检测、图像分割等诸多计算机视觉任务中，但在视频等 三维图像序列中表现欠佳，原因在于视频是由多帧二维图像按移动顺序堆叠而成 的，其不仅包含了单帧图像的空间表现信息，还包含了帧与帧之间的时序关系。 为了学习到三维图像序列的时间信息，三维卷积神经网络（thi-ee-dimensional CNN, 3DCNN）被提出，在文献［13］中作者将其应用在人体的行为识别中。该网络结构 的设计是将二维卷积神经网络增加一个时间维度，扩展到空间与时间组成的三维 结构中。在卷积操作时，不仅用到视频中的单帧图像，同时也考虑了时序上连续 帧的联系，可以看作是二维卷积神经网络在时间上的扩展。3DCNN是一个同时 考虑空间和视频序列时序关系的卷积神经网络，其不仅适用于人体的行为识别， 也适用于所有视频分类、手势识别等其他具有三维结构数据输入的机器学习任务。 2DCNN和3DCNN的卷积操作区别如图2-9所示，其中左中右三个子图分别描 述了传统二维卷积神经网络、将二维卷积神经网络结构应用于时空三维数据以及 常规三维卷积神经网络结构的卷积操作。另外需要说明的是，2DCNN和3DCNN 在通道上的概念是一致的，其代表了不同的特征风格。在三维卷积神经网络中， 池化层也针对三维数据进行了适配，形成三维池化函数。

图2-9二维卷积（左）、三维数据中二维卷积（中）、三维卷积（右）
2.3.2常用技术
卷积神经网络在图像等视觉任务上表现优秀，各种卷积神经网络模型也层出 不穷，在卷积神经网络中，还有一些技术能够让网络的训练变得更加准确和高效。 例如神经元丢弃（Dropout）技术〔4°］可以在每批次样本的训练中设置不同的神经
15 元连接，等同于不同模型组合提高了神经网络的泛化性能。批规范化(Batch Normalization,BN)⑷］可以加快网络的训练速度，并具有提高网络泛化性能的能 力，L2正则化可以帮助减小模型的参数值，深度可分离卷积［42］则大大减少了卷 积神经网络的学习参数量，加快模型的推理过程。
(1) Dropout 技术
过拟合(OverFitting)问题是机器学习领域中经常面临的问题，其指的是模 型对训练数据的过度学习，以至于在训练集上的一些非通用性特征以及噪音等也 被机器学习模型给“学会”了，而在更广泛的数据集上并不存在这样的特征，从 而导致模型在训练数据中的识别准确率偏高，在测试集上的拟合效果却不尽如人 意的结果。引起模型过拟合的原因有很多，其中最常见的一种就是模型过于复杂 所致。Dropout神经元丢弃技术由图2-10所示，可见Dropout技术是在网络的训 练过程中，随机挑选一部分的神经元使其停止工作，在前向传播时停止使用该部 分神经元进行传播，并在反向传播迭代时保持模型该部分参数暂不更新。该技术 相当于在每次训练神经网络模型时都属于不同的神经网络结构模型，因此最后得 到的训练模型天然具有机器学习集成的效果，提高了神经网络的泛化能力。


(a)常规神经元连接	(b)应用神经元丢弃
图2-10全连接型神经网络(左)、Dropout技术训练的网络(右)
(2)批规范化
机器学习领域有个很重要的假设就是数据的独立同分布假设，即假设训练数 据和测试数据是具有相同分布的，这是通过训练数据训练模型能够在测试集上获 得良好效果的一个基本保证。而在深层次神经网络的训练中，每批次数据会进行 串行计算和传递，包括隐藏层在内的所有神经元都参与了运算，导致隐藏层数据 的输出分布很不稳定，而随着网络层数的加深，更深层次的隐藏层数据输入受到 了多层浅层神经网络结构的影响会更不稳定，这就是所谓的“内部协变量转变” (Internal Covariate Shift, ICS)现象。这种现象的影响之一是机器模型在训练时 不能设置过大的学习率，导致训练变得困难，收敛速度也越来越慢，并且很容易 产生梯度消失或梯度爆炸的现象。批规范化是对数据归一化处理的办法，是一种 在神经网络内部对中间层输入数据的一种规范化，使隐藏层神经元的数据输入稳 定到均值为0,方差为1的正态分布。保证网络内部数据分布的稳定性，缓解了神经网络梯度消失及爆炸的现象，同时也加快了神经网络模型的训练速度，并天 然具有缓解模型过拟合的作用，批规范化算法的流程如表2-1所示。
表2-1批规范化算法
算法1 批规范化算法
输入：输入小批次特征数据X =
输出：y = {yi>y2,…,y”…,y«i}= B叫,B（X）
1 初始化批规范化参数：Y#
2 计算该批次均值方差:

3 更改该批次特征数据：
将数据分批送到神经网络模型中训练，BN算法首先对输入的每批次特征数 据计算其样本均值及方差，将其规范化为均值为0,方差为1的正态分布输入。 同时，BN算法在训练过程中不断通过反向传播更新两个批规范化可学习参数Y 和”，利用该参数将特征数据恢复成原始比例大小，保证学习模型的可靠性。这 两个参数代表了模型在所有训练数据上的泛化，即所有训练数据样本具有的可信 均值及样本方差。在每批次特征数据上进行的规范化保证了神经网络内部特征数 据的分布，使模型的训练更加稳定、收敛速度更快。批规范化一般添加在神经网 络的激活函数之前，以在激活函数之前规范化网络的特征数据。
（3） L2正则化
机器学习中过拟合是一种比较常见的现象，防止机器模型过拟合有很多种方 法，例如数据扩增、模型简化、模型集成等。还有一种比较简单且有效的方法是 加入模型参数的正则化，L2正则化则是在模型计算损失时将模型中的训练权重 以二次方的形式加入惩罚，其公式如式2-10及2-11所示。
其中，c是模型训练时的整体惩罚值,Co为模型预测误差损失，3是模型的 训练参数，久是正则化惩罚系数。将所有模型学习参数以二次方的形式加入到惩 罚项中，其导函数如式2-12及2-13所示，其中b是学习模型的偏置项。可见, 加入L2正则化项可以使网络在更新过程中不断减小模型的参数值大小，获得较
小的机器学习权重，且不对其他线性化项造成影响。
（4）深度可分离卷积神经网络
卷积神经网络通过共享卷积核的形式极大地减少了所需要的机器学习参数 量，但是在大规模的机器学习项目中，卷积神经网络会被多次使用，随着网络层 数的加深以及卷积维度的增加，传统卷积神经网络依然需要训练大量的参数。图 2-11是标准卷积的卷积核结构，其在空间维度上进行平移卷积运算，而在通道层 面上则使用不同的卷积核进行卷积计算，因此在标准的二维卷积中，每一个卷积 操作所需要学习的参数个数为：输入通道数X卷积核大小X输出通道数。

特征图权重单特征图
图2-12深度可分离的卷积神经网络结构
由图可以看到，在标准的卷积神经网络中，输出通道上的每个通道特征图是 由独立的卷积核卷积得到的，即输出通道上的每个特征图对输入数据进行完整的 计算，使得实际上的卷积网络需要消耗较多的计算资源。为了减少卷积核的数量 可以在通道层面上进一步简化，Andrew等人提出了深度可分离的卷积神经网络结构，即可以把输入数据逐通道进行卷积，再对每一个通道独立进行加权求和作 为每个输出通道上的特征图，如图2-12所示。深度可分离卷积神经网络所需要 的学习参数个数为：输入通道数X卷积核+输入通道数x输出通道数。在输入通道 数较多的情况下深度可分离卷积神经网络可以明显降低机器学习参数量及计算 成本。
2.4循环神经网络
卷积神经网络在图像处理任务中发挥着巨大的作用，在本章的第2.3小节中 己经介绍，常规的卷积神经网络是应用在二维图像上的，而通过扩展卷积核的维 度，卷积神经网络也可以应用于三维数据中，对手势视频进行分析处理。然而无 论是全连接神经网络还是广泛应用于图像任务中的卷积神经网络，它们都属于空 间域上的特征提取模型，区别只在于输入数据是一维还是二维结构，或者是扩展 了时间维度的三维卷积。而在语音、文字等数据形式中，每个词语、音节之间并 不是完全割裂的，它们具有很强的时序逻辑关系，基于视频的动态手势也是如此, 因此需要有一种神经网络模型可以在时序因果上综合考虑其时序特征，循环神经 网络(RecurrentNerualNetwork, RNN)的出现就是为处理这类任务而来的，在 处理包含时序信息的数据上RNN模型具有天然的优势，在此类应用中具有极高 的适应性。
2.4.1循环神经网络
循环神经网络的单个神经元模型如图2-13左侧所示，与常规神经元不同的 是，该神经元具有循环结构，即在时间上具有向后传递特征的功能，将其在时间 维度上展开多个神经元如图2-13右侧所示，每个神经元都向后续神经元传递当
outputs	Ot-1	Of	Ot+1

inputs	it-i	it	iz

图循环神经网络神经元结构图
前特征，后一个神经元的计算依赖于前一个神经元的输出，由此来传递时序特征 的历史信息。循环神经网络的公式如式2-14和2-15所示。当前时刻的隐输出吐
19 依赖于当前时刻的输入址及上一时刻的隐输出S—1，当前时刻的真实输出4与当 前时刻的隐输出吐有关，在循环神经网络内部则使用全连接结构，0为tanh激活 函数，羊根据不同的需求设计为归一化指数函数（Softmax函数）或S型函数等。
2.4.2 LSTM 及 GRU
长短期记忆网络（LSTM）刚是由 Sepp Hochreiter 和 Jiirgen Schmidhuber 两 人在1997年提出的循环神经网络结构的变体，长短期记忆网络的结构如图2-14 所示，其神经元包含了输入门、遗忘门和输出门三个门结构用于对每一个时间步 的特征信息进行记忆。

图2-14长短期记忆网络结构图
LSTM网络的公式如式2-16至2-21所示，其中j为输入门，/'为遗忘门，。 为输出门，。为S型激活函数，计算要记忆并向后传递的特征权重，结果为1表 示为全保留，0则表示全丢弃，［0,1］之间则表示对部分数据进行记忆。C为神经 元的隐藏状态传递，力为神经元的输岀。
i. =6（監・兀+ %.妇+勺）
门控循环单元（GRU）［仙则是由KyunghyunCho等人于2014年提出了一种 新型轻量级循环神经网络结构变体，其神经元结构如图2-15所示，与长短期记 忆网络不同，门控循环单元仅包含两个记忆门结构，分别为更新门和重置门，其 计算公式如式2-22至2-25所示。

图2-15门控循环单元神经元结构图

GRU与LSTM最大的区别在于门控循环单元不再计算遗忘与输入门，而是 通过更新门这一独立参数统一记忆前序状态以及更新当前状态的特征，即利用式 2-25保持当前状态与历史状态记忆之和为1,若历史状态选择保留的比重较大, 当前状态的记忆则会减少，不再单独设置两个门结构对前序状态和当前状态分别 记忆。该结构减少了网络学习的参数量，具有更快的训练收敛速度，实际效果略 优于或约等于长短期记忆网络结构。
2.4.3卷积循环神经网络
以上两小节中关于循环神经网络的技术综述围绕在时序特征的提取上，即循 环神经网络内部使用全连接结构提取一维特征。与二维卷积神经网络扩展至三维 卷积的思路类似，循环神经网络结构也可以通过扩展空间维度，使其匹配三维时 空数据输入。在时序信息处理中，循环神经网络可以将每一个时间步的特征传递 给后续神经元，对于图像空间，卷积神经网络是一种非常有效的特征提取方案。 因此，卷积循环神经网络（ConvRNN）结合了卷积神经网络和循环神经网络两者 的优点，利用卷积模块代替传统循环神经网络内部的全连接神经网络，同时提取空间维度特征及其时序关系。卷积循环神经网络与循环神经网络的结构保持一致, 区别仅在于输入数据与中间隐藏层数据的为二维结构，利用二维卷积操作对二维 数据进行记忆与更新。动态手势识别的关键技术在于有效选择手势的时空特征， 论文［45］对三维卷积神经网络以及卷积循环神经网络进行了结合，并加入时空特 征选择机制有效提升了动态手势识别的结果。
2.5本章小结
本章重点介绍了深度学习领域著名的卷积神经网络以及循环神经网络基础 结构，并介绍了其具体的一些变体结构例如深度可分离的卷积神经网络、长短期 记忆网络等。针对本课题基于计算机视觉的手势识别技术研究详细介绍了动态手 势视频的基本特征、传统机器学习常用方法，卷积神经网络与循环神经网络各自 在特征提取上的技术细节和优势，以及以上两种深度学习模型在三维手势数据中 的扩展应用，分别为扩展了时间维度卷积的三维卷积神经网络以及增加了二维卷 积操作的卷积循环神经网络结构的相关技术。
第三章基于时空多尺度特征融合的手势识别
3.1引言
第二章已经介绍了有关动态手势识别的基本方法，作为视频分类的一种，动 态手势视频围绕着图像特征，时间尺度上的序列关系建模等特点，形成了一系列 视频分类的优秀算法。在深度学习方法中，常将二维的卷积神经网络扩展至时空 尺度，或在循环神经网络结构中加入二维卷积结构，或两者结合进行动态手势的 识别。目前深度学习主流的方法中主要的挑战在于如何更好地利用手势视频中的 时间和空间信息并进行有效结合。在空间特征的提取上，卷积神经网络被公认为 是一种非常有效的模型，而在序列的关系建模上，循环神经网络则可能更为有效。 在时序关系建模的深度网络模型中，循环神经网络及其优秀变体例如长短期记忆 网络、门控循环单元等在自然语言处理、语音识别领域中被广泛使用，证明了该 模型在时序关系处理上的优越性能。Liang Zhang等人结合了三维卷积神经网络 以及卷积长短期记忆网络，实现了一种两者结合的串行网络结构“3DCNN + BiConvLSTM + 2DCNN”〔习，该结构结合了具有时间维度卷积的三维卷积神经网 络以及增加了空间卷积结构的卷积循环神经网络两者结构的优势，对动态手势视 频的时空特征进行有效提取及深层次的网络结构融合，可以增加神经网络的学习 能力，使得动态手势的识别准确率有所提高。然而，简单结合三维卷积神经网络 和卷积循环神经网络的串行结构导致了机器学习模型参数量和学习成本的增大， 本文基于该串行结构提出了卷积神经网络与循环神经网络结构的高效结合办法。 提出时空多尺度三维卷积神经网络结构对手势时空特征进行提取，并实现了一种 ConvGRU结构的变体，有效融合手势的长短期时空特征。本章首先详细介绍时 空多尺度的三维卷积神经网络模块以及基于卷积门控循环单元结构的时空多尺 度特征融合变体网络，接着通过该串行结构介绍本章算法的整体框架。最后通过 实验对本章内容进行验证及分析，对比说明本章方法的有效性。
3.2算法模块设计
3.2.1时空多尺度三维卷积神经网络
本节介绍本章提出的时空多尺度三维卷积神经网络特征提取模块。动态手势 视频作为一种三维数据，图像是其基本特征，因此卷积神经网络是应用于手势视 频分类的有效办法。在本文的第二章中已经介绍过，将二维卷积神经网络的卷积操作扩展至时空图像序列，即变成了具有时空信息提取的三维卷积神经网络。本 文的三维卷积神经网络结构参考了 Tran等人于2015年提出的C3D网络结构， 该结构如图3-1所示，共包含了 8个三维卷积层、5个三维池化层以及2个全连 接神经网络层加Softmax激活函数的16层神经网络结构。C3D网络中所有的三 维卷积核均为3x3x3大小，步长均为1；池化层则是采用最大池化，除第一个池 化层的大小及步长采用1x2x2的尺寸外，其他池化层均采用2x2x2的池化结构， 避免了时序特征过早地融合导致时序特征的减少。

图3-1 C3D卷积神经网络结构
本文使用的三维卷积神经网络模块参考C3D卷积神经网络结构，为减少学 习参数，本文采用包含批规范化层在内的总共十层的神经网络结构，如图3-2所 示。本文设计的时空多尺度三维卷积神经网络基本模块共包含有3个三维卷积网 络层、3个批规范化层以及3个ReLU激活函数层。其中3个卷积层的卷积核的 大小分别为3x7x7和两个3x3x3结构，第一层使用较大的空间维度卷积核其目 的是使神经网络具有更大的空间维度感受野，匹配手势数据输入。其次，由于卷 积神经网络被认为是在空间特征提取上非常有效的网络结构，因此仅在卷积结构 设计的最后一个池化层融合视频的短期时序关系，在三个卷积核中分别使用了 1x2x2及两个1x1x1的神经网络步长，以此来达到防止时序信息过早融合的作 用,而将长时间时序关系的特征融合交给更有效的循环神经网络模块。在3DCNN 模块中最后加入了最大池化操作，融合部分短期时空特征并减小特征图的大小， 池化层采用2x2x2大小的池化结构。

图3-2本文的三维卷积神经网络设计
将卷积神经网络通过扩展卷积维度而应用于时空序列中还有一个著名的神 经网络结构，即由Shaojie Bai等人于2018年提岀的TCN时间卷积神经网络网 络RS。时间卷积神经网络包含了因果卷积和膨胀卷积两种特殊的卷积结构。其模 型结构如图3-3所示，每个时间步的卷积输出只与其前面的序列有关，因而称之 为因果卷积。而利用膨胀卷积模块设计，使其扩大了时间维度上的视觉感受野。 在堆叠的卷积结构中，越深层的卷积层具有越大的时间维度感受野。本文参照时 间卷积神经网络的膨胀卷积思路，设计了一种时间维度三维膨胀卷积与常规三维 卷积网络结合的时空多尺度特征提取结构，该结构如图3-4所示，其三维膨胀卷 积模块与本章图3-2中设计的三维卷积网络结构保持一致，不同之处在于三维膨 胀卷积部分具有三个时间维度的空洞，其中的膨胀大小分别设置为lxlxk2xlxl
24

以及4x1x1,即时间维度膨胀率为1、2、4三维膨胀卷积结构。其他层次如批规 范化层以及激活函数等均与常规支路的三维卷积神经网络结构保持一致。该时间 维度膨胀卷积网络与常规三维卷积神经网络相互配合，获得一大一小不同时间尺 度的三维时空特征。在此基础上利用""I的卷积核进一步融合两个不同时间 尺度的三维卷积神经网络，组成完整的时空多尺度三维卷积神经网络模块。
3.2.2卷积GRU网络结构的变体
在本文的第二章已经介绍了深度神经网络中经常使用的卷积神经网络以及 循环神经网络结构。其中循环神经网络非常适合用于时序信息的处理中，为了使 循环神经网络适应三维结构的输入，研究人员在循环神经网络结构的基础上加入 了空间维度卷积功能，实现了卷积循环神经网络结构。而随着循环神经网络发展 出了许多优秀变体，如本文在第2.4.2小节中介绍的长短期记忆网络LSTM以及 门控循环单元GRU等，在适配三维数据输入的循环神经网络结构中，同样具有 卷积长短期记忆网络(ConvLSTM)与卷积门控循环单元(ConvGRU)等优秀变 体结构，其中，ConvLSTM的公式如式3-1至3-6所示：
其中，“ * ”表示二维卷积，“。”是哈达玛乘积。在卷积长短期记忆网络中， 利用输入的原始图像以及隐藏层的二维特征拼接后进行卷积操作，分别计算得到 二维结构的忘记门、输入门以及输出门三个记忆参数，再与上一个时间步的特征 图进行像素级哈达玛乘积得到更新后的特征图，对特征图的每个像素点进行单独 记忆。在门控循环单元中，则是分别计算二维结构的更新门以及重置门，利用这 两个门控单元对隐藏层的二维特征以及输入图像进行更新记忆。在卷积循环神经 网络的结构中，用作记忆加权的门控单元、直接参与计算的原始图像输入以及隐 藏层神经元输出都是具有二维图像数据结构，在进行记忆的过程中，通过卷积操 作获取每个像素点的记忆权重，通过哈达玛乘积完成对每个特征像素点的记忆， 并通过循环功能向后传递。
在本文的模型结构中，采用时间维度膨胀卷积的时空多尺度三维卷积神经网 络提取了不同时间尺度上的手势时空特征，该特征表示了手势的空间信息以及短 期时序关系，但没有对手势序列的长期关系进行建模，在时间尺度上没有进一步 融合。本章基于该短期时空多尺度特征，利用卷积循环神经网络进一步融合手势 视频的长短期时序关系。而传统的卷积循环神经网络在进一步融合时序关系的同 时也对空间信息进行了过多的卷积记忆操作，为了减少机器学习参数量、降低学 习成本，并保持循环神经网络在时序关系建模上的优势，本文设计了一种卷积门 控循环单元结构的变体(ConvGRU varient)来对动态手势的时空特征进行高效 融合，该变体公式如式3-11至3-16所示。变体采用全局平均池化功能在空间维 度上进行平均池化，仅保留时序及通道维度作为手势的短期时空关系表征，计算 卷积门控循环单元内部的更新门与重置门，接着采用全连接神经网络单元代替二
26

维卷积运算得到当前时间步的记忆更新参数，其中的权重是与通道数相等的一维 向量，在空间维度上对所有像素进行统一的记忆加权操作从而弱化空间维度上的 像素独立记忆，进一步减少机器学习的参数量、增强模型的泛化能力，并强化了 卷积门控循环单元在时序关系上的特征融合能力，使循环神经网络结构发挥出其 在时序上建模优势。
Xt=GlobalAvgPooling(Xt)
(3-11)
Ht_x = GlobalAvgPooling(Ht^x)
(3-12)
Z严b（化•区+%.耳1+氏）
(3-13)
"b（昭•同
(3-14)
r, = tanh(殓 *Xt+rto (Whh *
(3-15)

(3-16)

3.3算法整体框架
本章提出的算法整体框架基于Liang Zhang等人提出的“3DCNN + BiConv- LSTM + 2DCNN ”结构，该结构充分结合了三维卷积神经网络、卷积循环神经 网络以及二维卷积神经网络三者在动态手势识别中的优势，提取动态手势视频中 的时空特征以及对时空特征进行有效融合，在很大程度上提升了动态手势视频的 识别准确率，该框架的结构如图3-5所示。

输入规范化

图3DCNN+BiConvLSTM+2DCNN” 网络结构
首先最底层的输入层对输入数据进行规范化，再通过一个三维卷积神经网络 结构提取手势的浅层时空表征,将浅层时空特征送入到两个串行的双向卷积长短 期记忆网络(BiConvLSTM)中，利用二维卷积神经网络计算每一个时间步上的 时空特征，即具有不同长度时序记忆的二维空间特征，最后利用全连接神经网络 以及Softmax函数对动态手势进行综合分类。
本章基于时空多尺度特征融合的算法结构为“3DCNN&T-Dilated + Conv- GRU variant + 2DCNN"结构，基于时间维度膨胀卷积的时空多尺度三维卷积神 经网络作为前置，与空间维度一致加权的两层卷积门控循环单元结构变体结合， 进一步融合了手势的长短期时空特征，接着通过一个二维卷积神经网络结构计算 不同时序长度的时空特征融合结果，最后利用全连接网络以及Softmax函数对手 势进行最后的分类。Softmax函数的公式如式3-17所示，其中彳为第i个类别节 点的特征输出值。C为全连接神经网络的输出神经元个数，即为手势的类别总数。 通过Softmax函数可以将多类别的输出值转换到［0, 1］的概率区间，所有类别的 概率和为1,即为手势分类的概率分布。
Softmaxiz^ =花一	(3_17)
同时，为了进一步减少机器学习的参数量，保证模型的识别性能，本章结构 中还使用了深度可分离的卷积神经网络代替传统二维卷积神经网络结构。深度可 分离的卷积网络将二维特征图的空间维度与通道维度分离，分别计算每个通道上 的特征图卷积结果，再利用1X1卷积核对特征的通道数进行变换，在本文第2.3.2 小节卷积神经网络常用技术中已作介绍。
数据流经过最后一个卷积神经网络模块之后，具有时间、空间(长、宽)以 及通道四个维度，本章利用全局平均池化函数来进一步融合输出特征的长短期时 空特征，即在时空维度上进行平均池化操作，仅保留其时空特征的通道特征，该 特征代表了动态手势视频不同时空尺度上的特征融合。连接全连接神经网络训练 手势的分类器，将手势特征映射到手势类别的一维向量，代表手势属于各个类别 的概率值，选取最大可能性的手势作为最后的分类结果。在模型训练时使用多分 类的交叉爛损失函数来计算模型的分类误差，其公式如式3-18所示，其中，夕为 模型预测真实标签时的输出概率。
•Loss = -log®)	(3-18)
实验中计算的准确率和损失值为数据集验证集上的模型效果，即正确分类数 在总数据集上的占比，以及验证集上样本损失的平均值。
3.4实验及结果分析
3.4.1数据集
手势识别领域有很多可用的公开数据集，例如大型的通用手势识别数据集 Jester^],更复杂生活场景下的手势识别数据集ChaLeamLAPIsoGD^,以人脸 为第一视角的车辆控制手势识别数据集EgoGesture^]等。以下简要介绍一下本文 中所使用的两个大型公开手势识别数据集。
Jester: Jester数据集是一个非常大型的手势识别数据集，其用电脑摄像头收 集预设的密集手势视频剪辑。该数据集总共包含148092个手势识别视频，训练 集、验证集和测试集的样本比例为&1：1。共包括25个具体的手势以及2个不定 手势用于机器学习其他未知的模糊手势，数据集示例如图3-6所示，其是一个动 态手势顺序形成的十帧画面。
ChaLearn LAP IsoGD: IsoGD数据集由Jun W等人构建，其的目是使手势 识别数据集更接近于现实的使用场景。共包含有47933个RGB-D （RGB图像和 深度信息）形式的手势识别视频，由21个不同的人分别表演249种手势类别。 为了保证训练数据集的泛化性，来自同一个人的训练样本不会岀现在验证集和测 试集上，其数据集手势示例如图3-7所示
3.4.2数据增强策略
在计算机视觉任务中，常使用数据增强技术来降低模型的经验风险，防止模 型发生过拟合。卷积神经网络在一定程度上是具有某种平移不变性的，即模型学 习到的特征与物体所处的空间位置无关，即使物体在空间中移动了一些位置，卷 积神经网络也依然能够学习到物体的某些通识性特征。有研究表明，卷积神经网
29 络可以在局部学习到物体的纹理等特征，而非物体的整体形状，这是卷积神经网 络具有平移不变性特点的原因，而在更大范围内的旋转、缩放等变化对模型的泛 化能力有着巨大的考验。计算机视觉上的数据增强技术包括裁剪、翻转、旋转、 缩放和扭曲等几何变换，及像素扰动、光照调节、对比度调节等环境变化。通过 计算机视觉中的数据增强技术可以增加机器学习的训练样本,扩充样本的多样性, 加强模型对抗其非通用性特征的误学习能力，增强模型的泛化性能及稳定性。在 基于动态手势视频的识别任务中，由于输入数据是三维视频结构，即具有时间及 空间两种不同特征，因此，动态手势识别中的数据增强技术也分为空间数据增强 和时序数据增强。
在本文中，由于数据集采用大规模的手势识别数据集，同时在训练中采用计 算机视觉方法中常用的多轮训练策略，即多次重复训练同一份数据集以增强机器 模型的学识。为了使模型能够更好地学习到动态手势的空间多样性，避免经验性 风险，本文在实验中对输入的每批次训练数据进行空间域随机裁剪操作，这样在 多轮(epoch)训练同一份数据集的过程中，由于引入了空间维度的随机裁剪，使 得训练集天然具有空间裁剪和空间平移的数据增强效果。本文采用的空间域随机 裁剪算法如表3-1所示，即首先在图像中较长的一边随机裁剪形成正方形的原始 图像输入，再对图像进行缩放，调整至112x112x3的空间域大小。另外，本文在 进行空间域数据增强的同时对原始输入数据进行了规范化，即计算出数据集整体 在每个通道上的像素平均值，采取减去其通道平均值的做法来对原始图像进行规 范，加快神经网络模型的训练并提升模型的识别效果。
表3-1动态手势的空间数据增强
算法2	动态手势的空间数据增强
在时序维度上，相同的手势也可能有较大差别，例如不同表演者演示挥手与 “比ok”的手势在演示时长上就有一定差别，其每个动作完成的时间是不尽相 同的，因此尽管是在同一帧率摄像头前表演的各个动作其视频序列总长度也很难 保证一致。为了能够在不同的数据集上进行知识迁移并使模型具有更加广泛的场 景适用性，保证模型的稳定，本章针对两种不同的手势识别数据集参照其平均帧 数分别设置了不同帧数的固定长度对原视频进行抽取。同时，在时序维度数据增 强上采取随机均匀采样法来处理数据帧的选择问题，在保证选取序列中包含特定 手势的同时保证了视频帧率在时间维度上的稳定。由于采用了时序维度上的随机 均匀采样，在多轮训练同~个数据集时增加了样本的多样性。本文采用的随机均 匀采样时序数据增强算法如算法3所示，将原始视频序列厶站。均匀分成”等份， 在每等份中随机选取其中一帧作为该等份的抽取帧组成模型的输入序列厶eg。
表3-2随机均匀采样时序维度数据增强算法
算法3 随机均匀采样时序维度数据增强算法
输入：
输出：
原始视频序列厶劭。，固定序列长度" 模型的输入序列Lseq
1
计算原始视频序列与固定序列长度之比：div =floor(len(Lgo) /砂

3.4.3实验设置

针对本章提出的时空多尺度三维膨胀卷积与空间维度一致加权的卷积门控 循环单元结合的时空多尺度特征融合算法，本文在Jester和IsoGD两个数据集上 进行了多组实验，验证时空多尺度三维卷积神经网络时空特征提取的有效性以及 卷积门控循环单元变体时空特征融合的效果，本章还同时对比了其他动态手势识 别算法的分类效果，验证本章整体算法结构的有效性。在模型训练时，本文首先 在Jester数据集上进行了 30轮的基础训练，再将Jester数据集上训练好的模型 权重迁移至IsoGD数据集上进行微调训练。微调学习是机器学习领域常用的训
31 练方法，在一个大型的数据集上完全训练一个新模型，再用训练好的模型参数继 续训练样本数量较少的小数据集，在小数据集上微调机器学习模型，可以降低小 数据集模型的过拟合风险，同时通过在小数据集上微调训练模型的权重可以使模 型适应小数据集的数据分布，实现快速收敛的目的。
为了防止模型发生过拟合，本文在训练模型时对Jester数据集和IsoGD数据 集分别设置了不同强度的L2正则化学习参数惩罚，对模型参数大小进行限制。 同时为了让模型更好地收敛到全局最优点，训练时使用了多项式衰减的学习率， 初始学习率设置为0.001,结束学习率设置为io-6,实验中采用随机梯度下降 (Stochastic Gradient Descent, SGD)算法对模型进行优化。而由于Jester数据集 和IsoGD数据集在平均帧数上有所差别，本文分别设置了 16帧和32帧的固定 长度作为模型的序列输入。实验中为了保证图形处理器(Graphics Processing Unit, GPU)的使用效率，在训练Jester数据集和IsoGD数据集时设置了相同的批次大 小，实验中的超参数一览表如表3-3所示。
表3-3模型训练超参数一览表
Mr
集


3.4.4实验结果
(1) 微调训练方案对比及正则化参数实验
本文使用Jester和IsoGD两个公开的大型手势识别数据集进行多组实验，其 中Jester数据集仅包含RGB视频一种模态,IsoGD数据集则同时含有RGB手势 视频和深度视频两种数据模态。RGB视频和深度视频是两种物理意义具有较大 差异的数据形式，因此在Jester数据集上训练得到的模型并非完全可以用于 IsoGD数据集上的深度模态进行微调训练。同时，IsoGD数据集的RGB视频和 深度视频虽然属于两种不同的数据形态，但其属于同一个数据集，数据特征的分 布可能具有一定的相似性。因此本章设计了三种微调学习方案来验证不同数据集 预训练方法在IsoGD手势识别数据集深度视频中的有效性，三种具体的微调训 练方案为：(1)方案1 ： Jester数据集的RGB形态预训练模型微调至IsoGD数据 集的深度视频形态进行训练；(2)方案2： IsoGD数据集的RGB形态训练模型 微调至其深度视频形态中训练；(3)方案3：不采用任何预训练方法而直接在 IsoGD数据集深度视频形态上训练模型。实验(1)中在微调训练时仅对模型最
32
后一个全连接层神经网络不进行权重迁移。在训练中设置IsoGD数据集模型的 L2正则化参数惩罚系数为0.0004,在Jester数据集上预训练时设置L2正则化系 数为O.OOOL将以上三种微调训练方法在IsoGD数据集的深度模态上进行微调 训练。其微调训练模型在验证集上的识别准确率及其分类损失曲线如图3-8（上） 和3-8 （下）所示。
图3-8 IsoGD数据集深度模态微调学习方案对比：识别精度（上）、损失曲线（下）
可以看到，三种微调训练方案的训练结果具有较大差异。其中，基于Jester 数据集和IsoGD数据集RGB形态预训练的微调学习方法具有更快的训练收敛速 度和更高的识别准确率，且方案（2）的识别效果优于方案（1）,说明在IsoGD 深度模态下基于其RGB视频形式的模型预训练方法比基于Jester数据集的预训 练方法更加有效。尽管RGB视频与深度视频模态具有不同的物理意义，但其时 空特性具有一定的相似性.Jester数据集虽然具有更大量的训练样本，其微调学 习效果不如IsoGD自身的RGB数据集预训练模型。而方案（3）由于没有采用 预训练微调操作，其模型训练的收敛速度和识别准确率不如前两者。
本文实验中Jester和IsoGD两个数据集具有不同的数据分布，而IsoGD数 据集的RGB视频和深度视频两种模态也具有不同的表现形式，因此在实验中设 置不同强度的L2正则化参数惩罚强度是必要的。为了探究不同强度的L2正则化参数惩罚对模型泛化性能的影响，本文对IsoGD数据两种不同的数据模态设 置了不同的L2正则化参数惩罚来对模型进行训练。本文在Jester数据集上设置 了强度为0.0001的L2正则化参数惩罚系数对Jester数据集进行了 30轮的模型 预训练，将Jester数据集上训练好的模型迁移至IsoGD数据集的RGB模态进行 正则化参数微调学习实验，再将最佳的RGB模态模型迁移至其深度模态中进行 微调实验，其RGB模态和深度模态微调训练的实验结果如图3-9所示。

图3-9不同L2正则化系数对IsoGD数据集微调学习识别准确率的影响
由图可知，适合用于IsoGD数据集两种数据模态微调训练的最佳L2正则化 系数分别为0.0003和0.0004,其在RGB视频和深度视频模态下的识别准确率分 别达到了 54.62%和55.11%。在本文后续的实验中，将使用该参数训练所有基于 IsoGD数据集的手势模型。
(2) 验证时空多尺度特征融合算法独立模块结构的有效性
时空多尺度三维卷积神经网络利用时间维度上的膨胀卷积结构设计，获得不 同时间尺度的手势时空特征，结合常规三维卷积结构支路共同提取到不同时间尺 度的手势三维时空结构特征，通过连接1X1X1大小的卷积核在通道层面上对不 同时间尺度的手势时空特征进行融合。为了验证本章时空多尺度三维卷积神经网 络在特征提取上的有效性，本文通过实验对比结合了三维卷积神经网络与卷积长 短期记忆网络的其他优秀算法。其中，论文［50］使用了 “Res3D + ConvLSTM + MobileNet”的串行网络结构，其使用三维残差卷积网络代替传统3DCNN进行特 征提取操作，提取了深层次的手势动态特征。本文通过实验对比其三维卷积模块 在本文方法中的网络参数量变化及其在IsoGD数据集验证集上识别准确率的情 况验证本文模型中三维卷积神经网络单模块结构的有效性。为了验证单模块结构 的有效性，实验中采用控制变量法设置模型结构，并采取相同的训练策略，即首 先在Jester数据集上进行模型的预训练，再微调至IsoGD数据集，对比各个模型 在验证集上的识别准确率情况。其中用于对比的三种模型结构为：(l)“Res3D + ConvLSTM+ MobileNet”网络结构，即三维残差卷积神经网络结合卷积长短期记
忆网络的模型方法。（2）使用本文的常规三维卷积神经网络结构代替三维残差卷 积神经网络模块，即“3DCNN + ConvLSTM + MobileNet”的模型方法。（3）使 用本章提出的时空多尺度三维卷积模块代替三维残差卷积神经网络模块，即
“3DCNN&T-Dilated + ConvLSTM + MobileNet”的模型结构。其识别精度的实验 对比结果如表3-4所示。
表3-4三维卷积网络模块识别精度对比（％）

表3-4中的参数量为三种模型结构中的卷积神经网络模块的参数量对比。可 以看出，本文提出的时空多尺度三维卷积神经网络极大地降低了三维卷积神经网 络模块的机器学习参数量，其参数量仅为三维残差卷积神经网络结构的三分之一。 在将三维残差卷积神经网络替换成常规三维卷积神经网络结构后其RGB模态的 识别准确率有轻微下降，其原因是机器学习参数量的减少导致了模型学习能力的 降低，而在替换成时空多尺度的三维卷积神经网络结构后，本文模型在IsoGD数 据集的两种数据模态上的识别准确率均有所提高，在Jester验证集上的识别准确 率也非常接近，证明了本文时空多尺度三维卷积神经网络模块可以在明显降低机 器学习参数量的同时提升动态手势识别的精度。
在以图像序列作为输入的三维结构动态手势识别算法中，除了三维卷积神经 网络可以用于提取手势的三维时空特征外，卷积循环神经网络结构也可以使用。 其在提取手势视频时序关系的同时也对手势的空间特征进行着卷积记忆操作，提 取手势的空间特征。然而直接利用卷积神经网络来扩充循环神经网络内部的空间 特征处理不仅导致了机器学习参数量的直线增加，还可能导致模型变得过于复杂 而产生过拟合风险。本章第3.2.2小节提出了空间一致加权的卷积门控循环单元 结构变体，为了验证该变体结构的有效性，采用控制变量法分别对比了如下三种 网络结构模型的参数量及其在数据集验证集上的识别准确率：（1）论文［50］中使 用的“Res3D + ConvLSTM + MobileNet”网络结构。（2）本文基于时间维度膨胀 卷积的时空多尺度特征融合方法，即“ 3DCNN&T-Dilated + ConvLSTM + MobileNet”模型。（3）本文将卷积长短期记忆网络替换为空间一致加权的卷积门 控循环单元结构变体的时空多尺度特征融合模型，即“3DCNN&T-Dilated + ConvGRUvariant+ MobileNet"方法。该对比实验用于验证本文提出的卷积循环
35

神经网络变体结构在动态手势时空特征融合中的作用，实验对比结果如表3-5所
zj\ O
表3-5循环神经网络模块识别精度对比（％）

表3-5中的参数量为三个不同模型中循环神经网络模块的机器学习参数量， 由表可以看出，由于去除了卷积循环神经网络内部对于空间中每个像素点的记忆, 机器学习参数量得到了明显减少，因此本文提出的卷积门控循环单元结构变体提 高了动态手势的识别计算效率，降低了模型的计算成本。同时，由表可以看出其 手势识别精度也得到了提高，包括动态手势的RGB和深度视频两种数据模态模 型，由此证明了本章基于时空多尺度特征融合的ConvGRU变体模块的有效。
（3）对比现有其他手势识别方法的准确率
以上实验分别验证模型 “3DCNN&GDilated + ConvGRU variant+ MobileNet” 中时空多尺度三维卷积网络以及卷积GRU变体结构两个模块的有效性，验证了 本文提出的时空多尺度特征融合方法在降低机器学习参数量的同时，提升了手势 识别的效果。本文还对比了现有其他基于卷积神经网络的手势识别模型，对比结 果如表3-6所示。其中，ResNet50[51]是二维残差卷积神经网络，PyramidalC3D[52] 是三维金字塔卷积神经网络，C3D®]是Yunan Li等人提出的基于三维卷积神经 网络的手势识别模型，Res3Dei是三维残差卷积神经网络。
表3-6与其他模型在IsoGD验证集上的识别精度对比（％）

表3-6可以看出，本文提岀的基于时空多尺度三维卷积神经网络结合卷积门 控循环单元变体的网络结构在动态手势识别中具有优势，其对比二维残差卷积神 经网络、三维神经网络以及三维残差卷积神经网络等独立模型，识别精度具有较 大提升，而对比三维卷积神经网络结合卷积长短期记忆网络的其他模型，本文模 型不仅有效减少了网络的学习参数，提高了模型计算效率，还有效地融合了手势 视频中的时空特征，提高模型的泛化能力和动态手势识别的准确率。
3.5本章小结
本章针对动态手势视频中的手势时空特征，创新性地提出了时空多尺度特征 融合的网络模型，其充分利用三维卷积神经网络提取手势视频不同时间尺度的时 空特征，并通过本文提出的空间一致加权卷积门控循环单元进行融合，实现了手 势视频时空特征的高效提取，本章主要内容归纳如下：
(1) 在手势视频三维卷积神经网络结构中提出在时间维度上引入空洞，捕 捉不同时间尺度的手势时空特征的结构思路，并进一步利用1X1X1大小的卷积 神经网络融合不同尺度的短期时空特征。
(2) 改进卷积循环神经网络结构的空间加权方式，提出了一种卷积GRU结 构的变体，在减少卷积GRU机器学习参数量的同时更有效地融合了动态手势的 时空关系。
(3) 为了验证本章各个模块以及模型的有效性，进行了多组分模块对照实 验，在公开数据集Jester和ChaLeam LAP IsoGD上分析对比了本章算法的参数 量以及手势识别精度。
第四章基于注意力机制前置的手势识别
4.1引言
时空多尺度特征融合网络就三维卷积神经网络与卷积循环神经网络结构设 计了一种结合两者优势的手势识别模型，在明显减少学习参数量的同时实现了手 势识别精度的提升。该方法从整体结构上对手势视频的时空特征进行了提取，而 在手势视频中，手部通常位于摄像机视野的一定范围内运动，且在运动过程中手 部也有可能偏离中心位置而靠近边缘，甚至可能会超出摄像机的录制范围，因此 需要对手部进行检测定位。在传统的动态手势识别技术中，其流程包括手部检测、 手势特征提取和手势分类三个步骤。手部检测是为了检测手势的空间位置，排除 无关背景噪声等干扰。在OkanK等人研究的实时手势识别方法［旳中，动态手势 识别也被分为两级神经网络结构，第一级网络结构采用轻量级的卷积神经网络来 判断当前数据流中是否包含手势，第二级卷积神经网络则采用大型的网络结构对 数据流中的手势进行具体分类，该研究工作保证了输入到动态手势视频分类器中 的图像序列包含具体的手势行为。在计算机视觉方法中，基于深度学习的注意力 机制也可以让模型关注到图像中手势的具体位置而应用在端到端的动态手势识 别算法中。本章方法基于时空多尺度特征融合网络结构“3DCNN&T-Dilated + ConvGRUvariant + 2DCNN"引入时空注意力机制前置，采用改进的时空注意力 机制对手势的视频数据输入进行处理，代替手部空间位置检测以及手势视频关键 帧提取的操作，设计了针对视频输入的时空注意力机制数据处理办法。接着本章 还针对手势识别数据中的RGB和深度两种模态进行了手势双模态识别的技术研 究，利用RGB-D两种数据模态的手势识别模型进行多任务迁移学习训练，实现 其知识互补，提升单模态以及双模态手势融合的识别精度。最后通过实验验证本 章方法的有效性并对本章内容进行总结。
4.2基于改进的时空注意力模型
4.2.1注意力方法概述
通常来说，人们在看到一张图片的时候，会首先整体浏览一下图片，然后将 目光重点停留在图片中的某处或某几处之中，例如图片中的人、动物、茶杯以及 其他物品等。在做翻译时，人们会根据整体进行翻译，但对具体的某句而言，会 将理解的重点放在重要的几个词上，例如描述情感的词、物体属性描述的词等，
而轻微忽视掉其中冠词等不是特别重要的词语。深度学习方法中的注意力机制正 是从人类的这一基本行为中发展而来，让机器模仿人类观察事物的特点，重点关 注其中比较重要的数据信息。例如在手势识别场景中，视频的背景信息变得次要， 提取过多此类信息并不能很好地提高模型识别的准确率。在计算机视觉领域，图 片分类则是一种常见的与注意力行为挂钩的学习任务，例如区分图片中鸟类属于 啄木鸟、猫头鹰或是其他种类，此时区分鸟类具体类别的重点是识别出鸟类的嘴 型、爪形以及羽毛等局部特征，而对于图片中花草树木等背景则只能作为一种辅 助信息。由此可见在图像识别中引入注意力机制是一种非常关键的操作，可以让 深度学习模型关注到其中更加有用的局部信息。
在深度学习模型中的注意力方法分为软注意力和硬注意力两种，其中硬注意 力方法的注意力权重只有0和1两种数值，即选择一部分特征作为重要信息保留 而将另一部分非重要信息完全忽略。现有的深度学习项目中常使用软注意力模型 来对特征进行局部关注，其通过计算每个特征的权重，将重点关注在其中的重要 信息，而减弱其他位置信息的影响。软注意力模型的权重范围是［0,1］内的所有数 值，更重要的是，软注意力机制是一个天然可微的注意力结构，可以很自然地加 入到深度学习网络中进行反向传播学习，并且在学习中不完全丢弃掉其他信息， 一定程度上降低了模型误判带来的经验性风险，保证了模型效果的稳定性。本文 也采用软注意力方法来实现端到端的手势识别。在计算机视觉任务中，注意力方 法可以具体分为空间域注意力、通道注意力以及混合域注意力三种，分别对应于 图片的长宽以及通道两种数据维度及其混合：
(1) 空间域注意力
空间域注意力可以理解为让神经网络模型关注到图像中的局部空间位置，例 如图像上的实体处于图片中的具体位置，以此来加强实体区域的特征，而弱化其 他位置上的无关信息。文献［56］是一个图片描述任务，其神经网络模型通过重点 关注其中实体所在的空间位置而获得实体的位置关系，进一步用于描述图片中各 个实体的空间属性。
(2) 通道注意力
在二维图像结构中，除了可以提取其空间域的特征之外，还有用于描述图像 风格的通道信息，例如实际的图片通常都是具有红绿蓝三种颜色的彩色图像，即 RGB彩色图。通道注意力则是通过重新标定各个通道的权重，描述每个通道的 重要性程度，重点关注其中更加重要的通道。典型的网络如压缩激励网络(SENet) Bl,其通过对每一个通道上的特征图进行全局平均池化，再利用全连接神经网络 得到与通道数大小一致的注意力权重向量，通过相乘操作在通道维度上对数据进 行重新标定和修正。
40
(3)混合域注意力
混合域注意力模型则是对图像的空间及通道维度同时进行重标定，让神经网 络模型可以对图像的空间以及通道同时设置注意力权重进行关注，这是一种三维 结构的图像注意力方法。
在机器翻译、语音识别等任务中，不同于图像中空间和通道的三维数据，其 具有时间及空间两种信息。在机器翻译应用中，注意力模型主要用于关注哪个词 更具有代表性，这是一种时间维度上的注意力。与此相似，本文中用于手势识别 的视频数据也是一种具有时序关系的三维结构，视频中的每帧图像都与其前面的 帧具有紧密的联系，因此在手势视频的分类任务中，注意力机制可以应用于空间、 时间以及通道三种不同的维度，本章着手于视频输入数据，设计基于输入数据的 手势时空注意力模型。
4.2.2基于原始视频输入的空间残差注意力
注意力机制并不属于一种具体的机器学习算法，而是属于一种算法思维或者 方法论，它没有严格的数学公式定义。基于深度学习的注意力机制用于表征神经 网络对于输入数据特定位置的信息关注，在手势识别应用中则表现为对手部及其 手势图像帧的关注。本章针对手势识别应用中的时空注意力模型进行改进，在基 于时空多尺度特征融合模型的基础上提出将时空注意力机制放置于手势视频输 入侧用于提取原始视频中手势的关键信息，并将注意力加权处理过的手势视频送 入下一级的时空多尺度融合分类器中进行识别，其流程如图4-1所示

图4-1基于时空注意力机制前置的手势识别
空间注意力机制结构设计：在二维图像领域，空间注意力是最早应用的注意 力模型，具有最广泛的使用场景，在图片描述任务中，Kelvin Xu等人将空间注 意力机制应用于二维图像上［殉，定位图片中实体的空间位置，以方便机器模型描 述实体间的位置关系。空间注意力机制常使用普通的卷积神经网络作为其注意力 结构模型，Fei Wang等人于2017年提出了其二维图像领域中的残差注意力模型 结构国】，论文指出传统的注意力机制方法可能导致机器学习的特征遭到实质性 的破坏，例如已学习到的图像特征在经过与注意力权重矩阵相乘后导致特征效果 变差，机器学习特征提取将严重依赖注意力神经网络结构的稳定性。二维残差注 意力网络结构如图4-2所示，其包含两条特征提取支路，主路完成对图像特征的 提取，例如内置的卷积神经网络、Inception®】、ResNeXt®】等神经网络结构。辅
下采样
图4-2残差注意力网络
助支路为注意力权值计算模块，采用U形网络结构先将二维图像空间特征压缩， 提取到深层次的图像特征后再对其进行扩张，得到与主路特征图大小相同的注意 力权值矩阵，再与主路特征图进行像素级相乘得到网络的注意力特征，通过残差 结构与主路的特征图相加获得残差注意力特征，其计算公式如式4-1所示。其中， H(x)为残差注意力网络的图像特征结果，M&)是与主路特征图大小相同的注意力 权值矩阵，F&)为主路提取的二维图像特征，X代表二维特征图的像素值。7和c 分别代表了图像所具有的空间及通道维度。该残差短接的注意力方法避免了注意 力模型训练前期的不稳定因素对模型造成严重影响，保证了主路特征提取的可靠。
H.c(x) = (l+M.c(x))^F.c(x)	(4-1)
在二维残差注意力神经网络结构的基础上，本章设计了用于视频数据处理的 空间维度注意力结构，用于对视频中的每一帧进行独立的数据处理，实现手势视 频的空间关注。用于手势视频数据处理的空间维度注意力结构如图4-3所示，将 视频数据在时序维度上展开，形成连续帧图像组成的手势序列，利用残差注意力 网络对每一帧图像进行并行化处理，上支路表示残差注意力网络结构中注意力权 值矩阵的计算，采用U型网络结构。在获得图像序列的空间注意力权重之后使 用S型激活函数将输出限制在［0,1］区间，保证了注意力权值矩阵的物理意义。 最后通过重塑函数将图像序列重塑为三维视频结构，与下支路短接的原始视频输 入相加，得到本章空间注意力模块处理的视频数据。
池化	池化	上采样	上采糕
输入一~ »肖莖块一* 一＞盛差统：〉一＞ 我墓块一務誉块一＞〈►喪着块’”早一辛一》输出
图4-3手势;a频数据处理的空间维度注意力网络
本章基于时空多尺度特征融合网络的空间维度注意力数据处理应用于0均 值规范化后的手势视频，代替手势识别中的手部检测流程，而将手势的时空特征 提取交给更擅长的手势时空多尺度特征融合网络。其中，空间维度注意力网络的 残差块设计为二维残差卷积神经网络结构，其结构如图4-4所示。

图4-4空间维度注意力网络残差块结构设计
其中，图中的in和out分别代表了残差块整体结构的输入通道数和输出通 道数，使用该通道数作为其内部二维卷积网络的卷积核数目，以此来改变卷积块 的输出通道数。其内部的三个卷积网络分别设置了 1x1, 3x3和1x1的卷积核大 小，其步长均设置为1。另外，在残差网络结构中若短接支路与残差块最后输出 的通道数不一致，将使用1x1的卷积核改变其短接支路的输出通道以匹配特征 提取支路输出。本章空间维度注意力网络中的前4个残差块输出通道数设置为 64,最后一个残差块的输出通道数设计为3以匹配视频短接支路的输出。
4.2.3基于空间注意力机制的时间压缩激励网络
在手势识别中的注意力机制包含了通道注意力、空间注意力以及时序注意力, 其分别对应于通道、空间以及时间三个维度。经典的压缩激励网络（SENet）应 用于二维图像的通道维度，其结构如图4-5所示。利用全局池化函数将空间维度 压缩形成一维向量，接着利用全连接神经网络计算特征每个通道间的重要性关系, 将得到的一维注意力权重向量与原始特^£图在通道维度上相乘得到通道注意力 特征图。其中，图4-5 （左）是将SENet嵌入到开端网络结构中，图4-5 （右）是 在残差网络结构中加入SENet模块。

图 4-5 SE-Inception 模块（左）SE-ResNet 模块（右）
43

基于手势视频数据处理的空间残差注意力网络通过引入空间维度注意力机 制代替了手部检测，实现了端到端的手势识别。在动态手势视频中，视频数据具 有通道、空间及时间三种维度，而动态手势也很难通过单帧图像进行识别，原因 在于单帧图像表达的手势在下一时刻可能向着不同的方向演变，形成完全不同的 手势动作，因此充分利用手势视频中的时序关系是识别动态手势的关键。
时序注意力结构设计：在动态手势视频中，手势动作的判定往往会依赖于一 些关键的数据帧，本文在手势识别空间注意力模块的基础上设计了适用于手势视 频关键帧提取的时序注意力方法，将压缩激励网络应用于手势视频的时间维度， 计算每个数据帧对于其手势识别的关键性程度。将时序压缩激励网络（TSENet） 应用于手势视频空间注意力模块数据处理之后，使时序注意力网络更易获取到视 频的时序注意力权重。TSENet的网络结构设计如图4-6所示，利用全局平均池 化函数压缩其经过空间维度注意力模块处理的手势视频的空间维度，仅保留时序 特征，再通过全连接的神经网络计算各帧之间的特征重要性，得到与输入序列大 小一致的一维权重向量,将该权重向量与视频数据在时间维度上相乘得到最后的 手势时空注意力特征。其中，图4-6中的系数尸设置为2,第一个全连接神经网 络输出接ReLU激活函数增强模型的非线性学习能力，第二个全连接神经网络后 接S型函数将注意力权值限制在［0,1］范围。

4.3双模态手势识别
4.3.1手势多模态迁移学习
迁移学习是一种机器学习方法，指的是机器学习模型利用其他模型已有的知 识改进现有模型，迁移其中一方的知识到现有的机器学习任务中，扩大现有模型 的知识储备，提高现有模型的数据分辨能力。迁移学习方法常被用于小数据集的 模型训练中，防止小数据集模型学习能力不足而导致过拟合现象的发生，即是微 调的学习方法。在本文中，微调学习方法不仅应用于小数据集的迁移训练，同时 也将微调学习的方法用于训练本章的时空注意力机制数据处理模块，首先基于时 空多尺度特征融合网络模型对数据集进行预训练，接着在模型中加入时空注意力 机制的空间注意力模块，将训练好的时空多尺度特征融合模型预加载到具有空间 注意力结构的模型中进行微调。本文逐次加入空间注意力模块和时序注意力模块,
44

使用微调学习方法训练其手势识别模型，提升了手势识别注意力模型的收敛速度 及识别的稳定性。
在迁移学习方法中，还有一类学习方法也经常使用，即多任务的迁移学习方 法。该迁移学习方法针对多个机器学习任务，迁移其他领域的知识到本领域模型 中进行学习，其学习的前提是两个领域的数据分布具有一定的相似性。在本文中， 动态手势的RGB视频和深度形态的手势视频属于两种物理意义不同但数据分布 具有相似性的手势动作表现形式，都具有表征动态手势类别的全部时空信息。为 了高效利用手势两种不同的数据模态特征提升手势识别的准确率，本文在微调学 习的基础上利用多任务迁移学习的方法同时训练RGB-D两种数据模态的注意力 机制识别模型，采用多模态联合训练和单模态预测的方法[61] (Multimodal Training Unimodal Testing, MTUT)训练IsoGD数据集的两种数据模态，RGB-D双模态 多任务迁移学习的结构如图4-7所示。

图4-7双模态多任务学习
其中，RGB和Depth分别代表本章中两种注意力机制的手势识别模型，芹和 伦分别为两种手势识别模型最后一层二维卷积神经网络结构的特征输出，其包含 了动态手势类别的全部时空信息。本文利用RGB模型和深度模型两种结构进行 多任务迁移学习，分别计算其单模态的分类损失和双模态的时空语义对齐损失 (SSA损失)并求和进行反向传播。其两种模型的损失计算公式如式4-2和4-3 所示。其中，和Zossd分别为RGB模型和深度模型的训练损失，用于反向传 播更新单模型的学习参数。A为SSA损失系数，用于调节其分类学习与迁移学习 的比例关系。loss隠和Sssg；分别为深度模型知识迁移至RGB模型与RGB模 型知识迁移至深度模型的SSA损失，其计算公式分别如式4-4和4-5所示。

其中，p参数为控制多任务迁移学习方向的系数，在训练过程中调节每个批 次的迁移学习方向及知识量，可以防止模型知识的负迁移。其计算公式如式4-6 所示。S为0阈值滤波函数，效果等同于正值滤波。0为正值聚焦参数，用于调 节迁移的知识量。山为模型训练时的分类损失之差，在RGB模型中M = losses - lossh，若山＜ 0表示该批次的训练数据其深度模型的训练误差将大于RGB模 型，迁移学习的损失系数变为0,放弃当前批次训练数据从深度模型往RGB模 型的知识迁移。
其中d = WXHX厶表示手势特征在时空维度上的展开，E表示特征矩阵在时 空维度上进行的0均值高斯规范化矩阵。
4.3.2双模态手势融合识别
基于动态手势视频数据的多模态融合识别方法主要有以下三种：一是前端融 合，即不同模态的手势数据在输入模型前进行拼接等操作，融合模型的输入数据； 二是中间层融合，对两种模态的手势识别模型在中间层时空特征进行拼接，其后 训练分类器进行分类；三是后端融合，分别独立训练手势识别模型，在单模型分 类决策的基础上进行决策融合，属于加权融合方式，在决策树以及集成方法中常 被使用。在本文模型中，RGB形态与深度形态具有不同的物理意义，其在通道 维度上直接拼接不具有现实意义，因此不适于双模态手势识别的前端融合方法。 而在RGB-D双模态的多任务迁移学习中，本文基于网络最后一层特征输岀的学 习方法已经利用了手势识别模型的中间层特征数据，因此本文主要针对动态手势 识别中的RGB和深度模态进行后端融合识别研究。
后端融合方法是一种有效提高机器学习模型识别准确率的多模态融合方法， 也称为决策水平融合算法。其主要包括平均值融合、最大值融合以及乘积融合三
46
种方式，三种后端融合计算公式如式4-9至4-11所示。pav3(c\xr,xd^ pmMxr,xd-)^pprod(c\xr,xd)分别为手势双模态融合识别中的平均值融合、最 大值融合和乘积融合方式模型识别样本为c类的概率。pr(c|xr)和兀(4七)分别 为RGB和深度两种单模态模型决策时将样本预测为c类的概率。

计算后端融合所有类别的预测结果并将其最大输出概率对应的类别作为模 型的分类结果，如式4-12所示。其中，C*为RGB-D手势双模态融合识别的预测 结果，［1,刃为数据集类别标签的取值范围。

4.4实验及结果分析
4.4.1时空注意力机制
为了验证本章基于手势视频数据处理的时空注意力机制结构的有效性，本文 在时空多尺度特征融合模型的基础上采用微调学习的方式逐次加入空间注意力 及时序注意力模块，即首先利用训练集训练时空多尺度特征融合模型,在加入注 意力模块之后迁移其学习参数至注意力模型中的时空多尺度特征提取部分，并对 注意力结构单独进行随机初始化，训练该注意力模型以达到快速收敛的目的。加 入空间注意力模块并在Jester数据集上进行微调训练的结果如图4-8所示，其中 的准确率为模型每轮训练结束后在数据集验证集上的识别精度。

图4-8空间注意力网络在Jester数据集上的微调学习

47
可以看到，加入空间注意力模块的时空多尺度特征融合模型的微调学习方案 具有很高的学习效率，在第一轮数据集训练结束后即达到了 85.11%的手势识别 准确率。且基于Jester数据集的手势识别模型比IsoGD数据集模型具有更高的识 别准确率，说明了 Jester数据集本身具有更好的辨识度，其收敛速度也更快。同 时，加入空间注意力模块的手势识别模型的识别准确率略高于非注意力机制模型, 说明了空间注意力结构的有效性。
本章的时空注意力机制前置模块将图像领域的残差注意力网络应用于视频 结构的数据处理，并将压缩激励网络应用于视频输入的时间维度，设计了用于处 理视频数据输入的时空注意力网络，逐次加入空间注意力模块和时序注意力模块 并基于前一个网络结构模型进行微调学习，其注意力机制的可视化结果如图4-9 所示。其中，图4-9 （上）是Jester数据集验证集上的样本，挑选其中具有代表 性的三帧图像进行展示；图4-9 （下）是对应的空间注意力模块及时序注意力模 块的可视化结果，空间可视化部分展示的是单帧图像三个通道上的空间注意力权 重加和，其范围为［0,3］。
图4-9时空注意力模型在Jester验证集上的可视化
在图4-9中，空间注意力模块的可视化结果显示了其对于手部定位的能力， 其空间注意力模块在视频中手部的位置具有更高的关注度权重，而对其他空间位 置则保持着基本的信息关注。在获得空间注意力的关注度权重之后，时序注意力 模块则很好地提取了视频中各个帧对于手势识别的重要性权重。因此本章基于视 频数据处理的时空注意力模型可以很好地实现动态手势视频中的手势空间定位 以及视频关键帧提取，代替手部检测和视频关键帧提取的操作实现端到端的手势 识别功能。
为了验证本章提出的视频空间注意力机制（SA）和时序注意力模块（TSE） 对识别结果的有效性，本文基于时空多尺度特征融合网络依次添加SA及TSE模
48
块训练Jester数据集，而后通过Jester数据集预训练模型微调至IsoGD数据集上 进行训练，做了如下的对比实验：（1）时空多尺度特征融合网络，在Jester数据 集上训练并微调至IsoGD数据集的RGB模态，基于其RGB数据模态微调学习 其深度模态模型；（2）在视频数据输入侧加入空间维度的残差注意力网络结构SA 在Jester数据集上预训练，并在此基础上微调学习IsoGD数据集模型；（3）在空 间注意力模型的基础上加入时序注意力模块TSE,并在空间注意力模型的基础上 微调学习时空注意力机制的Jester数据集模型，在此基础上微调学习IsoGD数据 集模型。表4-1是不同注意力模型在Jester数据集和IsoGD数据集验证集上的识 别对比结果，参数量为IsoGD模型的注意力模块机器学习参数量。
表4-1不同时空注意力模型识别精度对比（％）
对比可知，加入空间注意力和时序注意力模块的手势识别模型其识别准确率 对比时空多尺度特征融合模型有所提高，证明了本章时空注意力模型结构的有效 性。本章提出的时空注意力模型并不直接用于对动态手势进行识别，亟是基于原 始视频数据进行改造，通过添加注意力权重的方式改善原始视频的视觉特征实现 识别精度的提升。

4.4.2基于迁移学习的手势双模态融合识别
在基于注意力机制前置的手势识别中，RGB模型和深度模型属于两个不同 的手势识别任务，其输入的RGB视频和深度视频两种模态在时空特征上具有一 定的相似性。本章基于迁移学习的手势识别模型利用两个独立模型输出特征进行 联合学习，迁移双方领域的知识来提升单模态的手势识别精度，在单模态手势识 别模型的基础上联合微调训练模型10轮，并将批次大小设置为8,其他参数保 持不变。SSA损失系数几设为50x10-3,正值聚焦参数/?设为2。
基于注意力机制的时空多尺度特征融合模型利用多任务迁移学习的方法从 单模型的中间层特征数据迁移学习另一模态的手势时空特征分布。本文在此基础 上进行了手势双模态的后端融合技术研究，在得到多任务迁移学习的单模态识别 模型后利用其最后的Softmax函数输出概率计算其手势类别的平均值融合、最大 值融合以及乘积融合三种后端融合方法的手势识别准确率。将本文方法与现有效
49
果较好的手势识别模型进行比较，其对比结果如表4-2所示。其中“Res3D + ConvLSTM + MobileNet” 和 “Res3D + ConvLSTM variant + MobileNet” 方法呦 是Liang Zhang等人提出的三维残差卷积神经网络结合卷积长短期记忆网络及其 变体结构的手势识别模型，MultiD-CNN方法【621是Elboushaki等人提出的RGB- D多维度特征双模态融合识别算法，对比方法中其他模型的后端融合策略均采用 平均值融合办法。
表4-2与其他模型在IsoGD验证集上的识别准确率对比

表4-2中本文方法在IsoGD数据集验证集上的RGB和深度两种数据模态上 的识别准确率分别达到了 56.04%和56.48%,对比进行双模态联合训练前的单模 态注意力模型其手势识别精度有所提高。基于RGB模态的手势识别模型识别准 确率比基于深度模态模型的识别准确率提升更大，也验证了本章手势双模态迁移 学习方法的有效。
本文还对比了三种基于注意力模型的手势后端融合方法的识别准确率，其中 平均值融合、最大值融合和乘积融合的手势双模态融合识别的识别准确率分别达 到了 70.41%、67.06%和68.23%,说明本章基于注意力模型的三种后端融合方法 中平均值融合的效果最佳。对比其他手势识别方法，本文方法具有更高的手势识 别精度，对比同结构的结合三维卷积神经网络和卷积长短期记忆网络的模型，本 文方法具有较大的识别精度提升。因此，基于注意力机制的本文模型可以对动态
50
手势进行很好的识别，其单模态和双模态的手势识别模型都具有更高的识别准确 率，证明了本章结构的有效性。
4.5本章小结
本章针对动态手势视频的空间定位以及视频关键帧提取操作，提出使用时空 注意力模型来处理视频输入数据的办法，确定视频中手部的空间位置以及每个时 序帧对于其手势识别的关键性程度。本章的主要内容归纳如下：
(1) 提出将二维图像残差注意力网络方法应用于三维视频数据处理场景下， 并在空间注意力模型的基础上结合时序压缩激励网络进一步识别手势视频的关 键帧，在少量增加模型参数量的情况下提升了手势识别的精度。
(2) 通过迁移学习方法在本文模型的基础上联合IsoGD数据集的两种数据 模态进行训练，提升了单模态和双模态的手势识别结果。
(3) 为了验证本章方法的有效性，进行了多组对照实验，在本文使用的两 个手势识别数据集上进行了模型参数量及手势识别精度的对比及分析。
第五章总结与展望
5.1工作总结
手势识别是智能人机交互的重要方式，其技术发展直接推动着人机交互技术 的发展；在工业界，自动驾驶技术的发展推动着手势识别成为其重要的车内人机 交互应用；在科研领域，基于计算机视觉的手势识别成为了炙手可热的前沿技术， 尤其是近十年来随着深度学习的技术进步，基于摄像头设备的手势识别方法成为 了主流的应用方式。但是，由于动态手势视频是一种三维数据，其相比于二维图 像具有更大的数据量，其所属类别不仅跟单张手势图片有关，更与其在时间维度 上的运动关系密切，手势的时空特征融合成为了研究的重点和难点。基于此特点 本课题对动态手势识别技术中的时空特征进行了深入研究，探讨如何高效地利用 手势视频中的空间和时序关系，进一步高效地提取动态手势中具有时空辨识性的 特征，本文的主要工作如下：
(1) 论文提出了一种新的基于时空多尺度特征融合的动态手势识别算法用 于提取不同时空尺度的动态手势特征，并通过改进的循环神经网络结构高效地融 合手势特征中的时空关系。该算法基于膨胀卷积理论提出了 一种常规三维卷积神 经网络与时间维度膨胀卷积结合的时空卷积结构，利用不同时间视野的卷积结构 提取不同尺度的手势时空特征。其次通过改进门控循环单元提出了一种卷积门控 循环单元结构的变体，通过在同一个时序帧上对手势的空间特征统一加权高效融 合动态手势的长短期时空特征，该方法在降低模型参数量的同时提高了模型的泛 化能力，进一步提高了动态手势识别的识别准确率，使三维卷积神经网络与卷积 循环神经网络结构的结合更加高效。
(2) 为了改进动态手势识别算法，本文提出了一种改进的时空注意力机制 用于对视频数据输入进行数据处理。将二维图像领域的残差注意力网络应用于本 文的三维视频结构，对每一个独立的视频帧进行空间注意力处理，并在空间注意 力结构的基础上应用时序压缩激励网络提取每一帧图像的注意力权重，在少量增 加模型参数量的情况下改善原始视频的特征，提高了识别模型对手势的辨识能力。 接着，本文在时空注意力模型的基础上针对RGB-D两种数据模态进行了多任务 迁移学习训练，利用注意力模型最后一层二维卷积神经网络的时空特征互相迁移 领域知识，提升了单模态的手势识别精度，同时通过双模态手势后端融合验证了 本文模型在双模态手势识别中也具有较好的分类效果。

5.2未来工作展望
通过实验验证，本文提出的手势识别算法相比其他手势识别模型具有先进性, 但本文主要围绕手势的时空特征提取以及融合进行展开，仅对手势的两种数据模 态进行了研究，因此未来可能的研究方向主要围绕以下的两个方面：
(1) 增加光流或者手势的运动表示进行手势多模态融合识别的研究，在不 同的手势特征之间提取特征的相似性，进一步强化手势多模态融合的特征分辨能 力。不同的手势模态具有不同的特点，其代表的物理意义不同，更能从多方面展 示手势动作的特点。因此结合多种手势模态进行研究，利用多种模态的手势数据 进行相互学习，可以从整体上进一步提高多模态手势识别的精度。
(2) 结合手势识别的技术特点设计实用的手工特征，利用手工特征与深度 学习特征进行有效结合。其深度学习特征属于隐性特征，尽管有很多的可视化手 段和工具可以描述深度学习特征，但手工特征仍然具有很强的可解释性，其在某 些场景下具有更强的区分性。通过设计手工特征的方法提取手势视频的有效特征, 再通过多层感知机等模型进一步融合手工特征和深度学习特征，进一步提高机器 学习模型的泛化能力。

参考文献
[1] Tran D, Bourdev L? Fergus R, et al. Learning spatiotemporal features with 3d convolutional networks [A]. // Proceedings of the IEEE international conference on computer vision [C], Santiago: IEEE Press, 201
