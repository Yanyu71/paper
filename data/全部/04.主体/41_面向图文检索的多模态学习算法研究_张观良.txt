
第一章绪论
1.1研究背景与意义
随着信息技术和网络的发展，人们可以随时随地分享自己的文字与图片内容, 并对图文添加自己的感受或者是对图片的描述［鸟⑦組此外，各类网站也为互联网 积累了大量图片以及相关信息，导致整个互联网范围的图像数据库以及文本数据 库的规模变得越来越大，如何让用户快速、有效地检索到其需要的图像信息，是 近年来的研究重点［”42,44,45,50］。
图像信息的检索一般分为基于文本的图像检索(Text-based image retrieval)1471 和基于内容的图像检索方式(Content-based image retrieval)"］。基于文本的图像检 索需要人工给图像标注关键字，标注的文本信息主要描述图像内容，例如Flickr 上分享的数据都有着用户打上的标签。此时用户通过输入关键字，利用关键字与 标注信息之间的匹配完成检索任务。另外搜索引擎利用关键字，可以定位到需要 的网页和网页中存在的图像文档。由于网页上的图片一般配有文字描述，因此用 户通过基于文本的图像检索可以找到这些图片。但是，假如与图片配套的文本信 息不是描述图片本身的时候，则检索到的结果很可能有较大误差。基于内容的图 像检索，通过比较图像的特征来获得图像检索结果，也就是“以图搜图，但图像 在计算机视觉特征上的相似与人类认为的相似有一定区别，存在所谓的“语义鸿 沟”问题【48】。"语义鸿沟”就是计算机获取的图像的视觉信息与用户对图像理解 的语义信息的不一致性而导致的底层和高层检索需求间的距离〔46】。通常人们在 在判别图像相似性时，是建立在对图像所描述的对象或事件的语义理解的基础上, 如”森林”，”喜庆”等，但这些无法从图像的特征上直接获得的。另外基于内容的 搜索需要用户预先给出相关图像，如果直接应用于检索中，会降低用户交互体验。 多模态数据是指多种类型的数据，如图像、音频、视频和文本内容【49］,由于媒 体数据类型的繁多，使得在跨模态的语义挖掘和检索已成为检索系统研究的热点, 一般的多模态的搜索归纳为以下流程：
请求输入=> 预处理=>特征提取=?模态转化 搜索结果
图1-1搜索流程


图1-2文本检索图片，句子先进行分词、去词和统一格式，之后替换成文本特征。获取 文本特征后根据多模态模型转成可以与图像进行计算的特征，在图像数据库中搜索数据。
图1-1中的预处理和特征提取都在输入数据自己的模态下进行，如图1-2虚 线内部的流程，多模态模型则处理模态转化和搜索结果。对于图像的预处理则是 使得图像更清晰或者适合算法要求。一般的预处理有去噪处理、减去数据集的平 均值或者像素的归一化处理35】。文本的预处理主要是分词、统计高频词、过滤 无用单词和词型转换等卩，35］。
特征提取则是多模态模型的重点，特征的提取方法影响着后续的模态转化方 法的选择。图像的传统特征方法有主成分提取(Principal Component Analysis, PC A)〔43］、尺度不变特征转换(Scale-invariant feature transform, SIFT)図和方向 梯度直方图(Histogram of Oriented Graident, HOG)卩等，第一个主要是提取图 像的全局信息，而后两个则是提取图像的局部信息，都是人工特征。随着深度学 习的发展，特征提取更多地使用卷积神经网络(Convolution Neural Network, CNN) ⑸提取特征，CNN能够根据具体任务自己学习特征参数。传统文本特征则是“词 袋模型"(bag-of-the-words)卽】，利用数据库中的文本建立单词字典，之后单词 的特征则是标记单词在字典中的位置，句子特征则是这些单词的出现次数。在特 征提取上，各种模态中都有着成熟研究结果，本文则是充分利用这些研究结果， 在其基础上建立多模态模型。
模态转化则是多模态模型的根本要求，不同模态之间的数据无法直接进行比 较，需要根据任务需求定义图像特征与文本特征之间的相似性关系。与单模态下 的信息检索不同，跨模态不仅要求模型能够学习到本身模态下的特征，还需要学 习不同模态的数据之间的内在关系，因此如何利用模型对这种内在关系进行建模, 实现多模态之间的信息交流从而完成模态转化是多模态模型的关键【49】。跨模态 检索需要将不同模态的数据转化到一个合适的特征空间上，使得数据在该特征空 间上存在一定的直接对应关系。搜索结果则是在完成模态转化后，根据多模态模 型所定义的检索函数，找出对应的结果。
通过多模态模型可以建立视觉特征与文本语义之间的关系，用户可以直接输 入搜索图像的描述语句，模型则将描述转换为特征，根据文本与图片之间的语义 关系，得到更符合描述的结果。而使用图片搜索文本时，模型无需考虑数据库中 的图片是否有着正确的文本信息，可以直接根据图像特征与文本的关系来获取 ［41,42］ o
1.2研究现状
自从2006年，Hinton等人发表了如何利用限制玻尔兹曼机(Restricted Boltzmann Machine)学习深度信念网(Deep Belief Network),从而构建深层网络以 来⑶，深度学习⑶受到学术界的广泛关注。深度学习通过构建多层神经网络模拟 人脑的分层结构。这种多层网络对底层输入进行逐层编码，提取从底层到高层的 特征，从而建立了底层简单的数值信息到高层语义的映射关系。包括微软、谷歌 等跨国公司和百度等国内大型互联网公司相继投入到深度学习的研究，并使用深 度模型提高自身产品的质量⑶］。2011年，微软将深度学习应用到语音识别上， 使得识别率达到了 7Q80%； 2012年，谷歌公司启动Google Brain项目，该项目 由斯坦福大学机器学习专家Andrew Ng和计算机系统专家Jeff Dean负责。在该 项目中，利用16000个CPU Core组成一个并行计算平台，构建机器学习模型。 该平台有10亿多个节点，用来训练一种称为"深度神经网络"的结构。该实验中， 这套系统通过大量的无标签数据学习特征转换参数，没有人工干涉，系统自己领 悟这些概念。最后利用采样方式，发现系统自己学习到了如何找到猫的脸；同年， Hinton等人［5］将卷积神经网络带入了深度学习中，刷新了 ImageNet Large Scale Visual Recogition Challenge (ILSVRC)竞赛中图像分类等项目的准确率，使得卷 积神经网络成为提取图像特征的重要工具。
在文本方面，由于词袋模型的各种缺陷[35]，在2001年，Bengio等人卩7］通 过一个三层神经网络构建出语言模型。该模型中，单词的特征是实数值向量，单 词之间可以相互比较，文中的基本思路和后续的语言模型差别不大。2007年， Hinton等人［4］将受限玻尔兹曼机引入到自然语言模型中，文中从基本的受限玻 尔兹曼机，逐渐修改能量函数，最终得到对数双线性(Log-Bilinear)模型。除 了在自然语言模型上，Hinton等人［1］根据主题模型的思想【35】，利用受限玻尔兹 曼机的特性，建立起重复软最大化(Replicated Softmax)模型，该模型使用隐藏 层作为隐藏主题，构建主题和单词之间的关系，并能够使用大量无标签数据进行 训练。在［17］中，最后一层的Softmax模型有着大量参数，为减少参数个数，
Mikolov 等人［44］在 2010 年提出了循环神经网络(Recurrent Neural Netwok)，在 减少参数的同时，理论上可以充分利用到所有上文信息来预测下…个词。
图像和文本模型在各自模态下都有着重要发展，可以更好地进行特征提取。 基于图像与文本的多模态模型中，主要研究方向有图文的检索和基于图像的描述 生成。图像检索方面充分利用了深度学习在各领域的发展，例如J.Ngiam等人［45］ 提出了双模态深层自编码机(Bimodal Deep Auto-encoder),通过逐层的训练和联 合特征，实现多模态语义关系的学习。此外还有Frome等人［41］和Karpathy等人 ［42］结合卷积神经网络与词向量模型，构建多模态模型。在基于图像的描述生成 方面，主要是在自然语言模型的基础之上，引入图像特征，学习如何根据图像影 响单词的生成概率，例如Vinyals等人［11］在以循环神经网络为基础的模型上实 现了文本生成。基于完整图像与文本的特征的多模态模型中［41,45］,分析了如何 使用深度学习模型提取特征，并根据特征的特点提出多模态特征学习的方法，但 忽略了一个固定长度的特征无法描述复杂图片或句子的问题。在基于细粒度特征 的多模态模型中［42］,提出了图像片段与文本片段之间的关系学习方法，但文本 中任意两个单词的关系根据依赖树人为确定，忽略了更多单词之间的语义关系。
1.3论文主要内容和组织结构
本文主要围绕基于图文搜索的多模态学习算法进行探讨，研究多模态模型的 特征提取、关系学习和检索方法，同时将较为复杂的模型转移到深度学习框架中。 最后使用公共数据集进行图文检索实验，并与其他图文检索工作进行比较，分析 算法的优点与缺陷。本文的主要贡献包括：
(1)利用依赖树递归神经网络和双向循环神经网络获取包含句子结构信 息的文本特征。
(2)根据文本特征提出多模态模型，并根据其优缺点，确定这些模型的使 用定位。
(3)在能够使用自然描述实现与图片之间的互相检索的基础上，细粒度多 模态模型能够根据训练集学习到视觉特征和文本语义之间的关系。另 外网络定义、特征提取、训练以及测试上可以在统-的框架下进行, 提高效率并方便引入新的模型进行改进。
论文一共分为六个章节，内容安排如下：
第一章：绪论，主要说明课题研究的背景，单模态和多模态的研究现状和论 文研究内容和组织结构。
第二章：概述在本文所使用的图像和文本特征模型，为后续的讨论提供理论 支持。以基于受限玻尔兹曼机的多模态模型作为切入点，研究在各自模态下的特 征提取和多模态特征的关系学习方法，实现基于自然语言描述和图像之间的检索。
第三章：根据第二章中多模态模型出现文本特征忽略句子结构的不足，本文 分别利用依赖树递归神经网络和双向循环神经网络构建包含句子信息的文本特 征。其中依赖树递归神经网络得到的是基于单词关系的句子特征，而双向循环神 经网络得到的是包含前后文信息的单词特征。
第四章:根据第三章的文本特征，定义图像特征与文本特征之间的相似距离， 建立多模态模型。
第五章：利用公共数据集，本文测试多模态模型在图文检索中的性能。分析 了各个多模态模型的优缺点，并展示了细粒度模型在学习视觉特征与语义关系上 的效果。实验表明，多模态模型能够利用自然语言描述完成图像检索，同时学习 到视觉特征与文本语义之间的关系。
第六章：对本文进行总结，并指出本文的不足以及下一步的研究方向。
第二章模型背景
2.1受限玻尔兹曼机模型
2.1.1受限玻尔兹曼机
基于受限玻尔兹曼机(Restricted Boltzmann Machine, RBM)的深度信念网络 (Deep Belief Network, DBN)[31模型作为最早的深度模型，在图像、音频等方面有 着广泛应用，其基本特性是对输入编码后能够通过取样重构输入，并且可以多个 RBM进行叠加，逐层训练。由于是对输入本身进行编码，不需要标签数据，因 此训练过程是无监督训练。无监督训练得到的网络参数可以作为神经网络的初始 值，避免了深度神经网络中由于随机初始化和网络过于复杂而导致的过拟合等现 象，因此RBM模型非常适合非常多的无标签数据，无标签数据是指没有标注类 别的数据，例如图像的类别和文章的类别。
RBM是对玻尔兹曼机(Boltzmann Machine)进行限制，每层中的节点之间互 相独立。它定义了在可视层ve｛0,l｝M和隐藏层腥｛0,1於上的联合分布，参数有 ｛附，如由｝,分别是可视层与隐藏层之间的关系权重以及偏置项，如式(2-1)所示:
尊;")	(24)
其中配分函数z(e)为：
Z(9)= Z Z expE+vTgb,)	(2-2)
怵｛0,1｝孔膈｛0,1)七
以能量模型对式(2-1)简化得
E(y,ti｝ = hiWv+blv+blh	(2-3)
用)=￡尸(财)=￡丝男疫
h	h 么 P)
根据能量方程引入自由能的概念，对式2-4进行改进得
Rv) = - log(￡exp(-顼 v,幻))
h
Z(6>)
当在输入和输出都为二元值时，其条件概率具有sigmoid的形式:
P(hi = 11 v) = sigmoid((IFv -F bh )f)
p(v. =1|A) = sigmoid((JKT/i+Z>v)y)	。一"
作为生成模型，RBM通过在训练集S上最大化平均对数概率来训练。为最大化 对数概率，需要对RBM的参数进行求导。

从式(2-8)可以得到第二项是v的输入可能值，求和表示对整个输入空间求和, 因此第二项无法直接求出。第二项可以看作EA 寄］,即在分布P下求霄 的期望。为获得第二项的近似值，根据分布P进行釆样，得到的样本近似整个输 入空间，如式(2-9)所示。
31ogP(v) #(v)	1 ▽护(9)
de de |"|幺 de
根据式(2-9),需要获得基于分布P的样本，取样算法根据［3］中的对比散度 (Contrastive Divergence, CD)算法来近似马尔可夫链蒙特卡罗(Markov Chain Monte Carlo, MCMC)取样。在CD算法中，需要分别得到输入层和隐藏层的条件 概率，因此在后续论文中，基于RBM的模型都给出对应的条件概率。
在训练过程中，在给定输入数据时，利用对比散度算法获取偏导近似值，从 而可以对参数进行调整。
2.1.2对比散度算法
根据能量模型定义，确定能量函数后，能量模型希望在正确输入的情况下有最小能量，其他错误输入则较大。根据该定义，在训练时使用的损失函数使用对 数似然函数，最大化对数似然函数相当于最小化负对数似然函数，如式(2-8)所示。
最大化似然可以看作是最小化两个分布之间的Kullback-Leibler(KL)距离。
假定P(x10)是用于生成数据点x,.的分布，定义如下模型参数分布：
^(x) = P(x|0)	(2-10)
类似地定义如下经验数据分布，相当于在实际数据上的分布：
N 1
契)=￡抑-玉)	(2-11)
端N
5是狄克拉delta函数，使用该经验数据分布，可以计算如下KL距离：
口月(x) II 丛3)| = J%x)log 需
=J 7), (x) log PD (x)dx - \PD(x) log PQ (x)dx	(2-12)
= -H|%x)|-J%x)log%x)山
00-伽")和)
最后一行中，去掉与。和(〉切)没有关系的部分，其中(〉切)表示在弓(x)上的 期望。根据式(2-12),最小化两个分布的KL距离，相当于最小化式子左侧的负 期望公式：
1 N
〈log乌(x))p ⑴=而￡汉Xf )logP(x|。)农
；	(2-13)
= ^logP(x,|0)
根据式(2-13),最后得到的结果是模型上的对数似然函数，因此最小化数据分布 和模型分布的KL距离相当于最大化模型上的对数似然函数。
针对式(2-8)进行改动，设定P0为在数据上的分布，是模型上的分布，同 时展开自由能公式(2-5)可以得到：
aiog(/y(v)) ldE(v,e)\ /dE(vM
de ~\ do //>(. \ 50	1	)
根据KL距离与对数似然的关系，CD算法的目标就是最小化
CD^KL(P°\\^-KL^\\I^)
其中砖由/经过一次吉布斯采样得到，更接近7T的分布，所以C4是非负的。 当叫为0时，表示P0和矽同分布，相当于P0釆样后不变。另外由于每次吉布 斯采样后的值更接近均衡分布，所以采样后不变说明已经达到均衡分布。最后, 因为KL距离也是非负的，所以最小化KlWllE1)-KL(E||用°),相当于使每次 釆样的变化更小，使得皿更接近0,近似得到MCMC釆样的均衡分布。
CD算法的目标函数为CDI=XL(P0||^°)-XL(^ ||罗)，对其求导可以得到:
一备(皿。|| “心II明)=(零)〃 -保乳
I明施(児||罗)
dO 為
经证明，最后一项可以忽略，此时式(2-15)与式(2-14)相同。
CD算法一般以CD-k表示，k指的是吉本斯釆样的次数，以下是受限玻尔兹 曼机的CD-k训练算法:
算法2-1 CD-k算法
输入：^,S,W,bv,bA 输出：AW，M，M 初始化：AFK = 0,Abv=0,AbA=0
对S训练集的样本循环，生成△ W,Ab“Ab?
for v in S do
v(0) := v
for ? = 0 to 1 do
h(,) =sample_h_given_v(v(,),FF,bv,bA)
v(s = sample_v_given_h(h。),附,by, b”)
end for
for z = 1 to nh,j = \ to nv do
△叫丿=△叫丿 + ［P（4 = 11 v（。））v；o）- P（九=11 v（*））vf）］ 啊=%+"）-吧
△勾=M, + ［户S = 1 I V⑼）一P0 = 1 I 必）］
end for
return △札,昭
根据CD-k算法，在已知条件概率公式时，我们可以训练基于受限玻尔兹曼 机的模型，其中sample_h_given_v相当于利用P(4=l|v)得到概率后，利用该概 率进行取样。内循环中的第一个循环是进行k次吉布斯采样，第二个循环是根据式(2-14)求模型中各个参数的导数。
2.1.3重复软最大化模型
概率主题模型【14】主要用于从大量文本集中分析和提取语义主题。主题模型一 般假设每个文档都可以由多个主题表示，每个主题是不同单词的概率分布。主题 模型也可以看作是一个图模型，其中每个隐藏主题都与文档中的代表词汇有连接 关系。上述连接关系可用RBM模型进行建模，其中隐藏层的单元相当于隐藏的 主题，而输入层的单元个数则为单词字典的大小，单元的值是该文档中某个单词 的出现个数，该模型被称为重复软最大化模型(Replicated Sofhnax Model)⑴。假 定ve{l,...,K}气 其中K是字典的大小，而D是文档的长度。Ag{0,1}f作为随 机二元主题特征。V是一个Kx。的二元矩阵，用于表示字典特征，此时#=1表 示文档中第i个单词在字典中的位置是ko类似于式(2-3)可以得到能量模型：
E(V,h) =	-f
i=1 J=\ k-\	/=) A=1	y-i
F K	K	F
*4 1,	(2-16)
丿=1 AT	A=1
其中{附,以}是模型参数，俨相当于计算第k个单词出现的次数。在训练过程中， 给定一个长度为N的句子，生成隐藏层的算法与RBM模型相同，但从隐藏层生 成输入层时，模型需要进行N次采样，将釆样结果进行求和。由于输入层是N 个单词向量求和得到的K维向量，因此展开后每一行是K维二值向量，只有一 个单元为1,其他为0,表示为一个单词的向量，如图2-l(a)右侧所示。每个单 词向量使用同一个权重，如图2-l(a)左侧所示。隐藏层在实际使用中可以不进行 二元化，直接输出sigmoid函数的结果，此时输入层的每个单元是单词的出现次 数，隐藏层的每个单元则是主题的概率。

(a)
11

Latent Topics


图2-1 (a)中的右图是字典矩阵K,其中每一列都公用一个权重值。(b)是实际训练的一层
RBM模型，输入unit是每个单词的出现次数，隐藏单元则是主题。
2.1.4高斯受限玻尔兹曼机
高斯受限玻尔兹曼机(Gaussian Restricted Boltzmann Machine, Gaussian RBM) [37]类似于重复软最大化模型，针对图像的原始输入或特征，RBM模型的输入层 通过修改使其可以针对浮点数进行取样。对于实数输入层vgRd,Gaussian RBM 的能量函数如下所示：
E(5 =尝夢-芯+咐广以也	(2-17)
心 厶。i	，=1 丿=1 0	y=i
2.2神经网络模型
2.2.1卷积神经网络
卷积神经网络(Convolution Neural Network, CNN)'从全连通的神经网络简 化而成，其中局部感知受医学研究的启发，视觉皮层的神经元是局部接受信息的, 即这些神经元只响应某些特定区域的刺激。卷积神经网络与前向神经网络相比, 有三个主要差异：局部感受野、权重共享和空间池化层。
对于一个普通的神经网络，每个神经元都与下一层的全部神经元有连接。在 隐藏层中，每个神经元的响应都与输入层的每个单元的值有关，但在视觉识别中， 神经元更倾向于与局部的单元有关。例如在一张图片中，相邻的像素在颜色和方 向上有着强烈的相关性，而两个相隔较远的像素则相关性较小或者没有关系。因 此在计算机视觉中，很多特征表示都是基于局部特征，如SIFT【9】和HOG卩5】。为 了能够获取这种局部信息，CNN模型限制每个神经元只依赖于上一层中的局部区域的值。例如给定一个32x32的图像输入，隐藏层中的某个神经元只依赖于图 片中的某个8x8的子区域。因此在输入层中，影响隐藏层中某个神经元响应的单 元就是该神经元的感受野。更直观地说，这部分就是神经元能看到的部分。
第二个因素是这些局部感受野的权重是共享的，每个感受野与隐藏层中的每 个神经元之间使用同一套参数。相当于用同一个权重对输入层中每个子窗口的单 元进行合并，得到隐藏层中的神经元响应。因此CNN是学习一个权重集合 F = {Fi\i=l,.../i ,每个权重都会作用到输入图像的所有子窗口上。权重共享逼 迫网络去学习一个普适的编码方式，同时减少学习参数，使得网络可以高效地进 行训练。由于这个计算过程相当于用一个卷积核对图像进行卷积运算，因此权重 集合也是一个卷积核的集合，通过卷积可以得到卷积响应图。
最后一个因素是池化(pooling)层。使用池化层的目的是减少卷积响应图的维 度，同时引入微小的平移不变性，其标准的方法是空间池化SI。对于卷积响应 图，首先将其分成AMX”的方格，之后通过池化函数计算每个方格的响应，这个 过程最后得到的是一个维度为mx”的响应图。假如池化函数是求最大值，则找 出方格中最大的值作为该方格的响应值；假如是求平均值，则求方格的平均数， 如图2-2所示。
2	　4	　6	　8		3	7
2	4	　6	　8
1	3	　5	　7		　　　4	4
7	5	　3	　1
卷积响应			Poo 1 ed响应
图2-2平均池化，对于卷积响应，分成一个2x2的方格，每个方格是2x2。针对每个方格求 平均值，得到一个2x2的池化响应。阴影部分则是(6+6+8+8)/4=7。

除了卷积层和池化层外，局部对比度归一化(Local Response Normalization, LRN)层和剔除(Dropout)㈣层也用于CNN网络。局部对比度归一化层主要针 对局部特征进行归一化，它会迫使同一特征图中的相邻特征进行局部竞争，还会 迫使在不同特征图上同一空间位置的特征进行竞争。该处理也是由计算神经科学 模型启发得到的，如式(2-18)所示。

min(iV-l,i+?/2)
%=《,y/(* + a Z (<y)2)	(2-18)
7=max(0,i-n/2)
是由卷积核i得到的特征图中，位置为(x,y)的响应。其中求和的n是相邻卷 积特征图的个数，N是该层的所有卷积特征图个数。
在深度模型中，由于参数众多，容易造成过拟合，特别是在最后的全连通层 ±o因此单元的剔除经常用于避免复杂网络出现过拟合，并模拟了多个神经网络 的融合。在CNN模型中，全连通层后一般都会接着剔除层。对于全连通层，输 入和输出的单元个数都为4096,因此输入与输出之间有着非常复杂的非线性关 系。在数据缺少的情况下，模型会对一些噪音进行建模，而这些噪音可能只出现 在训练集当中，这也导致网络出现过拟合。一般有许多方法用于解决这个问题， 例如当模型在验证集上的效果变差时就停止训练，或者通过L1和L2正则化， 惩罚过于复杂的网络参数。在有无限的计算资源时，则使用多个模型进行融合, 随机森林就是通过多个随机树来避免单一决策树的过拟合。但对于复杂模型，多 个模型的计算量巨大，另外模型合并需要各个模型有明显差异，其中可能需要用 不同的网络结构和不同的训练集。
剔除是从网络中剔除部分单元，但只是暂时将这些部分从网络去除，包括单 元之间关联，如图2-3所示。

图2-3 Dropout神经网络冋，(a)中为有两个隐藏层的标准神经网络，(b)是部分单元被 dropout后的神经网络，其连接也去拝了 o

每次剔除的单元是随机选择，每个单元的剔除概率可以根据验证集选择或者直接 使用0.5。
根据图2-3,模型具体计算如下，给定一个有L个隐藏层的神经网络， 是｛1,...妇是每个隐藏层的索引，z（'）表示对应层［的输入，俨）则为输出，时）和 砂）分别是权重参数和偏置项。前向神经网络的前向传播如下所示：
z件）=时+?（，）+涉S	（2-19）
北（5=/（*5）	（2-20）
/?是非线性函数，使用dropout后，前向传播方式如下：
驴?Bernoulli］ °）	（2-21）
刊）="）* 尹）	（2-22）
z；s）=讨“俨）+々如）	（2-23）
孝）=代件））	（2-24）
相比标准的神经网络，剔除网络需要先根据给定的概率p确定每个单元是否需要 去除，单元剔除后的操作与前向网络相同。在后向传播过程中，被剔除的单元不 再考虑，相当于对应参数的导数为0。由于单元剔除的引入，网络的训练时间加 长，整个训练时间一般为标准网络的2到3倍。训练时间加长的一个重要原因是 参数在更新时，每个训练数据都在训练一个新的随机网络，因此导数不是最终网 络的导数，导致训练时间变长
CNN网络目前主要使用已经训练好的模型，这些模型利用大量的数据进行 分类器的训练，比较常用的网络有AlexNetB】、GoogleNet^和VGG-16网。这些 网络主要是在卷积层和池化层的组合方式和参数上有差异，利用CNN网络提取 的特征一般以输入到最后一层分类器的特征为主。
2.2.2区间卷积神经网络
针对一张图片可以通过卷积神经网络获取特征图片特征，但本文为了能够提 取图片中不同物体以及场景的特征，需要利用物体识别算法标示出物体的位置。 物体识别算法，其基本方式是使用滑动窗口得到图片中的区域，之后利用分类器 确定该区域内是否有物体。为精确定位物体位置，每张图片都要进行大量分类运 算。区间卷积神经网络（Regions with Convolutional Neural Network, R-CNN）［8］通过 预测物体存在的位置，提高了物体识别的速度。
R-CNN算法有三个步骤，分别是候选边界框提取，边界框中的图片分类和 边界框的校正，如图2-4所示【8］。本文只使用前两个步骤获取每个候选边界框的

坐标以及分类器给出的的概率。边界框的提取算法有Selective Search^。］和
EdgeBoxesP】，用于提供可能有物体的位置。对边界框中的图片分类则使用卷积
神经网络和软最大化(Softmax)模型。

Input 2. Extract region 3. Compute 4. Classify image proposals (~2k) CNN features regions
图 2-4 R-CNN回

2.2.3循环神经网络
循环神经网络(Recurrent Neural Networks)卩刃是一种非线性动态系统，可以将 信息随着序列传递。其参数主要包含3个参数矩阵和对应的3个偏置项 ｛吃”小W。璀璀扁。给定一个输入序列(％,...,巧)，循环神经网络根据以下算 法来计算隐藏层h和输出层z ：
算法2-2循环神经网络前向传播算法 输入：vt,Whv,Whh,bh,Woh,bo 输出：z,
for t = l to T do
u,^-Whvvt+Whhh,_x+bh
”g(。,)
end for
return e()和g()是非线性函数，4是隐藏层的初始状态，每一步隐藏层的值也是下一步 的输入，如图2-5所示，虚线内部是传统的人工神经网络。
在训练过程中，需要对参数进行求导，此时后向传播是沿着序列进行传递
(Backpropagation through time,BPTT)。

图2-5循环神经网络模型㈣，前一个状态的输入同时影响当前状态。

2.3自然语言模型
2.3.1词向量
在2.1.3节的重复软最大化模型中，单词的特征是二元特征，只是作为单词 在字典中的位置索引。由于单词在字典中随机排列，因此根据单词特征无法得到 任意两个单词之间的关系。词向量(WordEmbedding)模型的思想是假如两个单词 所处句子的位置相似，具有相似的上下文信息，则对应的单词特征也应该相似, 单词的特征则是该单词的词向量。词向量模型最初由［20］提出，该模型是一种 n-gram模型，通过前n-1个单词预测第n个单词，如图2-6所示。


图2-6词向量模型'的
图中的。(叫_2)表示前第二个单词的词向量，并且只表示该单词。词向量保 存在一个|V|xm的矩阵C当中，|V|表示为字典的大小，秫是词向量的维度。网络的第一层是前〃-1个词向量串联得到，形成一个(?-1＞维的向量V。第二 层的隐藏层与普通神经网络相同，通过非线性运算后输入到最后的软最大化层中。 软最大化层中的每个单元是单词的出现概率。
2.3.2对数双线性语言模型
对数双线性语言(Log-Bilinear Language, LBL)［26］模型是基于RBM的词向量
模型，其能量模型如下所示：
E(w,；wg)=-枝寸RC,)RW 或-b",	(2-25)
1=1
C?是用于表示单词W,?和单词叫之间的关系，A是单词的词向量矩阵，匕?是单词i 的bag-of-words特征，是单词［,的词向量，该函数定义的是预测单词的词向 量与作为上下文单词的词向量之间的关系。与式(2-4)类似，可以得到预测单词的 概率：



2.4多模态深度玻尔兹曼机
文本数据以及图片数据之间的检索，难点在于不同模态之间的数据由于在特 征空间以及提取方式上的不同，无法直接进行比较。本文从RBM模型入手，通 过比较深度信念网(Deep Belief Network, DBNg以及深度玻尔兹曼机(Deep Boltzmann Machine, DBM)?之间的差别，确定使用DBM作为多模态模型的基础。
然后，分别利用重复软最大化模型和高斯受限玻尔兹曼机建立文本DBM模型和 图片DBM模型，最后通过训练联合特征完成不同模态之间的信息检索。
2.4.1深度信念网与深度玻尔兹曼机的差异
DBN与DBM都需要对多个RBM模型进行训练，但两种模型在RBM的连 接方式上有所不同。
对于DBN模型，每一层的输出作为下一层的输入，每层之间的训练不受影 响。如图2-7(a)所示，完成第一层的RBM训练后，下一层的RBM则利用上一 层的输出作为输入,训练该层参数。以概率图模型来看，为了得到最顶层的估计， 只需要由低向上进行运算。而对于DBM模型，中间层的值需要上下层进行估计， 如图2-7(b)所示。
(a)	(b)
图2-7 (a)部分是DBN模型的bottom-up流程，而(b)是DBM模型的流程。
在论文［52］中提到，DBM模型相比DBN模型，更能够对输入特征进行过滤 并保留有用信息，另外也可以直接使用前向传播获取高层特征。对于多模态模型， 为了学习不同特征之间的联合特征，需要在文本与图片的模型上添加一层RBM 模型。如果以DBN的方式训练，则相当于学习联合特征的任务只落在训练最顶 层的RBM上。对于DBM,由于在原有的文本与图片的DBM上加入新的RBM 模型作为联合特征，因此原有的DBM模型的输出依赖于联合特征和低一层的响 应。从这里可以看出，为了学习联合特征，DBM整个网络的参数都需要进行调 整，因此学习任务落在整个网络上。根据通过分析，基于DBM的多模态模型在 多模态学习上优于基于DBN的多模态模型。
2.4.2模型结构与训练
在多模态DBM中，文本与图片都先使用DBM模型进行建模。由于DBM 的中间层需要上下两层来进行估计，而最顶层与最底层只需要一层，因此中间层 的训练需要进行改动。

对于只有一个中间层的DBM模型，如图2-7(b)所示，其简化的能量方程如 下所示(忽略偏置项)：
E(v,h(1),h<2)) = - vTW(1)h(1)-h(,)TW(2)h(2)	(2-29)
对于输入层以及两个隐藏层的条件概率如下所示：
p(砖,)=l|v,h(2)) = sigmoid(￡*⑴坊+￡竹洌 2)),	(2-30)
/	m
〃(玲=l|h(D) = sigmoid(2X%(D),	(2-31)
pl% = 1| h(1)) = sigmoid(Z%9)勺	(2-32)
为初始化DBM模型，这里使用逐层训练的方法来学习堆积RBM模型，分 别学习两个RBM模型后再进行合并。针对这种有两个隐藏层的部分，需要对输 入层和第二个隐藏层进行复制，如图2-8(a)所示。
(b)
图2-8 (a)为未合并的两个RBM模型，(b)为整合后的DBM模型
针对图2-8(a),条件概率定义如下式：
p(矿)=11 v) = sigmoid(￡%⑴V, +￡%(%,)	(2-33)
/	I
p(yi = 11 h⑴)= sigmoid(￡/"%/)	(2-34)
p(— =l|h ⑵)= sigmoid(Z 竹霁刀+Z 明昭2))	(2-35)
m	m
= 11 h⑴)=sigmoid(、峪)矿))	(2-36)
这里可以看出式(2-34)、式(2-36)分别与式(2-32)、式(2-31)相同。根据这些式子可 以分别计算两个RBM模型，之后再合并得到如图2-8(b)的时候，权重分别乘以 0.5,得到式(2-30)。这种通过复制输入层和隐藏层来模拟两个输入的方法，解决 了在逐层训练过程中，中间隐藏层的依赖输入数量与实际模型中的依赖输入数量 不同的问题。
根据以上介绍的DBM训练方式，可以分别训练基于文本与图片的DBM模 型，其中文本的输入模型为重复软最大化模型，图片的输入模型则是高斯受限玻 尔兹曼机模型，最后在两个DBM模型之上添加一个隐藏层作为联合特征，形成多 模态深度玻尔兹曼机模型(Multimodal Deep Boltzmann Machine, M-DBM)冋，如 图2-9所示。
1( X XX )1	h⑴
W(四)w’j'
呻	1(豉 x)i
l(X*乂)1	l(xgx)l
Image W"'}	' W(,l) Text
N	l(x文X)l	1以义X)l俨
图2-9 M-DBM模型
根据图2-9和式(2-17)可以得到图片输入层的条件概率：
「傭)=11 h(ffll)) = N(’.支矿	(2-37)
7=1
D v(w)	D v(/w)
p(丈)=l|v) = s@n如(￡ 亠-曾(2-38)
j=l D	/=1 Q
从h("到yS)是高斯取样，同时复制输入V(“)，其他条件概率的计算方法则与普 通DBM相同。根据式(2-16)可以得到文本输入层和隐藏层的条件概率:
的以=喚)=
D K	。 K
p(町)=1| V。) = S 观湖(￡￡ 寸咐 + ￡￡ 寸辎)	(2-40)
/=! A=1	i=] k-]
文本DBM的其他条件概率与普通DBM相同。
对于最顶层的联合RBM模型，可以得到如下条件概率:
p(妒)=11 h(w2),h02)) = sigmoid公骨理 2)+ ￡噬)疗)(2-41)
m	m
由于增加了联合隐藏层h⑶，所以h("2)和h同依赖的输入变为2o此时针对多模 DBM模型的图片部分，相当于一个有3个隐藏层DBM模型。根据论文［2］中的 介绍，复制输入只针对底层与顶层的单元，所以基于h("2)和甘冲)的RBM模型在 训练过程中，不再需要根据式(2-35)复制寸心。此时俨?的条件概率定义如下： 以破)=］| hS),h⑺)=sigmoid①V絆计？ +	呻)(2-42)
m	m
多模DBM模型的文本部分处理方法与式(2-42)相同。以图2-9为例，多模DBM 训练流程如下：
算法2-3多模DBM训练算法
输入：图像数据集I,文本数据集T,图像文本组合P
输出:W(ml),W(m2),W(叫w(,1),w(a\w(〃)
初始化：各个参数初始化为较小的随机值
训练基于俨°和砂")的RBM模型,根据式(2-37)和式(2-38),利用 CD算法训练参数所向)。
训练基于外心和砂刀的RBM模型，根据式(2-38)得到*°的值， 但权重需要乘以0.5o根据式(2-30)和式(2-31),利用CD算法训练 参数归(〃⑵。
训练基于和。5)的RBM模型，根据式(2-39)和式(2-40),利用 CD算法训练参数
训练基于力"和砂2)的rbm模型，根据式(2-40)得到砂)的值，但 权重需要乘以0.5,其余同步骤2。
此时已经分别完成图片与文本的DBM模型初始化。加入隐藏层爬 后，在给定图片和文本数据时，利用各自的DBM模型得到?心和 砂2)的值。根据式(2-41)和式(2-42)训练参数 W 和Ww ?注意图 像输入与文本输入有着对应关系。
流程中的CD算法参考算法2-1,其中各模态下输入RBM模型的条件概率在本 节中已经给出。
2.4.3信息检索
在RBM模型中，给定-个随机输入，根据条件概率通过多次吉布斯采样,可以使得随机输入逐渐趋向于有意义的输入⑶，这种方法也可以用于观察RBM 模型的学习情况。例如对于手写数字数据库MNIST,利用单层RBM模型训练后, 对于随机输入通过多次吉布斯釆样，可以得到如图2-10的结果。

图2-11,基于文本特征v"）进行特征重构，单箭头表示直接进行前向计算，双箭头表示 进行采样。
根据这种原理，在给定输入文本的）时，可以直接得到隐藏层砂2）的值，但外浪）的 值未知。因此可以根据式（2-41）和（2-42）进行多次吉布斯采样，重构出稳定的胛2）。 之后沿着图像DBM模型往下计算，最终得到重构的寸购特征。重构的特征通过
相似性计算检索数据中的图片特征，从而得到最终结果。同理，在给定图片输入 v㈣时，可以重构出/),完成信息检索，如图2-11所示。
2.5本章小结
本章主要讨论了在文本和图像中深度模型，这些模型作为本文多模态模型的 理论基础。在本章的最后，利用受限玻尔兹曼机实现了多模态深度玻尔兹曼机模 型，该模型在进行信息检索时，其优点在于可以重构出某一个模态的特征。利用 重构特征进行检索时，数据库中的数据可以预先建立特征索引，从而快速地获取 结果，因此多模态深度玻尔兹曼机模型适用于较大的数据库。

第三章自然语言处理
在多模态深度玻尔兹曼机中，文本的每个单词由一个二值向量表示，并且该 向量只有一个维度为1,用于表示该单词出现在字典中的位置。这种方法明显忽 略了单词在句子中的位置关系，同时单词特征之间没有可比性【171。为利用句子 结构以及单词本身的特性，本章中的单词特征以词向量表示，在此基础上分别利 用依赖树递归神经网络和双向循环神经网络获取句子结构从而构建新的文本特 征。
3.1依赖树递归神经网络
在词袋(bag-of-the-words)模型中，每个句子的特征是关键单词的出现数目， 这种模型忽略了句子的结构。而在许多语言模型应用当中，例如语音识别、文本 压缩中，句子结构都有着重要作用。5】。因此这一节当中，通过依赖树(dependency tree)。】获取句子结构。句子的依赖树是根据单词之间的语法关系建立的，如图3-1 所示。在树结构中，每个单词都有自己的词向量，通过依赖树对词向量进行整合， 可以分辨两个有着相同单词而不同结构的句子的特征。
因为依赖树是根据单词关系建立,所以在单词整合上也应该对这种关系进行 建模。这也相当于在两种不同的单词组合中，假如在依赖树中的关系相同，则应 该使用一样的参数。利用这种思想，本文利用递归神经网络(Recursive Neural Network^】预先定义一组权重参数来对应依赖树中各种单词的依赖关系，之后对 句子中的单词进行整合。
对于一个简单的句子"Students ride bikes at night.",可以得到如图3-2所示的 依赖树结构，该树根据单词的顺序确定其左右关系。根据图3-2可以得到单词1, 3和5是没有子树，直接对单词的词向量进行非线性转换，如式(3-1)所示，/是 非线性函数。为获取句子特征处，需要计算缶，计算方法如式(3-2)所示。根据式 (3-2)可以看出特征％先通过吒映射到隐藏层的特征空间后，佑通过线性转化与 其结合，最后再对结果进行非线性变换。
4"(F，c = l,3,5	(3-1)
hA=f(Wvx4+Wr}h5)	(3-2)

在式(3-2)中,矩阵吧6职*"中的rl表示节点5是节点4在右边的第一个节点， 因此递归神经网络是对节点的左右位置进行建模。左右节点的权重参数数目预先 设定，假如在测试集中，左右子树的个数超过训练集的个数时，则直接使用单位 矩阵。现在己经得到內所依赖的所有隐藏层特征，根据式(3-3)得到句子特征。
fh = f(WvX2 +岡也 +乙佑 + 仍2用)	(3-3)
模型训练过程包含前向传播和后向传播。前向传播中，需要利用树的后序遍 历算法思想，计算每个节点左右子树的隐藏层的值后，才能得到本节点的值，其流程和计算图3-2依赖树的姻一样。后向传播则是树的中序遍历，以计算图3-2 的依赖树为例，算法如下(忽略矩阵转置)：
算法3-1依赖树中序遍历算法
输入：损失函数误差de沥(丿)，单词特征x,?和隐藏层特征九
输出：△%,△作"仍2，A%】，△坊2
初始化：△气，△化"化2,△怡,△。为0
1、	对奶求Wv,Wn,Wr},Wr2的偏导，可以得到：
g(h2)= delta(J)*%
△吸+ = g饱)工2
△銘i+ = g(&)4
A%+ = g(始九
△忻+ = g(妇4
2、	根据中序遍历，先遍历左子树，即计算4。对九求亿的偏导：
g(4) = (g")*4
grad(%)+ = g(E
4节点没有其他子树，返回为后遍历右子树佑，计算流程与步骤2 相同，只需要替换参数。
3、遍历为后到达禹，同样可以得到：
g(4) = (g(妃吧 2)*〃
豳j = g(如)工4
△?i+ = g(4)4
节点4有右子树也，同时4没有子树，因此&的计算流程与步骤2 相同。
从后向传播算法中可以看到，每一个节点都计算完吨和左右参数后，将导 数累积到相关缓存中，再遍历其他节点。遍历完依赖树后，则可以得到全部相关 参数的导数，根据训练算法更新参数。另外对于损失函数中的max函数，当max 函数为0时，跳过该次迭代。
3.2双向循环神经网络
词向量模型中，每个单词都有自己特有的词向量并固定不变，不同单词之间的词向量互不相同。但将单词放在句子中时，希望单词的特征能够根据所处上下 文的不同而有所变化。例如："A police car zoomed by very close to them.”和“The car park was absolutely packed solid with people."中的单词“car”,在第一个句子 中与"police"组成"policecar”,而第二个句子中则与“park”组成"carpark”, 这种关系可以通过依赖树得到，如图3-3所示，并利用递归神经网络得到该词组 的特征。但本文在后续的多模态模型中，希望单词特征本身就可以包含这种信息, 相当于“car”的单词特征中有“police”的信息，因此本文利用循环神经网络中 隐藏状态可以传递的特性，实现单词包含句子信息的功能。循环神经网络通过状 态的传递使得每个单词的特征都包含着前文的信息，但缺少后文的信息，例如
“The carpark”中，“car”需要包含“park”的单词。为了使得每个特征都包含 前后文信息，需要添加一个相反的状态传递序列，成为双向循环神经网络 （Bidirectional Recurrent Netural Network, Bi-RNN）网。假定前向传递序列的隐藏层 状态为矿，后向传递序列的隐藏层状态为矿，则最终输出的结果是 z, —g（吧.（矿+矿）+聂，其结构如图3-4所示。
ROOT

假定输入句子有N个单词，单词的词向量用玉表示，其中t = l...N表示单词 在句子中的位置，根据Bi-RNN的定义，得到如下式子：
et=f(Wext+be)	(3-4)
h—+WM+bf)	(3-5)
hf=f(et+Wbh^+bb)	(3-6)
鸟=，吧印+矿)+如)	(3-7)
式(3-5)和式(3-6)分别是隐藏状态的前向转移和后向转移。每个单词特征通过 式(3-4)进行一次转换后，前后隐藏状态就分别通过权重参数与该单词特征结合， 得到该位置上的隐藏状态。最后模型将序列的隐藏状态相加，并进行非线性转换 从而得到输出特征。根据以上式子可以得到双向循环神经网络的训练算法：
算法3-2双向循环神经网络训练算法
输入：损失函数误差delta,.,单词特征耳，其中i = O...N-l
输出：参数的导数△叱,△飪，地,和输出s,.
初始化：△化,△吃,竺,的,M，紬为0，前向和后向传递缓存 也,旳为0,其中i = Q...N-\
1、前向传播，计算输出号.
for z = 0 to Ndo
e,=f(Wex,+be)
end for
试=f(eo+b‘)
加=1"1+辅)
for i = 1 to N_\ do
矿=f(el+Wfh!_}+bf)
end for
for i = 1 to N-2 do
就=，(e,+伍戒+勾)
end for
（续上表）
for z = 0 to N—l do
￥=■/（气（矿+矿）+如）
end for
return s
2、后向传播，计算参数导数
for i = 7V-l toO do
ds = delta. *s；
AWd =^Wd+hfdsT
Nbd = bJ^d +ds
4F+W汕 dh_f=df^h/'
if z > 1 then
^Wf=^Wf+h^dh_fT
end if
AZ>y = +dh_fT de = dh_f *e/ △阡△錦+x# bbe =皿+de
if z >1 then
end if
end for
for z = 0 to TV ~ 1 do
ds = delt^ *5/
△町=码+灿丁 db—dbj+Wjds dh_b = dbi*hf
if z<A^-lthen
end if
(续上表)
hsbb =^bb+dh_br de = dh_b*e.
△阡頌+耳把
△b*=?e+de
if i<N—l then dbM=dbM+W^dh_b
end if
end for
return △明,△”,△伍△佻,伙，啊
在双向循环神经网络的后向传播中，根据式(3-7)分出两条状态传递序列，对 应步骤2中的两个循环，因此利用BPTT算法分别在这两条状态传递序列中计算 参数导数。在后向传播过程中，用于保存从前后状态和输出号.传来的导数。
3.3本章小结
本章主要讨论了如何使得文本特征能够包含句子结构的方法,其中依赖树递 归神经网络最终得到的是句子特征，而双向循环神经网络则是单词特征。这些文 本特征将用于本文的多模态模型中。

第四章多模态模型
4.1依赖树递归神经网络多模态模型
在2.4节中，本文利用RBM模型的特性，通过一个模态的数据重构出另外 一种模态的特征，从而通过特征之间的比较完成信息的检索。在这一节中，图片 也是利用卷积神经网络完成特征提取，而文本的句子则通过3.1节中依赖树递归 神经网络建模，因此还需要定义损失函数学习文本特征与图片特征的映射关系， 同时训练递归神经网络中的参数。
在一个模态中，利用输入特征去检索己有数据中的特征时，希望正确结果 在输出队列中处于较前的位置。而在检索数据时，输入特征与数据库中的特征可 以进行比较，获取相似程度。根据这种思想，对于两个模态之间的互相检索，同 样需要正确结果处于前列，不同模态的数据可以进行相似性比较，因此定义一种 排列损失函数去完成特征融合。
首先，图像的特征与文本特征处于不同的特征空间，因此本文对图像特征进 行转换，使得其维度与文本特征相同，如式(4-1)所示。
=WjXf	(4-1)
x,是第i张图片的4096维特征，v,?则是线性转换后的特征。假如每张图片对应 着一个句子，通过递归神经网络得到的特征为y,由此得到排列损失函数：
丿(仍，。)=￡ ￡ max(0, A
'加	(4-2)
+Z Z max(0, △ - V；乃 + 诺光)
J E
0是递归神经网络的参数，不同模态特征之间的相似程度通过内积表示。损失函 数的第一项是根据图片去检索句子，max函数中的v,表示正确的图片-文本组 合的相似程度，诺力表示同样是给定图片i时，与错误的句子j之间的相似性。 根据正确的结果应该处于前列的思想,损失函数要求正确结果的内积比错误结果 的内积大。假如满足该条件，那么max函数的结果为0。△是内积的相差程度， △越大，那么模型对于正确与错误的分辨性能则越高，但过大的△会使得模型无 法收敛。损失函数的第二项则是给定句子去检索图片。损失函数是非负的，假如 损失函数为0,那么说明所有正确的内积都大于错误的内积，模型的训练是最小 化损失函数。
在给定N个句子和对应的N张图片时，可以得到图像特征与文本特征的内
积矩阵SclRgN,该损失函数的训练算法如下：
算法4-1损失函数前向传播和后向传播算法 输入：相似矩阵S,区间△
输出：损失值/qss,导数矩阵AZ
初始化： loss = 0, AL = 0, count = 0
前向传播：
for i = 0 to N do
for j = 0 to N do
if J then
loss = loss + max(0, A - S[很]+ 5[f,y])
count — count
end if
end for
end for
loss = loss / count
return loss
2、	后向传播：
for z = 0 to AT do
for 7 = 0 to AT do
if i^j then
mdist = A-5[z,z] + S[z, j]
if mdist > 0 then
z] = AL[i, z] -1 / count
AL[i9j] = l/ count
else
皿丿]=0
end if
end if
end for
end for
return AZ
该算法中，矩阵S对角线上的值作为正确组合的分数与同一行的其他分数比 较，计算损失函数的输出。后向传播中，假如max函数非0,导数则非0。假如 S中每一行对应一张图片与多个句子之间的关系，那么该算法是计算式(4-2)中的 第一项，第二项需要对矩阵S进行转置后再使用算法4-1进行计算。根据M可 以简单得到图像参数仍的导数，而求递归神经网络导数的算法则与算法3-1相 同。
4.2细粒度多模态模型
前文主要从一个完整图片或句子中提取一个固定长度的特征，但该特征不足 以描述复杂的内容。例如，图片中一般包含多个物体与背景，而CNN网络是针 对图像分类训练得到，因此获取的特征一般会针对某个特殊的物体，使得背景和 其他物体的信息无法得到或者在特征中不明显。为解决这种情况，图片部分需要 直接针对图片中的物体进行特征提取，获取更细粒度的特征。文本部分也是同样 的情况，但是文本中的每个词向量就是更细粒度的特征，只是特征中没有包含句 子的结构信息。为解决句子结构的问题，本文使用3.2节中的双向循环神经网络， 通过隐藏状态的传递，使得转换后的单词特征包含前后文信息。
4.2.1图像细粒度特征
原有的CNN的固定长度特征向量不足以描述复杂图片，因此本文通过物体 识别算法直接确定物体位置后再从物体的区域中提取特征。物体识别算法使用 2.2.2 节的区域卷积神经网络(Regions with Convolutional Neural Network, R-CNN), R-CNN的第一步是获取候选边界框，其算法有Selective Search。。】和EdgeBoxes[2l], 该步骤可以预测物体可能存在的位置，从而减少后续进行图像分类的运算a。】。 在Selective Search中，每个边界框都是从过分割的区间之间合并得到的，合并 时使用了多种策略来评价区间之间的相似程度。在EdgeBoxes中，候选边界框是 先通过滑动窗口生成，之后根据该边界框包含边缘轮廓的能力来进行评价。包含 的轮廓越完整，同时与边界框没有重叠，则评价越高。两种候选边界框算法的差 异也使得提取物体时的性能有所不同，EdgeBoxes更倾向于物体或者边缘丰富的 物体，对于一些没什么边缘的物体，根据EdgeBoxes的评分标准，得分明显会较 低。而Selective Search除了能够发现物体外，还会找出颜色相近或者纹理相近 的区间，根据算法会优先合并，并从新区间中生成新的边界框。两者之间互有优 劣，假如是偏向于物体识别，那么EdgeBoxes可能会有一定的优势，但对于边缘 较少的物体或颜色单一的物体，Selective Search会更有优势。
通过候选边界框提取算法后，R-CNN利用CNN网络提取边界框内的图片特 征，并通过分类器给出属于某个物体的概率。根据这些概率对候选边界框排序， 就可以得到最可能出现物体的边界框。本文使用前19个边界框以及整张图片作 为最终候选边界框，并利用CNN网络提取特征，作为图片的细粒度特征。
4.2.2多模态映射
与4.2.1节中的多模态映射一样，本节使用排列损失函数训练文本与图片模 型的参数，但是需要重新定义多模态细粒度特征之间的相似性评价标准。在4.2.1 节中，其相似性利用了两种模态特征之间的内积，但正确图片-文本对之间的特 征是一对一，而本章的细粒度特征则是多对多。同时图片中的物体与句子中的单 词没有预先给出对应关系，因此这种对应关系是该模型的隐藏特征。
为解决这种细粒度特征多对多的问题，本文利用正确的物体-单词组合在训 练数据中出现频率高于错误组合的情况，定义如下相似性评价函数：
v = WnS.CNNe{IbS\ + bm	(4-3)
S” =￡max%	(4-4)
f^gl
仏	(4-5)
i商
式(4-3)中，从物体图像K中通过CNN网络得到特征后，利用线性转化使得与文 本特征处于同一维度。在式(4-4)中，&表示第k张图片的边界框索引集合，i 表示第i个边界框，因此匕表示图片中的第i个边界框的特征，假如第k张图片 有20个边界框，那么& ={1,...,20}。同理幻表示第/个句子的单词索引集合，特 征之间的相似度评价依然使用内积。max函数是要求在给定句子中的单词t时， 找出与s,内积最大的图像特征所对应的边界框，形成单词与物体之间的对应关系。 对所有单词求和后得到的&就是在给定句子/并且为每个单词找到对应边界框 后，句子/与图片k的相似程度，式(4-4)也用于给定句子检索图片。同理式(4-5) 是给定图片k并且每个边界框找到对应单词后，得到图片k与句子/的相似程度， 可用于给定图片检索文本。由于物体与单词存在着对应关系，例如狗的图片与单 词”dog”，那么这种组合的出现频率会高于其他错误组合，因此模型会更倾向于 将狗的图片与”dog”关联，从计算结果来看，就是内积的值更高。
根据式(4-2)、式(4-4)和式(4-5),可以得到细粒度多模态模型的排列损失函数：
丿(°)= Z￡max(0, △-，.》+&) +
k /	r/
￡Zmax(0, △，&+&)
k I
当上=/时，表示正确图片-文本组合，该函数的训练方法与算法4-1相同。
4.2.3 Cafie 概述
对于双向循环神经网络，隐藏状态在序列中传递，沿着状态传递序列来看, 该网络是一个深层网络。假如输入句子长度为30,此时网络有30个隐藏层，只 是每一层的参数共享，因此训练速度较慢。为解决该问题，本文在Caflfe【3。］上实 现细粒度多模态模型。
Caffe是一个以layer作为模型基础的深度学习框架，每个layer都有自己功 能，其中主要分为 data layer、vision layer、loss layer 和普通 layer。
data layer主要负责数据的读取，其中包括从规定格式的数据库或者内存 中读取数据。本文主要使用其中的memory layer,该layer主要从内存中 读取数据，用户需要将数据以及标签的指针传送到该layer中。
vision layer主要包括卷积、池化和局部对比度归一化层。
loss layer则是训练网络的最后一层，其中定义各种损失函数相关的layer, 本文所使用排列损失函数也需要定义为loss layer。
普通layer主要包括各种数据操作，例如reshape、transport和resize等。 本文根据实际需求定义的一些数据操作都为普通layer<,
一个完整的网络是根据这些layer搭建出来，每个layer根据定义对输入进行 操作，然后将结果输出。数据操作定义在每个layer中的forward和backward函 数礼 同时实现了 CPU和GPU版本，所以新增layer时，实现的操作都需要有 两个版本。
除了数据操作外，Caffe定义了用于数据传输与保持的Blob类。由于Caflfe 同时管理者内存和显存，因此为使得存取数据时，保持数据的一致性和操作的透 明性，Caffe定义了 SyncedMemory类来完成底层的数据存取操作。在 SyncedMemory中保存着指向内存和显存的指针，同时利用own_cpu_data_标记 最新数据的存放位置。假如一个数据先存放在内存中，那么在获取内存中的数据 时，则不需要搜索显存。当获取显存中的数据数据时，由于最新数据保存在内存 中，因此SyncedMemory会将数据从内存转移到显存里。另外当用户是获取可变 动显存数据时，则认为最新数据保存在显存中，再次获取显存中的数据时，则不 需要与内存同步。因此own_cpu_data」J^^数据存取更加迅速，在编写layer操作 时，数据的操作都需要注意取出的数据是否需要修改。layer定义了前向传播和 后向传播的操作，而Blob类则是每个layer之间的桥梁，其中包括保存前向传播 数据的data_和后向传播数据的di町，两者都是SyncedMemory类。

每-一个layer允许有多个输入和多个输出，在创建网络时，layer会检查输入 和输出数目是否符合自身定义。输入称为layer的bottom,而输出则是top, bottom 和top都是Blob类的实例。Caffe定义了 Net用于管理这些layer, Net的主要工 作是根据定义创建网络，存放layer参数，为用户提供透明的前向传播和后向传 播操作，无需担心layer的执行顺序。在训练网络时，Caffe定义了一组Sovler 类，用于管理训练的参数，例如迭代次数、学习率的变化方式等。一个Sovler 保存了一个训练Net和多个测试Net,初始化时会自动根据定义创建完成。Caffe 的网络定义和训练方式是通过编写配置文件完成的，配置文件使用Protocol Buffer语言。
4.2.4双向循环神经网络实现
Caffe中的网络在初始化后不能再作修改，因此无法直接处理不定长的句子 输入。为解决该问题，网络需要预先定义序列长度，本文使用的序列长度是33, 长度较小的句子通过0补齐，过长的句子可以通过多次计算补齐。对于双向循环 神经网络，沿着传递序列看就是一个深度网络，每一层都有输出。因此根据该特 点，配置文件可以定义一个深度为33的神经网络，但共享同一组参数。
输入的序列一般有较长的无用数据(置0的数据)，但在计算过程中，偏置 项会使得没有单词的部分变成非0,影响后续的计算。为解决该问题，本文加入 蒙版输入，在适当位置将无用数据置为0o例如固定长度为L,句子长度为h时， 那么蒙版向量的维度为L,但只有前h维是1,其他为0。假定一个句子的特征 是，仁祀8, D是特征维度，表示一个单词的特征。与蒙版输入运算后，单词特 征的第1维到第h维保持不变，其他变为0。蒙版主要用在隐藏层的状态传递序 列上。
将双向循环神经网络展开后可以发现其中的层数众多，并且大多数参数设定 相同。为减少配置文件的编写困难，本文通过Protocol Buffer在python中的代码 库，利用代码生成网络的配置文件。其中需要在配置文件中预先定义好网络的关 键参数，包括亿、出、仇和仇。假定输入特征为t,其大小是(n,L,l,D), n是 训练时的batch大小，表示有n个句子。利用Caffe中的Slice层将每个句子展 幵得到特征',i = l,...,L,匕的大小为(n,l,l,D)o t,就作为图3-4中虚线部分网络的 底层输入。最终利用隐藏状态得到一系列的输出，通过Concat层将其重新整合， 作为多模态模型的细粒度文本特征。
4.2.5多模态模型实现
根据边界框标注的位置，模型从图片中获取物体特征后，利用InnerProduct层完成线性转换从而得到多模态模型的细粒度图像特征。为实现式(4-6)的损失函 数，需要先获取图像特征与文本特征之间的相似性矩阵。假定文本输入是 jeR(nx33)xW)图片输入是veK(-2o)xW> h是特征维度的大小，n是batch大小， 以下为计算相似性矩阵和实现损失函数的流程：
文本输入和图片输入进行矩阵运算得到
T
scoreb = vs
score。的大小为(〃x20/x33), Caffe中没有定义矩阵运算层，但有相应 的矩阵运算函数，因此本文直接利用该函数增加Multiply层。
为利用Caffe中的Pooling层完成式(4-5)的max运算，本文利用Reshape 层将scorq调整为大小是(1,1,mx20,mx33)的矩阵。在该Pooling层中， 宽度是序列长度33,高度和步长为1,相当于从每个句子中，为边界框 中的物体特征找到内积最大的值。因为在双向循环神经网络的定义中， 句子长度一般小于序列长度，多出的维度以0补齐，所以score,中有部 分值为0。这种情况影响了 Pooling层的计算，因为图片特征与文本特征 的内积可能会小于0,而文本特征超出部分以0补齐，这会造成max运 算的结果为0而不是真正的最大值，所以sco幣在进入Pooling层前，将 scoreb中以0补齐的值转变成非常小的值，消除对Pooling运算的影响。
通过Pooling层后，得到scorem,其大小为(1,1,*x20,")。之后同样使用 Pooling层完成式(4-5)中的求和运算。该Pooling层中，高度是每张图片 的边界框个数，宽度和步长为1。
通过步骤3后，经过Reshape整理得到大小为(n,n)的矩阵，每一行表示 一张图片与该训练批次中所有句子的相似程度。对角线则是正确图片- 文本组合的相似程度。根据这种情况，本文定义了 RankingMatrixLoss 层，该层的特有参数为margin,作为式(4-6)中的△,前向传播和后向传 播算法与算法4-1相同。以上流程完成了式(4-6)中的第二项。
对步骤1的sc。擀进行转置后，余下流程与步骤2到步骤4类似。对score； 调整为(l,l,"x33,〃x20)的矩阵后，通过两个Pooling层得到大小为(",〃) 的矩阵，将其输入到RankingMatrixLoss层中完成式(4-6)中的第一项。
利用Caffe框架除了可以实现深度模型外，还可以方便进行模型微调。例如 在训练好的细粒度多模态模型中，图像特征原本直接使用最后连通层的输出，为 了对全连通层微调，需要将图像特征改为pool5的输出，而全连通层则加入到多 模态模型中。Caffe在利用配置文件完成网络初始化后，允许网络从其他网络中 复制参数，其中参数复制根据layer的name进行匹配，但需要参数大小与原网 39
络定义的大小相同。通过这种参数的复制，模型可以在加载多模态模型后，再从 CNN网络中复制全连通层的参数。
4.3自然语言多模态模型
前文所研究的多模态模型关注提取句子特征与图像特征后，特征之间关系的 学习，其中2.4节利用了联合特征构建句子与图像之间的关系；4.1和4.2节则使 句子特征和图像特征在同一特征空间下能够进行比较。这种方法的优点在于可以 学习各种模态特征之间的关系，并利用可视化工具对特征进行管理和展示〔49】。 本文关注的是图文检索，主要强调分析句子结构和图像以获取更好的检索性能, 因此本节从另外一个角度出发，在没有获得句子特征的情况下，根据自然语言模 型在整合前后文信息上的能力，研究如何使得自然语言模型能够融合图像特征, 并进行信息检索。这种模型的优点在于可以基于图片生成文本，但其检索速度相 对较慢。
4.3.1多模态对数双线性模型
在2.3.2节中介绍了对数双线性模型(Log-Bilinear Language, LBL),该模型基 于RBM模型进行改进，利用上下文特征去预测下一个单词的特征。目前许多研 究都通过在自然语言模型中，引入图片特征来生成图片的描述，例如［11］中，在 短时记忆循环神经网络(Long Short-Term Memory Recurrent Neural Network, LSTM-RNN)中，引入了图片特征。因此本文也通过向LBL模型中引入图片特征， 对自然语言模型进行扩展。
steam


图4-1多模态对数双线性模型
引入图片特征的方式受［25］的启发，对图像特征进行转化后作为自然语言模型中的偏置项，根据式(2-25)可以得到预测特征：
昌艺以.	(4-7)
*是第i个单词的词向量，求和是对前1到n-1个单词求和。加入偏置向后得到：
M—1
方(4-8)
i=\
其中x是图像特征，C(‘)是图像的转换矩阵，使得图像特征与文本特征处于同一 维度，模型结构如图4-1所示。根据式(2-25),得到能量函数：
E(W"；Wi："t，x)= -洛“	-寿“	(4-9)
P(t=，|wg,x)的形式与式(2-26)一样，将能量函数代入即可求出。模型是 以受限玻尔兹曼机为基础，因此训练依然使用CD算法。
4.3.2信息检索
本节的多模态模型是基于自然语言模型，因此其损失函数不再是分别面对图 像特征和文本特征。图像的特征是用于影响文本预测下一个单词的概率，没有明 确的文本特征。为了能够使得该模型也可以用于信息检索，同样需要定义图像与 文本之间的相似性。在自然语言模型中，困惑度(perplexity)是用于评价该模型 预测下一个句子程度的好坏［17］：
log? C(吗” | x) = -￡:￡她2 P(吗=/| %_”x)	(4-10)
N wb?
其中辎：”_1表示1到n-l个单词，其序列长度为N。遍历整个序列得到的概率负 对数平均，则是困惑度。假如正确单词的概率越高，说明模型性能够好，其困惑 度则越小。因此给定一个长度为N的句子，从图片数据库中检索图片时，将图 片特征代入，根据式(4-10)得到每张图片对应该句子的困惑度。因为正确的图片 会指导语言模型去预测更好的单词，所以其困惑度更小，从而完成信息检索任务。 例如给定”There is a dog.”,猫和狗的图片在预测前3个单词时，预测概率会相似， 但预测关键字”dog”时，狗的图片得到概率会比猫得到的概率高，从而区别出猫 和狗的图片。这种方法的缺点非常明显，在给定一个句子时，需要遍历整个图像 数据库，计算每个句子对应图片的困惑度，无法建立索引进行加速。
当给定图片，对文本进行检索时，同样需要计算图片与所有句子的困惑度， 但不同于文本数据，整个数据库的图像特征是可以预先计算的，相似的图片之间 特征也相近。假如给定一张有狗的图片，那么可以利用这张图片的特征，通过特征之间的相似性计算，找到数据库中相似图片。搜索方法可以先根据图像特征建 立索引，获取前k张图片。在前k张图片中，各自都会有相应的描述，此时请求 的图片再与这些描述一起计算困惑度，从而检索到文本结果。
4.3.3文本生成
在给定开始单词与图片后，根据式(2-26)可以求出下一个单词的出现概率， 概率最高的作为该位置的单词，之后再利用新的上下文预测新的单词，当遇到特 殊介绍单词，，<end>”时则停止。生成的句子的质量依赖于训练数据的质量和数量, 生成句子的风格会与训练数据挂钩。如表4-1所示为给定图片生成文本，模型通 过Flickr8k【23］训练，每张图片中的前5个句子是数据集中图片对应的正确句子, 第6个句子是模型生成的句子，并给出对应的困惑度，困惑度越低说明生成句子 质量越高。
表4-1生成文本
a tan dog jumping through the field with some barren trees in the background .
A tan dog runs through the brush.
A white dog runs on brown grass.
A white dog with beige spots is running through a field.
The light colored dog is running through a field.
a dog is running through the grass. (0.586217)
a boy runs along the street.
A child running on the sidewalk.
a young boy running in a street race.
A young boy runs in a race.
Blond child running in a race.
a young girl wearing a red shirt is holding a object in the background』1.262091)
The girls are taking a picture of themselves.
Two blonde girls are taking a picture of themselves.
Two blonde women are smiling while one is holding a camera to capture their image.
Two girls taking a picture of themselves.
Two young girls are taking a picture of themselves with a

(续上表)camera.
the woman is holding the camera , while the woman and
the other is playing the the street (1.960438)

从生成文本可以看岀，模型基本可以找到图片中的关键部分，但有一定的语 法问题或者是描述错误。
4.4本章小结
本章利用第三章得到的文本特征，分别构建出依赖树递归神经网络多模态模 型和细粒度多模态模型。前者利用依赖树分析了句子结构，使得模型在面对有着 相似单词集合的两个句子时，可以根据句子结构对文本特征进行区分，有利于提 高图文检索精度。后者则通过学习细粒度特征之间的关系，使得模型自己去寻找 图像与文本中的关键部分，利用关键部分的匹配实现图文检索。在本章的最后， 本文利用图像特征作为偏置项，构建出基于对数双线性模型的多模态模型。由于 图像特征会影响单词预测概率，因此本文在图文检索中使用困惑度评价图像与文 本之间的相似度。当图像使得自然语言模型在计算句子困惑度越低时，则说明图 像与文本更加匹配。这种多模态模型在检索速度上由于要计算句子困惑度，使得 检索速度较慢，但其优点是能够根据图像生成描述。

第五章实验
为验证不同模型的效果，这里使用同样的数据集Flickr8k【23】，该数据集有 8000张图片，每张图片有5个句子。其中图片数据是来源于Flickr,而文本数据 则是人工生成，不是原始数据。原始数据主要有图片描述、标签、标题和用户评 论，这些文本数据虽然丰富，但是文本数据一般不针对图像的内容，更多是人的 情感或者拍这张图片时的地点和发生的事情PR。该数据是用于信息检索，因此 文本数据通过Amazon Mechanical Turk重新生成，如表5-1所示。这8000张图 片中，1000张作为验证集，1000张作为测试集，剩下的作为训练集。
表5-1训练数据
A child in a pink dress is climbing up a set of stairs in an entry way.
A girl going into a wooden building.
A little girl climbing into a wooden playhouse.
A little girl climbing the stairs to her playhouse.
A little girl in a pink dress going into a wooden cabin.
m ’him	A black dog and a spotted dog are fighting
A black dog and a tri-colored dog playing with each other on the road.
A black dog and a white dog with brown spots are staring at each other
jv 1	in the street.
涔緇雪京	Two dogs of different breeds looking at each other on the road.
Two dogs on pavement moving toward each other.

5.1训练
对于多模态深度玻尔兹曼模型，本文首先利用更大的数据集MIR Flickr^】 对网络进行预训练。该数据集包含一百万张图片和用户给的标签，这些数据来源 于Flickro在这一百万张图片中，有25000张图片标记了 24个主题，例如:bird、 tree、people、indoor> sky和night等。该数据集中有2000个高频标签，平均每 个图像有5.15个标签，标签数量的标准差为5.13。另外，在25000张图片中， 有4551是没有文本输入。使用VGG-16【38］的CNN网络中最后一个连通层的输出 作为深度玻尔兹曼模型的图片特征，那么图片的高斯RBM模型有4096个输入 单元，之后两层RBM的隐藏单元数目均设定为1024。对于文本部分，结合MIR
Flickr的高频标签和Flickr8k的高频词汇，得到2000高频单词，因此重复软最大 化模型有2000个输入单元，表示字典大小为2000,之后两层RBM的隐藏单元 数目同样是1024。对于最顶层的隐藏层，其单元数目设定为2048。每层RBM 模型都使用PCD【3i］算法来初始化DBM模型，PCD算法是CD算法的改进。在 CD算法中，每次吉布斯釆样的初始值为数据本身，而PCD则是使用上一次吉布 斯采样后的值，PCD优点是随着采样的进行，更接近均衡分布。而CD算法则在 每次迭代时，需要以输入数据作为初始值，进行多次吉布斯采样，从而更接机均 衡分布【31】。训练高斯RBM中，设定式(3-9)中的方差为1,并且保持不变，相当 于不对方差进行训练。预训练的初始学习率为0.001,参数使用方差为0.01、均 值为0的高斯函数进行随机初始化，遍历训练集25次，学习率线性降到原来的 0.01倍。完成预训练后，使用Flickr8k对模型微调，图片使用相同方式处理，根 据字典统计文本中句子的单词数目作为文本特征。训练算法使用PCD算法，初 始学习率为0.0001,遍历训练集15次，最后3次学习率变为原来的0.1倍。
在依赖树递归神经网络中，文本需要根据依赖树生成句子特征。因此本文使 用斯坦福大学的语言分析器〔39】为句子生成依赖树，同时使用word2vec【4。］预先训 练好的词向量矩阵，对于没有词向量的单词，使用特定的向量替换。图片特征依 然使用基于VGG-16的CNN特征，转换后的维度设定为600?训练使用随机梯 度下降，batch size为100,参数通过高斯函数随机初始化，初始学习率为0.01, 每当遍历数据集10次后变为原来的0.1倍，直到变为0.0001则不再下降。损失 函数中的△为3,当损失函数趋于平缓时停止训练。
对于细粒度多模态模型，分别利用Selective Search和EdgeBoxes提取2000 个候选边界匡。使用基于Caffe的R-CNN模型得到边界框中存在物体的概率， 由于使用EdgeBoxes提取的边界框过于集中，因此使用非极大值抑制对边界框进 行过滤刖，其中IoU分别设定为0.5和0.6。如4.2.1节中介绍的流程，获取20 个边界框。边界框内的图像特征分别使用R-CNN模型和VGG-16的CNN网络 进行提取，但训练完成后对VGG-16的CNN网络进行微调。文本使用word2vec 的词向量，去除句子中的标点符号以及”a”、”the”和”an”，罗马数字统一由一个 词向量代替。训练初始学习率为0.001,遍历数据库20次，最后4次学习率变为 原来的0.1倍，batch size为100。使用VGG-16的多模态模型，训练完成后微调 CNN网络中的最后两个全连通层，此时提取的特征是pool5层输出，其大小为 (n,512,7,7),初始学习率为0.0001,遍历数据库15次，最后3次学习率变为原来 的0.1倍。双向循环神经网络中的隐藏状态维度为600,输出维度为1200。式(4-6) 的△为10, △从1到10的时候，检索结果的topi、top5和toplO都有提高，到 10以后则基本不变，但中值以及平均正确检索值则继续降低，说明△的增大，可以提高模型的整体性能。
对于自然语言多模态模型，对数双线语言模型使用word2vec的词向量初始 化,所有上下文参数矩阵使用的weight decay为1.0 x 1 而单词特征使用1.0 x 10书。 batch size为20,初始学习率为0.2,以指数方式下降，参数为0.998,上下文特 征的步长为5,相当于5-gram。
5.2模型方法对比
本文将与关于图文检索的相关工作进行性能对比，包括DeViSEl",学习图 片与标签或没有注释的文本数据之间的关系，该模型的特点是在为图片打标签时 能够达到zero-shot预测，即在训练中该标签下没有图片数据;Deep Fragment"】， 该模型与本文的细粒度多模态模型相似，图片部分使用基于Selective Search的 R-CNN提取边界框，但在文本部分是根据依赖树的关系建模，同时在计算文本 与图片特征之间相似性方法上不一样。
5.3实验结果
实验基于Flickr8k的测试集，有1000张图片，每张图片有5个句子，因此 在利用文本检索图片时，是遍历5000个句子，每个句子从1000张图片中找出结 果。利用图片检索文本时，是遍历1000张图片，每张图片从5000个句子中找出 结果。本文使用［42］中的评价标准，提供排列中值(median rank, Medr),即所有 测试集获取到正确结果后进行排序，获取其中的中位数。例如有5个测试集，其 正确结果分别位于2、10、2、13和14,那么Med r为10,该值越低越好，用于 评价模型整体的检索性能。R@N,指前N个结果中，有正确结果的比例。例如 有100个测试集，其中有50个测试集可以从自身检索的前5个结果里找到正确 的结果，那么R@5为50/100*100%=50%,因此该值越高越好。
表5-2的细粒度模型中,EB-50 RCNN和EB-60 RCNN表示分别使用IoU为 0.5和0.6的非极大值抑制对EdgeBoxes生成的边界框进行过滤，用R-CNN的 CNN网络获取图像特征。SS VGG-16表示使用SelectiveSearch算法生成边界框， 用VGG-16获取图像特征。SS finetune VGG-16表示使用SelectiveSearch算法生 成边界框，用微调后的VGG-16获取图像特征。SS RCNN表示使用SelectiveSearch 算法生成边界框，用R-CNN的CNN网络获取图像特征。
从实验结果中可以看出基于Selective Search和R-CNN的细粒度模型有最好 的结果。EdgeBoxes在提取候选边界框时速度快于Selective Search,但由于 47
EdgeBoxes的边界框是根据边缘生成，因此会聚集在图片边缘丰富的位置。使用 IoU为0.5的非极大值抑制时，可以过滤大部分的集中边界框，但还是有明显的 聚集现象。使用IoU设定为0.6时，有部分边界框开始标记一些场景，但有许多 是无意义的位置，如图5-1所示。
表5-2图文检索
Sentence Retrieval
模型	R@1	R@5	R@10	Med r
随机排列	0.1	0.6	1.1	631
DeViSE〔4i】	4.8	18.0	28.6	32
Deep Fragment1421	12.6	32.9	44.0	14
Multimodal DBM	3.3	15.3	25.2	34
多模态对数双线性模型	8.2	26.2	32.4	30
依赖树递归神经网络	10.0	29.9	44.4	13
细粒度EB-50 RCNN	13.2	34.8	45.0	13
细粒度EB-60 RCNN	15.1	35.9	50.1	9.8
细粒度SS VGG-16	12.3	33.1	44.5	21.7
细粒度SS
finetune VGG-16	15.4	37.6	51.2	10
细粒度SS RCNN	16.2	38.9	53.4	8.6
Image Retrieval
随机排列	0.1	0.5	1.0	500
DeViSE"	5.9	20.1	29.6	29
Deep Fragment?	9.7	29.6	42.5	15
Multimodal DBM	4.9	17.1	26.9	32
多模态对数双线性模型	7.6	25.0	33.4	31
依赖树递归神经网络	7.4	24.9	36.3	21
细粒度EB-50 RCNN	9.4	29.8	42.3	18.6
细粒度EB-60 RCNN	10.2	30.5	43.3	14.2
细粒度SS VGG-16	8.2	27.4	39.5	20
细粒度SS
finetune VGG-16	10.5	31.6	43.1	18
细粒度SS RCNN	11.5	32.8	44.9	15.6

从实验结果也可以看出,IoU为0.6的检索精度高于IoU为0.5的检索精度。 本文还比较了细粒度模型中，使用VGG-16和R-CNN的CNN网络在提取图片 特征时的效果，从实验中可以看出，由于R-CNN的CNN网络是基于物体识别 进行了微调，因此可以更能反映出物体本身的特征。但在对VGG-16的全连通层 进行微调后，可以发现明显的检索精度的提升。根据论文［12］中的介绍，对conv3-l 以上的网络进行微调可以得到更好的效果。Deep Fragment同样是对从图片中提 取物体，但在文本建模上是利用单词在依赖树的关系形成词组，寻找与物体之间 的关系，实验表明双向循环神经网络优于依赖树的建模。
在众多模型当中，多模态深度玻尔兹曼机的效果较差，主要原因在于文本建 模上。当两个句子有着相似单词的情况下，由于字典大小的限制可能会出现文本 特征相同的情况，这会造成在检索结果上的混淆，但依然可以检索到相似结果。 该模型的优点在于特征重构上，可以利用数据库中的特征预先建立索引，提高检 索速度。另外RBM模型可以利用大量无标记数据进行预训练，还具有提升空间。
依赖树使用单一特征表示句子和图片，因此在检索结果上比细粒度模型差， 但由于使用了依赖树和词向量对文本进行建模，所以优于多模态深度玻尔兹曼机。 在图片特征提取上没有物体识别和提取多个图片特征的流程，因此速度比细粒度 模型快。
自然语言多模态模型在检索上使用困惑度作为图片与文本之间的匹配评价 标准，因此需要连续计算句子中下一个单词的出现概率才能完成一次困惑度的计 算，所以检索速度较慢。但自然语言多模态模型可以根据图片生成文本，其效果 与训练集有关。

(a)	(b)	(c)
图5-1边界框，(a)是使用Selective Search提取边界框后，利用R-CNN过滤后的19个边 框图。(b)是EdgeBoxes算法得到的，而(c)是使用IoU为0.6的非极大值抑制过滤后的边框 图。可以看ii Selective Search能够将球和女孩标示出来，而EdgeBoxes则将重点放在球 上，经过过滤后才能标示出女孩，但有部分边间框处于无用位置上。

使用多模态模型检索的结果如图5-2所示，尽管模型无法将最为正确的图片 结果处于最前位置，但依然能够获取非常相似的图片。在细粒度多模态模型下,使用文本去检索图片得到的前3个结果如图5-3所示，其中将每个单词和单词找 到的物体关联起来。从图5-3中可以看到，单词”children”都获得较高分数，同时 在第1、3张图片中占绝大部分分数。第二张作为正确图片，关键单词的分数分 布比较均匀，例如"naked”、"showering”、"containers”与"children”有着相近分数， 使其能够进入结果的前3位。图5-4是使用图片检索文本的例子，检索的前3个 句子都是对应句子，展示方式和文本检索图片一样，但在实际当中是20个边界 框去找最适合的单词。在图5-4的全部图片中，单词”red”和”ball”都指向红色的 球，这相当于为红色球找到对应的文字解释。另外动词”chasing”指向包括了狗和 球的边界框，刚好阐述了这个动作的含义。在图5-3的第二张图片中也有类似的 情况，形容词”naked”指向了小孩的身体。从图5-3和图5-4中还可以看出，句子 中的许多介词与图片之间的关系基本上小于0,这是由于在训练中介词没有特定 的图片-文本组合，因此也没有学到任何关系，这也说明式(4-4)和式(4-5)学习到 了图片坷文本之间的隐藏特征。根据图5-3和图5-4可以得到，细粒度多模态模 型除了能够提升图文检索精度外，还建立了视觉特征与文本语义之间的关系。

图 5-2 检索结果，检索句子为 a bus driving on the street next to a Victorian style building,前两个结果是错误，第三个是正确目标。从这里可以看到三张图片差异较小，唯 —的差别只在于最后的三个单词Victorian style building,模型可能无法学习到


Victorian style,但能够确定bui Iding,因此返回相似图片。


(b)
(c)
图5-3文本检索图片，第二张是正确结果，评价分数从上往下降低。
12.74.bail
J-5?.rwo
2.34 .small
J.0.77.white
6.05,dogs ,3.59；chasing -O.?S,after
(b)

第六章总结与展望
6.1总结
本文的具体研究内容主要围绕当前跨模态检索中图像-文本的交互检索问题。 由于深度模型在各模态下的发展，使得能够更好地获取图像与文本特征。因此本 文以这些深度模型为基础，根据这些模型在特征提取上的特点，研究了如何学习 图像特征与文本特征之间的关系，建立多模态模型，并通过实验证明了其在图文 检索上的性能和学习视觉特征与文本语义关系上的能力。
具体而言，本文的研究主要根据图1-1的流程进行展开：分析单模态下特征 提取的优缺点，使用相关模型完成特征提取。得到特征后，分析检索时需要的信 息，定义模态转化方法和检索时评价检索结果的指标。得到模态转化方法后，研 究如何根据对应的损失函数完成多模态模型的训练。
在2.4中，从基于受限玻尔兹曼机的模型来引入多模态模型。多模态模型第 一步是针对不同类型的数据进行特征转换，使其能够在后续操作中进行融合。例 如该章中，图像是密集型的特征，而文本是稀疏型特征，为了能够对这两种特征 融合，使用深度玻尔兹曼机对原始特征进行编码。根据受限玻尔兹曼机在重构特 征上的特点，利用联合特征去学习图像与文本在特征上的关系，使得在缺少单一 模态时，依然能够利用釆样重新构建缺失的数据。这种多模态模型虽然在实验中 精度不是很高，但可以利用特征预先建立索引，提高检索速度。
为解决多模态深度玻尔兹曼机中文本特征的缺点，第三章讨论了如何使得文 本特征包含句子结构信息。依赖树递归神经网络考虑到句子本身的结构，对单词 之间的关系进行建模。本文只使用了依赖树分析句子结构，因此还可以用其他树 来对句子进行分析。另外可以使用卷积神经网络，直接让模型去学习不同的单词 结构。
第四章在第三章的文本特征上，从两个角度来建立多模态模型，其中4.1和 4.2节是学习不同模态特征之间的关系，4.3节是对自然语言模型进行扩展。在 4.1节中，定义了文本特征与图像特征之间的关系，引入排列损失函数学习递归 神经网络和图像转换的参数，该函数需要获取图片-文本组合的关系评分，使得 正确的组合比错误的组合高，所以本文通过特征的内积获得评价分数。该模型相 比多模态深度玻尔兹曼机，在检索精度上有所提升，但无法根据单一模态的数据 重构另一模态的数据，只能与数据库中的特征进行内积计算来检索结果。4.2节 中为了使得模型能够从复杂数据中获取更多的信息，在图像方面利用物体识别算法从图片中找出物体和场景的位置。文本则是利用双向循环神经网络使得单词特 征包含上下文信息。细粒度多模态模型的关键是能够准确地获取图片和文本中的 关键信息，例如图像中的场景信息。在训练集中经常有人与各种动物的图片，部 分文本的重复度极高，其中的差别就是背景信息以及人与动物的动作。在实验中 使用了两种边界框提取方式也是表现出这种差别，EdgeBoxes可以很好地找出物 体，但比较难挖掘出其他信息，而Selective Search由于其实现机制，可以很好 地获取场景信息。即使同样是无法获取，相比EdgeBoxes, Selective Search也不 会经常获取一些无用的纹理信息。EdgeBoxes提取的边界框有集中到复杂纹理的 倾向。在细粒度多模态模型中，另外一个较为关键的部分是这些图片与文本的片 段如何进行关联。在训练集中，这些关联没有给出，只能依靠模型去学习，因此 物体与单词的关联关系是隐藏特征。该关联关系的学习主要体现在式(4-4)与式 (4-5)中，每次只获取内积最大的片段，假如某个单词与物体经常岀现，那么该部 分学习的次数就会增多，最后就会建立关联关系。在实验当中，这种关联关系也 很好地变现出来。4.3节则是使用了另外一种特征融合思想，前两节的多模态模 型都需要分别针对图片与文本进行建模和获取特征，再根据特征训练多模态模型。 在4.3节中，模型是建立在自然语言模型上,通过对其进行扩展来学习关联关系， 因此该方法可以扩展到其他自然语言模型上。
从最后的实验结果可以看出，细粒度的特征在信息检索方面比粗粒度特征好, 但细粒度特征的提取方法会影响最终结果，同时在提取特征上需要较长的时间。 自然语言模型由于其本身的限制，在检索上会收到限制，但其可以用于文本生成。
6.2展望
本文介绍的多模态模型主要集中在信息检索上，但多模态模型的使用范围非 常广泛，不应该限制在文本与图片中，例如将其用在语音和图片中，进行更准确 的语音识别，其中图片就是读取嘴唇变化。而本文介绍的细粒度模型中，物体识 别算法方面可以通过Faster R-CNN"】，将图片细粒度特征提取方法进一步整合 到多模态模型当中。
多模态模型也有它的极限，多模态模型受限于不同模态数据的研究程度。例 如深度学习在图片、文本语音上的应用，使得这些类型的特征提取上有巨大进步， 而多模态模型能够在这些特征上进行近一步学习，获得较好的效果。另外多模态 模型目前还没有使用更多模态的数据。当模态增加时，学习参数也会增多，同时 更多模态的数据是否能够提升性能也需要进行研究，过多的模态反而会使得模型 不能收敛。

最后，由于作者的研究水平和时间方面的限制，对一些研究方法和研究问题 的认识上难免存在不足，恳请各位专家、老师予以批评指正。

参考文献
[1]Hinton G E, Salakhutdinov R. Replicated softmax: an undirected topic model [C]//Advances in neural information processing systems. 2009: 1607-1614.
[2]Salakhutdinov R, Hinton G E. Deep boltzmann machines[C]//International Conference on Artificial Intelligence and Statistics. 2009: 448-455.
[3]Hinton G, Osindero S, Teh Y W. A fast learning algorithm for deep belief nets [J]. Neural computation, 2006? 18(7): 1527-1554.
[4]Mnih A, Hinton G. Three new graphical models for statistical language model- ling[C]//Proceedings of the 24th international conference on Machine learning. ACM, 2007: 641-648.
[5]Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.
[6]Socher R, Lin C C, Manning C, et al. Parsing natural scenes and natural language with recursive neural networks[C]//Proceedings of the 28th International Conference on Machine Learning (ICML-11). 2011: 129-136.
[7]De Mameffe M C, MacCartney B, Manning C D. Generating typed dependency parses from phrase structure parses[C]//Proceedings of LREC. 2006, 6: 449-454.
[8]Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation[J]. arXiv preprint arXiv:1311.2524,2013.
[9]Lowe D G. Distinctive image features from scale-invariant keypointsfJ]. International journal of computer vision, 2004, 60(2): 91-110.
[10]Le Q V, Mikolov T. Distributed Representations of Sentences and Docu- ments[J]. arXiv preprint arXiv: 1405,4053, 2014.
[1 l]Vinyals O, Toshev A, Bengio S5 et al. Show and Tell: A Neural Image Caption Generator [J]. arXiv preprint arXiv: 1411.4555, 2014,
[12]Girshick, Ross. ”Fast R-CNN.” arXiv preprint arXiv: 1504.08083 (2015).
[13]He, Kaiming, et al. HSpatial pyramid pooling in deep convolutional networks for visual recognition.'' Computer Vision-ECCV 2014. Springer International Publishing, 2014. 346-361.
[14]Blei D M, Ng A Y, Jordan M I. Latent dirichlet allocation[J]. the Journal of ma-chine Learning research, 2003, 3: 993-1022.
[15]Dalal N, Triggs B. Histograms of oriented gradients for human detec- tion[C]//Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on. IEEE, 2005,1: 886-893.
[16]Boureau Y L, Bach F, LeCun X et al. Learning mid-level features for recogni- tion[C]//Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on. IEEE, 2010:2559-2566.
[17]Bengio Y, Ducharme R, Vincent P, et al. A neural probabilistic language model[J]. The Journal of Machine Learning Research, 2003,3: 1137-1155.
[18]Schuster M, Paliwal K K. Bidirectional recurrent neural networks]J]? Signal Processing, IEEE Transactions on, 1997,45(11): 2673-2681.
[19]Funahashi K, Nakamura Y Approximation of dynamical systems by continuous time recurrent neural networks[J]? Neural networks, 1993, 6(6): 801-806.
[20]Uijlings J R R, van de Sande K E A, Gevers T, et al. Selective search for object recognition^]. International journal of computer vision, 2013, 104(2): 154-171.
[21]Zitnick C L, Dolldr P. Edge boxes: Locating object proposals from edg- es[M]//Computer Vision-ECCV 2014. Springer International Publishing, 2014: 391-405.
[22]Dollar P, Zitnick C L. Fast edge detection using structured fbrests[J}? 2014.
[23]Hodosh M, Young P, Hockenmaier J. Framing image description as a ranking task: Data, models and evaluation metrics [J]. Journal of Artificial Intelligence Research, 2013: 853-899.
[24]Huiskes M J, Lew M S. The MIR Flickr retrieval evaluation[C]//Proceedings of the 1st ACM international conference on Multimedia information retrieval. ACM, 2008: 39-43.
[25]Ma, Lin, et al. "Multimodal Convolutional Neural Networks for Matching Image and Sentence,*' arXiv preprint arXiv: 1504.06063 (2015).
[26]Mnih, Andriy, and Geoffrey Hinton. ”Three new graphical models for statistical language modelling.,^ Proceedings of the 24th international conference on Machine learning. ACM, 2007.
[27]Felzenszwalb, Pedro F., and Daniel P. Huttenlocher. ”Efficient graph-based image segmentation.*1 International Journal of Computer Vision 59.2 (2004): 167-181.
[28]Ren, Shaoqing, et al. "Faster r-cnn: Towards real-time object detection with region proposal networks/1 arXiv preprint arXiv: 1506.01497 (2015).
[29]Duchi, John, Elad Hazan, and Yoram Singer. "Adaptive subgradient methods for online learning and stochastic optimization.n The Journal of Machine Learning Research 12(2011): 2121-2159.
[30]Jia, Yangqing, et aL nCaffe: Convolutional architecture for fast feature embedding.n Proceedings of the ACM International Conference on Multimedia. ACM,2014.
[31]Tieleman, Tijmen, and Geoffrey Hinton. "Using fast weights to improve persistent contrastive divergence/1 Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 2009.
[32]Tinto, Vincent. ^Dropout from higher education: A theoretical synthesis of recent research.n Review of educational research (1975): 89-125.
[33]Felzenszwalb, Pedro F., et al. "Object detection with discriminatively trained part-based models." Pattern Analysis and Machine Intelligence, IEEE Transactions on 32.9 (2010): 1627-1645.
[34]Martens, James, and Ilya Sutskever. nLearning recurrent neural networks with hessian-free optimization." Proceedings of the 28th International Conference on Machine Learning (ICML-11). 2011.
[35]Wallach H M. Topic modeling: beyond bag-of-words[C]//Proceedings of the 23rd international conference on Machine learning. ACM, 2006: 977-984.
[36]Hochreiter S, Schmidhuber J. Long short-term memory [J], Neural computation, 1997, 9(8): 1735-1780.
[37]Bengio Y, Lamblin P, Popovici D, et al. Greedy layer-wise training of deep networks [J], Advances in neural information processing systems, 2007, 19: 153.
[38]Simonyan K, Zisserman A, Very deep convolutional networks for large-scale image recognition^]. arXiv preprint arXiv: 1409.1556, 2014.
[39]Chen D, Manning C D. A Fast and Accurate Dependency Parser using Neural Networks[C]//EMNLP. 2014: 740-750.
[40]Mikolov T, Chen K, Corrado G, et al. Efficient estimation of word representations in vector space[J]. arXiv preprint arXiv: 1301.3781,2013.
[41]Frome A, Corrado G S, Shlens J, et al. Devise: A deep visual-semantic embedding model [C]//Advances in Neural Information Processing Systems. 2013: 2121-2129.
[42]Karpathy A, Joulin A, Li F F F. Deep fragment embeddings for bidirectional image sentence mapping[C]//Advances in neural information processing systems.2014: 1889-1897.
[43]Jolliffe L Principal component analysis[M]. John Wiley & Sons, Ltd, 2002.
[44]Mikolov T, Karafidt M, Burget L, et al. Recurrent neural network based language model[C]//INTERSPEECH. 2010,2: 3.
[45]Ngiam J, Khosla A, Kim M, et al. Multimodal deep leaming[C]//Proceedings of the 28th international conference on machine learning (ICML-11). 2011: 689-696.
[46]Smeulders A W M, Worring M, Santini S, et al. Content-based image retrieval at the end of the early years[J]. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 2000,22(12): 1349-1380.
[47]S.K.Chang. Pictorial database systems. IEEE Computer, 1981, 30( 11 ):13?31
[48]温超，耿国华.基于内容图像检索中的“语义鸿沟”问题[J].西北大学学报: 自然科学版,2005, 35(5): 536-540.
[49]O'Halloran K, Tan S, Smith B, et al. Challenges in designing digital interfaces for the study of multimodal phenomena[J]. Information design journal, 2010, 18(1): 2-2L
[50]Zeng C, Cao J, Peng Z, et al. A novel cross-media layered semantic mining model [J]. Wuhan University Journal of Natural Sciences, 2008, 13(1): 21-26.
[51]Dahl G E, Yu D, Drag L, et al. Context-dependent pre-trained deep neural networks fbr large-vocabulary speech recognition]J]. Audio, Speech, and Language Processing, IEEE Transactions on, 2012,20(1): 30-42.
[52]Montavon G, Braun M L, Muller K R. Deep Boltzmann machines as feed-forward hierarchies[C]//Intemational Conference on Artificial Intelligence and Statistics. 2012: 798-804.
[53]Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 1-9.
[54]Srivastava, Nitish, and Ruslan R. Salakhutdinov. "Multimodal learning with deep boltzmann machines/' Advances in neural information processing systems. 2012.

