
第一章绪论
1.1研究背景
自互联网诞生以来，人类社会发生了天翻地覆的变化。互联网从各个方面改 变着人们的生活方式，使人们的社交变得简单而快捷，地球因为互联网的告诉发 展而真正成为“地球村”。十年前，互联网只是高薪收入家庭的宠儿，而十年后 的今天，随着互联网的高速发展，移动互联网等其他方便快捷接入互联网的上网 方式的出现，人们在生活中越来越依赖互联网卩】，使用互联网、习惯互联网的人 也越来越多。互联网不仅给人们带来了精神享受，同时也提供了各种各样接口， 人们可以在互联网上购物、找工作，满足人们各种各样的需求。互联网不断的发 展进步、而它的发展也使得人们进入了大数据时代闵。
近年来，随着互联网的高速发展，各种网络应用层出不穷，中国乃至全球的 互联网使用人数与日俱增。《第36次中国互联网络发展状况统计报告》指出， 截止到2015年6月，中国网民的数量已超过6.68亿，半年内共计新增网民1894 万人，互联网普及率达到了 48.8%[31。随着互联网的越来越普及，人们在日常生 活中和互联网之间的联系也越来越紧密，导致网络流量数据呈现爆炸式增长，一 旦出现网络流量异常，用户的隐私安全和使用体验将受到极大的影响和威胁。网 络流量异常，有可能是恶意的网络攻击。攻击者首先通过木马或者僵尸网络等病 毒感染一批计算机，之后便可以操控它们来对用户主机进行攻击，通过在短时间 内制造大量网络垃圾，造成网络堵塞的方式，也就是俗称的分布式拒绝服务攻击， 来对新目标进行打击，严重威胁用户主机甚至整个网络的安全。据悉，2014年 12月，国内一家知名游戏公司，其服务部署于阿里云上，遭遇到持续了 14小时 的全球互联网史上最猛烈的一次DDoS （Distributed Denial of Service:分布式拒 绝服务）攻击，其峰值流量达到了惊人的453.8Gb/s【4〕。可见，DDoS攻击产生 的严重影响，所以，现在的网络流量分析领域中，异常流量检测分析尤其是DDoS 攻击已成为网络流量分析中最为关键、最为急迫的研究内容。
随着互联网的高速发展，网络攻击也在迅速发生着变异，网络攻击的速度越 来越快，攻击方式也越来越隐蔽，找寻可感染的肉机也越来越高效，破解网络攻 击的难度也越来越大。传统的网络流量检测大多是基于网络流量特征分析的，对 于如此狡猾的网络攻击已越发的无力。因此，越来越多的人开始重视分布式拒绝 攻击（DDoS）,并且已在对此有针对性的研究新的检测技术来应对分布式拒绝
攻击的威胁。而通过对异常网络流量的检测，即有很大可能发现DDoS攻击。
在异常网络流量检测方面，通过很多专家和学者们不断的对网络流量进行分 析尝试，总结出了许多检测异常网络流量的方法。其中最具有代表性的是基于阈 值基线的异常流量检测法。阈值计算可以分为静态和动态。静态阈值就是确定一 个值，用当前网络流量和这个阈值进行比较，若超过此阈值则可以认为是异常流 量。此种方法由于阈值的固定不变，不能随网络流量变化而变化，因此局限性很 大。另一种是基于动态的阈值，即可以随着网络流量的变化动态的计算阈值，此 种方法效果较之静态阈值有了较大提升，缺点是计算量有点大。随着互联网业务 的高速发展，用户数的快速增加，网络流量数据越发膨胀，网络阻塞的情况日益 频繁，对网络流量数据的处理也要求数据海量化、处理实时化，原有的一些分析 方法己不能满足现有的需要，所以，需要引入更有效、更稳定的大数据处理平台 和与之相适应的快速的计算方法。
1.2研究目的及现状
自互联网融入人们的生活开始，网络流量的异常检测显得越发的重要，特别 的，对于网络服务提供商来说，检测网络的流量异常可以表示网络服务出问题的 区域，因此实时的网络流量的异常就有着战略性的指导意义。随着研究的不断深 入，各种各样的检测法被提出，有些是基于时域流量数据，也有一些是基于频域 的流量数据，根据频域的数据变化特征来检测网络流量的异常。也有一些学者另 辟蹊径，提出将小波分析理论与实时流量数据相结合，经过一系列复杂的计算， 也可以实现异常检测，但是由于计算过于复杂，实际应用并不理想。除此以外， 也有根据网络流量的自相似的性质来做一些检测算法的研究，根据一些特定参数 的值来推断此时网络流量是否发生异常［5】，由于要做自相似模型，因此其准确度 比较依赖网络流量的数据密集度。虽然检测方法很多，但是最适合网络异常流量 检测的方法不是很多，所以需要去找寻新的解决方案。
随着网络接入的移动化以及普遍化，人们对网络越来越依赖，网络已经成为 人们生活中不可或缺的重要的一部分。随着也产生了海量的网络流量数据。整个 互联网行业也因此进入了大数据主导的时代。大数据处理技术也因运而生。现在， 大数据处理技术中，离线大数据处理平台代表性的有Apache Hadoop. Apache Spark,实时大数据处理平台代表性的有Apache Storm等圏。由于Hadoop分布式 平台的计算框架为MapReduce,即基于批处理的计算框架，其优点很明显，就是 可以很快的处理海量数据［刀。缺点是由于每次处理都要先把数据预处理存到 HDFS上，没完成一个Job也会自动停止，在实时处理海量数据时效果不理想。 Spark虽然也是基于批处理，但是其实时性较Hadoop有了较大的提升，可是由 于Spark实时处理技术比较新，无法对其稳定性做保证。Storm是Apache开源的 流式数据处理平台，其特性是流式处理，且任务一旦开始就不会停止，除非人为 干预。Storm在实时数据处理方面表现很优秀，其性能、稳定性等都获得了大家 的认可。
本文中，将以Storm作为基础，研究适合海量网络异常流量数据的检测算法, 以及后续的用Storm加以实现整个系统。
1.3论文结构
本文根据网络流量异常的特点，结合实时性能的需求，设计了一个新的系统 来检测异常网络流量。本文由六个章节组成，各章节内容主要如下：
第一章，绪论。本章主要介绍了当下互联网高速发展带来的利弊。随着互联 网的高速发展，海量网络流量数据的异常问题开始越发显著，急需通过一些方式 来解决，而传统的网络流量监测方法已无法满足当今的海量数据的网络大环境， 对这些海量网络流量数据的处理和存储有新的要求。而分布式处理框架正是为了 海量数据处理而诞生的新型框架，随着网络的发展，在海量数据的基础上，也对 实时性提出了一点要求。本文使用了兼顾实时性和海量数据处理的分布式处理框 架来进行网络流量异常检测的主要技术手段。
第二章，相关技术研究综述。本章主要介绍了大数据相关的技术以及研究现 状，包括专注处理离线数据的Hadoop、Spark等大数据处理技术，和在处理实时 流的大数据上表现更佳的Storm、S4等技术，以及与大数据处理相关的技术，即 前期消息队列Kafka和后期数据存储Hbase等。由于后续大部分工作是用Storm完 成，因此其中着重介绍了Storm的一些特性及组件。
第三章，异常流量检测算法的研究。本章通过分析对比传统的异常流量判定 方法，找到传统异常流量检测法的不足，并根据网络流量是时间连续的特点，引 入时间序列分析来处理网络流量数据，利用网络流量异常是相对值的特性，将表 现很优秀的传统格拉布斯检测法和动态K近邻相结合，选择合适的置信概率，选 择恰当的K大小，使达到更加精确的检测异常值的效果。为了说明可以采用传统 的异常检测算法来检测异常流量，本章先对网络流量进行了正态性检测，证明网 络流量在一定的模型下符合正态分布，可以釆用格拉布斯法进行异常值检测。
第四章，异常流量实时监控系统的设计与实现。系统主要实现的功能是在海 量数据的基础上，实时的检测异常流量数据并反馈。本章主要从数据采集模块、 数据处理模块、数据存储模块来单独介绍系统各个部分，并在最后进行了一个总 结。系统选择了Kafka消息系统作为数据中间站，选择了Hbase作为经过Storm流 处理平台处理之后的存储系统。本章详细介绍了该系统的设计和实现。最后介绍
了一下在搭建异常流量检测系统中实现的一些关键技术。
第五章，异常流量实时监控系统数据分析。本章先对网络流量数据的来源进 行了一些介绍，再介绍了综合不同维度的统计方法。分两个部分分析了异常网络 流量，一是针对主机流量，二是针对企业局域网的总流量进行了分析。重点分析 了异常网络流量所表现出来的含义，根据异常网络流量实时检测的结果，不同的 异常情况表现出来的含义也不同。本章将对网络异常流量进行详细的分析。
第六章，总结与展望。本章对现有研究成果进行了总结，结合异常网络流量 检测方法和大数据处理技术分析了本人研究成果的不足和对未来研究的展望。
第二章相关技术研究综述
2.1引言
随着互联网的告诉发展，数据量的爆炸式增长，数据分析技术经历了不同的 发展阶段，从最初的基于关系型数据库的数据操作，到如今的大数据处理技术， 想从数据中挖掘岀更大的商业价值，实现成本的节省，有效的数据分析变得尤为 重要，相应的新技术也不断出现，内容涵盖数据获取与清理、传输、存储、分析、 挖掘、展现等方面，覆盖了数据处理的全部方面。本章列出目前流行的大数据处 理技术，尤其是实时流处理技术，然后针对论文应用到的技术进行相应的介绍。
2.2大数据处理技术的研究
2.2.1大数据处理技术概述
Hadoop
Hadoop源于Google提出的GFS (Google File System),是谷歌公司为了存 储海量数据而设计的文件系统，后来由Apache开源而普及开来［8】。Hadoop是开 源的、分布式的并行计算框架，是海量数据处理的首选平台。Hadoop的核心是 HDFS (Hadoop Distributed File System)和 MapReduceo MapReduce 是一种编程 思想，即先将数据分块成多个独立的小块数据，再去对每个小块数据单独进行逻 辑运算囲，这样就可以极大的利用集群的资源，处理海量数据速度也非常快，体 现了 “分而治之”的思想。HDFS (Hadoop Distributed File System, Hadoop 分布 式文件系统)是容错性很高的文件系统，由于其部署成本低，易于维护，非常适 合用来存储海量数据。随着Hadoop的发展，也催生了一大批依赖于Hadoop的 工具，如基于Hadoop的Hive,非关系型数据库Hbase等。这些工具组成了 Hadoop 自己的生态圈，互相补充，共同发展。
HDFS由一个主节点Namenode和多个工作节点Datanode组成。Namenode 管理着文件系统的命名空间，维护文件系统树及其中的元数据。Datanode是文件 系统的工作节点，根据一定的调度规则存储和检索数据，并定期向Namenode汇 报。
Hadoop的框架决定了其适合处理海量数据的特性，但是其更偏重于吞吐量、 较高的响应时间、数据预处理较繁琐而决定其更适合处理离线的、静态的数据。 而对于要求实时性较高的场景，Hadoop表现则不尽人意。另外，如果计算要求 迭代或者循环，在MapReduce的计算模型下，很难确定结束时间，且对于吞吐 量也要求较高，故在此情景下，Hadoop也不是最佳选择。
Spark
Spark是由加州伯克利的AMP实验室提出的、类Mapreduce的计算框架。 由Apache开源以后，Spark发展迅速，由于其出色的大数据处理能力，现己得 到越来越多用户的青睐。
Spark是基于Hadoop MapReduce实现的算法，其拥有MapReduce的种种特 性和优点；不仅如此，Spark对MapReduce进行了改良，使Job产生的中间结果 保存在内存中而不是写入磁盘，从而减少了 HDFS读写带来的效率低下的问题， 使其计算速度比Hadoop更快。Spark这种计算特性也很好的解决了 Hadoop所不 能胜任的迭代计算和循环计算。
Spark拥有出色的处理大数据的迭代计算的能力，而数据挖掘和机器学习等 恰恰需要大量的迭代计算。因此，Spark是数据挖掘和机器学习的宠儿。Hadoop 只有单一的Map和Reduce两种接口，简单直接但是功能不多，有一定局限性。 Spark则有多种数据集的操作类型，这些操作统称为转换(Transfbrmation)。同 时也得益于多种操作类型，Spark各个节点间的通信也不只有单纯的Shuffle方 式。用户可以自定义中间结果的存储位置等信息，其编程有极大的灵活性，不受 编程框架的限制。
Spark的核心是RDD (Resilient Distributed Dataset),即弹性分布式数据集。 RDD是Spark特有的数据结构，其高容错性、高并发度的特点可以让用户方便 的进行数据的存储和分区。RDD只能通过已存储的数据集和其他已有的RDD确 定操作来创建，这样的动作即为Transformation.,实质上说，RDD只是一个不可 修改的记录分区的数据集。RDD定义了两种操作：转换(Transfbrmation)和动 作(Actions)。转换指根据现有的数据集来新建一个数据集，而动作指对数据 集进行运算后返回给程序的值。
Spark是基于内存的计算框架，这使得其速度极快，但是缺点也很明显，当 运行过程中断电或者死机，则数据将永远丢失。常规的解决方案是定期设置检査 点，根据日志进行恢复。总的来说，Spark是可能会是下一个大数据的技术宠儿。
Pregel
除了 MapReduce,谷歌还开发出了一种名为Pregel的新型计算框架。据说, 谷歌内部运行的数据处理程序，有80%的框架是MapReduce,剩下的20%用的 框架即为Pregelo Pregel解决了图论计算所需要的分布式共享内存问题，因此被 专门用来处理大规模的图论计算，例如网页排名，图遍历等。
Pregel采用的是Bulk Synchronous Parallel模型，即整体同步并行计算模型。 比较经典的Pregel运行步骤即：首先输入数据，然后把该图进行初始化，接着进 行超步运算，每一次的超步都是独立的，而且是全局的。循环计算直到整个计算 结束，输出结果。
在每一次超步运行过程中，本次的运行结果都能发送到下一次的超步运行开 始，这个过程中还可以修改其其自身的状态信息，包括以该顶点为起点的发散线 的状态信息，或变换整个图的拓扑结构。
Pregel框架很简单，用户所要做的就是针对图节点自定义计算逻辑即可，而 其他的一系列的任务分配、程序维护等均由Pregel系统封装实现。
集成框架YARN
纵观现有的大数据解决方案，如Hadoop, Storm和Spark等，虽然其都是大 数据处理技术，但是有其最适用的应用场景，并不是有单一的解决方案可以涵盖 所有需求。只有在合适的场景下，选用最适合的解决方案，才能完全发挥各种方 案的特点和专长。但是直接在一个集群上装Hadoop> Storm和Spark等，难免会 有所冲突，此时就需要有更高层的框架来将这些框架集成到一个集群中，使得资 源得以充分利用，运维成本也得以降低。Yahoo的YARN很好的解决了这个问题。
老的MapReduce框架在性能上有一定的瓶颈，受限于框架本身，其改变很 难。因此在Hadoop-0.23开始，MapReduce重新构建组成新的MapReduceV2, 也即Yam。YARN诞生的目的是为了修复MapReduce的不足和局限，并提升了 集群的可伸缩性、可靠性和资源利用率等。YARN的基本思想是，把Job Tracker 的两个主要功能，即资源管理和作业调度/监控四，拆分成了两个独立的进程单 元，也就是全局资源管理器RM和针对每个程序的应用主节点AM,应用指的是 MapReduce任务或者是有向无环DAG任务。
Yam的核心是资源管理器(ResourceManager)。RM控制着集群并管理着 集群资源的分配。RM和节点管理器(NodeManager)组成了数据的逻辑框架， 同时RM负责分配资源给NM[10]o NM与应用主节点(ApplicationMaster) 一起 分配资源，与NodeManager 一起执行和监控任务。NM则负责将资源的监控情报， 包括CPU、内存、硬盘、网络等情况，上报给NM和AM。
从某种意义上来说，Yarn已经不单单是MapReduce框架，其更是一种云操 作平台。MapReduce> Storm、Spark等均可以借助Yam共生于一个集群中，共 享数据及计算资源。
2.2.2实时流处理技术概述
Hadoop等大数据处理技术发展到现在，优势渐渐明朗，即处理离线非实时 数据。而对于实时的海量数据处理，Hadoop则显得力不从心。随着大数据的发 展，对于实时海量数据的处理的需求也变得越来越迫切，实时的流计算也继 Hadoop批处理后成为下一个大数据领域的技术热点。迄今为止，比较热门的实 时流处理技术有Twitter Stonn, Yahoo! S4[11]o其中最成熟使用最多的当属Storm, 而S4和Storm在各方面都很相似，最明显的区别在于S4没有像Storni那样可靠 的消息保障机制。
Storm
Storm是由尼森马拉斯设计提出的、专门用来处理实时大数据流的计算框架。
Strom的处理数据的机制很特别，这使得其与其他的大数据技术框架都不同。 Hadoop的本质是批处理，数据首先被存入HDFS上后，Hadoop才会对其进行切 分、计算，最后将结果返回到HDFS进行存储，这样做虽然可以处理的数据量变 大了，但是牺牲了实时性。而Storm则不同。Storm通过建立拓扑(Topology) 结构，当数据产生时，即被传输、处理、入库，这种机制就保证了在计算资源充 足的情况下，延时降到最低。此外，这种拓扑结构一经开始，除了人为终止或者 集群宕掉，将一直运行下去。
Storm的拓扑结构包括：源源不断的流数据Stream；消息的生产者，负责从 外部数据源获取数据并发射数据的Spout；消息的处理单元，负责接收数据并对 数据进行计算，最后再将数据发射的逻辑单元的Bolt；负责具体任务的处理的工 作线程,Spout和Bolt最终通过Task实现工作;负责启动Task的工作进程Worker 等洛个Bolt组件及Spout与Bolt之间的数据分发方式由Stream Grouping定义， 共七种,常用的一般为Shuffle Grouping。
S4
S4是Yahoo!提出的分布式流计算模型，旨在提供接口简单、可扩展、低延 时、易于维护、可插拔的、易于编程的大规模分布式流计算服务，设计之初是为 了解决搜索所推送广告的精准度，预测用户对广告的喜好，使广告有效点击率上 升的需求。
S4中定义的流数据为(Key,Attribute)形式的键值对，另外还有EventType 来表征每个流的类型。S4由一^个的数据处理单元(Process Element)组成，每 个Process Element只处理其对应的EventType, Key, Attribute都符合的流数据, 计算完后将结果反馈给下一个PE。若是本次流数据没找到相对应的PE进行计算 时，则S4会自动创建一个新的PE,因此每条数据都基本能被处理。但是这就导 致了 PE过多可能形成冗余，占用资源。因此S4会定期清理使用率较低的PE,
防止资源被占用。在进行PE的清理之前，由于数据保存于节点的内存中，因此 S4会对数据进行持久化处理，防止清理PE的过程中造成数据的丢失。
S4是一款很优秀的实时流处理平台，对于一些特定的实时作业，S4展现了 很好的效率和可操作性，速度也很快。但是S4的不足在于传输机制不够稳定， 在数据传输过程中可能发生丢失，没有类似Storm一样可靠的ACK机制。另外， 由于S4的数据保存于节点的内存中，一旦发生宕机，数据就会永久丢失，这一 点同样有待改进。
2.3分布式消息系统Kafka
Kafka最初是领英提出的分布式消息系统，基于发布/订阅的模型，因为良好 的扩展性和优秀的传输性能而被广泛采用。Kafka 一般被用来处理活动的流式数 据。这种数据在网站数据中很常见，包括用户的Page View (PV)、Unique Visitor (UV)、Event等行为。通常，这些数据会以log文件的形式保存下来，到一定 时间再统一进行处理。Kafka有良好的可扩展性，与当下的很多大数据处理框架 都相容，Kafka-Storm已成为Storm处理形式上的经典组合。
Kafka的架构包括以下组件：
Broker： Kafka由多个Broker服务器组成，已发布的消息保存在Broker中。
Topic：每条消息数据发送到Kafka几千前，都会被要求指定一个Topic, Kafka按不同的物理逻辑对消息数据进行分类存储，同一个Topic可能被存与不 同的Broker服务器上，但是不影响消息数据的消费顺序。
Partition：消息在物理上的分区即成为Partition, 一个Topic可以由多个 Partition组成，这样即可达到负载均衡的效果。
Producer： Producer指消息的提供者，负责发布消息数据到Kafka Broker ±. 对应的Topic o
Consumer： Consumer指息的使用者，其可以从Kafka关注多个Topic,并 在相应的Topic有新消息数据时，从Kafka集群获得数据，并加以后续处理。
Consumer Group： 多个 Consumer 组成 了 Consumer Group, 单个 Consumer 也可自定义Group Name,若不指定Group Name,则属于默认的Group。
Kafka拓扑结构图：

图2-1 Kafka拓扑结构
如图，Kafka集群中可能会有多个消息生产者，这些生产者可能是一些log 文件，或者是网站的PV, UV等；多个Broker服务器，显然服务器越多，Kafka 集群性能也越好；多个消费者组，消息消费者都属于一个特定的消费者组；一个 Zookeeper集群，Kafka集群内部是用Zookeeper进行通信并协调各节点的。生产 者通过Push模式发送消息到Kafka集群，消费者通过Pull模式从集群获取消息。
Kafka存储策略
Kafka集群的消息存储模式一点都不复杂。消息数据会按照Topic进行分类， 并有每个逻辑日志与之匹配，在物理存储上，同一个逻辑日志由一系列同容量的 log文件组成。Producer发送一个消息数据到对应的Partition,该消息数据将被追 加到对应的最新的log文件中。当log文件超过一个阈值后，Kafka会将其写入 硬盘存储。之后，Consumer即可以从硬盘上获得该数据。特别的是，一般的消 息系统所传输的消息数据都会有一个对应的消息ID,而Kafka却没有。Kafka 是通过log文件的偏移量来控制消息数据的。这样做的好处是免去了通过消息ID 来反向寻找对应消息的时间和开销o Kafka集群中通过偏移量来定位消息，若想 获得下一条数据的偏移量，则用本条消息数据的偏移量加上本条数据长度即可实 现，方便快捷。
Consumer是从其订阅消息的Partition获得数据，所以Consumer获取了所关 注消息的偏移量，则其获得了该条以前的所有消息数据。Consumer每次向Ka&a 请求获取消息时都会包括所要获取消息的偏移量。而当Kakfa接收到该请求后， 会利用SendfileAPI来快速的将消息数据发送给Consumer=

2.4分布式流处理平台Storm
Hadoop是大数据分析领域无可争辩的王者，其在本质上是一个批处理系统。 数据首先会被存储到HDFS后，才会被发送到各个NameNode计算处理。当 NameNode计算完毕后，数据依然会被存储到HDFS上，开发者需要从HDFS上 取得数据。这种批处理的方式对离线大数据处理很有效，但是这种批处理的模型 特性并不能完全满足所有场景。比如一个场景需要较高的即时性时，用Hadoop 处理显得比较复杂且效率低下。为了满足实时性的需求，Twitter的工程师尼森 马拉斯提出了 Storm平台。Storm富有魅力的地方在于其独特的拓扑结构。Storm 通过构建拓扑来处理源源不断的流数据。需要注意的一点是，Storm的流处理一 旦开始即不会自动停止，故其可以不间断的处理接收到的流数据。Storm不擅长 批处理，但其可以很快速的进行流处理。
2.4.1 Storm平台主要特性介绍
Storm专长于流式处理，其主要特点有一下几点：
简单的编程模型。与MapReduce编程模型减少了分布式批处理的复杂度所 接近，Storm的编程模型也能有效减少实时流式处理的复杂度。
支持多种编程语言。在Storm上可以使用各种语言进行编程。默认支持的 有Ruby、Java、Clojure和Python等语言。对于菲默认的编程语言，只需实现一 个简单的Storm相关的通信协议，即可顺利在Storm平台上进行开发。
良好的容错性。Storm会自动定位并处理Worker进程和节点的故障，编程 者无需考虑错误处理。
良好的可扩展性。Storm中的计算可以在多个线程、多个进程甚至多组服 务器之间并行处理。
可靠的消息处理。Storm可以保证每一个由spout发布的消息至少能得到 一次完整处理。当消息未能得到完整处理时，spout会重新发送该消息直至得到 完整处理的响应（Ack） o
快速的处理能力。Storm的系统设计保证了消息能得到快速的处理，使用 T ZeroMQ （可弹性伸缩的、多线程、高性能消息处理队列库）作为其底层消息 队列。
本地模式。Storm除了集群模式，还设计有本地模式，本地模式可以在代 码运行过程中完全模拟其在Storm集群上运行的效果，可以使得开发者更加方便 的进行开发和测试拓扑逻辑。
2.4.2 Storm平台主要组件介绍
Storm集群主要由一个主节点（Master Node）和一群工作节点（Worker Node） 组成，集群内部通过Zookeeper （分布式服务框架）进行协调。
Nimbus：在Strom集群主节点（Master Node）上运行的后台程序，负责在 Storm集群内分配任务并发送代码到工作节点，并且负责监控整个集群的拓扑运 行状态。Nimbus之于Strom类似于JobTracker之于Hadoop。
Supervisor：在Storm集群每个工作节点（Work Node）上运行的后台程序， 负责监听从Nimbus分配给本工作节点执行的任务，据此启动或停止执行任务的 工作进程。
Topology： Storm 中 Topology 的概念和 Hadoop 中的 MapReduce Job 很相似。 类似于 Hadoop MapReduce 中一个 Job 包含一组 Map Task>Reduce Task, Topology 是一个用来编排、容纳一组Storm计算逻辑组件（Spout、Bolt）的对象，这些逻 辑元件可以根据需求自由组合成有向无环图，并且可以根据Stream Grouping的 方法自定义消息的分发方式，组合成一个由计算逻辑组成的DAG图，从而完成 更加复杂计算任务对象。拓扑流一旦开始运行就不会自动终止，即会永远运行下 去，直到人为终止拓扑，或者服务器节点宕掉，拓扑才会终止。
Spout：在拓扑中，一个消息流产生的起点称为Spout。Spout可以源源不断 的产生数据流。Spout只是一个代号，其实现形式可以多种多样，其可能是Kafka 的Consumer,也可能是监听的某个目录下的log文件，也可能是网站的PV, UV 指标等等。Spout产生的数据流在拓扑中是以Tuple的形式传输的，Tuple通过在 拓扑的各个组件间传输来完成计算任务。整个流计算也就是这样完成的。
Bolt： Storm中数据的计算是在Bolt中实现的，Bolt中可以自定义计算的逻 辑，只需在Bolt中实现其对应的函数即可，函数编写和普通java函数类似。特 别之处在于，要按照所设想的拓扑中数据流动的规则来定义Spout和Bolt、Bolt 和Bolt之间的消息传输机制，包括Declare> Stream Grouping等。Bolt可以从多 个对象接收消息数据，既可以从不仅限于一个Spout接收消息，也能接收不仅限 于一个Bolt的消息数据，甚至可以从Spout与Bolt组合接收数据。
Stream Grouping： Storm的拓扑中，消息流在逻辑元件之间的传输策略机 制被称为Stream Grouping□ Storm定义了如下7种分发策略：Shuffle Grouping （随机分组）、Fields Grouping （按字段分组）、All Grouping （广播分组）、 Global Grouping （全局分组）、Non Grouping （不分组）、Direct Grouping （直 接分组）、Local or Shuffle Grouping （本地/随机分组）。
Tuple： Storm使用Tuple来作为它的数据模型。Tuple是一堆值的统称，每 个值可以有不同的名字。Tuple可以有很多类型，基本上Java里所有的数据类型都可以做为Tuple。只要对数据进行一些基本的序列化，理论上，用户甚至可以 自己编写数据类型来当Tuple。一般来说,Tuple本来应该是以键值对(Key-Value) 的形式来传递的，但是由于Strom的消息传递机制，逻辑元件间传输的Tuple的 Key已经定义好了,所以Tuple只需要按序填入各个Value,即一个Value Listo
Storm各组件关系图如图2-2所示：

图2-2 Storm各组件关系
Storm分布式处理平台定义了不同于MR的流处理模型，即拓扑(Toplogy)。 拓扑中的传输的源源不断的数据元组Tuple即组成了数据流(Stream)。Tuple 可以是任何类型的数据，可以是Integer, Float,或者Byte数组，也可以由使用 者根据自己的需求定义新的数据类型。Stream之间通过一个唯一 ID进行区分， 以确保拓扑传输过程中不会混淆。Stream从Spout出发，Spout将Stream发射到 下一个Bolt,完成了将外部数据源的数据传输进拓扑中，Storm计算由此开始。 当数据进入Bolt中，Bolt便根据使用者设定对数据进行计算。如果一级Bolt满 足不了使用者的需求，使用者也可自己调整Bolt结构，串联或者并联多级Bolt 进行数据处理。最后，Bolt也可负责将计算结果存入Hbase或者MySql等数据 库或者数据仓库中。整个Storm拓扑结构如图2-3所示。

图2-3 Storm拓朴结构图

2.5非关系型数据库Hbase
数据处理完后，考虑到持续性，较常用的方法是将处理结果存入数据库中。 就当下来说，数据库按存储结构可以分成关系型数据库和非关系型数据库 (NoSql)两大类。关系型数据库，是指按数据的关系模型来保存数据的数据库 ［⑵。
关系模型，换句话说，即用一个表格来体现数据之间关系的模型。关系型数 据库存储数据时维护了这样的一个模型。这样做的好处是可以很直观的体现数据 之间的关系，符合人体本身对数据的理解，利于使用。因为众多的优点，关系模 型数据库被广泛用于数据的存储，并慢慢发展成了最主流的数据库，在很长的时 间里服务于各个行业。然而，随着时代的发展，数据量渐渐增多。关系型数据库 的劣势也渐渐显现。由于结构问题，关系型数据库对于海量的数据的读写效率低 下，本身结构所限也无法满足高并发的解决方案。为了解决海量数据的存储问题, 非关系型数据库的概念便诞生了。最初的非关系型数据库指代的是非关系型的， 分布式的，且一般不保证遵循ACID原则(数据库事务必须具备ACID特性， ACID 是 Atomic 原子性，Consistency 一致性，Isolation 隔离性，Durability 持久 性)的数据存储系统。非关系型数据库的存储结构和关系型数据库有着本质的区 别。非关系型数据库按照Key-Value的模式进行存储，且可以有不同的列。每条
数据记录可以包含不同的字段信息。这样，当需要获取用户的特定信息时，无需 取出用户的所有信息，只需取对应的数据即可。这样可以减少很大的查询开销， 保证了查询的效率。
Hbase(Hadoop Database)受启发于 Google Bigtable,是 Bigtable 的开源实现版 本，以其高并发、高效率、面向列、分布式的特性而被广泛运用于大数据存储的 分布式存储系统。值得注意的是，Hbase的存储数据的结构是面向列的存储结构。
因此，在海量数据中查询相应的数据时，只需找到对应的Key即可，因此， Hbase速度很快，效率很高。
Hbase 的底层用 HDFS(Hadoop Distributed File System)来作为其存储系统， 由Zookeeper作为协同服务，通过使用Hadoop的DFS工具就可以看到这些这些 数据存储文件夹的结构，还可以通过Map/Reduce的框架对Hbase进行操作。
HBase中的表一般有这样的特点：
1海量：Hbase中一个表可以包含多达几亿行，几百万列。
2面向列：基于列的存储，查找时各列独立。
3稀疏：每条数据并不需要填满所有的列，只需保存需要的列字段即可。
数据模型：
HBase是一个非关系型数据库，其采用的的存储结构和关系型数据库差别很 大。HBase通过四个字段对数据进行描述，分别是：
行键(Rowkey):每条数据都包含一个唯一的键值，这个键值代表了这条 数据的查询依据。Hbase中依照Key的次序对数据进行排序，以此来确定数据的 位置，查询时也能更快定位到该条数据。因此，RowKey须根据后续查询条件进 行设置，不能随意设置。
列簇(Column Family)：每条记录都包含一个或多个列簇，一个列簇可能由多 个列组成，且没有上限，可以随时根据需要定义新的列，扩展性能很好。存储时， Hbase默认列簇以二进制存储，使用者可以自定义类型转换。
列修饰符(Column)：列簇中的列，保存了数据的字段信息。多个列组成了列 簇。
版本：在每列的末尾都定义了一个版本值，默认值是系统时间戳。表中会显 示最新版本的数据，若要获得较早版本的数据，可以通过指定版本来获得。每次 操作数据都会更新对应的版本。
Hbase的数据存储结构如下图所示:
表2-1 Hbase数据存储结构图
Row Key	Timestamp	Column Family
URI	Parser
rl	t3	url=http ://www.taobao.com	title。天天特价
t2	host=taobao.com
tl
r2	t5	url=http://www.alibaba.com	content?每天…
t4	host=alibabaxom

2.6本章小结
本章一开始主要介绍了大数据环境下的各种大数据处理技术。按处理机制的 不同，分了两类来介绍。一类是批处理离线大数据技术，介绍了 Apache Hadoop、 Apache Spark、Google Pregel,接着介绍了 Apache Hadoop Yam 这种大数据技术 整合框架，方便将各种大数据处理技术整合到一个集群。另一类是实时流处理技 术，主要介绍了 Apache Storm和Yahoo! S4,该两者除了 akcer不同，其他很相 似。接着按照本实验用到的技术，详细介绍了分布式消息系统KM<a、流处理平 台Storm和分布式非关系型数据库Hbase,主要介绍了相关组件、结构和相关特 性等。

第三章异常流量监测算法
3.1引言
异常流量检测系统是网络安全防御技术的关键技术手段，其检测攻击行为的 判定依据是：通过对网络和主机上流量报文信息的某些关键字段进行统计分析, 监测其是否有异常行为，并对监测到的异常行为进行告警。传统的异常流量监测 是通过机器学习的方法进行的，根据大量的数据采集，通过釆用合适的算法，建 立起拥有某几项特征的数据模型，监测期间，将采集到的信息与模型进行拟合， 当模型的预测值与现实采集到的数据差别超过一个阈值时，便认为发生异常行 为，并告警。其本质上通过计算得到阈值，并依据阈值来判定当前值是否为异常 值。阈值的计算也可以分为静态阈值和动态阈值。静态阈值即对流量的某种特征, 根据机器学习训练得到一个模型，然后即运用于监测中，不会因为环境的变化而 变化，所以对于多变的网络环境来说，此种方法可移植性很差，监测效果也不尽 人意。另一种阈值计算为动态阈值。即在静态阈值的基准上，根据一段时间的网 络流量的某种特征，进行一些参数的即时修改，修正这个静态基准，以此来适应 多变的网络环境。此种方法较第一种的可移植性和准确度都有所提高，但是缺点 是比较繁琐，且无法保证过往可能的异常流量对其的影响，一旦影响则无法挽回。
在网络应用越来越广泛的今天,网络流量变得越来越多元化，每天的流量变化 很大，传统的建立模型来监测异常值的方法的适应性已变的越来越差，因此对新 的更加合适的监测方法的要求越发的迫切。本文中，根据网络流量随时间唯一变 化，因此可用时间序列来处理的特性，结合了传统的异常值监测法-格拉布斯法 (Grubbs ),提出了基于网络流量时间序列的K最近邻-格拉布斯法 (KNN-Grubbs)来监测异常网络流量。
3.2网络流量和时冋序列的关系
3.2.1时间序列分析简介
时间序列(time series)指在一定时间内，对某变量按时的、等间隔的进行
测量，从而得到一系列观测值的数据集合。其本质是通过随机过程等数学原理，得到数据遵循的数学规律，以此预测序列发展等。事实上，从某种意义来说，时 间序列分析也可以算是一种回归分析。回归分析是指，通过自变量对因变量的特 殊数学关系，来预测因变量的值。这种分析方法很有效，但是前提是自变量和因 变量相互独立且共同分布。但是，时间序列和回归模型最大的区别在于，时间序 列的值不互相独立。时间序列的预测是指，用该变量以前的值取预测该变量的未 来值。换句话说，这种关系下，因变量是该变量的未来值，而自变量为过往观测 值。
时间序列分析法大体上可以分成两种，描述性时序分析和统计时序分析。描 述性时序分析是指，根据简单的比对或者画图观察，从而发现数据的规律，该方 法易于实践、直观有效，一般的，进行时间序列分析时，该方法往往是一开始会 做的事，从而对数据有个整体印象。统计时序分析又可以从两个角度进行，频域 和时域。频域分析法，顾名思义，即对时间序列进行傅立叶变换，得到其频域中 的信息，在频域中进行分析。这种方法做分析的效果很好，但是因为计算方法国 语繁琐，需要极强的数学基础，分析结果也不能进行直观解释，因此具有一定的 局限性。时域分析法则不同。时域分析法主要是从序列自相关的角度解释时间序 列的发展规律，意在得出数据之间的相互关系和规律卩3〕，并采用恰当的数学模型 对该相互关系进行描述，更进一步通过该模型得到序列将来的趋势。该方法由于 理论基础强，建模过程客观，结果数据较直观，因此时间序列分析领域常常釆用 此法进行时序分析。
3.2.2网络流量的时间序列分析
生活中的网络流量是随时间变化的，持续不间断的一组流量数据，通过间隔 固定时间间隔釆集统计并进行上报，则可以认为网络流量是一组时间序列，进而 可以用时间序列分析法对网络流量进行建模分析，将不好处理的网络流量转换成 可以数学建模处理的时间序列，解决了网络流量的难以监测的问题。
3.3时间序列的异常值检测法
3.3.1格拉布斯异常值检测法
要在一组测量值中找出异常数值，常规的检测准则有Grubbs检测法，3@检 测法，Chauvenet检测法，Dixon检测法和t检验法。据统计，在数据满足正态分 布的前提下，在所有异常值检测方法中，Grubbs检测法统计的正确率是最高的, 所以，Grubbs法在全球被广泛釆用，基本可以认为是国际通用的检测异常值算法。为了适应不同场景，使得Grubbs法在某些场景下表现更好，误差更小，精 确度更高，有学者对Grubbs法进行了一些改进，本文采用的即是改进型格拉布 斯准则法，消除了同侧异常数据的屏蔽效应，使结果更加精确。
Grubbs检测法与其他检测法不同的特点是，将正态分布中最具代表性的参 数，方差和平均值，引入计算过程中，作为判定该值是否为异常值的依据之一， 增加了判断的维度与可信度，使其准确度较高。
Grubbs检测法概述：在同一组检测数值中，若某个数值点偏离平均值超过 其他绝大多数点的偏离程度，则该数值点称作“可疑值”。可疑值可以是一个，也 可以是多个。故此，在一组数据中，最值得怀疑的可疑值不是最大值就是最小值。 因为他们显然是离平均值最远的两个点。下面介绍下Grubbs检测法的判定步骤。
设样本总数为n,并设样本为，则对第i个样本数值，检验数据是否为异常 的Grubbs检测法如下：
(1)将X\,X2,X3,---,Xn按升序排列成顺序统计量，此时即X(1),X(2),X(3),???,X(")。 则异常值可能为由和X3),此处举例"。
(2)计算均值和标准差，即
(3-1)
(3-2)
(3)计算得到Grubbs统计值，即皿)的残差与标准差的比值，即

⑷确定检验水平，相当于做出“弃真”行为的概率系数，若Pc为置信概率, 则。不宜选择太小，因为如果选择过小，固然会把非异常数据划定为异常数据 的机会减小，但把异常数据判定为非异常数据的机会却增大了。通常取0.01(1%) 或0.05(5%),也即去置信概率为99%或95%的情况。确定以后，再结合样本总 数n,从表中查得。
(5)判断。若g(〃)>=g(”q),则检测值为异常值。反之，则为正常范围内的 值。

表3-1 Grubbs检测值表
*	0.95	0.99	I	0.95	0.99
3	　　1.135	　　1.155	　　　17	2.475	2.785
4	　　1.463	　　1.492	　　　18	2.504	　　2.821
5	　　1.672	　　1.749	19	2.532	2.854
6	　　1.822	　　1.944	20	2.557	2.884
7	　　1.938	　　2.097	　　　21	2.580	2.912
8	　　2.032	　　2.231	22	2.603	2.939
9	　　2.110	　　2.323	23	2.624	2.963
10	　　2.176	2.410	24	2.644	2.987
11	　　2.234	　　2.485	25	2.663	　　3.009
12	　　2.285	　　2.550	30	2.745	3.103
13	　　2.331	　　2.607	35	2.811	　　3.178
14	　　2.371	　　2.659	40	2.866	　　3.240
15	2.409	2.705	45	2.914	3.292
16	　　2.443	2.747	50	2.956	　　3.336

由上表可以看出，g("，a)的值和"及a均有关系，随其改变而改变。
3.3.2时间序列的K近邻算法
在网络流量时间序列中，不一样的检测方式或者不一样的检测区间对网络流 量的特性就有不同的差别，例如，从整天的网络流量来看时间序列的数值差别会很 大,而从局部的一小段时间内看，网络流量的差别并不大,具有一定的稳定性。
网络流量的异常值，是指相对来说，流量显得异常突兀的值，这里的参考系 即之前的网络流量的值，这也是本文选择K近邻算法(K Nearest Neighbors, KNN) 来辅助检测异常值的重要依据四。
该方法的思路是：“在样本集的特征空间中，若某个样本的K个最相似的 样本，即特征空间中最邻近的样本中的大多数属于某一个类别，则该样本也属于 这个类别”［⑸。其中，待测值所需要的多个邻近值是经过正确分类的事物。一般 来说，KNN算法在分类时只参照近邻值，可以是一个近邻值，也可以是多个近 邻值，以此来判断该待分类事物的类别，而与其他值无关。从数学上分析来说， KNN算法虽然采用了极限定理的数学思想，但是在分类时，待分类值只与一部 分邻近值有关。
KNN算法运用场景很灵活，不仅仅局限于对事物进行分类，也能够用做回 归分析。得到某个事物的K个最邻近样本数据后，将这K个样本值的属性值按 照一定的权重赋给该样本，较常用的算法是根据距离的远近来计算对待测事物的影响因子，从而确定权重。
然而，虽然KNN算法有诸多优点，但是，KNN算法也有一些尚待优化之处。 首先，当某个场景中的样本值倾斜很大，即某个特定类的样本数量占了绝大多数 时，可能出现一个新样本的K个邻近数值都是属于该特定类的，这样显然会导 致分类结果失真。无论怎样，样本数量不应该影响分类结果。其次，KNN的特 点事实上也可以算是一个缺点。由于确定新样本的K个最邻近数值时需要对全 局样本进行计算欧式距离，从而导致计算任务特别繁重。为了提高性能，可以在 分类计算前先按一定规则过滤掉一部分，再通过赋予不同的权重来消除样本数量 的影响。总的来说，KNN算法较适合大规模的，精度要求不是特别高的分类， 样本太少可能误差比较大，分类效果不好。
KNN算法过程如下：
1首先我们事先定下K值（就是指K近邻方法的K的大小，代表对于一个 待分类的数据点，我们要寻找几个它的邻居）。
2根据事先确定的距离度量公式（如：欧氏距离），得岀待分类样本和全部 已分类的样本点中，距离最短的K个样本。
3在该K个样本点中，待测特征的值。根据k个样本中，待分类样本的数 学统计量，来判断把这个数据点定为什么类别。
其中K值选择比较重要。若选择的K过小，则训练样本集过小，随机误差 增大，导致最后的模型太狭隘，无法完成总体的分类任务；若选择的K过大， 极端情况下，和样本数一致，则导致所得模型太宽泛，没有合适运用部分样本的 有价值的信息去进行建模预测，只是简单比对样本在训练样本集中的类。所以， 在实际运用KNN算法时，选取合适的K尤为重要。可以对选取的K进行测试 比对，来确定最优值。
3.4实时网络流量的KNN-GRUBBS法
由上两节的介绍，我们了解了 KNN回归算法及GRUBBS检测法。本文采 用了 KNN检测法的思路，通过定义一个距离规则来计算各个样本点的距离，再 选取离待测样本最近邻的K个样本去对待测样本进行一个分类验证卩6】，验证该 待测样本最终是归入正常值类别还是异常值类别。验证算法采用3.2.1介绍的 Grubbs检测法，将待侧值人为规定为可疑值，并以前K个样本数据当做一组正 常样本数值，判定待侧值是否为异常值。而且，为了适应实时的需要，该K个 最近邻值是动态的，随着待侧值的不断更新变化而变化，保证了异常值判定算法 的准确性，提高了准确检测异常值的成功率。
本文成功实现了将KNN回归算法及Grubbs检测法结合到一起并成功运用到异常流量检测中去。本文将网络流量数据按时间序列分割，每10MIN统计一 次流量数据，并加以处理。此即每小时有6个点数据，每天即144个数据点，且 严格按照10MIN的时间维度排序。此时网络流量数据就可以看做是时间序列。
取合适的K值，将当前值*心与前K个值一起，用Grubbs法判 别此值是否为异常流量值。此前提为前K个值均为正常流量值，不存在异 常流量数据。若判定mk为异常数据，则将x，5标记，当检测xm 时，其参考 值依旧为即将k从后续计算中剔除，此时K个值不做更新。 若判定xs为正常值，则检测xm时，其前K个参考值为x，+ i,x，+ 2,?",X5, 即此时X5 + I参与后续计算，并将工，剔除于后续计算。可以将此K值看成一个 长度为K的窗口。若判别值为正常流量值，则窗口滑动一个时间单位。若判别 值为异常流量数据，则窗口不变检测下一个值。因为此方法需要K个值均为正 常流量值，以此为前提。若K个值中有异常值，则检测效果可能会不理想，甚 至可能将后续正常值都判别为异常值，即失真。而当判定数据前不足K个正常 值时，则有多少正常数据就用多少数据计算格拉布斯值，并判定。整个算法的流 程图如下。


图3-2 KNN-Grubbs算法流程图
3.5算法合理性验证
3.5.1 KNN-GRUBBS算法合理性验证
格拉布斯法是以数据为正态分布为前提，即若数据大致上符合正态分布，则 采用格拉布斯准则来做异常值判定是很合适的。本节的主要目的是验证系统釆用 格拉布斯准则检测网络异常流量的合理性，即检测网络流量符合正态分布即可。

对于一组样本数据集，要判定该组样本是否服从正态分布，通常可以采用以 下几种方法：
通过对样本集作P-P图或者Q-Q图目测，若所得样本点均在尸x曲线附 近，偏移不多，则可认为样本服从正态分布。通过P-P图或者Q-Q图来验证样 本是否服从正态分布，虽然不够精确，但是这样做的好处在于比较直观.
对样本做K-S检测，通过该检测法计算出双尾渐进显著性，若显著性大 于0.05,则可认为样本集服从正态分布；否则，认为该样本集不服从正态分布。 通过该检验量就可以判断样本是否服从正态分布。
看峰度和偏度，但是这个统计学上没有定论，没有固定数值，一般偏度 接近0就可以认为数据满足正态分布，如果偏度等于0就是完美正态分布。
为了严谨，本节采用先用Q-Q图目测，然后再用了 Kolmogorov-Smirnov检 验，即K-S检验，来验证样本是否服从正态分布。
3.5.2网络流量数据正态性检验
在将KNN-Grubbs算法引入网络流量异常检测前，需对网络流量进行正态性 检验。关键在于如何选取样本。实验所用数据为某局域网的总流量数据。考虑到 算法的特点，需要保存前K个状态来实现对K+1状态的计算，且状态随着K的 变化而实时更新，因此不适合多线程算法，而如果用单一线程来计算的话，无法 体现Storm分布式流计算的计算速度，对单一的Bolt压力也较大。并且，用网 络总流量直接用该算法进行计算时，发现局域网的网络总流量曲线比较多变，并 不具有典型特征。可能是由于对于单一局域网来看，其用户数较整个流量群来说 还是很少，因此流量曲线的随机性比较大。对这样的局域网做正态分布，发现并 不是特别符合正态分布。
本文中，从另一个方向进行考虑。用户流量可能每个时间序列之间起伏较大, 但是将一个小时内的流量相加，并用本月30天的同期数据进行比较的话，可以 发现流量数据相对稳定，且呈现一定的规律性。下面两张图分别取自某局域网某 个月的按小时统计的流量曲线。如3-3图为9点-10点的月同期曲线图，可以发 现，整体来说，整个流量在该范围内呈现平稳性。对此月同期数据进行Q-Q图, 发现整体数据点都分布在疔x附近，说明该样本数据很可能服从正态分布。对该 样本进行K-S检验，结果如图

某局域网内9点-10点的流量曲线图


表3-1某局域网9-10点月同期总流量K-S检测表
本 Kolmogorov-Smirnov 检验
某局域网9点至
10点流量数据
数字		31
正态参数師	　　平均值	23958219.1935
标准偏差	1983073.61868
最极端差分	　　绝对	,109
正	.087
负	-.109
检验统计		.109
渐近显著性	（双尾）	,200c-d
a.检验分布是正态分布。
b.根据数据计算。
c.Lilliefors显著性校正。
d.这是真正显著性的下限。
由表3-1可见，渐进显著性（双尾）为0.2,大于0.05,说明该月同期总流 量数据样本确实符合正态分布。因此，用Grubbs检测异常值是非常合理的。
另取一个时间段检测，如图3-5显示，为某局域网月同期23-24点的总流量 数据图。可以发现，除了 3月16日有一个明显高峰外，其他值都比较平稳。而 该高峰过于大了，基本是其他样本数据点的十倍，因此可以认为该点为异常数据 点。当把该样本数据点去除后，再对样本数据作Q-Q图，可以得到图3-6。可以 发现，数据点也基本在尸x附近，并没有特别偏离的数据点或者数据点群。对该 样本数据进行K-S检测的结果如表3-2,可以发现,其渐进显著性（双尾）为0.053, 也是大于0.05的

图3-5某局域网某月同期23-24点总流量曲线



某局域网23至24点流量数据的常规Q-Q绘图



图3-6某局域网某月同期23?24点总流量Q-Q图
表3-2某局域网23-24点月同期总流量K-S检测表
本 Kolmogorov-SmiHiov 检验
某局域网23至
24点流量数据
数字	30
正态参数或 平均值	27816338.0333
标准偏差	11739732.45385
最极端差分	绝对	.158
正	.158
负	-.072
检验统计	.158
渐近显著性（双尾）	.053。

a.检验分布是正态分布。
b.根据数据计算，
c.Lilliefors显著性校正。

3.5.3 KNN-Grubbs检测法正确性检验
从上一小节，我们验证了网络流量数据在一定程度上符合正态分布的特性。
本节我们对KNN-Grubbs进行进一步的检验，已验证其检测的正确性。
依旧对上一小节的两份样本数据进行检测。由于KNN-Grubbs的检验特殊 性，其要求首先输入的K个样本数据均为正常值。另外，对K的选择也需经过 对比。过小的K可能导致数据模型较苛刻，后续的正常值可能会被误判为异常 值。而若K过大，则模型过于简单，可能导致异常值被判定为正常值。因此， 选择合适的K也很重要。本实验中，对于K的选取，做了一些对比试验，结果 发现，当选择K=10时，正确率已经达到了 98%,而当K比10小时，则正确率 递减，当K比10大时，如12时，其正确率为97%,略比当K为10的正确率低, 但是当K再增大时，则正确率渐渐下降。因此有理由相信，本实验中，对K取 10时，效果最好。
表3-3不同K值的检测正确率
n
P	0.95	　　　　n
P	0.95
5	80%	8	93%
10	98%	15	94%
12	97%	20	　　90%

取K为10,对上一小节的两份样本进行检测，检测结果如下。其中，检测 结果0为正常值，检测结果为1为异常值。
某局域网内9点-10点的流量曲线及检测图
2Z	\
15000000	0.6

f数据流量e检测结果

图3-7某局域网9-10点月同期总流量检测图
28
某局域网内23点-24点的流量曲线及检测图
1E+09
900000000
800000000
700000000
600000000
500000000
400000000
300000000
200000000
100000000
0
图3-8某局域网23-24点月同期总流量检测图
可以发现，对于图3-7中的流量来说，虽然有所波动，但是大部分在检测允 许的范围内。因此大部分检测所有值均为正常值。只有3月19日、3月22日和 3月30日的检测结果被标记为异常。从流量图上看，这几个样本流量点都在一 定程度上与整体相偏离，有的过大而有的过小，因此在一定的程度上，确实可以 标记为异常点，异常检测结果也与预期基本相同。对于图3-8的流量来说，有一 处明显的异常，且也被检测并标记出来了。但是还有另外的两处异常也被标记出 来。从图上看，这两处异常均是小高峰，但是由于3月16日的异常值太大，因 此衬托出3月12日及3月24日的流量异常不明显，但从数据上看，其较其他数 据确实偏移了很大。因此检测结果也比较正确。其他并未发现明显异常，与检测 结果一致。因此有理由相信，KNN-Grubbs检测法正确率较高，符合实验预期， 可以完成异常检测任务。
3.6本章小结
本章首先介绍了网络流量和时间序列的定义及特点，并且通过网络流量是时 间连续的这一特性，引入通过时间序列来对网络流量进行分析的概念。接着，通 过引入Grubbs异常值检测法和时间序列的K近邻分析法，来引入时间序列的 KNN-Grubbso接着从网络流量本身来验证该算法的合理性和正确性。通过一些 样本数据的选取，并对这些样本进行正态性检验，得到样本数据符合正态分布的 特点，从而可以说明用Grubbs检测法的合理性。后续展示了 KNN-Grubbs检测 法进行检测的正确率，可以发现，KNN-Grubbs的检测正确率很高，在误差允许 的范围内，基本可以满足网络流量时间序列的异常值检测。


第四章 异常流量实时监控系统设计
4.1引言
如今的我们正处于一■个信息大爆炸的时代。互联网的迅猛发展、大规 模普及，使得互联网与我们的生活紧密相连，无法分割。我们也因此时时 刻刻体验着信息时代的便捷。而与之对应的，则是各种数据信息的疯狂爆 增。据统计，如今的企业及互联网数据以每年50%的速率在增长，用户每 天产出的数据总量呈指数级爆增趋势，平均每六个月产出的数据总量是此前的数 据量之和。所以，如何处理这么庞大的海量流量数据，以及如何存储这些海量数 据，是当今世界所面临的一个巨大的挑战。
在这种情况下，Hadoop诞生了。Apache Hadoop是当前公认的最优秀的分 布式大数据处理框架［W,其核心是分布式文件系统HDFS和分布式计算框架 MapReduce,即先将数据存储到HDFS上，再用MapReduce进行批处理。尽管 Hadoop有着优秀的海量数据处理能力，高容错率和处理效等，但是Hadoop依然 有着一定的局限性。Hadoop的数据处理方式注定了它只适合做离线的大数据分 析。而对于海量实时数据的处理，Strom的表现令人瞩目。Strom是流处理平台， 实现了一种基于数据流的计算模型，很符合异常网络流量监控的海量网络流量计 算的实时要求。
本章中，我们将介绍分布式消息系统Kafka、分布式流式处理平台Storm和 分布式非关系型数据库Hbase,并且将这三个分布式平台组合来构建一个实时的 流处理平台，通过一定的算法设计，实现对海量网络流量信息的实时处理，并且 将结果保存于分布式数据库，从而完成异常网络流量监测的任务。
4.2异常流量实时监控系统
4.2.1数据采集模块
Storm本身不负责规定所要处理的数据来源，即Storm可以处理的格式可以 是多样的，例如日志文件、数据库、消息队列或者直接连接socket等。Storm的 输入多种多样，只要Spout实现相应的接口，即可从任何所需的地方获取数据。 然而，Storm也并非万能的，其处理文件格式存在一个问题：数据可能存在不同 的位置，不同服务器中，而Spout无法从多个来源获取数据。即使把所有数据集中到同一台机器上，则分配给Spout任务接口的并发度只能为1,无法发挥Storm 分布式的特点，因此，如何实现Storm处理文件的完全并行化是本系统要解决的 一个问题。本文采用在Storm前加一个Kafka消息队列集群的方案来解决Storm 获得多个源数据的问题。
Kafka的目的是提供一个发布-订阅模型的解决方案，它可以处理生产者产生 的所有动作流数据。这种流动作通常需要进行实时的处理，Kafka接收各种流数 据是比较可行的。生产者不断的将外部源数据读入消息队列，Storm作为消息队 列的消费者主动从消息队列拉取数据进行处理，实现Storm的实时消费。
使用Kakfa做消息中间件，将不同数据源的数据放入消息队列，Storm作为 消息队列的消费者来处理数据，这样做有几个好处。首先，解决了 Spout读取文 件不能并行化的问题。其次，这种结构可以很方便的使得不同的拓扑结构共享数 据源，提高了系统的可扩展性。再次，通过消息中间件Kafka,掩盖了外部数据 源格式的不一致性，实现了数据的归一化。最后，Storm提供了从Kafka读取数 据接口 KafkaSpout,减少了 Storm使用Kafka编码的复杂性，我们只需要实现 producer即可。虽然引入Kafka会增加整个系统的开销及复杂性，但是当数据量 达到一定程度时，增加Kafka集群而导致的系统的性能损耗是可以忽略的。数据 收集部分结构如图所示。

Storm集群

图4-1数据采集模块示意图
4.2.2数据处理模块
数据处理模块釆用Storm自带的API来实现数据分析,主要的工作是实现相 应的接口，如 Spout 中的 open。、nextTuple。、declareOutputFields(), Bolt 中的 prepare。、execute。、declareOutputFieldsQ, Spout 的核心功能是通过 nextTuple() 函数实现的，该函数实现并完成了 Tuple的读取和发射，Bolt的核心功能是通过 execute。实现的，该函数实现并完成了 Tuple的处理和发射，这两个函数会被框 架周期性的调用，以保证任务的不间断执行。系统的主要设计思路是通过 KafkaSpout读取Kafka消息队列的数据，然后通过各级Bolt实现数据分析的具 体业务逻辑，并将结果保存到Hbaseo
下图显示了异常流量检测系统处理的拓扑结构。有四个基本组件： KafkaSpout, SplitBolt, KnnGrubbsBolt 和 WriteBoltoKafkaSpout 实现的是从 Kafka 读取数据流，并发射输出到SplitBolt, SplitBolt将每条数据的各个字段进行分割， 传输到KnnGrubbsBolt中，KnnGrubbsBolt将数据与其保存的前K条正常数据进 行KNN-Grubbs算法的计算，最后将结果发送到WriteBolt,由WriteBolt将结果 写入Hbase非关系型数据库。在每一个阶段可自定义Tuple, Storm会自动被传 递到下一个Bolt进行处理，在这个过程中，依托Storm的拓扑模型和框架，用 户只需专注于Spout和Bolt的功能实现,其余的分布式处理由Storm框架自动完 成。
| Kafka消息队列|

图4-2数据处理模块整体架构

4.2.3数据存储模块
HBase是基于HDFS的、面向列的非关系型数据库，是Google论文《Bigtable:
一个结构化数据的分布式存储系统》的开源实现。因为HBase是基于Hadoop平 台的分布式数据库，所以HBase可以支持海量数据，并且，经过测试，HBase 支持高并发的读写，这适用于实时的大数据存储。在这个系统里，HBase将接在 Storm平台之后，用来接受并存储Storm平台各个Bolt输出结果。
数据存储模块由一级Bolt组成，即WriteBolto WriteBolt主要用来计算每个 IP对应的上下行报文数的总量，每个WriteBolt线程单独启动一个定时器定时（每 个时间粒度）发送信号，将存储的每个IP以及IP对应的上下行报文总数写入 HBase表格中。同时，将该条记录的检测状态也写入Hbase,正常记为0,异常 记为1,以供后续分析。HBase存储的表格结构如下表。
表4-1 Hbase存储格式
RowKey	Timestamp	Column Family:columns
IP+每个时间粒度起 始时间	当前机器时间	当前时间粒度内的 总流量	检测状态
4.2.4系统架构
本文中介绍的实时网络异常流量检测系统各部件己介绍完毕,此时可以完整 的将系统呈现出来。基于Storm的实时处理平台是本文异常检测系统的基础， 这个实时处理平台釆用 Kafka+Storm+HBase的结构。Storm 平台的 KnnGrubbsBolt使用了 KNN-Grubbs检测算法实时检测异常网络流量。实时检测 系统结构如图4-5所示。计算系统的输入与消息队列kafka交互，计算系统的 中间处理通过topology实现，计算系统的输入结果保存于Hbase。处理方式是将 数据源的数据导入Kafka消息队列，然后通过Storm的Spout拉取数据并用bolt 进行业务逻辑计算。将处理完的结果加好标记保存于Hbase。



Zookeeper 集群
图4-3系统架构图

4.3关键技术介绍
4.3.1 Kafka性能测试
考虑到以后可能的业务发展，异常流量监控的各组件需要较可靠的性能和较 优秀的可扩展性。尤其对于数据源与Storm系统的消息中间件Kafka,可靠的性 能显得尤为重要。因此，此处对Kafka进行了一系列性能测试，以保证Kafka完 全满足系统需求。Kafka实验平台技术参数如下表。Storm集群和Kafka集群使 用同一个机房的同配置的服务器。其中3台用作Kafka集群，8台用作Storm集 群。由于此11台服务器之前就安装了 Hadoop及Hbase。
表4-2实验平台服务器参数
硬件配置	CPU	8核64位
内存	32G
硬盘	900G*6
软件配置	操作系统版本	CentOS Release 6.4
Storm版本	Storm 0.93
Kafka版本	Kafka 0.8.1
网络环境	网卡	千兆以太网
测试方法：
1.首先，通过运行下列命令创建topic
bin/kafka-topics.sh		—zookeeper
192.168.0.10:2182,192.168.0.10:2183/config/tancheng/test/mykafka —create —topic kafka-test -partitions 3 -replication-factor 1
2.通过Kafka自带的Kafka-producer-perf-test.sh脚本，产生一百万条数据， 并push到相应的topic o并记录所用的时间。
实验结果如下：
表4-3 Kafka写入速度
单条消息大小	batch size/条	式			传输速度Message/S
500	　　　　　200	10 不?S		11.1513	23369.8916
500	　　　　　200	10 Gzip		14.045	　　　　29425.1878
500	　　　　　200	10 Snappy		32.2064	67471.785
50	　　　　　200	10不碰		5.3654	111399.5121
50	　　　　　200	10 Gzip		2.6479	54979.4926
50	　　　　　200	10 Snappy		4.4217	91836.641
900	　　　　　200	10不碰		11.0518	12867.3632
900	　　　　　200	10 Gzip		17.3944	20261.3717
900	　　　　　200	10 Snappy		31.0658	36174.215

测试结论：
不同的压缩方式对Kafka处理速度有影响，其中综合表现最好的为Snappy 压缩方案，在单条数据不是很小时，其速度明显比其他方案快很多。
在单条数据较小时，不考虑网络延时的情况，Kafka每秒大约可以处理 10万条数据。
4.3.2 Kafka与Storm的连接
系统的技术难点之一在于如何将实时流处理平台Storm与消息队列Kafka相 连接，本文釆用了 KafkaSpout来实现两个组件的连接。KafkaSpout是Storm中 自带的Spout,使用KafkaSpout时需要子集实现Scheme接口，它主要负责从消 息流中解析出需要的数据。连接成功后终端显示信息如下：

图4-4 Kakfa与Storm连接成功返回信息
4.3.3Zookeeper集群配置
Storm集群需要通过Zookeeper来进行集群内部通信，而Storm并不自带 Zookeeper,因此需要单独安装配置Zookeeper。Zookeeper安装很简单，只需下 载解压进行相关配置即可，在此不多做介绍，只是展示配置项zoo.cfg：
tickTime=2000
dataDir=/var/zookeeper/
clientPort=2181
initLimit=10
syncLimit=5
server. 1 =nimbus :2888:3888
server^supervisorl :2888:3888 server.3=supervisor2:288 8:3888
Server.4=supervisor3:2888:3888
Server.5=supervisor4:2888:3888
其中，tickTime指的是ZK中的最小时间单元，一个session的最小超出时间

为2*tickTime； dataDir即表示内存数据所保存的目录，同时也是myid文件所在 的目录;clientPort 即客户端连接 server 的端口，一般为2181；initLimit和 syncLimit 一般取默认值即可，是ZK同步时间和内部心跳检测时间°server.id=host:port:port, id是为Storm集群服务器编号，也即每个Zookeeper节点的编号，后面的两个端 口号分别用来连接Leader的端口和用来选举Leader的端口。
4.3.4Storm集群配置
Storm安装其实并不复杂，主要是其依赖的组件比较多，安装Storm前需要 安装ZeroMQ、JZMQ、Python等。本文不介绍组件安装，主要介绍下Stomyaml 的配置。
storm.zookeeper.servers:
-"192.168.10.10"
-"192.168.10.11"
-"192.168.10.12"
-"192.168.10.13"
-"192.168.10.14"
此处主要配置了 Storm所使用的Zookeeper集群的地址。
stonn.local.dir: "/home/uesr/storm/workdir"
此处主要指定了 Stom的工作路径。
j ava.library.path: "/usr/local/lib :/opt/local/lib:/usr/lib "
此处主要制定了 Storm运行所需的ZMQ和JZMQ地址，也可用默认的，则 不需要配置。
nimbus.host: "192.168.10.10"
此处主要指定了 Storm的主节点地址。
supervisor.slots.ports:
-6700
-6701
-6702
-6703
此处指定了每个Supervisor节点可运行的Worker的端口。Stonn默认一个 Supervisor可运行4个worker,则每个worker可用的端口即为6700、6701、 6702/6703o
38

4.3.5Storm性能优化
Storm集群中，多个Supervisor合作进行Topology的计算，即实现了 Storm 的并行运算。Spout和Bolt的Task实例运行在集群的Supervisor上。Task实例 即是最终完成数据处理的实体单元，即Spout或者Bolt的最小实例单元。 Supervisor上存在着一个或多个Worker进程。一个Worker进程中可以存在多个 Executor线程，而每个Executor线程又可以有一个或多个Task实例卩句。整个 Supervisor 上 Worker、Executor> Task 的关系如图下所示。
storm集群的1台物理机会启动1个或多个 worker?程(即jvm进程)，所有的 topology将在这些worker进程里被运行。
J	J
图4-5节点上的Worker> Task等关系图
本实验中，对Kafka和Storm的连接性能做了一定测试，以此来优化Storm 性能。测试数据来源为下一张使用的真实流量数据，共有1669331条数据，共 895M。数据皆先Push到Kafka,然后再用Kafka-Spout来pull进系统。实现的 Bolt很简单，仅仅为统计各字段的总数。实验结果如下：
表4-4 Kafka和Storm连接性能测试
Worker^ 目	Spout并行度	Bolt并行度	Spout_pending大小CPU使用星	内存使用量	消耗时间
1	1	1咐	　　　　35%	40%4m30s
1	2		　　　　45%	90% 3m30s
1	2	i	500	　　　　50%	70% 2m39s
2	2		1	500	　　　　40%	40% 3ml2s
由表可得，当不设置Spout_pending时，内存可能比较容易成为瓶颈。设置 了 500后，其性能明显上升o Spout_pending可以改变Spout可缓存的Tuple数目， 可以发现，当不设置时，Tuple可能出现无限堵塞导致内存被占满，从而导致任 务变慢。另夕卜，Worker、Spout、Bolt的并行度也能对Storm性能产生一定影响。
因此，Storm的优化可以从以下两方面考虑：
1 .设置并发度
Storm的并发度可以从以下几个方面进行设置：一是Supervisor上的Worker 的数目，二是一个Worker内Executor的数目，三是一"个Executor内Task的数目。
下面分别进行介绍。
Worker：可以在storm.yaml中进行配置，也可以通过 config.setNumWorkers(workers)设置，具体得由测试分析得到。
Executor 的设置： 通过 builder.setSpout(id, spout, parallelism_hint)、 builder.setBolt(id, bolt,parallelism_hint)分别设置 Spout 和 Bolt 的数量。
Task 的设置：通过 spout/boltDeclarer.setNxmTasks(num)设置对应 spout/bolt 的task个数。
Akcer：通常，一颗Tuple树结束后会调用一次Acker。因此当并发时，可能 有多个Tuple0
需要调用Acker,因此Acker也可能成为制约效率的因素。一般与Worker 数相等。
2.监控内存及CPU等参数使用量
一般情况下，Storm启动Worker时的默认最大内存为768M。但是在需要加 载大量数据进行计算的情况下，768M内存并不能满足需求，甚至导致内存溢出 而宕掉。此时，可以通过在Strom的配置文件storm.yaml中设置worker的启动 参数:worker.childopts: "-Xmx2048m" <, Worker在启动时会自动读取该配置项，然 后Worker的最大内存即可扩展到2048M-
4.3.6Storm拓扑设计
KafkaSpout：用于从KafkaBroker获取数据并传入拓扑中，为整个拓扑数据 流的源头。
SplitBolt：用于将数据按照每个小时分割，并将同一个小时的流量合并，然 后将各个不同小时的数据分发到KNNGrubbsBolt对应的Task进行处理。
KNNGrubbsBolt:通过KNNGrubbs算法，将不同日期的同一时间段的数据 进行异常检测，并将数据与结果发送到WriteBolt进行存储。
WriteBolt：将获取到的数据进行写入Hbase。
整个Stonn的拓扑即如图4-6所示：


图4-6 Storm拓扑图
4.4本章小结
本章先分三个模块介绍了异常流量实时检测系统。首先是数据釆集模块，说 明了数据来源，并且展示了数据釆集模块示意图。接着介绍了数据处理模块，主 要是用Storm实现的。然后，介绍了数据处理后的存储模块，简要展示了数据保 存的格式。然后，将各模块合而为一，从整体介绍了本实验的异常流量实时检测 系统。接着，是对本检测系统中使用到的一些关键技术进行了简要说明，包括 Zookeeper和Storm的配置，Kafka的性能测试，Kafka和Storm的连接关键技术 点，以及Storm的性能优化等。

第五章异常流量实时监控系统数据分析
5.1引言
上一章里，我们主要介绍了整个异常检测系统的架构。本章我们主要介绍该 系统处理的数据及对处理后的数据进行分析。本章中使用的数据100%均是来自 大量真实用户的真实上网流量，保证数据的安全可靠。
5.2数据来源
企业网是指一个企业内部网络。由于企业的特殊性，内部数据一般不与外部 流通，有一定的区域性，因此可以认为是一个局域网。企业网内部数据流通多样, 但是一般连接外网的网口只有一个，所有员工的网络流量数据都将通过该网口与 外网进行通信交换。因此，我们只需将数据采集的设备安置在该网口处，即可采 集到该企业的所有上网流量，这个设备即我们实验室的网络流量检测设备。釆集 到的数据统一的处理平台，称为网监平台，如下图所示。


图5-1网监平台布局
数据采集设备被部署在超过200个企业网的网口处，总计有接近2000台设 备。采集设备随时收集用户的网络流量数据，并将收集到的数据进行处理，并上 传到一个总的服务器进行汇总，以进行后续处理。为了更好的对这些数据进行分析，我们将数据进行自定义的字段处理，并称之为“复合会话”。复合会话由一 个四元组作为唯一标识的实体，包括源IP,目的IP,网络协议和目标端口。相 较于传统的五元组，四元组可以更有效的汇总流量并进行传输。
数据采集设备持续不断的釆集数据，在这过程中，网络流量可能会分时段的 空闲和忙碌。因此，我们为复合会话定义了相应的忙期和闲期。当釆集设备检测 到上行或者下行的流量数据时，意味着此时为忙期，相应的忙期计数器增加一。 当两个上行或者下行的流量数据包被检测到的时间间隔超过一个阈值，如一秒或 者两秒，则可以认为此时为闲期，相应的闲期计数器增加一。
如图5-2所示，探测器以10MIN为周期，规律性的将采集到的数据（由宏 观、中观、微观三个维度的24个统计参数组成）形成一个文件，时间累积到一 定时间（即一个报告期时间，通常为3小时）后，所有的文件将被上传到中央服 务器，并作为一个新的文件存储。




V	汇总上报周期	A

图5.2周期上报示意图
复合彝
复合会话是我们在研究企业网流量数据时，为了便于分析而自定义的一种数 据格式。复合会话所包含的字段分为三个层面，即宏观层、中观层以及微观层， 每个层面又具化为多个统计量。宏观层主要统计了一个统计周期内的总流量、报 文等信息。中观层主要统计了一个统计周期内忙期和闲期的流量，此外还包含一 些简单的数学计算量。微观层主要统计了忙期时流量内的上下行报文数，并包含 更多的复杂的数学计算量。复合会话具体的统计信息如下图所示：
44
表5-1复合会话数据格式
类别	名称	描述
宏观层	TUP/TDP	上下行报文数
TUB/TDB	上下行字节数
TSE/TSR/TA
S	周期内新建/结束/活跃
中观层	BT/IDT	忙期/闲期总数
BE/IDE	忙期/闲期平均时长
v_bd/v_id	忙期/闲期标准差系数
微观层	E_TS	忙期内发言切换平均次数
E_DT/E_UT	忙期内上下行发言平均次数
E_DTP/E_U
TP	上下行发言平均报文数
E_DTB/E_U
TB	上下行发言平均字节数
V_DTP/V_U
TP	上下行发言报文数标准差系数
V_DTB/V_U
TB	上下行发言字节数标准差系数
当服务器接收到探针上传来的复合会话文件后，再对复合会话针对主机进行 进一步分析，得到主机流量的实时表、日表、月表。实时表是对复合会话即时的 记录，日表是对复合会话跨度一天内的流量数据进行统计记录，月表是对复合会 话跨度一个月内的流量数据进行统计记录。本实验用的数据为主机的实时表。实 时表的统计字段基本和复合会话一致，只是添加了部分字段。此处不多加介绍了。
在设备的一个统计周期结束后，复合会话的统计数据也会随之更新。但是此 时数据并不会上报，而是等一个汇总周期以后才会汇总上报。因此，考虑某些极 端情况，比如某次复合会话持续了一个汇总周期，则受限于设备的内存，复合会 话产生的数据可能会超过设备内存，从而导致设备崩溃。为了解决此类问题，研 究组设定了两个方案。一是针对复合会话的忙期闲期设定一个上限，即65535, 当超过该阈值时，则会将该复合会话的闲期、忙期统计量清零，重新开始进行数 据统计。其次是规定，当一个复合会话连续超过两小时没有产生流量数据，则将 该复合会话从设备中删除。只有当设备再次检测到该复合会话，才会对其重新记 录。


但是这样处理之后，可能存在一个问题，即将一个复合会话拆分记录到2 个统计文件中。因此需要对此2个文件中的同一会话记录进行合并。
假设复合会话被分成的两个文件分别包含m条记录和n条记录。
个部分的平均值和方差记为饥、e“和&、v?o则统计算法为：
（JYI _	+（72 _ l）Vn 4	_ e^）2
i =	*
7W +〃一 1
mem + nen
Cm + ■=
m-\~n
以此来计算整个复合会话的相关统计量。
5.3主机流量分析
在本节中，我们展示了一些实验结果来测试系统的准确性。实验数据是上节 中所展示的复合会话处理后得到的主机流量实时表的一天的数据。探测器以每 10MIN为粒度上报数据，进过整合成每小时粒度后，再对其进行异常检测。原 因是因为企业网主机乃至企业网整体的样本容量太小，样本随机性太大，若再按 照10MIN的粒度进行计算，则误差可能会很大。但是将数据整合到小时粒度后, 整体随机性大大下降，实验结果较符合预期。实验结果图如下：
某主机某天的数据流量和检测图

图5?3某主机某天的数据流量检测图
从图中可以看到，在该用户（主机即可认为是一个用户）的流量记录中，共 存在三个异常值点。从0点到8点，该用户的整体流量偏低，从实际生活角度看, 这种情况也较符合预期，因为0点到8点为非上班时间，该用户的流量数据较少 符合实际。另一方面，数据流量并不为0,可能由于该用户未关机的，而电脑上 的一些软件自动安装更新或者缓冲等产生。在此期间，3点至4点，有两个明显的数据流量高峰，甚至超越了平时14-17点的数据高峰，与之前十天的数据预期 不符，因此极有可能为异常值，与检验结果相一致。从8点开始，数据量渐渐增 加，可能是8点至9点为上班时间，用户回归工位且开始正常使用。到11点时， 可以发现用户流量出现了一个小高峰，此时刚好为午休时间，因此该用户可能去 吃饭或者开始缓冲一些视频来观看。从下午1点开始到17点，该用户流量保持 高流量运行，说明开始了下午的工作且持续到下班。从19点开始到23点，可以 发现流量由高峰逐渐降低到趋近0,此时用户应该已经下班，不再进行高流量的 网络使用。在19点时候出现了异常，说明此时用户的流量应该已经趋于0,但 是此时流量仍旧很高，与平常的行为有异，因此判定为异常。产生这种情况的原 因有可能是数据异常，也有可能是用户平时不加班，当时加班到较晚。因为用户 主机的随意性，因此属于哪种行为并不好判断，但是可以看出，检测算法还是很 有效的。
5.4企业网流量分析
5.4.1企业网流量参数计算
企业网为一个网口内所有主机的统称。由于其性质的特殊，中观层、微观层 的一些标准差等统计量无法直接得出，得通过主机的标准差等参数间接计算得 出，故此引入误差传递公式。
设间接测得量N = /（X1.X2.X3）,式中X1,X2,X3均为彼此相互独立的直接测得 量，每一直接测得量为等精度多次测量，且只含随机误差，那么间接测得量N的 最可信赖值（用平均值戸表示）为：
而=/（爲，刘，元3）	（5-3）
标准差传递公式为：
序点7磚忐无云7	（5-4）
V 0X1	0X2	0X3
以此即可计算得企业网流量的中观层、微观层参数。
5.4.2企业网流量数据分析
上一小节，我们测试了主机的数据流量检测结果。本小节中，对局域网整体 进行了一系列数据流量的检测，并展示了相关的检测结果图。实验数据来源于某 局域网一天的主机流量数据，经过上面的误差传递公式计算得到的企业网整体实时表数据。数据的时间粒度依旧为小时，是对原数据整个得到。原因同上，虽然 企业网已具有一定的用户规模，但是不可否认的是，企业网的用户规模还是较少， 按原粒度的话，随机性依旧可能造成很大影响。实验的结果如下：
I -		 				 ――	■
6.00E+08
5.00E+08
4.00E+08
3.00E+08
2.00E+08
1.00E+08
O.OOE+OO
图5-4某企业局域网某天的数据流量检测图
由图中可以看到，在0点至10点的时间内，企业网整体流量呈现较低水平， 从10点开始，数据流量才缓慢增加，可以猜测该企业网上班时间为上午10点左 右。12点至13点时间内，数据流量从小高峰略微减少，根据常识猜测，该时间 内该企业网员工集体吃饭、午休时间，因此整体使用流量数据稍微减少了一些。 14点至16点，整体流量数据保持在较高水平，但是从17点开始，数据流量急 剧降低，可以猜测17点为该企业下班时间，因此从17点开始，流量数据使用量 大大减少。但是有图可以发现，在19至20点两个时间区间内，该企业网流量反 常态的增加，与以前的趋势完全不符，因此判定为异常流量，符合预期。从21 点开始至23点，流量数据逐渐降低为较低水平，与预期也较为符合。
5.5设计目标综述
上面两小节分别从主机的角度和企业网的角度对总流量进行了异常检测及 分析。以Storm作为流式处理平台，既可以实现数据的准实时处理，也避免了用 MapReduce处理时每处理完一个Job就得重新跑一次MapReduce程序的麻烦。 以KNN-Grubbs作为Storm的Bolt计算的逻辑，通过将数据分割整合到24小时 内进行计算比对，很好的将企业网流量数据进行异常检测，并且，检测结果通过 Hbase存储后，后续可以展示到页面，也可以设置报警短信，即时灵活的提供告 警功能。并且，通过将该算法在Storm实现以后，可以对全网、企业网、用户提 供不间断的、三个级别的服务，可以从整体查看流量数据变化，也可以细化到企

业网，乃至细化到企业网用户。此系统即可作为全网的网络流量监控平台，用户 按照自己的需求需，订制所需要监控的目标服务，即可随时随地的接收到高准确 率的异常告警。即整个系统可以实现成为一种SAAS管理模式。并且，现阶段， 该系统已经在公司启用，检测一部分的业务目标，以后也会在本网络流量实时异 常检测系统的基础上，进行一些服务升级，慢慢向SAAS模式演进。
5.6本章小结
本章首先介绍了数据来源,主要说明了数据的详细采集平台及数据釆集后的 处理策略。以此为切入点介绍了自定义的复合会话数据，包括其处理流程、数据 格式、消除一些问题的方案以及由复合会话产生的主机流量实时表。接着分析了 某个主机一天的流量检测结果，可以发现与预期的结果一致。然后介绍了由主机 流量实时表得到企业网流量数据的算法，之后分析了企业网的流量数据检测结 果，发现检测效果也较好。因此可以得出结论，本文的异常流量检测系统较为符 合预期，完成了实验的检测目标。最后简要介绍了一下系统整体的架构，以及有 望形成的架构体系。

第六章总结与展望
6.1全文工作总结
本文着重研究了基于时间序列的海量网络流量分析系统的研究与实现。大数 据处理作为当代的流行趋势，其带来的网络安全隐患比以往更加强烈。本文首先 对于网络流量数据的本身特点入手进行分析，结合时间序列的特性，发现网络流 量可以用时间序列分析法来进行分析处理。接着，从常规异常检测方法入手，根 据系统实际情况，结合时间序列分析中的K近邻法，提出了 KNN-Grubbs检测 法，并且根据Grubbs判别法需要数据符合正态分布的特点，对网络流量进行取 样检测，证明在一定的取样条件下，网络流量同期呈现正态分布，符合预期。因 此用KNN-Grubbs检测法判定异常值很合理。接着又通过实验结果，证明 KNN-Grubbs检测法正确率很高，符合实验要求。然后，为了适应新时代产生的 新需求，本文结合了当前的几大热门技术：Storm、Kafka和Hbase,设计并实现 了一个可以对网络流量进行实时异常检测的系统，并将KNN-Grubbs异常检测算 法成功运行于系统中，完成了本文的设计目标，即实现实时网络流量异常检测系 统。并且根据实现的系统，完成了真实网络流量的检测，并且分析了网络流量异 常的行为。
总的来说，本文完成了以下几项工作：
1.设计并实现了实时网络流量异常检测系统。在了解并学习了前沿的大数 据处理技术的基础上，对各种大数据处理技术进行有机结合，提出了从Kafka 消息队列到Storm流处理平台，最后到Hbase分布式数据库的整个系统架构。整 个系统由三个模块组成。数据釆集模块主要包含企业网数据釆集设备及其中央服 务器和Kafka集群。企业网数据采集设备通过探针从局域网收集网络流量数据 后，经过一定的预处理，被送入中央服务器，再由中央服务器将流量数据push 至Kafka集群对应的Partitiono数据处理模块主要由Storm实现。Storm的拓扑 由一个Spout和两级Bolt组成。第一级Bolt对数据按小时进行分类，第二级Bolt 按小时对数据进行处理，。数据存储模块由Hbase实现，将Storm检测完的数据 存入数据库。为了使整个系统性能更好，也方便以后的可扩展性，试验中还对 Kafka进行了一系列性能测试，也对Storm做了一些性能优化，以使实时网络流 量异常检测系统表现更好，处理的速度更快。
2,本文在研究了网络流量本身特点的情况下，引入时间序列分析的概念，
结合Storm处理机制，对传统的异常值检测算法Grubbs检测法灵活的做了一些 改变，成功的将该算法运用于实时网络异常检测系统中去。同时为了验证算法的 合理性和准确性，在试验中对流量数据进行采样分析，先将样本进行正态检验， 证明了数据符合正态分布，因此对其用Grubbs检测法很合理。接着将 KNN-Grubbs检测法进行实例检测，可以发现，检测正确率很高，完全符合预期。
3.本文提出了一种自定义的复合会话的数据格式。复合会话是由源端、目 的端、网络协议和目标端口所唯一标识的实体。并且，由复合会话得到了主机流 量的实时表，再针对实时表进行下一步的分析。此外，通过同一个局域网的主机 流量，根据误差传递公式，求得了整个企业网的流量数据，并且也对其进行了分 析。
6.2展望
本文通过对企业网流量数据的研究，提出了一个算法设计方案，并实现了基 于Strom的实时流处理系统设计。但是仍有很多不足，本人觉得至少可以在以下 两个方面进行提升：
1.由于企业网用户的基数较少，因此随机性导致的误差依旧存在，未来可以 考虑釆集一些较大的企业的流量数据进行分析，以减少随机性误差，增加精度。
2.复合会话存在多种维度，本文中只对总流量进行了分析，后续可考虑对其 他维度也进行考量，并进行一个多维度的综合分析，来更好的检测异常网络流量。

参考文献
[1]刘滨.基于中韩比较的移动互联网行业发展研究[D].中国科学技术大 学,2011.
[2]赵丽婷.互联网技术的发展趋势[J].黑龙江科技信息,2013.
[3]中国互联网络信息中心(CNNIC).第36次中国互联网络发展状况统计报告[J]. 2015.7, http://www.cnnic.cn/.
[4]杨健康，张建伟.分布式拒绝服务攻击的攻击树建模卩].装备指挥技术学院
学报,2004.
[5]贾慧，高仲合.基于自相似的异常流量检测模型[J].通信技术,2010.
[6]陈清，李维舟，杨欣捷.大数据支撑技术探讨[J].中国金融电脑,2015.
[7]李明桂，肖毅，陈剑锋.基于大数据的安全事件挖掘框架[J].通信技术,2015. 凶查礼，程学旗.天巩大数据引擎及其应用[J].集成技术,2014.
[9]郭思奇.基于目标特征的多分辨率体绘制算法研究[D].电子科技大学,2014.
[10]董春涛，李文婷，沈晴霓.Hadoop YARN大数据计算框架及其资源调度机制 研究.信息通信技术,2015.
[11]程学旗，靳小龙，王元卓.大数据系统和分析技术综述[J].软件学报,2014.
[12]谢海涛.南航通用考试系统的设计与实现[D].东北大学,2007.
[13]鲁凌.两类时间序列模型预测的分析与研究[D].南京信息工程大学,2009.
[14]钟智，朱曼龙，张晨.最近邻分类方法的研究[J].计算机科学与探索,2011.
[15]周洲.K近邻法在matlab上的应用与分析[J].商情,2013.
[16]仲媛.最近邻分类的若干改进算法研究[D].南京理工大学,2012.
[17]逮晨.海量空间环境数据分布式并行处理关键技术研究[D].电子科技大 学,2014.
[18]梁慧林用Visual Basic.NET实现多线程编程[J].计算机与网络,2005.
[19]Twitter Stonn, http://storm.incubator.apache.org/
[20]Leonardo Neumeyer, Bruce Robbins, Anish Nair. S4: Distributed Stream Computing Platform. 2010.
[21]Kumar S, Gomez O. Denial of Service due to direct and Indirect ARP storm attacks in LAN environment[J], Journal of Information Security, 2010.
[22]Huang C T, Thareja S, Shin Y J. Wavelet-based real time detection of network traffic anomalies[C]//Securecomm and Workshops, 2006. IEEE, 2006: 1-7.
[23]Imdadullah. "Time Series Analysis". Basic Statistics and Data Analysis. itfeature.com. Retrieved 2 January 2014.
[24]Das D, Sharma U, Bhattacharyya D K. Detection of HTTP flooding attacks in multiple scenarios[C]//Proceedings of the 2011 International Conference on Communication, Computing & Security. ACM, 2011: 517-522.
[25]StormKaflca, https://github.com/nathanmarz/storm-contrib/tree/master/storm-kafka.
[26]Dhruba Borthakur, Joydeep Sen, Jonathan Gray. Apache Hadoop Goes Realtime at Facebook. STGMOD, June 2011.
[27]Barfbrd P, Kline J, Plonka D, et al. A signal analysis of network traffic anomalies[C]//Proceedings of the 2nd ACM SIGCOMM Workshop on Internet measurment. ACM, 2002: 71-82.
[28]Kafka, http://kafka.apache.org/.
