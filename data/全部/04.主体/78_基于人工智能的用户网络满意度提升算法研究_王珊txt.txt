第一章绪论
1.1	研究背景与意义
2017年8月，工信部明确指出要在2020年全国范围内推行携号转网服务山。调查 显示，有50.8%的用户有强烈意愿办理携号转网⑵。携号转网政策的落地实施将对三大 运营商造成局部洗牌以“提速降费”重大决策的部署客观上也削弱了三大运营商数据 业务的盈利能力HL随着获客成本升高，运营商依靠抢占用户拉动增长的经营模式已不 再见效，存量经营的价值开始凸显。在此背景下，原有的以网络为核心的业务经营模式 已经不能满足当前的用户需求，取而代之的是以用户体验为中心的新型价值模式。例如， 目前中国移动用户基数大，随着用户通信需求的快速变化，尤其是移动互联网内容应用 的日益普及，用户对网络、资费及业务各环节的服务能力和标准都提出了新的要求，用 户投诉数量及复杂程度呈明显上升趋势，而当前投诉管理主要采取事后补救措施，缺乏 事前分析的信息、工具，对用户投诉的热点问题缺乏有效的监控手段。推动投诉预警探 索，是积极应对社会、舆论关注焦点的需要，而基于数据挖掘技术的网络投诉预警建模 研究，可以对有投诉倾向的用户进行预判，扭转当前事后补救的投诉处理方式，防患于 未然。
电信业是非常适合数据挖掘的应用领域，三大运营商企业覆盖16亿移动用户，运 营商大数据平台拥有海量数据，不仅包括用户基本信息，还包括终端信息、消费信息、 APP使用信息、通话行为数据、上网行为数据等，通过对这些数据的分析与挖掘可以帮 助电信运营商理解商业动向，更好地利用资源从而提高服务质量，比如识别用户购买行 为，发现用户消费模式和趋势，设计更好的分销策略；预警用户投诉行为，及时给予个 性化关怀，提升用户感知；将用户划分为具有战略意义的群组，更加精准地把握用户需 求，实现精细化运营等。基于数据挖掘技术的智慧化运营是当前的研究热点，也是运营 商数字化转型的关键［文
聚类算法和分类算法是数据挖掘基础算法。聚类算法既可作为单独的过程用于发现 数据内在的分布结构，将数据划分为紧密相关的群组，用于用户分群、图像识别等，也 可作为其他算法的预处理过程，用于奇异值检测、特征构造等。聚类分析已广泛地应用 于包括信息检索、生物医学、智能商务在内的多个领域。聚类算法的应用中大多是没有 标记的数据，需要自动去发现数据的内在结构，这种利用无标记数据进行学习的无监督 学习过程很难保证算法的精确度，因此，近年来研究热点聚焦在如何综合利用少量有标 记数据指导聚类的完成。
分类算法在企业的生产经营中有着重要的应用价值。分类的主要目的在于预测，近 些年来，理论界开始探索组合分类模型在电信业用户流失预测上的效果⑹。相对于单一 模型，组合模型在预测精度上有着更好的性能，但当数据量较大时，算法时间复杂度较 高，可能会影响项目的实施，并且复杂模型的输出有时可能不易理解与应用。
携号转网、提速降费等政策多次被写入政府工作报告，三大运营商纷纷响应号召， 近两年来相继提出多种低价套餐、不限量套餐，这些政策的施行给用户带来了更优质的 智能信息服务，同时也给运营商带来了更激烈的市场竞争，运营商该如何在加强网络建 设的基础上提升用户网络满意度，做好用户保有，本文从网络投诉预警及分层分级精细 化运营的角度给出解决办法：将专家经验与数据挖掘算法结合，将相似用户分群，了解 用户的真正需求及企业在服务能力上的不足并加以改善；围绕用户感知，利用大数据技 术防患于未然，实现对潜在投诉用户进行预警并主动关怀；预测用户满意度评分，从低 到高对潜在投诉用户进行优先级排序，搭建分层分级的用户关怀体系。本文的研究对于 运营商企业提升用户满意度、做好用户保有，在激烈的市场竞争中立于不败之地具有重 要意义。
1.2	国内外研究综述
数据获取和存储技术的进步，使得各组织机构可以积累海量数据。传统的数据分析 工具和方法已不适用于如此巨大的数据量。面对这些挑战，数据挖掘技术得到了空前的 发展，可在大型数据库存储中，自动发现有用信息IL并将这些信息用于指导人们更好 地生产与生活，如电信领域的定向营销、流失预测，生物学和医学领域的基因组发现、 疾病检测等。
1.2.1	半监督聚类算法研究
尽管拥有海量数据，但这些数据大多是无标记的，能为数据挖掘算法提供的数据分 布信息有限网，综合利用监督信息的学习过程称作半监督学习，如通过引入监督信息指 导聚类完成的半监督聚类算法，可以从提高聚类精度或降低算法复杂度的角度提升聚类 的性能⑼。半监督学习的研究始于二十世纪末，并在二十一世纪初蓬勃发展。“Semisupervised" 由Merz首次提出，并应用于分类问题，实验数据表明半监督ART神经网 络算法与未引入监督信息相比分类预测性能得到提升口叽Pedrycz等学者研究了基于模 糊聚类的标量性能极小化方法，提出了半监督聚类思想，但该方法在标记信息过少时会 退化为无监督学习算法并且收敛缓慢，不适用于多数实际问题口】。Klein等学者在监督 信息非常有限的情况下，给出成对实例约束，改进了之前的约束K-means算法，能够成 功地为各种数据集类型合并约束口叫Wagstaff K等学者提出的Cop-Kmeans算法要求对 象满足必须分配到同一个簇中的must-link约束和不能分配到同一个簇中的cannot-link
约束，这两种约束条件为半监督聚类带来了新思路口叫Yan等学者提出了一种ICop-Kmeans算法来解决Cop-Kmeans的约束冲突问题，通过加权关联计算对象的确定性，进 一步提升聚类的性能口久Basu等学者基于COP-Kmeans算法，引入Seeds集概念，将标 记样本作为Seeds集生成约束进而指导聚类的完成“叫ChangYu等学者提出通过扩充 Seeds集结合成对约束指导聚类过程阿。Rodriguez等学者提出了一种基于密度峰值的快 速聚类方法，从如何快速寻找聚类中心的角度出发，通过绘制“密度-距离”决策图，人 为选择聚簇中心，其余点通过指派到最近的聚类中心完成聚类过程口刀。刘如辉等学者为 了解决基于密度峰值的快速聚类方法存在的误选中心点、簇的数量需要主观判断等缺陷, 从半监督角度出发，使用相对密度度量节点密度，多角度分析决策图并自动选择候选中 心点【⑻。陶性留等学者提出了在FCM-NMF聚类算法框架下，采用非负矩阵分解提取 样本的本质特征，并且加入成对约束条件指导聚类过程进行模糊聚类口叫W）iron等学者 研究了成对约束对无监督谱聚类的影响，引入了一种新的约束传播，在降低注释成本的 同时，最大限度地提高了聚类质量，实验证明了所提方案的有效性mi。Zhou等学者提 出了一种基于贝叶斯信息调整相似度矩阵，并根据成对约束确定类标签的半监督聚类方 法，实验结果表明，基于贝叶斯决策的相似性调整方法是有意义的，聚类的边界划分更 加准确⑵]。Roul等学者基于多层极限学习机（ML-ELM）,提出了一种在ML-ELM特 征空间中利用K-Means和种子K-Means进行无监督和半监督聚类的方法。实验结果证 明在ML-ELM特征空间中，种子K-Means的聚类结果优于传统K-Means[22] = Fogel等学 者提出了一种非参数神经网络聚类框架，通过分析与每一对成对约束相关联的损耗来细 化约束集。结果表明，在数据量有限的情况下，该方案也能提高聚类性能RI。Tian等学 者提出了一种半监督集成聚类算法，首先提出了一种新的分层特征抽样方法，用于处理 高维数据，保证基聚类的多样性；其次，利用半监督聚类，得到基聚类；最后，提出在 基聚类生成过程中利用先验信息，保证先验信息得到充分利用，并通过实验证明了所提 模型的有效性Ml。
1.2.2	集成分类算法研究
分类预测是数据挖掘的基本课题，近年来，集成学习算法因其能显著提高模型的泛 化能力而成为分类算法重要的研究方向。集成学习算法将多个学习方法组合在一起，通 过对单个分类器的预测结果进行投票表决，得到最终的预测结果，当单个分类器存在差 异时，集成分类算法的提升效果更为显著。
Schapire首次提出了强学习器和弱学习器的概念p5]。Breiman提出Bagging算法， 通过训练不同的模型，采用取平均值或投票的方法得到最终的预测结果。实验表明， Bagging算法在预测精度上有显著提升阳。Schapire还提出了 Boosting算法，不同于 Bagging算法可并行运算，Boosting算法是一个迭代的过程，弱分类器在迭代过程中自
适应地改变训练样本的分布，最终可提升为强学习器12叫Freund等学者提出了 Adaboost 算法，对每次训练错误的样本加权，并基于样本的预测结果对分类器进行权值调整，“惩 罚”表现较差的分类器，而不是采用多数表决的方法。Adaboost算法被证明是最优秀的 Boosting算法之一［27］。Breimant等学者提出了随机森林算法，由多棵通过对样本或特征 采样训练生成的决策树组合在一起，所有决策树的预测结果经过投票来完成最终的预测, 有效地降低了模型的方差网。Breimant还基于Wolpert所提的“堆叠”概念，提出Stacking regressions算法，一种形成不同预测因子线性组合以提高预测精度的方法，其思想是利 用交叉验证数据和非负约束下的最小二乘法确定组合中的系数，在不同大小的叠加回归 树中加入模拟叠加线性子集，实验证明了该方法的有效性UI。Ting研究了 Stacking算法 中的两个关键问题：适合导出更高层次模型的泛化器类型和作为其输入的属性类型，并 证实了高阶模型结合低阶模型的置信度可以获得最佳结果［3瞑
近年来，Stacking算法基础上衍生出很多变体，在不同应用领域取得了良好的预测 效果。Bamwal等学者对一层神经网络进行优化，建立了价格加密货币的方向模型用于 资产方向预测，通过堆叠集成方法提高预测准确性⑶］。Kevin等学者使用Stacking模型 预测单个癌细胞株的药物敏感性，探讨了叠加模型的预测性能以及叠加对预测偏差和平 方误差的影响BL Liu等学者提出了一种新的组合分类方法用于文本分类，将TFIDF训 练的各种弱分类器与Word2vector算法相结合，从多个方面对文档进行表达，充分利用 文档提供的信息。实验结果证明了这种堆叠算法比单独使用Word2vector算法以及简单 的弱分类器组合分类方法都有更好的分类效果R］。Zhang等学者提出了一种改进的多卷 积神经网络堆叠算法，采用卷积神经网络作为基分类器对原始数据进行分类，然后用元 分类器对新样本进行分类。为了降低元分类器中输入数据的维数和相关性，采用主成分 分析(PCA)方法对基分类器的输出进行降维。实验结果表明与传统的堆叠、平均后验 概率和投票相比，该算法在相似网络中的分类精度更高、更稳定Ml。
1.3	论文的主要工作
本文针对用户网络满意度提升算法进行研究，主要围绕网络投诉预警及网络满意度 预测展开，经过对运营商某地市公司用户投诉数据研究发现，导致用户投诉的因素大致 可分为资费投诉、服务态度投诉、网络性能投诉、通话性能投诉四类，本文首先将用户 基于四种投诉因素划分为四种敏感类型，并基于这种个人情感差异进行特征构造；其次 构建投诉预警模型，挖掘潜在投诉用户；最后对潜在投诉用户进行网络满意度量化预测， 定位高危投诉用户，为搭建分层分级的用户关怀体系提供理论依据。本文主要研究工作 和创新点包括以下方面：
(1)本文研究了用于用户分群的半监督聚类算法，提出了一种新的基于成对约束 的半监督聚类算法，将专家经验与数据挖掘算法结合，由专家指定将用户划分为N个群
组，并挑选初始代表对象，以初始代表对象附近的局部峰值对象作为备选聚类中心，在 已有约束条件下进行迭代并完成划分；还提出一种聚类算法评估度量聚类均衡度C，用 于衡量每个聚簇包含样本数量的相对大小。实验结果验证了所提算法的均衡度和有效性 都得到显著提升。本文基于聚类结果提出敏感因子概念，将用户对每种投诉因素的敏感 程度赋予权重，结合个人情感差异构造特征。
(2)本文研究了用于预测潜在网络投诉用户的集成分类算法，提出了改进的 Stacking算法，采用7x7折循环训练方法，避免交叉学习问题，基于构造特征及原始特 征，融合多个单个学习器的优势，构建网络投诉预警模型，从预测的准确率、误判率、 漏判率等多个角度对算法进行评估，验证了所提算法的有效性，并提出净损函数概念， 用于辅助决策最佳判决门限。
(3)本文研究了对潜在投诉用户进行优先级排序的评分卡模型，结合网络性能指 标及用户业务使用需求，基于用户打分数据，构建网络性能用户感知评分卡模型，定量 预测用户当前网络满意度，精准定位高危投诉用户，搭建分层分级的用户关怀体系；此 外，在用户呼入投诉过程中可快速识别用户业务使用偏好及所处网络环境带来的不良感 知，精确定位用户诉求，使一线话务员可以更好地应对用户投诉，提高沟通技巧并妥善 处理投诉问题。
1.4	论文的结构安排
论文主要分为六个章节，具体内容安排如下：
第一章，绪论。本章对论文的研究背景进行简要概述，介绍了携号转网背景下做好 用户保有，提升用户满意度的重要意义，围绕用户投诉预警，对国内外针对该问题的理 论研究进展进行了总结归纳，特别是对半监督聚类算法和集成分类算法的研究现状进行 了详细的分析和阐述，梳理了论文所完成的主要工作，展示了全文的结构安排。
第二章，用户满意度提升问题建模与算法概述。本章首先简要介绍了用户满意度的 概念及电信运营商与各大通信标准化组织用于评估通信网络服务能力的指标，并介绍了 两种提升用户满意度的常用方法，接着提出了本文以网络投诉预警为核心结合用户分群 及用户满意度评分的研究框架，在聚类算法和分类算法的基础上进行研究。对聚类和分 类的概念、基础算法及性能评估指标进行了概述，为后续的用户分群及投诉预警问题的 算法研究提供了理论基础。
第三章，半监督聚类算法在用户分群及特征构造中的研究。本章首先对半监督聚类 算法进行概述，并基于实际应用提出了一种新标准用于评估聚类模型，基于快速密度峰 值聚类算法，提出一种新的基于成对约束的半监督聚类算法。在解决用户分群问题时， 将专家经验与数据挖掘算法结合，由专家指定分为N个群组，并选出初始代表对象，以
初始代表对象附近的局部峰值对象作为备选聚类中心，在已有约束条件下进行迭代，大 大缩减了聚类中心的优化过程，降低了算法运行时间，并能有效降低奇异值的影响。本 章基于用户营销数据及投诉数据对所提算法进行了仿真和分析，验证了算法的有效性, 最后基于聚类结果提出了敏感因子的概念及计算方法。
第四章，基于Stacking算法的网络投诉预警建模研究。本章首先阐述了 Stacking算 法的原理及其训练过程中存在的交叉学习问题，然后从三个方面对Stacking算法进行改 进，采用及7折循环训练方法，避免交叉学习问题，基于构造特征和原始特征，结合决 策树、逻辑回归、支持向量机三种基分类器，构建集成分类模型，基于用户投诉数据对 所提算法进行仿真，验证了算法的有效性。
第五章，基于用户感知的网络性能评分卡建模研究。本章结合网络性能指标及用户 业务使用需求，基于用户对网络性能的打分，分析了影响用户网络使用体验的相关指标。 基于逻辑回归算法构建网络性能用户感知评分卡模型，解决了逻辑回归输出结果复杂、 不易应用的问题，可定量预测用户的网络满意度，基于用户网络性能打分数据进行仿真, 验证了所建模型可根据满意度评分在指定用户群体中能较好地预测出高危投诉用户。
第六章，总结与展望。本章对论文的主要研究内容和所做工作的不足之处进行了讨 论，并对于今后的研究中需要改进的方向做出了展望。
第二章用户网络满意度提升问题建模与算法概述
2.1	用户满意度相关概念
用户满意度(consumer satisfaction)描述了用户对服务行业提供的产品或服务感知 的效果与用户自身期望的匹配程度。一般认为，用户体验决定了用户满意度，二者呈正 相关关系［3久电信行业有不同的指标用于评估电信运营商提供的服务：
(1)服务质量(Quality of Service, QoS)：广义上指通信系统提供给用户通信网 络的服务能力，狭义上指带宽、时延等底层数据传输性能指标，为客观的可量化指标;
(2)关键性能指标(Key Performance Indicators, KPI)：在电信行业指用于评价网 络质量与性能且可测量的网络层面的指标；
(3)关键质量指标(Key Quality Indicators KQI)：指贴近用户感知的质量指标， 用于评价业务质量，针对不同业务有不同的KQL
这些传统指标用于衡量网络质量时，经常会出现各项指标良好，而用户满意度低的 情况，主要原因是这些指标都是从客观角度对运营商所提供网络服务质量进行衡量，缺 少用户的主观反馈，从而不能反映出用户的实际体验，使得运营商对用户满意度的预测 与用户自身感知有误差。
近年来用户体验(Quality of Experience, QoE)的概念被提出并受到广泛的关注， 它指用户对业务的主观感受，直接影响了用户满意度。QoE的影响因素包括客观因素和 主观因素，客观因素指那些可以被衡量的QoS指标，而主观因素如用户期望、个人情绪 等因为不可控性而不被考虑，因此当前对QoE的研究主要是基于QoS与QoE之间的映 射关系PL而实际上，正是不可控的主观因素，如用户业务使用偏好、用户个人期望等 造成了预测满意度与用户自身感受之间的偏差。
不可量化闪穿
FX信道惩•!.
ri 时至
用户期鎏
设备三凄
王美瞬翦；.X
±先碣比?率
「--±赖率

I 持动
nx 丢曳率
X用P界面
IX帮给怯
图2-1用户体验的影响因素
7
2.2	用户网络满意度提升问题建模
传统的用于电信用户满意度提升问题的研究一般有两种思路：
（1）基于QoE的网络资源分配
基于用户体验的网络资源分配是近年来从优化网络指标的角度出发提升用户满意 度的研究热点。当前基于QoE的网络资源分配研究主要分为两类，一类是建立不同QoS 指标到单项业务QoE的映射，如研究响应时间、延时、抖动等QoS指标对语音业务QoE 的影响，不同业务具有不同的影响因素，如表2-1所示，此类研究通过端到端控制，将 提升用户体验作为优化目标；另一类是建立某种QoS指标如传输速率到系统QoE的映 射，此类研究以系统QoE最大化作为优化目标的。
表2-1不同业务的影响因素卬】
业务类型	影响因素
语音	响应时间、延时、抖动
视频 响应时间、延时、抖动、丢包率
FTP传输	响应时间、传输速率
游戏	响应时间、传输速率
网页浏览	响应时间、传输速率
（2）用户满意度测评
从统计学角度设计调查问卷对用户满意度进行测评从而发现自身服务能力的不足, 进而做出针对性的改进也是运营商常用的提升用户满意度的方法。影响用户满意度的因 素包括技术因素、服务运营因素、价格因素、用户预期因素等，统计学多采用ACSI模 型来构建用于衡量用户满意度的测评体系。ACSI模型基于消费者行动理论，根据用户 动态的消费情况对用户的满意度做出评估卬】，ACSI模型结构如图2-2所示。
图2-2 ACSI模型结构
以上两种针对用户满意度提升的思路中，思路（1）从优化网络指标的角度出发，建 立QoS到QoE之间的映射关系，主要涉及运营商后端网络维护；思路（2）从用户主观
8
角度出发，主要涉及前端市场服务。本文将从建立网络投诉预警模型及分层分级关怀体 系的角度出发提升用户网络满意度，网络投诉既反馈了用户体验，又关联到网络维护， 挖掘网络投诉处理环节的短板和不足对于提升用户满意度意义重大。
本文提升用户网络满意度采用的研究框架如图2-3所示，首先针对半监督聚类算法 在用户分群及特征构造中的应用进行研究，提出一种新的半监督聚类算法及评估指标， 更贴合运营商实际工作，通过半监督聚类算法将相似用户分群，区别用户敏感类型，精 确用户诉求定位；其次，针对Stacking集成分类算法在网络投诉预警建模中的应用进行 研究，提出改进的Stacking算法，基于聚类结果结合个人情感差异构造新特征参与构建 网络投诉预警模型，通过分类预测挖掘潜在投诉用户；最后针对基于用户感知的网络性 能评分卡模型进行研究，定量预测用户满意度，将潜在投诉用户按照满意度评分确定关 怀优先级，在用户呼入投诉时，可通过评分卡模型快速识别其业务使用偏好及不良网络 指标，从而更好地应对投诉并妥善处理。
图2-3用户网络满意度提升算法研究整体框架
2.3聚类算法概述
聚类算法是一种无监督学习算法(unsupervised learning),与有监督学习(supervised learning)相比，样本中没有任何类标记。无监督学习算法需要自动找到这些数据中隐藏 的结构和特征，其目的在于数据可视化、数据压缩、数据去噪或更好地理解数据中的相
关性。聚类分析在数据挖掘过程中可以作为独立的一环用以发现紧密相关但事前未知的 群组，使每一个样本子集形成的簇中的对象彼此相似，不同簇的对象不相似；也可以作 为数据挖掘中其他算法的预处理部分。在聚类分析中，将距离用作表征相似度的度量, 二者成反比关系，距离越大，相似度越小，当两个样本之间的距离为零时，表示两个样 本完全相同。样本之间距离的计算在描述属性(特征)上进行。
令X产｛阳,兀，…，％｝与巧=｛々,马，…，肛｝是由n个数值属性描述的对象，常用的 距离计算方法有⑺：
(1)欧式距离(Euclidean distance)
d(x，T)=	(2-1)
V
(2)曼哈顿距离(Manhattan distance)
〃(x”Xj) = £k* - XjJ	(2-2)
k=l
(3)闵可夫斯基距离(Minkowski distance)
n	J
d(xi,xJ) = (£ W. 一 XJ ) g	(2-3 )
I
其中，夕为实数且公式(2-3)可看作公式(2-1)、公式(2-2)的推广。本 文使用“欧氏距离”作为样本间的距离计算方式。
2.3.1	K-means 算法
K-means算法是经典的聚类算法，它是一种基于划分的聚类算法，也是一种基于原 型的聚类算法，在划分方法中，将〃个对象划分为互不交叉的上个组，每个对象仅属于 一个簇，每个簇中至少包含一个对象；在基于原型的聚类算法中，将每个簇中所有对象 的质心作为簇的原型，簇中的任意对象距离定义该簇的原型比距离定义其他簇的原型都 近。K-means算法随机选取初始聚类中心，将所有对象指派到距其最近的聚类中心，完 成一次划分后重新计算每个簇的质心后再次分配所有对象，迭代直至质心不再变化或满 足终止条件。
K-means算法通过随机的方法选择初始聚类中心，不同的初始聚类中心时往往会得 到不同的聚类结果，有时可能会导致聚类效果较差，一些改进算法在初始聚类中心的选 择上做出优化，使算法的性能得到提升。此外，K-means算法还对离群点敏感，少量的 离群点在迭代过程中会对质心的计算造成很大影响，从而影响簇的分配。
10
2.3.2	聚类算法性能评估
聚类问题常常作为最优化问题处理，完成所有对象的划分后，由实际情况指定用于 优化的目标函数，经过多次迭代，使得目标函数最优化或达到迭代终止条件，完成最终 的聚类。聚类算法的评估度量一般分为三类：
(1)用于评估聚类结构优良性的非监督评估度量，一般考虑簇的凝聚性和分离性， 不使用任何外部信息，如误差平方和(Sum of the Squared Error, SSE)；
(2)用于评估聚类结果与已知外部结构匹配程度的监督评估度量，能够反映聚类的 有效性，需要使用外部信息，如纯度；
(3)用于比较不同聚类结果的相对评估度量。
K-means算法一般选择SSE作为聚类结构优良性的评估度量，用于衡量聚簇的凝聚 性，SSE定义如下：
K
SSE = EZ 由s/(g , x)2	(2-4)
i=l除
其中，K表示聚簇的个数，成sf是两个对象之间的距离，G表示聚类结果中的第， 个簇，网表示第i个簇中所包含对象的个数，第i个簇的质心由公式(2-5)定义：
G = — Vx	(2-5)
纯度表示每个簇只包含单一类对象的程度，其定义如下：
purity = A	(2-6)
m
其中，阳表示对象总数，p由公式(2-7)、(2-8)定义，砥/表示簇z•中类标号为 )的对象的个数：
pi = max py	(2-7)
目前已有大量成熟的聚类算法应用于各个领域，如用于稀疏高维文档数据聚类的 K-means算法，用于发现不同形状和不同大小聚簇的DBSCAN算法，用于发现层次结 构的AGNES算法等。在所有的聚类算法中，没有一种算法能适用于所有的场景和数 据类型，只能说现有的聚类算法在某些场景运行良好，而在很多情景下，什么是一个 好的聚簇，很难一概而论。某种意义上可以说，每种聚类算法在特定的簇类型上生成， 相应地就需要不同的评估度量，因此在不同应用场景中，应选择合适的度量来评估聚 类结果。
11
2.3.3半监督聚类
网络和计算机系统每天都在生成大量的对象数据。为对象数据创建类别可以改进 网络的搜索速度、提高生产力、降低存储成本，并且可以更好地利用对象数据。专业 人员通常需要在大量非结构化对象数据中标识特定分类或聚类信息。由于缺乏适当的 工具，许多组织和用户依靠手动分类对象的方式，该过程可能需要大量人力，耗时、 昂贵并且容易出错。手动分类的替代方法是训练用来执行聚类的机器学习模型。
传统的监督学习，需要大量已标记的数据对模型进行训练从而赋予新的、无标记 的对象类标号，以保证模型的泛化能力。但在实际应用中，我们能获取的海量数据绝 大部分是无标记的，这种无监督学习过程很难保证算法的精确度ML因此，近年来的 研究热点聚集在如何综合利用少量有标记数据指导聚类完成的半监督学习方法〔39〕。
成对约束是半监督学习的一个重要分支，通过引入先验监督信息，根据少量被正 确划分的样本数据，促使其近邻能被正确地划分，进而实现整个数据集的划分RO】。近 年来半监督聚类相关的研究成果越来越多，并有一些已经取得了较好的应用效果。但 目前的半监督聚类算法大多是基于某一角度对己有无监督聚类算法的改进，完整且系 统的研究还依然空缺，仍有较大空间有待发掘。
2.4分类算法概述
分类算法是一种监督学习算法。监督学习的主要流程是对已有类别标号的训练集通 过训练得到一定形式的初步模型，然后可通过检验集对得到的模型进行优化和选择，经 过调优后得到最终的模型，使用该模型就可以完成对测试集输入自变量自动输出目标变 量的功能。分类统计(classification)和回归分析(regression)是常见的监督学习算法⑷］。 监督学习的任务是通过对已有数据的学习实现对未知数据的预测，可根据预测结果为连 续型还是离散型分为类标号预测与数值预测，分类模型可实现类标号预测，回归模型可 实现数值预测。
训练集
YES S 44K
图2H分类算法的一般过程
12
分类模型可根据由单个分类器组成还是多个分类器组成分为单一学习器(又称基学 习器)和集成分类模型，集成分类模型通过将多个基分类器组合在一起，实现算法性能 的提升。分类算法的一般过程如图2-4所示，第一步使用带有类标号的训练集(training set)建立分类模型，第二步将模型应用于类标号未知的测试集(testset)。
2.4.1	基分类器
基分类器由单个分类算法确定分类模型。常用的基分类器有决策树、支持向量机 (Support Vector Machine, SVM)等。
(1)决策树
决策树顾名思义是一种类似于流程图的树形结构，树的顶端是根结点，存放了与目 标变量最相关的属性，树中每个内部结点表示对一种属性进行测试，经过测试后不同分 支表示不同输出结果，当对一个未知样本进行预测时，由根结点开始，经过多次属性判 断，最终落到一个叶结点内，叶结点内存放的类标号即是对该样本的预测结果。决策树 因其简单快速的分类步骤、直观的表示形式及较高的准确率，是最常用的分类器之一。
构造决策树时，有多种选取分支属性的标准。CHAID决策树依据局部最优原则，利 用/检验作为结点属性选择方法。CART决策树将基尼系数作为检验不纯度的指标， CART树为二叉树且每个自变量可反复使用。ID3算法选取分割后的结点进行分类所需 的信息量最小作为属性选择的标准，这种标准称为基于信息增益的选择。C4.5算法改进 了 ID3算法中倾向选择具有大量值属性的问题，使用具有最大信息增益率的属性作为分 裂属性来克服这种偏倚。上述算法除CHAID决策树外都采用贪心策略，在选择划分结 点的属性时，采取一系列局部最优决策。
(2)支持向量机
SVM最早起源于统计学习理论，它是一种对线性和非线性数据都适用的分类方法， 使用训练实例的一个子集来表示决策边界，将元数据映射到较高维上后，通过决策边界 将样本数据分离。因为具备诸多较好性质，SVM已经成为广泛使用的分类算法之一。 SVM可表示为凸优化问题，不同于基于规则的分类器和人工神经网络都采用贪心策略， 通常只能获得局部最优解，SVM可通过优化目标函数得到全局最优解，相应的其算法 复杂度也较高，需要较长的训练时间。SVM通过最大化决策边界的边缘来控制模型的 性能，同时还需要提供其他参数，其中核函数的选择是算法的关键。目前，SVM在高维 数据的应用中展示了很强的实践效用。
2.4.2	集成分类算法
相对于单个分类器由单一学习算法构成，集成学习方法(ensemblelearning)又称分类 器组合方法(classifiercombination),通过在原始数据上构建一组由相同或不同算法得
13
到的基分类器，对这一组基分类器的预测结果进行多数表决从而实现最终的分类。集成 分类算法的性能在基分类器的性能优于随机猜测且相互独立且时能得到较好的提升，而 在实践中，很少能达到基分类器完全独立，但是集成方法仍可以有较好的表现。常用的 集成分类算法有装袋(Bagging)、提升(Boosting)、随机森林(Randomforest)等网。
图2-5集成分类算法模型
集成分类算法在数据集D上通过样本抽样或特征抽样创建r个训练集，每个训练集 用于创建不同的基分类器，当对未知样本进行预测时，每个基分类器都会进行一次预测 并返回预测结果，通过投票的方法，产生最终的预测结果。集成分类算法模型如图2-5 所示，集成分类算法的一般过程如表2-2所示：
表2-2集成分类算法
输入：
•	D：原始训练数据集；
•	左：基分类器的个数；
•	T：检验数据集；
输出：一个复合模型。
算法：
1 ： for z=l to k do
2：	由。创建训练集Di
3：	由O创建基分类器C
4： end for
5： for每一个检验记录xW7do
6：	C*(x)=Vbte(Ci(x)C2(x),…,G(x))
7 ： endfor
14
基础集成技术包括以下几种：
（1）最大投票法：每个模型都拥有一票投票权，每个模型的预测都被视为一次“投 票”，大多数模型的预测结果作为最终预测结果，可将此方法视为采用了所有预测的众 数；
（2）平均法：类似于最大投票法，对每个样本进行多次预测取平均作为最终的预测 结果。平均法可用于回归问题的预测或分类问题概率的预测；
（3）加权平均法：是平均法的扩展，为所有模型分配不同的权重，定义每个模型的 预测重要性。
2.4.3分类算法性能评估
分类模型建立后需要对模型的准确率进行评估，如果建立了多个分类器想选择其中 “最好的”，需要进行模型选择。由于算法使用训练数据进行学习得到分类器，若仍然 使用训练数据对模型结果进行评估可能会错误地导致过于乐观的估计，因此，一般会将 原始数据拆分为训练集和检验集，检验集由未参与模型训练且含有类标记的样本组成, 通常在训练集上学习得到分类器模型，在检验集对模型进行评估。拆分的方法有保持、 随机抽样、交叉验证和自助法等。
表2-3所示的混淆矩阵（confusion matrix）汇总了用于表示分类结果的样本个数。 给定加个类（其中加三2）,混淆矩阵是一个至少为mxm的表，它显示了正样本和负样 本的合计，可对分类器识别不同类别样本的能力进行分析。
表2-3 2x2混淆矩阵
实际情况	预测结果
正例	反例	合计
正例	TP	FN	P
反例	FP	TN	N
合计	P'	N'	P+N
从混淆矩阵中容易看出TP （True Positive,真正例）、TN （True Negative,真负例）、 FP （FalsePositive,假正例）、FN （FalseNegative,假负例）各指标的含义，从而可以 得到被正确或错误预测的样本个数，但是混淆矩阵表示的预测结果还不够直观。接下来 介绍一些常用于分类算法性能评估的指标。
准确率（accuracy）是评估分类模型好坏的一种常用度量，它表示被正确分类的样 本占所有样本的比例。准确率的定义为：
TP + TN accuracy =------
P+N
(2-9)
当类分布相对平衡时，准确率可很好的评估分类模型性能，当类分布不平衡时，如
15
在欺诈检测或医学检验中，正样本都是稀少类，如欺诈检测中类标号属性为“力md”， 可能取值为“yes”或“力。”，98%的准确率看上去效果良好，但若只有2%的训练样本 是欺诈样本，该分类器可能只是正确地标记了非欺诈样本，而错误地标记了所有欺诈样 本。因此，不平衡数据进行分类时，还需要其他的评估度量。灵敏性(sensitivity)和特 效性(specificity)常用来评估不平衡数据下的分类模型。灵敏性又可称为真正率(TPR), 表示实际所有正样本被正确预测的比例；特效性又称真负率(TNR),表示实际所有负 样本被正确预测的比例，而假正率(FPR)表示实际所有负样本被错误地预测为正样本 的比例。以上度量定义为：
TP TPR=sensitivity=下-	(2-10)
TN TNR ^specificity=	(2-11)
FP FPR=L specificity= ——	(2-12)
N
召回率(recall)和精度(precision)也常被用作分类算法的评估度量，召回率越 高，表示越多的正样本被预测正确，实际上，召回率与真正率的值相等；精度表示被
分类器预测为正样本的记录中实际为正类的比例。以上度量定义为:
recall=
TP
TP + FN
precisions
TP
TP + FP
(2-13)
(2-14)
分类算法还有很多其他评估度量。ROC曲线是其中一种可视化方法，ROC曲线是 一条连续的曲线，如图2-6所示，其横纵坐标分别为假正率和真正率，曲线上每一点代 表了不同门限下的分类模型，改变门限值便可看到真正率和假正率之间的权衡。ROC曲 线可用于模型选择，对比不同分类模型的ROC曲线，越接近(0,1)点则表示分类模型
的性能越好。ROC曲线只能定性地对不同分类模型进行比较，若想定量表示分类模型的 性能，可采用ROC曲线下的面积(AUC),理想情况下AUC的值为1,随机猜测时,
AUC的值为0.5 o
图2-6ROC曲线示意图
16
2.5本章小结
本章主要阐述了用户网络满意度提升问题的研究框架及基础算法。首先简要介绍了 用户满意度的概念及电信运营商用于评估通信网络质量的常用指标，接着介绍了两种提 升用户满意度的常用研究方法，并提出了本文以构建网络投诉预警模型为核心结合用户 分群及用户满意度评分的研究框架，在聚类算法和分类算法的基础上进行研究。本章还 对聚类算法与分类算法的概念、基本原理、经典算法及性能评估指标进行了概述，为后 续的算法研究提供了理论基础。
17
18
第三章半监督聚类算法在用户分群及特征构造中的研究
当前运营商用户投诉问题涉及方方面面，不同用户对不同服务的感知也有很大的差 另Ik根据运营商某地市公司2018年的投诉数据，可将导致用户投诉的因素分为资费投 诉、服务态度投诉、网络性能投诉、通话性能投诉四类，对不同方面敏感的用户在基本 特征及行为习惯上存在较大的差异。基于以上分析，可将用户划分为资费敏感型、服务 态度敏感型、网络性能敏感型、通话性能敏感型。区别不同用户类型，描绘用户画像， 精确定位用户诉求并提供个性化关怀，有助于提升一线话务员应对投诉的沟通技巧从而 提升用户满意度。
本章将重点研究用于用户分群及特征构造的半监督聚类算法，提出了一种新的基于 成对约束的半监督聚类算法，旨在将专家经验与数据挖掘算法结合，更具落地价值，还 提出一种新的聚类算法评估标准，用于衡量每个聚簇包含样本数量的相对大小，使聚类 结果更贴合运营商实际工作，最后基于聚类结果的均衡性和有效性对所提算法进行了分 析与验证，并基于聚类结果构造了新特征为下一章构建网络投诉预警模型做铺垫。
3.1	半监督聚类算法概述
用户分群问题中，数据由大量的用户和描述用户的众多属性组成，若想人工地将用 户划分为具有战略意义的群组费时费力，甚至是不可行的，而无监督的聚类得到的结果 可能不够精确或是不符合商用的指标，这时可以通过人为的添加一些先验信息用于指导 聚类的完成，不仅可以提高聚类的性能，还可以更好地解决实际问题［4叫
在实际应用中，虽然不容易获得对象数据的标记信息，但根据经验可以轻易的获得 一些监督信息，监督信息大致可以分为两种类型，一种类型是两个对象之间约束关系： must-link约束要求将对象数据必须被分配到同一个聚簇中，cannot-link约束要求对象数 据不能被分配到同一个聚簇中，在整个聚类过程中，这两种约束条件不能被打破，约束 K-means算法(Constrained K-means)便是基于这种约束条件的聚类算法 例；另一种监 督信息是挑选“种子”集，不同于K-means算法随机选取初始聚类中心，种子K-means 算法(Seeded K-means)将挑选出的种子用作初始聚类中心，在迭代过程中种子样本所 在的的簇保持不变［45］。
3.2	聚类模型评估新标准
评估聚类结果首先要确定评估标准，然后根据标准通过定量的方法对聚类结果进行
19
评价和比较。目前已有多种聚类算法评价指标，如SSE、ARI、AMI、轮廓系数等146］。 此外，由于大量簇类型的存在，几乎每种情况都需要不同的评估度量。
在处理用户分群问题时，我们一方面希望簇内相似度高，每个群体的用户特征尽量 相似，另一方面希望聚簇不受奇异值影响，簇的大小较为均衡，使面向每一个具有战略 意义的群组提出的针对性策略覆盖较广。若考虑聚类结构的优良性选择SSE作为聚类算 法性能评估度量时，离群点会很大程度影响所发现的簇。具体来说，离群点的存在会导 致SSE值较高，且聚类结果簇心的代表性下降，为优化SSE,有时一组离群点构成很小 的簇，这样的簇在实际应用中缺乏落地价值。图3-1为K-means算法对一组用户数据的 聚类结果，每个聚簇包含样本点的数量分别为634、83、1327个，若想针对每一个用户 群体分析其特点，得到相应画像特征，分析不同群体特点精确定位其需求，并提出个性 化的业务方案，上述聚类结果中83个样本点所在的聚簇覆盖率很低，可能包含奇异值， 不能很好地代表某一类群体。
针对上述问题，本节提出一种新的用于评估聚类结果优良性的指标：聚类均衡度， 这是一种非监督的聚类算法评估度量，用于衡量每个聚簇包含样本数量的相对大小。聚 类均衡度定义为：
I 2,k「kj)2
C = /"e 而，R	(3-1)
V N
其中，k】,左2,…版分别表示N个聚簇包含的样本点数目，。越小，表示各聚簇包含
的样本点数目差异越小，聚类的均衡度越好。
K-means K=3聚类结果
图3-1 K-means算法聚类结果
3.3	基于成对约束的半监督聚类算法
3.3.1	相关研究方法及原理
"Clustering by fast search and find of density peaks w (CFSDP)是一种基于密度的聚 类方法口刀。CFSDP算法的核心思想在于通过绘制“密度-距离”决策图，人工确定聚簇
20
个数及聚类中心，将其余所有样本点划分到最近的聚类中心完成快速聚类。CFSDP算法 基于两个假设：
(1)聚类中心本身的密度大，其临近点密度均不超过聚类中心；
(2)聚类中心与其他密度更大的样本点之间的距离相对更大。
CFSDP算法给出了局部密度和距离的定义：
局部密度从定义为：
(3-2)
刑
其中，
l,x<0; 09 x > 0
(3-3)
参数&的含义为截断距离，需要事先指定。均为两样本间的距离， S中与样本点i之间的距离小于的dvc的样本点的个数。
。，表示数据集
距离必定义为:
§i='
m呼能｝,	①,
(3-4)
其中，指标集：
rs={kels:pk >Pi}	(3-5)
显然，当2=受产{0}时，有4=①。
由定义(3-4)可知，当i具有最大局部密度时，/表示所有样本点中与i距离最大 的样本点与i之间的距离；否则，&表示在所有局部密度大于i的样本点中，与z•距离 最小的样本点与i之间的距离。
由(月,可)做出的图称为决策图，可用于确定聚类中心，聚类中心同时具有较大的。 值和较大的5值，而离群点具有较小的。值和较大的5值。由图3-2所示的决策图可观 察到，样本点1和样本点10同时具有较大的O值和6值，适合作为聚类中心，而样本 点26、27、28具有较小的。值和较大的3值，是离群点。通过决策图确定聚类中心后， 与K-means算法需要经过多轮迭代完成最终的聚类不同，CFSDP算法将其余样本点划 分到距其最近的聚类中心所属的簇中，完成整个聚类过程。
21
A
B
c ㉕ ⑰品㉙ ⑯巡% ⑭ ®@® @ ⑫⑪⑨㉑



①
1.0-
0.8-
0.6-
0.0-
㉖

图3-2 CFSDP算法决策图[17]
当无法通过肉眼在决策图上确定聚类中心时，CFSDP算法给出了一个辅助决策的 提示：
K=pJi，（3-6）
公式（3-6）中将o值和3值综合进行考量。了值越大，该点越有可能成为聚类中心， 可将/值降序排列后选取。
CFSDP算法为聚类算法的设计和如何寻找聚类中心提供了新的思路，能够快速完 成聚类。但其中仍然存在问题，通过决策图人工确定聚类中心及簇的个数可能存在误选、 漏选的情况，并且算法使用有场景局限，针对一些特殊数据集容易出错RI。
3.3.2	MLDP 算法
本节基于CFSDP算法，提出一种新的基于成对约束的半监督聚类算法（MLDP算 法）。在解决用户分群时，由专家指定将数据分为N个类别，并为每个类别选取初始代 表对象，以初始代表对象附近的局部峰值对象作为备选聚类中心，与初始代表对象相比, 备选聚类中心更适合作为聚类中心，对备选聚类中心在约束条件下进行迭代，与传统聚 类方法相比，大大缩减了聚类中心的优化过程，提高了聚类的效率；当存在少量奇异值 的对象聚类时，传统聚类方法可能会因为奇异值的存在出现聚类结果不均衡或空簇的问 题，而本方法由于优化了聚类中心，并将专家经验与数据挖掘算法融合，降低了奇异值 的影响，聚类结果的均衡度显著优于传统聚类方法，更具有实际应用价值。本文所提的 MLDP算法具体步骤如表3-1所示，算法流程图如图3-3所示：
表3-1 MLDP算法步骤
22
算法：MLDP算法
输入：个样本点
,初始代表对象（ai, az, —on）
, must-link 约束集
•r：比例系数
输出：N个簇的集合
1：计算初始代表对象以在截断距离&内的局部密度值o %, TWk&N,并将以 在截断距离&内的局部密度值最大的对象设为服的局部峰值对象以；其中， dmmWdcWdg "为任意两个对象之间的距离；
2：根据以对应的以，确定所有初始代表对象（0,。2,…弧）对应的局部密度 峰值点（ci, C2,…QJ）；
3：判断＜C1, C2，…CN）中是否存在相同对象，如果是，执行步骤4；如果否， 执行步骤7。若（ci, C2,…皈）中存在相同对象，会导致输入对象不能聚类成 N类对象，需要将相同的对象更替为不同的对象；
4：若（m，ai, •■•on）中的。相和。”对应的c加和c”为同一个对象，则判断加 和a”是否存在must-link约束集，如果是，执行步骤5；如果否，执行步骤6； 5：将am替换为与am处于相同must-link约束集中的其他对象，和/或将a„替换 为与a”处于相同must-link约束集中的其他对象，返回步骤2,通过更替代表 对象，将相同的备选聚类中心更替为不同的备选聚类中心；
6：将Cm替换为新，的为斯与外中局部密度值较大的对象，返回步骤3,本 步骤将相同备选聚类中心的一个聚类中心替换为初始代表对象，使得更替后的 聚类中心不同。两个代表对象中，局部密度值越大，则表征该代表对象越适合 作为聚类中心；.
7：将（C1，C2,…弥）作为N类对象的聚类中心，并将每个对象在不违背所有 约束条件的前提下划入最近的聚类中心，完成N类对象的聚类优化，不同于K-means算法需要进行多轮迭代，本算法只需一次分配便完成聚类，上述步骤可 输出N类对象的聚类结果；
8：由公式（3-1）计算聚类均衡度，C越小，表示每个聚簇包含的样本点数目 相差越小，聚类的均衡度越好；
9：在上述的对象聚类优化方法中，每个截断距离”可对应一种聚类优化结果， 当不确定是否为最优结果时，可以通过调整&,返回步骤1,直至。达到最小 值，此时得到均衡度最优聚类结果。
23
下面给出一种截断距离de的调整方法：对所有d进行递增排序得到有序数列，共 （环1）/2个，记为dWifeW……W力，令截断距离&=。网，其中/为比例系数, 表示取整，然后通过调整比例系数调整截断距离小的大小。
图3-3 MLDP算法流程图
24
3.4	模型仿真与性能评估
3.4.1	数据预处理
本实验原始数据来源于运营商某地市公司2018年12月的用户投诉数据，包含有效 样本3351条，其中未投诉样本3134条，投诉样本207条。原始数据共316个字段，根 据类别将字段分为基本信息、终端信息、话费信息、通话行为、上网行为、APP使用情 况、打分情况、投诉情况八类。部分用户投诉字段说明见表3-2。
表3-2客户投诉数据字段说明
类别	变量名称
基本信息	性别、年龄、用户在网时长、套餐、是否高星用户、是否学生、用 户级别、是否手厅活跃用户、黑名单标识、停开状态、欠费标识、 出行省内次数、出行国内次数、出行国外次数
终端信息	使用手机总数、使用手机品牌数、最便宜手机价格、最贵手机价 格、使用苹果手机数
话费信息	账单费用合计、减免费用合计、未结清费用合计、拒缴费用合计、 充值卡抵扣费用合计、其他实收费用合计、近半年账单费用最大、 近半年账单费用平均
通话行为	通话总次数、通话总时长、免费通话次数、免费通话时长、主叫通 话次数、主叫通话时长、被叫通话次数、被叫通话时长、2G通话 次数、2G通话时长、3G通话次数、3G通话时长、4G通话次数、 4G通话时长、4G高清语音通话次数、4G高清语音通话时长、长 途通话次数、长途通话时长、接听10086次数、接听10086时长、 拨打10086次数、拨打10086时长
上网行为	总流量、平均月流量、上行流量、下行流量、忙时上行流量、忙时 下行流量、闲时上行流量、忙时下行流量、工作日流量、非工作流 量、2G流量、3G流量、4G流量、移动数据上网收费流量、移动 数据上网闲时流量、移动数据上网忙时流量
APP使用信息	各类型app上行流量、各类型app点击次数
打分情况	打分总体、打分资费、打分服务、打分网络总体、打分网络覆盖、 打分手机上网、打分语音通话
投诉情况	投诉总次数、各类投诉次数
（1）数据清洗
a）重复性检验
根据用户编号（N。）字段，检验原始数据中是否存在重复数据。经检验，3351条原 始数据以用户编号（No）字段作为唯一标识，不存在重复数据。
b）缺失值处理
25
针对数据采集过程中由各种原因导致的记录丢失或不确定的情况，本文将采用两种 方法处理缺失值：
•统计变量缺失比例，剔除高比例缺失变量（缺失比例高于30%）,最终共剔除变 量172个；
•对关键变量，对缺失值进行填补。
对于分类打分这样能体现用户感知并能通过用户的某些行为进行推断的关键变量, 本文采用回归的方法对缺失值进行填补，统计分类打分情况如下：
表3-3关键变量缺失情况统计
变量英文名	变量中文名	缺失比例
score ni	打分总体	0
score_fee	打分资费	0
score_serve	打分服务	33%
score__net	打分网络总体	0
score_call	打分语音通话	0
C）低信息变量处理
当大部分用户在某一变量上分布较为集中时，认为该变量在构建模型时贡献度较小, 本文对变量中属性集中程度大于80%的变量进行剔除，共剔除34个变量，剔除的部分 变量如表3-4所示。
（2）缺失值补全
原始数据共316个变量，经过数据清洗，剔除高比例缺失变量172个，剔除低信息 变量34个，剩余110个变量。
本文使用最可能的值对缺失值进行填补，通过多元线性回归的方法基于推理将变量 “打分服务”补全。与其他方法相比，它使用已有数据的部分信息来预测缺失值，在估 计打分服务的缺失值时，通过考虑其他属性的值，有更大的机会保持“打分服务”与其 他属性之间的联系。通过相关性检验，以皮尔森相关系数为衡量指标，挑选与“打分服 务”相关性最高的10个字段用于构建多元线性回归方程，这10个字段如表3-5所示， 所得回归方程如公式（3-7）所示：
score _ serve = 0.674 * score _ fee + 0.108* score _/h + 0.133* score _ net + 0.005 * totalflue
-0.04 * busytime _ down _ flux - 0.096 * work _ day _ flex+0.041 * rest _day _ flex	（3-7）
-0.012* busytime _up _flux
由公式（3-7）可以看出打分资费、打分网络、打分总体与打分服务均有正向关系。 从回归模型系数的检验来看，参数显著性检验均大于0.1,最终调整后的R方为0.734, 该回归模型预测效果良好。
26
表3-4低信息变量统计
变量英文名	变量中文名	集中程度
os_cnt	停开状态	96%
stude 叫 flag	是否学生	99%
travelguowai	出行国外次数	97%
wlan_dur	WLAN使用时长	99%
camp_wlan_dur	校园WLAN使用时长	99%
pc_wlan_dur	pc端WLAN使用时长	99%
grp_wlan_dur	政企WLAN使用时长	99%
call_10000_cnt	与10000通话次数	95%
call 10000 dur	与10000通话时长	95%
call 10010 ent	与10000通话次数	99%
call 10011 dur	与10000通话时长	99%
call_10088_cnt	与10088通话次数	94%
call 10088 dur	与10088通话时长	94%
call 114 ent	与114通话次数	93%
call 114 dur	与114通话时长	93%
g3_net_flux	3G流量	98%
acct_type	账户类型	98%
pay_family_flag	家庭统一支付标识	99%
fav_fee2	减免费用合计	98%
gene_pay_fee	代付合计	98%
refused_ffee	拒缴费用合计	98%
card_pay_fee	充值卡抵扣费用合计	98%
otherjpay_fee	其他实收费用合计	98%
表3・5与“打分服务最相关的字段”
变量	变量解释	皮尔逊相关性
score_fee	打分费用	.827**
score_net	打分网络	.619**
score_m	打分总体	.592**
age	年龄	.141**
innet_dur	用户在网时长	.124**
totalflue	总流量	-.121**
busytime_down_flux	忙时下行流量	-.114**
work_day_flex	工作日流量	-.113**
rest_day_flex	非工作日流量	-.109**
busytime_up_flux	忙时上行流量	-.103**
27
3.4.2	实验验证
本节为验证所提算法的有效性及泛化能力，除用户投诉数据外，再选取一组来自运 营商某地市公司的用户营销数据进行实验，并已根据经验，在实验前为用户营销数据选 取了高价值用户、中价值用户、低价值用户代表对象及约束条件，为用户投诉数据选取 了资费敏感型、服务态度敏感型、网络性能敏感型、语音性能敏感型代表对象及约束条 件。实验配置为4G内存、2.30GHz主频，IntelCOREi7的PC,采用Python3.7进行仿真 程序设计，选取运行时间作为算法复杂度的评估指标，选取聚类均衡度为算法性能的评 估指标，选取纯度为算法有效性的评估指标。实验数据的具体情况如表3-6所示。
表3-6实验数据说明
组别	实验数据	维度	样本总量	聚簇数目
1	用户营销数据	13	2044	3
2	用户投诉数据	110	3351	4
本节将 MLDP 算法与 K-means、Constrained-Seeded K-means (C-S K-means)、CFSDP 三种算法进行比较，其中，K-means算法指定聚簇个数K, Constrained-Seeded K-means 算法与MLDP算法引入相同的监督信息初始聚类中心及成对约束，样本分配过程中初 始聚类中心所属类别不发生变化且要确保成对约束条件得到满足，CFSDP算法选取最 优参数人工选取聚类中心过程不计入运行时间，MLDP算法通过调整比例系数/得 到不同聚类结果如表3-7、表3-8所示。
表3-7基于用户营销数据三种算法结果对比
比例系数/	簇1	簇2	簇3	运行时间	C
K-means	\	1773	20	251	38.2	1337.8
Constrained-Seeded	\	278	573	1193	16.5	660.4
K-means	\
CFSDP	0.02	1143	139	762	5.1	716.7
0.01	1943	17	84	4.8	1545.9
0.02	774	685	585	5.5	133.7
0.03	570	1314	159	5.8	827.9
MLDP	0.04	1462	225	357	6.2	960.6
0.05	543	904	597	6.7	275.3
0.06	1295	673	76	7.3	862.0
0.07	543	538	963	7.9	344.9
表3-8基于用户投诉数据三种算法结果对比
28
K-means	比例系数/	簇1 941	簇2 1887	簇3 434	簇4 89	运行时间 79.9	C 1354.7
Constrained-Seeded K-means	\	347	421	923	1660	37.4	1047.8
CFSDP	0.02	1023	1655	223	450	17.2	1109.2
0.01	1066	1000	737	548	16.7	415.3
0.02	761	317	894	1379	17.3	757.0
0.03	376	263	455	2257	17.7	1644.4
0.04	795	968	782	806	18.3	151.3
MLDP	0.05	1281	400	1148	522	18.8	764.2
0.06	999	736	643	973	19.9	304.2
0.07	839	214	1585	713	20.4	981.3
0.08	533	1148	1378	292	21.4	882.5
0.09	959	180	1638	574	22.5	1075.7
由表3-7、表3-8可以看出，从总体上MLDP算法的聚类均衡度相对于K-means算 法、Constrained-Seeded K-means算法和CFSDP算法都有大幅提升。表3-7中，当/取 值在［0.02, 0.0刀时，MLDP算法聚类均衡度均小于K-means算法，，取0.02时，达到最 优聚类均衡度，仅为K-means算法的10%, Constrained-Seeded K-means算法的20%, CFSDP算法的18%o在表3-8中，/取0.04时，达到最优聚类均衡度，为K-means算法 的 11%, Constrained-Seeded K-means 算法的 14%, CFSDP 算法的 14%。
由图3-4、图3-5还可看出，随着/增加，运行时间逐渐增加，本节综合考虑算法复 杂度及聚类均衡度,最终基于用户营销数据,选取/=0.02,基于用户投诉数据，选取片0.04。
-S-聚类均衡度C T-运行时间
图3-4比例系数♦对MLDP算法的影响（用户营销数据）
29

1800.0
1600.0
1400.0
1200.0
1000.0
800.0
600.0
400.0
.o.O 0(( 2
1644.5
.8
8
5. )7
25.0
20.0
3叵任仁阳 .O.O 5.O.
0.02	0.04	0.06	0.08
比例系数f 一^■^聚类均衡度C	运行时间
O O.
0.1


图3・5比例系数1对MLDP算法的影响（用户投诉数据）
由图3-6、图3・7可以更清晰地看出，，取最优参数时，四种算法中MLDP算法聚类 均衡度最佳，运行时间略高于CFSDP算法，远低于K-means算法和Constrained-Seeded K-means算法。综合以上分析，可得出MLDP算法可大幅降低聚类均衡度，并且与K-means算法和Constrained-SeededK-means算法相比，在降低算法时间复杂度上有较好的 效果。
1600.0
1400.0
1200.0
1000.0
800.0
600.0
400.0
200.0
0.0
45.0
40.0
35.0
30.0
25.0
20.0
15.0
10.0
5.0
0.0
1337.9
133.7
麒一聚类均衡度	1337.9	660.5	716.8
T一运行时间	38.2	16.5	5.1
图3・6Z取最优参数时四种算法性能对比（用户营销数据）
30
图3-7 t取最优参数时四种算法性能对比（用户投诉数据）
接下来对实验结果进行进一步分析，表3-9、3-10分别给出了/取最优参数条件下， MLDP算法与未添加监督信息的K-means算法基于用户营销数据和用户投诉数据更详 细的聚类结果对比。
表3-9 t取最优参数时聚类结果对比（用户营销数据）
K-means 算法						MLDP算法
类标 签	样本 个数	营销是 否成功	当月 ARPU	营销成 功率	占总体用 户的比例	类标 签	样本 个数	营销是 否成功	当月 ARPU	营销成 功率	占总体用 户的比例
0	1773	617	125.93	35%	87%	0	774	245	110.49	31%	38%
1	251	87	199.74	35%	12%	1	685	238	136.35	35%	33%
2	20	1	210.59	5%	1%	2	585	223	168.76	38%	29%
总计	2044	705	135.82	34%	100%	总计	2044	705	135.82	34%	100%
表3-10 K-means算法聚类结果细分（用户投诉数据）
类标签	样本 个数	每个簇 的比例	资费 投诉	服务 投诉	网络 投诉	通话 投诉	投诉 次数	投诉 比例	纯度
0	1887	56.31%	28	20	40	28	116	6.20%	0.0119
1	434	12.92%	6	8	10	7	31	7.16%	0.0029
2	89	2.66%	2	0	4	0	6	6.74%	0.0011
3	941	28.08%	16	9	19	10	54	5.74%	0.005
总计	3351	100.00%	52	37	73	45	207	6.21%	0.0218
31
表3-11 /取最优参数时MLDP算法聚类结果细分（用户投诉数据）
类标签	样本 个数	每个簇 的比例	资费 投诉	服务 投诉	网络 投诉	通话 投诉	投诉 次数	投诉 比例	纯度
资费敏感型	782	2334%	22	6	14	7	49	6.26%	0.0281
服务敏感型	806	22.83%	9	17	13	8	47	5.70%	0.0211
网络性能敏感型	968	28.89%	12	6	34	11	63	6.50%	0.0351
通话性能敏感型	795	23.72%	9	8	12	19	48	6.16%	0.0264
总计	3351	100.00%	52	37	73	45	207	6.21%	0.0278
由表3-9可以看出，在用户营销案例中，若依据用户每月为运营商企业所创造的价 值，将用户分为高价值用户，中价值用户和低价值用户，K-means算法和MLDP算法聚 类结果均符合中低价值用户群体数量较多，高价值用户数量较少的规律，每个类别的营 销成功率有所差别，其中，中、高价值用户营销成功率较高，低价值用户营销成功率较 低，K-means算法得到的聚类结果中，高价值用户群体中仅包含一个样本，显然受到奇 异值的影响，这样的聚类结果在实际应用中显然无法落地，而MLDP算法得到的每个簇 大小较为均衡，且每个群体用户平均价值区分度较大，具备落地价值。
由表3-10、表3-11可以看出，在用户投诉案例中，不同类别的用户群体投诉率有所 差别，在MLDP算法中，由专家先验指定将用户划分为“资费敏感型”、“服务态度敏 感型”、“网络性能敏感型”、“通话性能敏感型”，由表3-11可以看出，“网络性能 敏感型”用户投诉比例相对较高，而由K-means算法得到的结果中，尽管各个簇投诉率 有所差别，但是若想概括每一个聚簇的相似特征，还需要进一步的分析。理想情况下， 经过MLDP算法聚类后，每种敏感类型的聚簇中应当只包含该种投诉类型，而得到的聚 类结果中，每个聚簇都包含多种投诉类型，本文通过“纯度”指标衡量敏感类型与投诉 种类的匹配程度，纯度越高，则说明簇中包含与之匹配的投诉类型越多，聚类越有效， 由公式（2-6）、（2-7）、（2-8）可计算得到纯度。经过纯度检验，将每个聚簇中投诉 样本最多的类作为这个簇代表的类，MLDP算法相对于K-means算法纯度提升了 27%。 综上，MLDP算法在降低算法复杂度的前提下，能够显著提升聚类的均衡度和有效性。
3.4.3	特征构造
本文认为不同用户对运营商所提供不同种类服务的需求及敏感程度是有所区别的， 如有的用户通话需求大，对通话质量要求较高，在同等通话环境下，该类用户更有可能 对通话质量不满从而产生通话投诉；有的用户上网需求大，当处于相同的网络环境下， 该类用户更有可能对网络性能不满从而产生网络投诉。基于以上分析，本文针对如何量 化不同用户的敏感程度，提出敏感因子概念，将用户对资费、服务态度、网络性能、通 话性能的敏感程度赋予不同权重。并将敏感因子权重及用户标签作为新的特征变量增加
32
到训练集中用于下一章构建分类预测模型。本文取每个样本点归一化后到各聚类中心的 距离的反比作为每项敏感因子权重的度量，距离聚类中心越近，敏感因子权重越大，具 体计算方法如下式：
每个样本方的向量表示为：
（七
其中，〃表示特征维度，将所有特征变量归一化后短表示为：
（吊工,…X）
设聚类中心为左表示第七个聚簇，归一化后表示为：
（力匕,…,％.）
则样本Xi的第k个敏感因子权重为：
1
叫二----
d（W ）
其中，
(3-8)
(3-9)
(3-10)
(3-11)
(3-12)
代芯阳）=仲［一匕）2
若X/ = Xc（Q,则令磔=1。
基于MLDP算法对用户投诉数据进行聚类后，为每一个样本根据其所在聚簇的初 始代表样本，打上资费敏感型、服务态度敏感型、通话性能敏感型及网络性能敏感型的 标签，完成用户分群，基于以上计算，可得到每项敏感因子权重，完成特征构造。
3.5本章小结
本章针对半监督聚类算法在用户分群及特征构造中的应用进行研究，首先提出了一 种聚类算法的评估度量，用于衡量不同聚类包含样本数的相对大小；其次在基于密度峰 值的快速聚类算法基础上，提出MLDP算法，与传统聚类方法相比，大大缩减了聚类中 心的优化过程，并降低了奇异值对聚类结果的影响，将专家经验与数据挖掘算法结合， 更具实际应用价值；再次基于用户营销数据及用户投诉数据对算法进行了仿真和性能评 估，结果显示所提算法能够很好的提升聚类结果的均衡度及有效性；最后基于聚类结果 提出了敏感因子的概念及权重计算方法，作为构造特征为下一章投诉预警建模做好铺垫。 本章所提算法对于帮助运营商识别不同敏感类型的用户，精确定位用户诉求，提高一线 话务员沟通技能，从而更好地应对用户投诉，提升用户满意度有着重要意义。
33
34
第四章 基于改进Stacking算法的网络投诉预警建模研究
随着科技水平的持续发展以及用户需求的不断增长，服务能力正在成为各行各业的 评判标准之一。用户投诉管理作为用户服务的基础在整个用户服务工作中处于非常重要 的位置。用户投诉直接反映了用户的意见和不满，是用户对企业服务能力的评判，而网 络投诉因为既反馈了用户的不良体验，又关系着运营商的网络维护，在运营商的投诉管 理中显得尤为重要【4叫
本章将重点研究用于构建网络投诉预警模型的Stacking算法。围绕网络投诉，利用 数据挖掘技术防患于未然，实现对潜在投诉用户进行预警并主动关怀，从而提升用户满 意度。本章提出改进的Stacking算法，利用“7折循环验证，避免交叉学习问题，并基 于构造特征及原始特征，结合多个单个学习器，构建分类预测模型，旨在提升分类算法 的准确率，降低误判及漏判，并提出净损函数，用于辅助决策最佳判决门限。
4.1 Stacking 算法
Stacking与Bagging、Boosting等算法均属于集成学习方法，与其他集成方法相比， Stacking是一种更特殊的结合策略，Stacking算法的基础上衍生出很多变体或特例口叫 Stacking集成学习方法一般由两层组成，第一层为多个基分类器，对原始训练集进行学 习，称为初级学习器；第二层以初级学习器的输出作为训练集进行学习，称为次级学习 器，次级学习器的类标记与原始数据集保持一致，经过两轮训练得到最终的预测结果。 Stacking算法的关键在于次级学习器训练集和测试集的生成，如图4-1所示。
X train new=
X_train	X_train	X train		X test	X test X test	X test
q		¥
Modell1	Model 12	Model la		Modell j	Modell?	Model lo
y pred_2				j^pred_2	j^pred_n
yjestj	y_test_2i	y_test_nj
y_pred_22	y_^red_n2		y_test_b	y_test_22	y_testji2
y_pre<L23	UMed1%			y_test_23	y_test
y_pred_L	y^)red_24	y_j>red_n4		y_test_i4	y_test_24	y_test__n4
y户d』	yjpred^s	yj>red^n3		yjesLh	y__tesL-5
yjpred_2m	y	J		\ y_test_lfc	y_test_2k	y_test_Dfc
图4-1 Stacking算法次级学习器训练集与测试集生成示意图
35
Stacking算法在训练阶段，为降低过拟合的风险，一般会拆分为训练集和检验集， 使用交叉验证或留一法来生成次级学习器的训练集，以5折交叉验证为例，Stacking算 法训练阶段的基本结构如图4-2所示：
model_T	probT
初级学习器
次级学习器
图4-2 Stacking算法训练阶段
第一层：将训练数据7>{(X2l),(X2,"),…的,词}划分为互不交叉的5份，标记为 4到。5,接下来对每个学习算法，进行5折交叉训练，每次训练将其中4份数据作为 训练集，经过训练得到一个初级学习器，对剩下的一份数据进行预测，保存预测结果， 即从。5作为检验集，使用口到。4建模预测A；再以。4作为检验集，使用。、6、 。3、A建模预测。4，如此循环，直至A到A都被预测到，将预测结果按照。1、。2、 。3、。4、。5的顺序组合，完成以上步骤便可得到训练集在第一个基分类器上的预测结果。 当选定的T个基分类器都完成上述操作后，便得到T个基分类器对所有训练样本的预测 结果。
每一次训练完成得到的初级学习器都对测试集做出预测，经过5次训练，便可在测 试集上得到5个预测结果，将这5次的预测结果求平均值，作为第一个基分类器在测试 集上的一个预测结果。重复7次上述操作，便可得到测试集的T个预测结果。
第二层：将训练集经过初级学习器训练后得到的T个预测结果作为输入，类标号与 原始数据的类标号相同，训练次级学习器，将第一层测试集的预测结果输入到已经训练 好的次级学习器中，输出测试集的最终预测结果。
36
表4-1 Stacking算法流程
算法：Stacking
输入：
・	训练集。={(玉,弘),(工2，%)，"依，九)}
・	初级学习算法G1，G2「・<7；
・	次级学习算法G
方法:
1: for t=l,2,--,T do
2：	%=q(D);
3: end for
4:Q'=@
5:	for i =	do
6:	for 1 = 1,2,…do
7：	Z"=4(xJ；
8:	end for
9:	£>' = Z>' u ((z” 02,z,7), x)；
\O:end for
11: A'=?(£>');
输出：H(x) = A'(/^ (x), h2 (x), - A (x))
Stacking算法在使用交叉验证构建模型时存在交叉学习现象，如图4-2所示，在构 造次级学习器输入时，如由。1、9、。3、。4构成训练集预测。5,而在预测D1、。2、。3、 04时，又将A作为训练集，这便是交叉学习现象，会影响模型的准确性。
4.2	Stacking算法的改进
4.2.1	初级学习器特征构造
对电信行业来说，不同群体、不同方面敏感的用户在投诉前表现出的业务使用需求 及行为特征是不同的，因此本文以用户分群为基础，将用户标签及表示用户对不同服务 敏感程度的敏感因子权重作为新特征，加入到原数据集中，通过丰富原始样本的特征， 提高预测的准确性。初级学习器的输入可表示为：
D={(Xj, Ci, Mt,^/)|z=l,2,—,7w; Z=l,2,…4)	(4-1)
37
其中，方表示第i个样本的原始特征，G表示第i个样本的用户标签，M表示第i个 样本的敏感因子权重，"表示第i个样本的类标号，初级学习器输入特征维度为％I+N+2, 其中M表示第i个样本原始特征维度。
4.2.2	TxT折循环训练法
上一节中提到Stacking算法中存在交叉学习问题，本节提出7x7折循环训练法，避 免交叉学习问题出现。假设选取T个基分类器，则将初始样本划分为互不交叉的T份， 得至(…，Dt},对第一个基分类器，每次选取作为训练集，用来预测D, 循环直至Dx到Dr均被预测，以此作为训练集在第一个基分类器上的第一组预测结果。 为确保每个基分类器对原始数据的充分学习，重新将原始数据划分为互不交叉的T份， 再次进行T折循环训练，重复T次，完成训练集在第一个基分类器上的“T折训练，得 到 T组预测结果，共 2T列。用 probkt(i)={ probki(io),probk^ii)}(^, t=1, 2,…，7)表示预测 结果，其中pro此4io)表示第k个基分类器在第t次T折循环训练中对第z个样本预测为 0的概率，p/•湖以时表示第七个基分类器在第t次7折循环训练中对第i个样本预测为1 的概率。当选定的T个基分类器都完成上述操作后，得到7个基分类器生成的2/列训 练结果。每个基分类器完成一次T折循环训练后，在测试集的一个样本X,上，共生成T 个预测结果，取平均后作为基分类器在测试样本整上的一个预测结果，每个基分类器在 训练集完成八7折训练后，则在测试集共产生T个预测结果，共2T列。
inodei_T	probT
初级学习器
次级学习器
图4-3 7x7折循环训练法训练阶段
为保留原始特征和预测类概率之间的隐含关系，将原始特征加入到次级学习器的输 入中，次级学习器的输入可表示为：
38
D'={(xi, Ci,Mi,probk^f) j沛=1,2,…k, /=1,2,—,77	(4-2)
次级学习器的输入特征维度为冈+2/+N+2。
考虑算法的复杂度，加为样本个数，T为基分类器个数，基分类器的算法复杂度估 计为。0)，则Stacking算法的复杂度估计为TxO(m)+O@), NStacking算法的复杂度估 计为Tx<9(M+O(d2), TStacking算法的复杂度估计为涔0(加〃)+0(出)，其中，0(0为次 级学习器的算法复杂度。NStacking算法与Stacking算法相比，次级学习器训练样本维 度增加网维，TStacking算法初级学习器训练样本个数减少为总样本的1/T,但训练次数 增加为Stacking算法的7倍，次级学习器训练样本维度增加因+NH维。TStacking算法 的基分类器个数增加时，会大大增加训练次数，因此基分类器个数T的选择不宜过大。 次级学习器维度的增加会增大训练时长，因此TStacking算法在高维数据集上耗时较长。
4.3	基于改进Stacking算法的网络投诉预警建模方案
本章从三个方面对Stacking算法做出改进：
(1)通过MLDP算法进行特征构造；
(2)采用7x7折循环训练方法构造次级学习器输入；
(3)将原始特征加入到次级学习器输入中。
本章基于改进Stacking算法构建网络投诉预警模型,初级学习器选取常用的决策树、 逻辑回归、支持向量机模型，次级学习器选择适用于高维数据的支持向量机模型。建模 方案如图4-4所示。
潸在投诉用户
图4-4基于改进Stacking算法的网络投诉预警建模方案
4.4	实验验证
39
4.4.1	不平衡处理
原始用户投诉样本共3351条，其中网络投诉有73条。若将网络投诉作为正样本, 其余作为负样本，则正负样本比例达到1:45,是典型的不平衡数据集。产生网络投诉行 为的目标人群在全部电信用户中的比例相对较小，不平衡数据会影响到分类预测模型性 能［5%因为多数类对模型准确性的影响会显著大于少数类，若分类模型评估准则为分类 结果的准确性，则在不平衡数据中很难挖掘到少数类的规律，分类预测结果倾向于将少 数类预测为多数类。因此，在构建分类模型前，首先对数据进行不平衡处理⑸】。
本文采用过采样方法通过增加少数类样本的数目从而平衡正负样本比例，达到提升 分类算法性能的目的。常用的简单复制少数类样本的方法不增加任何信息量，可能会导 致过拟合，从而影响分类器性能，故本文不予采用。本文采用SMOTE算法［52］,由下式 生成新的少数类样本：
Xij=Xt+ rand（Q,\）*（Xj- xi）	（4-3 ）
新样本的生成在少数类样本及其与同类近邻的连线上，SMOTE算法构造了少数类 样本的“近邻”，从而使少数类样本数量增加，达到平衡正负样本比例的目的，使少数 类样本的特征更容易被挖掘到，从而增强了分类算法的性能。
采用SMOTE算法经过不平衡处理及其他数据预处理后共得到4776条数据，其中 正样本1632条，负样本3144条，正负样本比例约为1:2。
4.4.2	模型评估标准
训练样本经过投诉预警模型预测后可得到混淆矩阵，由混淆矩阵可以看出，所有的 用户被分为四类：预测投诉的投诉用户、预测不投诉的投诉用户、预测投诉的不投诉用 户、预测不投诉的不投诉用户，其中前三类用户是模型重点关注的。对于预测投诉的投 诉用户，如果能妥善处理投诉问题，有可能消除用户不满进而提升其忠诚度，若未能妥 善处理用户投诉，可能会造成用户流失；对于预测投诉的不投诉用户，误判会增加安抚 用户成本，同时给用户带来不必要的打扰；对于未预测到的投诉用户，漏判未能提前预 警，使用户未被关怀主动投诉，相对误判，带给用户更差的体验。为了更清晰的描述经 过投诉预警模型预测后用户的分类，细化混淆矩阵中的各个指标如下所示：
表4-2投诉预警模型混淆矩阵
预测
实际	0 （不投诉）	1 （投诉）	合计
0 （不投诉）	a	b	a+b
1 （投诉）	C	d	c+d
合计	a+c	b+d	N
本文采用三项指标对模型的预测效果进行评估：准确率、误判率、漏判率。准确率
40
表示预测正确的用户占用户总数的比例，误判率表示预测投诉实际不投诉的用户占实际 不投诉用户总数的比例，漏判率表示预测不投诉实际投诉的用户占实际投诉用户总数的 比例，计算公式如下：
准确率：
a + d
N
(4-4)
误判率:
b
a + b
(4-5)
漏判率:
c + d
(4-6)
4.4.3	初级学习器构建
本章构造初级学习器选取决策树、逻辑回归、支持向量机三种常用的机器学习算法。 决策树算法理论清晰，易于理解和解释，能够同时处理多种类型的变量，学习能力较强， 但是泛化能力较差，对训练集的变化非常敏感，是一种不稳定的分类器，这种不稳定的 分类器有助于提升集成分类算法的性能；逻辑回归算法常用于解决二分类问题，广泛应 用于工业问题，逻辑回归模型进行分类预测时计算量小，速度快，其结果可以观测到样 本的预测概率值，但逻辑回归模型假设严格，需要人工对非线性特征进行转换，面对高 维特征时容易欠拟合；支持向量机算法则可将学习问题转化为凸优化问题从而得到全局 最优解，尤其在数据量大、维数高时性能表现良好，但是耗时多，并且需要找到合适的 核函数。本文采取Stacking集成策略，将以上三种算法模型融合在一起，综合各个模型 的优势，提升分类模型的性能。
(1)决策树
本节选取CHAID、CART、ID3三种决策树通过实验选取最优算法模型，由表4-3 可以看出，CHAID决策树预测准确率最高，漏判率最低，ID3决策树误判率最低，漏判 率最高，在用户投诉案例中，漏判与误判相比更影响用户体验，错误成本更高，因此漏 判率是本文关注的重点，综合以上分析，选取CHAID决策树作为基分类器。
表4-3多种决策树算法预测效果对比
CHAID	CART	ID3
准确率	72.9%	71.4%	72.4%
误判率	14.7%	14.2%	9.8%
漏判率	50.1%	54.5%	60.4%
(2)逻辑回归
本节构造逻辑回归模型时，分别选取五组特征变量用于验证不同特征的预测能力。
41
第一组基于用户基本信息，第二组基于用户打分信息，第三组基于用户业务使用信息, 第四组基于用户全部信息，第五组基于用户全部信息加构造特征。由表45可以看出, 模型5准确率最高，漏判率最低，效果最好。
表多种特征组合逻辑回归模型预测效果对比
模型1	模型2	模型3	模型4	模型5
准确率	66.0%	66.5%	73.0%	73.2%	73.3%
误判率	1.3%	5.6%	8.2%	9.1%	9.4%
漏判率	97.1%	87.3%	63.2%	61.2%	61.0%
（3）支持向量机
在构建支持向量机模型时，核函数的选择是算法关键，本文选用对大样本数据和小 样本数据预测性能都较好的高斯核函数。
基分类器在原始样本未增加构造特征采用十折交叉验证的预测结果如表4-5所示, 增加构造特征后的预测结果如表4-6所示。由表4-5、表4-6可以得出，添加构造特征 后，CHAID决策树、逻辑回归、SVM三种模型预测准确率均有所提升，其中SVM模 型提升比例最高为1.1%,漏判率均下降，SVM模型下降比例最大为2.0%,逻辑回归模 型误判率略有升高，CHAID决策树和SVM误判率均下降，总体来看，构造特征的加入 可使基分类器预测性能提高。三种基分类器中，CHAID决策树模型预测准确率较高，漏 判率较低；逻辑回归模型漏判率较高，但误判率最低，且十次交叉验证的标准差最小, 模型最为稳定；SVM模型能有效处理高维特征，预测结果中准确率最高，漏判率最低， 综合以上分析，认为SVM为三种基分类器中性能最好的基分类器。
表4-5未添加构造特征基分类器预测结果
CHAID决策树	逻辑回归	SVM
准确率	误判率	漏判率	准确率	误判率	漏判率	准确率	误判率	漏判率
1	72.7%	143%	54.6%	73.0%	9.7%	61.4%	77.9%	15.4%	48.9%
2	72.8%	18.1%	45.2%	73.2%	8.7%	61.8%	74.1%	17.5%	48.5%
3	72.7%	18.7%	38.4%	73.5%	9.2%	60.8%	72.0%	17.2%	44.8%
4	74.4%	14.7%	47.2%	73.6%	9.8%	61.3%	72.2%	14.1%	53.8%
5	72.9%	13.4%	56.1%	73.6%	8.6%	60.3%	73.4%	15.6%	48.7%
6	72.0%	14.5%	49.7%	73.4%	8.9%	60.8%	74.4%	18.5%	38.5%
7	72.7%	10.8%	56.3%	73.2%	9.0%	61.3%	72.2%	19.3%	40.6%
8	73.5%	15.6%	46.8%	73.0%	8.9%	61.8%	72.2%	18.3%	40.6%
9	72.9%	12.9%	54.7%	73.2%	9.0%	61.3%	75.7%	13.5%	41.5%
10	72.4%	14.0%	52.1%	73.0%	9.4%	61.3%	75.4%	16.2%	38.7%
平均值	72.90%	14.70%	50.11%	7327%	9.12%	61.21%	73.95%	16.56%	44.46%
标准差	0.00616	0.02218	0.05479	0.00228	0.00381	0.00439	0.01851	0.01827	0.04986
42
表添加构造特征基分类器预测结果
准确率	CHAID 误判率	漏判率	准确率	逻辑回归 误判率	漏判率	准确率	SVM 误判率	漏判率
1	72.9%	11.8%	54.8%	73.2%	9.0%	61.3%	73.5%	19.5%	40.4%
2	73.5%	10.4%	57.2%	73.6%	10.8%	60.3%	75.1%	12.0%	48.8%
3	72.6%	13.8%	53.0%	73.4%	8.9%	60.8%	73.9%	14.3%	51.6%
4	74.0%	17.6%	42.1%	73.6%	8.8%	60.3%	74.0%	16.9%	43.8%
5	73.7%	10.6%	56.3%	73.0%	9.2%	61.3%	75.6%	13.3%	44.8%
6	72.8%	19.1%	45.1%	73.5%	10.8%	60.8%	75.9%	18.0%	35.9%
7	73.5%	14.6%	48.9%	73.2%	9.0%	61.3%	75.0%	15.8%	39.5%
8	73.8%	13.3%	50.8%	73.0%	8.9%	61.8%	74.3%	12.2%	52.0%
9	73.1%	21.8%	36.0%	73.4%	9.2%	61.3%	75.6%	16.3%	41.9%
10	73.2%	13.2%	52.3%	73.2%	8.8%	61.8%	74.8%	19.3%	36.9%
平均值	73.31%	14.64%	49.64%	73.30%	9.43%	60.99%	74.76%	15.75%	43.55%
标准差	0.00447	0.03571	0.06423	0.00231	0.00801	0.00496	0.01015	0.02607	0.05447
4.4.4	实验结果比较及分析
本文构造TStacking模型，选择准确率高、漏判率低、适用于高维数据的SVM模型 作为次级学习器。为验证所提算法的有效性，本节将在用户投诉数据集上设置以下实验:
(1)采用TXT折循环训练法并加入构造特征与原始特征作为次级学习器输入的 TStacking算法和组成它最优基分类器进行比较；
(2)将TStacking算法与原始Stacking算法进行比较；
(3)将TStacking算法与添加原始特征作为次级学习器输入的NStacking算法进行 比较。
多种集成分类算法采用十折交叉验证的预测结果如表4-7所示：
表4-7多种集成分类算法预测结果
准确率	Stacking 误判率	漏判率	准确率	NStacking 误判率	漏判率	准确率	TStacking 误判率	漏判率
1	83.8%	113%	25.6%	83.0%	10.7%	29.6%	83.8%	13.7%	21.1%
2	83.4%	14.2%	21.1%	82.5%	13.0%	26.3%	84.3%	13.0%	21.1%
3	84.4%	14.7%	17.6%	81.8%	15.2%	23.8%	84.3%	13.2%	20.9%
4	82.4%	10.3%	32.3%	83.8%	13.1%	21.9%	85.5%	15.8%	23.3%
5	81.1%	11.7%	32.9%	83.9%	17.2%	14.1%	84.9%	15.0%	23.0%
6	83.7%	14.2%	20.3%	83.3%	18.7%	19.5%	85.5%	11.5%	23.2%
7	80.4%	15.9%	26.8%	82.7%	13.2%	25.0%	84.3%	11.3%	24.3%
8	82.9%	14.7%	21.7%	83.5%	9.4%	30.2%	84.6%	14.5%	16.9%
9	82.1%	20.0%	13.6%	83.6%	13.6%	22.0%	85.9%	13.5%	22.3%
10	83.4%	12.6%	24.4%	84.0%	17.4%	21.3%	85.1%	15.6%	25.4%
平均值	82.76%	13.97%	23.63%	83.21%	14.15%	23.38%	84.81%	13.71%	22.14%
标准差	0.01204	0.02621	0.05779	0.00662	0.02829	0.04531	0.00641	0.01485	0.02226
43
由表4-6、4-7可以得出，TStacking模型集成了三种个体学习器的优势，最终的预 测结果具有最高准确率，达到84.81%,和最低漏判率22.14%,漏判率相对于最优基分 类器还下降了 49.0%,且模型标准差小，效果稳定，以上分析表明TStacking算法性能 优于基分类器，集成是有效的。
由图4-5可以更直观地看出，TStacking算法相对于最优基分类器性能显著提升； NStacking算法相对于Stacking算法，准确率提升了 0.54%,误判率升高了 1.3%,漏判 率降低了 1.1%,总体表现来看，性能有所提升，即次级学习器输入中加入原始特征，保 留了原始特征和类概率之间的隐含关系，算法预测效果有所提升；TStacking算法相对于 NStacking算法，准确率提升了 1.9%,误判率下降了 3.1%,漏判率下降了 5.3%,且模 型结果更为稳定，由此可见，构造特征的加入及Txt折循环训练方法的引入可进一步提 升算法预测效果，综上，本文所提算法可有效避免交叉学习问题，并使算法预测性能得 到提升。
图4-5多种分类算法预测性能对比
4.4.5	净损函数
以上算法均基于判决门限40.5,即当预测投诉概率大于0.5时，将该样本预测为投 诉。现在TStacking上分别设定判决门限上0.3及40.7,研究不同门限对TStacking算 法预测结果的影响，实验结果如表4-8所示，预测结果与门限为上0.5时进行对比，结 果如图4-6所示。
由图4-6可以更直观地看出，当改变分类判决的门限值时，算法的准确率较为平稳， 而误判率和漏判率产生了较大变化，随着门限值升高，算法误判率降低，漏判率升高。 在实际用户投诉场景中，基于本文所提模型预测准确的投诉用户将在企业的关怀策略下 满意度提升，而基于本文所提模型误判和漏判的用户，将会产生更多不良感知，从而给 企业带来净损失。因此，本节提出净损函数L用于评估如何选取门限值使净损达到最低。
44
表4-8 TStacking算法选取门限＞1=0.3及上0.7预测效果
k0.3				k=G.l
准确率	误判率	漏判率	准确率	误判率	漏判率
1	82.1%	24.8%	5.5%	82.9%	4.3%	41.0%
2	82.7%	23.5%	5.6%	83.4%	4.2%	40.1%
3	82.7%	23.7%	5.5%	83.6%	4.2%	39.7%
4	83.8%	28.6%	6.2%	84.7%	5.2%	43.3%
5	83.4%	26.9%	6.0%	84.2%	4.8%	43.6%
6	83.8%	20.6%	6.1%	84.7%	3.8%	44.1%
7	82.9%	20.3%	6.4%	83.4%	3.6%	46.3%
8	83.0%	26.0%	4.4%	83.7%	4.7%	32.1%
9	84.1%	24.4%	5.8%	85.0%	4.3%	42.4%
10	83.4%	28.1%	6.7%	84.3%	5.0%	48.2%
平均值	83.19%	24.70%	5.83%	83.99%	4.42%	42.08%
图4-6 TStacking算法选取不同门限时性能对比
假设测试样本总数为N,投诉率为力对于误判用户会产生外呼成本%及给用户带 来的打扰成本由2,对于漏判用户，会因为未能及时发现用户不满导致用户投诉，降低用 户满意度，因此带来未关怀成本〃，设用为误判率，尸2为漏判率，基于以上假设，将净 损函数I定义为：
L=(a+加2)N (A-q) F\+ nNqFz	(4-7)
假设选取100000个测试样本，基于专家经验，设定g=5%,加1=1元，掰2=1元，而 对于不同不满程度的投诉用户，会带来不同的未关怀成本，设定〃分别为5、10、20、
45
30、40、50、60元，用于评估不同门限带给企业的净损失值，由公式(4-7)计算净损失 值所得结果如图4-7所示：
(30期*隔鼬
k=0.3	48387	49845	52760	55675	58590	61505	64420
k=0.5	31584	3711Q	48189	59259	70329	81399	92469
k=0.7	18918	29438	50478	71518	92558	113598	134638
—k=0.3 -®-k=0.5 -A-k=0.7
图4-7不同参数设置下净损失值
由图4-9可知，当取不同未关怀成本时，不同判决门限下的净损失值不同，当〃约 为20时，三种门限净损失值最为接近，当“V20时，门限上0.7时净损失值最低，当〃 >20时，门限Q 0.3时净损失值最低。
当门限k=0.5且未关怀成本〃=20时，TStacking算法产生的净损失L (TStacking) =48189元，Stacking算法产生的净损失A (Stacking) =50173元，NStacking算法产生的 净损失L (NStacking) =50265元，即在100000个样本中，TStacking算法相对于Stacking 算法可降低净损失50173-48189=1984元，TStacking算法相对于NStacking算法可降低 净损失50265-48189=2076元。若在拥有一千万移动用户的地市部署该投诉预警模型， 算法的改进将为企业降低净损失约20万元。
4.5	本章小结
本章针对网络投诉预警进行建模研究，在Stacking集成分类算法的基础上，将用户 标签及敏感因子权重作为新特征加入到训练集中，提出方7折循环训练方法，避免交叉 学习现象，并将样本原始特征加入到次级学习器的输入中，结合三种基学习算法，构造 分类预测模型。最后通过仿真对TStacking算法进行了分析与评估，并提出净损函数概 念，辅助决策最优判决门限，仿真结果验证了 TStacking算法的有效性。本章所提算法 对于帮助运营商挖掘潜在投诉用户，提前预警主动关怀，提升用户满意度，降低企业损 失具有重要意义。
46
第五章基于用户感知的网络性能评分卡建模研究
传统网络QOS指标多选取基于传输层和应用层的端到端指标［5叫经常会出现网络 QoS指标良好，而用户满意度低、投诉多、抱怨体验差的问题，主要原因是传统的QoS 指标缺少对用户使用体验的关注，只从客观角度对网络业务质量进行了评价，而未对用 户主观感知设定考核指标，使得统计结果不能反映出用户的真实体验［53
本章将结合网络指标及用户业务使用信息，基于用户对网络性能的打分数据，对网 络性能用户感知评分卡模型进行研究。各大通信标准化组织对影响用户体验的网络指标 有不同的选取标准［55］，本章重点分析了本次实验可采集、可量化的指标。本章基于逻辑 回归模型构建网络性能用户感知评分卡，给每个变量不同取值或区间设定不同分值，定 量预测用户网络满意度，将潜在投诉用户进行优先级排序，为制定分层分级的用户关怀 策略提供理论支持。
5.1	评分卡原理概述
5.1.1	逻辑回归模型
逻辑回归模型常用于解决二元分类问题，它研究目标变量与多个自变量之间的关系, 逻辑回归将多元线性回归模型生成的预测值%+ 卜3mX,",输出范围为(-°°,+ 8),通过Sigmoid函数转化为接近0或1的y值，通过这种变换，可得到近似概率预 测，有助于需要通过概率辅助决策的任务，Sigmoid函数图像如图5-1所示：
Sigmoid函数表示为:
1 y = ~ ~ l + e -
(5-1)
将多元线性回归模型2= 30+31X1+…+。户„，代入式(5-1)中，将歹视为样本x作为
47
正例的可能性，可得到:
产尸(y = l) = ] + e--+：	(5-2)
对公式(5-2)进行变换可得到：
历(7^-) = %+2再+…缥4	(5-3)
1-P
式中e为自然数，g,%…3nl为多元线性回归模型参数，由“极大似然法”估计得 出⑷,公式(5-3)实际是用线性回归模型的预测结果去逼近正负样本相对可能性的对数。 逻辑回归模型的输出较为复杂，可经过变换将其转化为较为直观且容易理解的形式，评 分卡就是基于逻辑回归模型的一种应用[461。
5.1.2	证据权重(WOE)
在构建评分卡模型过程中，首先需要将连续变量离散化，又称为变量分箱。证据权 重(Weight of Evidence, WOE)是对同一个变量不同取值的评价指标，计算公式如下：
(5-4) P(%)
公式(5-4)中，p(“D表示当前分组中样本类别分别为修 和户〃的概率值。 举例来说，表中以“上行流量”为自变量，用户对网络性能是否满意为目标变量，由于 “上行流量”是连续型变量，故需要对其进行离散化处理，假设离散化为5组，不满意 和满意表示两类用户的数量分布，通过变换可以看出，印OE反映的是一种差异，它表达 了自变量的不同取值或不同区间对目标变量的影响。
表5-1卯0E计算方法示例
上行流量 (GB)	不满意	满意	WOEi
1: [0,0.05)	569	2407	=ln((569/4001)/(2407/7466)>ln((569/2407)/( 4001/7466))
2:[0.05,0.10)	448	1560	= -0.8184 =ln((448/400 l)/(1560/7466))=ln((448/l 560)7( 4001/7466))
3:(0.10,0.20)	810	2023	=-0.6238 =ln((810/4001)/(2023/7466)>ln((810/2023)/( 4001/7466))
4:[0.20,030)	766	851	=-0.2915 =ln((766/4001)7(851/7466))=ln((766/851)/(4001/7466))
5[0.30,3.55)	1408	625	=0.5186 =ln((1408/4001)/( 625/7466))-ln(( 1408/624)/( 4001/7466))
合计	4001	7466	=1.4360
48
5.1.3	信息量（IV）
信息量（Information Value, IV）是用来衡量自变量与目标变量之间关联性的指标, 信息量由以下公式定义：
什（阿-响™,—,））小翳.
(5-5)
1
(5-6)
其中，J•为变量分组的个数。"将收9E当前分组赋予权重以为？（啕，当前分组占 整体样本比例越高，则对变量整体预测能力的贡献越大。因此，"值相对于用OE值是 对自变量预测能力更好的衡量指标，可以按照//值从高到低挑选变量参与建模。
5.1.4	评分卡原理
评分卡将逻辑回归模型的结果进行转化，为每个变量不同取值设定不同分值，使 结果更加直观，易于理解。
（1）评分卡计算方法
设几率为4表示正例用户概率（7）与反例用户概率（i-尸）的比值，定义为：
4=产	（5-7）
1 一尸
可将评分卡最终得到的分值通过几率对数来定义，公式如下：
score 息=2+ 5 * ln(0Q)
(5-8)
设定逻辑回归模型预测几率为4的分值为器，预测几率为组的分值为此+HDO,代入 上面的公式可得到：
P0=A + Bln(^
"Pa + PDO = A + Bln(2G0)
(5-9)
求解上述公式，可以得到/、3的值：
］，、
■ ln2	（5-10）
A = Po-Bln（0o）
Po和产OO都是已知常数，由公式（5-10）可计算出得到幺和3的值，代入公式（5-8）便可得到不同预测概率的分值，经过上述过程，便可得到一个样本的最终评分结果。
（2）分值刻度分配
在实际应用中，可计算出每个变量各分箱对应的分值，当有新用户产生时，将各变
49
量值对应到每个分箱后得到对应的分值，与初始分值相加后，便可得到最终的评分结果。
逻辑回归模型预测概率为P，由公式（5-3）、（5-7）、（5-8）可得:
score总=2+3*加(％) = 4+5*(。0+叼石+…+ 3/叫) ^(A+B*a)0) + B*(oix1+--- + B*(omxa
(5-11)
其中，（N+5* 3。）为基础分数，8*3阳，5*3*2,…，3*0必„为每个变量的分数， 变量经过分箱处理后通过计算可得到每个分箱的WOE值，根据变量的取值便可得到该 变量的分数，如表5-2所示。
表5-2评分卡模型
变量	分箱类别	分值
基础分数	・	4 + 3*/
1	(B*co1)*WOEn
石	2	（5*例）*肱叫
I	（B*吗）*的9岛
1	(B*a)2)*WOE2l
2	{B*co^WOEn
%	• ••	...
J	(B*o)2)*WOE2J
• ••	•••	• ••
1	(B*a)„)*WOEnl
4	2	(B*a)nyWOEn2
K	{B*co^WOEnk
5.2基于用户感知的网络性能评分卡实施
本节结合网络指标及用户业务使用信息，基于用户对网络性能的打分数据构建网络 性能评分卡模型，具体实施流程如下图所示：
50
图5-2基于用户感知的网络性能评分卡实施流程
5.2.1数据获取
本节从运营商某地市公司提取了相关数据，主要包括以下四类：
(1)基本属性：采集日期、采集时段、基站名称、经度、纬度、小区内的平均用户 数、小区内的最大用户数等；
(2)网络指标：无线接通率、无线掉线率、上行PRB利用率、下行PRB利用率、 切换成功率、上行平均干扰等；
(3)用户业务使用信息：上行流量、下行流量、上下行总流量、话务量等；
(4)用户感知指标：用户对某一时段内对网络性能的打分。
用户打分数据通过电话、短信、APP采集，网络指标及用户业务使用信息来源于被 访用户常驻小区打分前三天内的数据，时间颗粒度为小时，在忙时和闲时各选取一个时 段，取三天内的平均值，共计16063条数据参与建模，将其拆分为训练集和检验集。用 户打分范围为1到10分，分数越高，表示用户对网络性能越满意，定义用户打分大于 等于7分表示用户对当前网络性能满意，设为正样本，打分小于7分则表示用户对当前 网络性能不满意，训练集中正样本7466条，负样本4001条，合计11467条。从采集到 的实际数据可以看出，对运营商所提供的网络服务较为满意的用户相对更多。
5.2.2	变量筛选
本节通过"值来挑选预测能力较强的变量参与构建评分卡模型。首先需要对连续 变量进行分箱处理，由表5-1所示可计算出所有变量各分组用OE,由公式(5-5)、(5-6)可计算出各变量7T值，结果如表5-3所示：
51
表5-3各变量〃值
序号	变量名称	IV值	影响强度
1	上行流量	0.653239	强
2	切换成功率	0.650255	强
3	无线掉线率	0.455859	强
4	无线接通率	0.219383	强
5	上行PRB利用率	0.156768	强
6	下行流量GB	0.128390	强
7	上下行总流量GB	0.105267	强
8	下行PRB利用率	0.056055	中
9	话务量VO	0.024552	中
10	上行干扰平均	0.020440	中
11	采集时段	0.006120	弱
12	小区内的平均用户数	0.003395	弱
13	小区内的最大用户数	0.002574	弱
一般认为若某变量与目标变量之间的〃值小于0.02,则认为该变量不具备预测能 力，因此，舍弃采集时段、小区内的平均用户数及小区内的最大用户数3个变量，剩余 10个字段参与构建评分卡模型。
5.2.3	基于用户感知的网络性能评分卡模型构建
基于逻辑回归的输出参数及印OE值，网络性能用户感知分析模型可表示为：
PC = 1) = 1 + 0-(3。+ 他呼+…皿EQ	( 5/2)
由最大似然估计法可到得各变量模型参数如表5-4所示。
由公式(5-9),令。0=1.85时(实际满意用户与不满意用户的比例)，score总=60,
夕°=3.70时，score fe=80,计算得到Z和B：
(4=52.14 (5=21.42
(5-13)
(5-14)
scoyb息=52.14 + 21.42 * ln(
基础分数为:
A+B 0=52.14+21.42*(-0.149859)=48.92	(545)
52
表5-4各变量模型参数
序号	变量名称	模型参数名称	模型参数值
1	上行流量	®i	0.448587
2	切换成功率		0.381346
3	无线掉线率	g	-0.085321
4	上行PRB利用率	%	0.195732
5	无线接通率	吗	0.197898
6	下行流量GB	8 6	0.215297
7	上下行总流量GB	叫	-0.195227
8	下行PRB利用率	叫	-0.107773
9	话务量VO	%	0.021412
10	上行干扰平均	%	-0.008074
11	常量	/0	-0.149859
由表5-2给出的评分卡形式，最终可得到网络性能用户感知评分卡如表5-5所示:
表5-5网络性能用户感知评分卡
变量	变量分组	得分
基础分数		48.92
上行流量GB	1： [0,0.05)	-7.80
2:[0.05,0 .10)	-6.65
3: [0.10,0.20)	-2.35
4:[0.20,0.30)	4.14
5[0.30,3.55)	14.59
切换成功率	1: [0,99.62%)	-0.23
2: [99.62%,99.82%)	-2.69
3:[99.82%,99.99%)	2.12
4:[99.99%,1]	5.87
下行流量GB	1:[0,0.05)	-7.72
2:[0.05,0 .10)	-2.06
3: [0.10,0.20)	-0.60
4: [0.20,0.30)	7.46
5:[0,30,40.00)	9.88
53
（续上表）
变量	变量分组	得分
无线接通率	1:[0,99.85%)	1.27
2:[99.85%,99.93%)	1.47
3:[99.93%,99.98%)	2.35
4:[99.98%,1]	3.18
上行PRB利用率	1:[0,14.63%)	-2.98
2:[14.63%,20.06%)	-4.50
3:[20.06%,26.54%)	-1.80
4:[26.54%,40.00%)	2.63
5:[40.00%,96.67%]	8.43
上下行总流量GB	1:[0,0.50)	9.80
2:[0.50,1.20)	4.96
3:[1.2052.00)	1.60
4:(2.00,3.50)	223
5:[3.50,40.00)	-8.98
无线掉线率	1:00	1.76
2:(0.0.036%)	-0.92
3:[0.036%,0.087%)	-0.62
4 叫087%,27.570%)	-0.52
下行PRB利用率	1:[0,7.07%)	2.31
2:[7.07%,13.63%)	2.62
3:[13.63%,22.70%)	0.56
4:[22.70%,37.87%)	-2.66
5:[37.87%,99.56%]	-6.21
话务量VO	1:[0,0.10)	-0.62
2: [0.10,0.50)	-0.27
3:[0.50,1,25)	0.26
4:[L25,50.00)	1.50
上行干扰平均	1:1-124,-117)	0.15
2:[-117,-115)	-0.08
3:[-115,-72]	-0.41
54
5.2.4	基于用户感知的网络性能评分卡模型评估
将所得网络性能用户感知评分卡模型应用于检验集，用户评分分布直方图如图5-3 所示：
E6) 号0) 206) 与荽) 弓笔 32) 与罡 CFf邑 用8匚 w E 〈七女) nt Z.X.OISE) 19r--s 59) %s) Zr-E ASE 二工匕 8次) 三*2 丈二豆 Z.F& dp) 口).W ¥-0三
网络性能用尸感知评分
图5-3网络性能用户感知评分分布直方图
图5-4高危网络投诉用户覆盖率变化图
其中最低分为40.47分，最高分为94.46分，平均值为63.92分，标准差为7.478。 若假设打分为1的用户对当前网络性能极不满意，为高危投诉用户，则在检验集中高危 投诉用户共H0人，占检验集全部用户的2.4%,与上一章中网络投诉用户所占比例相 近，定义覆盖率为指定用户群体中高危投诉用户占全部高危投诉用户的比例，图5-4反 映的是按照用户评分从低到高指定用户群体，随着指定范围不断扩大高危投诉用户覆盖
55
率的变化情况，评分最低的5%的用户中，高危投诉覆盖率为32.73%；评分最低的15% 的用户中，高危投诉覆盖率为50.01%；评分最低的30%的用户中，高危投诉覆盖率为 67.27% o
基于用户感知的网络性能评分卡模型可根据用户当前所处网络环境及用户业务使 用需求，对用户网络满意度做出定量预测，基于投诉预警模型定位潜在投诉用户，结合 评分卡模型由分数从低到高进行优先级排序，由上一章可知，不同程度的不满用户未关 怀成本不同，带给企业的损失也不同，因此在企业关怀支出有限的前提下，可采用分层 分级的用户关怀策略，对于投诉预警模型预测为不投诉的用户，可暂时不采取措施，维 护好用户所处网络环境；对于投诉预警模型预测的潜在投诉用户，可根据评分卡模型所 得评分将关怀优先级分为高、中、低三级，高优先级用户评分低感知差，为高危投诉用 户，可采取电话呼入的方式进行主动关怀，及时了解其不满原因并改善服务质量；中优 先级用户评分较低感知较差，有一定可能产生投诉，可采取发送短信或APP推送的方式 对其进行关怀或得到反馈后再采取措施；低优先级用户可标记为重点关注对象，根据其 后续行为再采取进一步行动。
表5-6网络性能用户感知评分对应关怀优先级
评分百分比	分数	关怀优先级
(0,5.0%]	(0,51.72]	高
(5.0%,15.0%]	(51.72,56.47]	中
(15.0%,30.0%]	(56.47,59.91]	低
此外，在受理用户投诉时，还可通过评分卡模型根据用户每项指标得分快速识别用 户业务使用偏好及带来不良感知的网络因素，从而使一线话务员可以更好地应对用户投 诉，明确用户诉求，精准安抚用户的不满情绪，为投诉问题的妥善处理提供良好的氛围。 5.3本章小结
本章针对基于用户感知的网络性能评分卡模型进行研究，采集网络环境指标、用户 业务使用需求及反映用户感知的打分数据后，首先对连续变量进行分箱处理，计算每个 变量不同取值或区间的印OE值，在此基础上计算每个变量的犷值，从而挑选出具有高 预测能力的变量参与构建以用户是否满意为目标变量的逻辑回归模型，基于逻辑回归模 型输出并进行转化，最终可得到基于用户感知的网络性能评分卡模型。仿真结果表明本 章所建模型可以根据预测评分在指定用户群体中较好地预测出高危投诉用户。本模型可 应用于对潜在投诉用户进行优先级排序，在关怀支出有限的前提下，优先关怀高危投诉 用户，本模型对通过提供更加个性化的服务及关怀策略提升用户网络满意度具有重要意 义。
56
第六章总结与展望
本章对本文的整体研究工作进行总结阐述，分析所做工作的不足和缺陷，同时对下 一步的研究内容进行展望。
6.1工作总结
本文以电信用户网络满意度提升作为研究对象，对用户分群、用户网络投诉预警及 用户网络满意度预测进行了深入的探讨和研究。电信用户规模巨大，不同群体用户对运 营商所提供服务的需求是不同的，给企业创造的价值也是不同的。在流量红利消失，数 字业务盈利能力削弱的今天，精细化管理用户，让用户的需求得到切实有效的满足，是 用户保有的关键。服务能力正在成为衡量各企业的标准之一，用户投诉管理是用户服务 工作的基础，其中网络投诉因为既反馈了用户的不良体验，又关系着运营商的网络维护， 在运营商的投诉管理中，显得尤为重要，构造投诉预警模型，挖掘潜在投诉用户，扭转 当前事后补救的投诉处理方式，对于提升用户体验，降低企业损失具有重要意义。对用 户满意度进行定量预测，对潜在投诉用户进行优先级排序，精准定位高危投诉用户，对 于企业在关怀支出有限的前提下通过制定分层分级的用户关怀策略提升用户网络满意 度具有重要价值。
本文重点研究了围绕网络投诉预警及应对的用户满意度提升算法，主要研究工作与 成果如下：
(1)提出一种聚类算法评估度量聚类均衡度，更贴合运营商的实际应用；提出一种 新的基于成对约束的半监督聚类算法，用于用户分群问题，将专家经验与数据挖掘算法 结合，降低算法运行时间，提升聚类结果均衡度及有效性，实验结果验证了所提算法的 优越性及落地价值。并基于聚类结果提出敏感因子概念，结合个人情感差异构造特征。
(2)提出一种改进的Stacking集成分类算法，用于挖掘潜在投诉用户，实验结果 验证了所提算法可避免交叉学习问题，并使分类预测性能提升，此外还提出净损函数概 念，用于辅助决策最佳判决门限，实验结果再次验证了所提算法可通过有效降低误判及 漏判，减少企业损失。
(3)构建了基于用户感知的网络性能评分模型，将潜在投诉用户按满意度评分进 行优先级排序，实验结果验证了所建模型可以根据满意度评分在指定用户群体中较好地 预测出高危投诉用户，创新性地将评分卡模型应用于通信领域，通过评分卡模型更好地 应对网络投诉。
57
6.2工作展望
虽然本文针对用户分群问题、投诉预警及用户满意度预测问题做出了一些研究，取 得了一些初步成果，但还有许多有待完善的地方，需要进行更深层次的探索和研究，具 体包括以下方面：
(1)对于所提出的基于成对约束的半监督聚类算法，为每个聚簇选取初始代表对 象具有较强的主观性，后续可以基于一组初始代表对象通过迭代选取更优的聚类中心进 行深入研究；对于提出的敏感因子权重计算方法，本文由每个样本点距离各聚簇中心的 欧式距离的反比计算得出，后续可以基于如何获取最佳权重计算方法进行深入研究。
(2)对于提出的改进Stacking集成学习方法，本文只验证了指定基分类器为三个 时能取得较好的预测效果，后续可针对不同数据集如何确定最优基分类器个数进行深入 研究；在训练过程中，每次应用1/n的数据重复7x7次训练生成次级学习器的输入，特 征维度为原来的T倍，后续可基于如何挑选一些预测能力较强的特征作为次级学习器的 输入进行深入研究，在不影响预测性能的前提下降低算法时间复杂度。
(3)对于提出的基于逻辑回归的网络性能用户感知评分卡模型，因原始数据只获 取了包括部分网络性能指标及用户使用需求在内的十余个字段，模型学习不够充分，后 续可采集更多字段对用户感知与网络性能指标之间的关系进行更深入研究。并且本文采 用离线分析方法，后续可搭建在线满意度预测平台，根据用户所处网络环境实时预测其 网络满意度。
参考文献
[1]李小虎.《信息通信行业发展规划(2016—2020年)》解读[J].科技中国,2017(06):59-62.
[2]艾媒产业升级产业研究中心.2019中国携号转网新规用户心态与行动预判调研报告. https://www.iimedia.cn/c400/64504.html, 2019-05-23.
[3]马宁.运营商如何进行数字经济下的IT转型[J].通信世界,2013(9):27-27.
[4]工信部联通信[2018) 87号，国资委关于深入推进网络提速降费加快培育经济发展 新动能2018专项行动的实施意见,2018.
[5]黄海峰.华为王纪奎:借大数据使能电信运营商数字化转型叫通信世界,2015(20):38.
[6]王纯麟，何建敏.基于AdaBoost的电信客户流失预测模型[J].价值工程，2007 (02): 106-109.
[7]	Tan PN, SteinbachM, Kumar V.数据挖掘导论[M].人民邮电出版社,2006.
[8]李昆仑，曹铮，曹丽苹.半监督聚类的若干新进展[J].模式识别与人工智能，2009, 22(5):735-742.
[9]周志华.《机器学习》[M].北京：清华大学出版社,2016.
[10]	Merz C J, Clair DCS, Bond W E. Semi-supervised adaptive resonance theory (smart2)[A] // [Proceedings 1992] IJCNN International Joint Conference on Neural Networks[C]. Baltimore: IEEE, 1992: 851-856.
[11]	Pedrycz W, Amato A, Di Lecce V, et al. Fuzzy clustering with partial supervision in organization and classification of digital images [J], IEEE Transac-tions on Fuzzy Systems, 2008,16(4): 1008-1026.
[12]	Klein D? Kamvar S D, Manning C D. From instance-level constraints to space-level constraints: Making the most of prior knowledge in data clustering[R]. Stanford, 2002.
[13]	Wagstaff K5 Cardie C, Rogers S, et al. Constrained K-means Clustering with Background KnowIedge[C]// Proceedings of the Eighteenth International Conference on Machine Learning (ICML 2001), Viliams College, Williamstown, MA, USA, June 28 - July 19 2001. Morgan Kaufinann Publishers Inc. 2001.
[14]	Yang 丫 Tan W Li [ et al. Consensus clustering based on constrained selfbrganizing map and improved Cop-Kmeans ensemble in intelligent decision support systems [J]. Knowledge-Based Systems, 2012, 32: 101-115.
[15]	Basu S9 Banerjee A, Mooney R J. Semi-supervised Clustering by Seeding[C]// Machine Learning, Proceedings of the Nineteenth International Conference (ICML 2002), Univer-
59
sity of New South Wales, Sydney, Australia, July 8-12, 2002. Morgan Kaufinann Publishers Inc. 2002.
[16]常瑜，梁吉业,高嘉伟，等.一种基于Seeds集和成对约束的半监督聚类算法[J].南京 大学学报(自然科学版)，2012,48(04):405-411.
[17]	Rodriguez A, Laio A. Clustering by fest search and find of density peaks [J]. Science, 2014, 344(6191):1492-1496.
口8]刘如辉，黄炜平，王凯，等.半监督约束集成的快速密度峰值聚类算法[J].浙江大学学 报(工学版),2018, 52(11):2191-2200.
[19]陶性留，俞璐，王晓莹.基于非负矩阵分解和模糊C均值的图像聚类方法[J].信息技 术与网络安全,2019, 38(03):44-48.
[20]	Voiron N, Benoit A, Lambert P, et al. Semi-supervised spectral clustering with automatic propagation of pairwise constraints[C]// 13th International Work-shop on ContentBased Multimedia Indexing (CBMI), Prague, 2015: 1-6.
[21]	Zhou Y Wang Y Chen D, et al. Semi-supervised spectral clustering algorithm based on bayesian decision[J]. Journal of Computational Information Systems, 2015, 11(4):1333-1342.
[22]	Roul R K5 Sahay S K. Semi-supervised clustering using seeded-kMeans in the feature space of ELM[C]// IEEE Annual India Conference (INDICON), Bangalore, 2016: 1-6.
[23]	Fogel S5 Averbuch H, Cohen D, et al. Clustering-Driven Deep Embedding With Pairwise Constraints [J]. IEEE engineering in medicine and biology magazine: the quarterly magazine of the Engineering in Medicine & Biology Society, 2018,39(4): 16-27.
[24]	Tian J? Ren Y Cheng X. Stratified Feature Sampling for Semi-Supervised Ensemble Clustering[J]. IEEE Access, 2019, 7:128669-128675.
[25]	Schapire R E . The strength of weak learnability [J]. Proceedings of the Second Annual Workshop on Computational Learning Theory, 1989, 5(2):197-227.
[26]	Breiman, Leo. Bagging predictors[J]. Machine Learning, 1996, 24(2):123-140.
[27]	Yoav Freund, Robert E Schapire. A Decision-Theoretic Generalization of OnLine Learning and an Application to Boosting[J]. Journal of Computer and System Sciences, 1997?55(1).
[28]	Breiman L. Random Forestsf J]. Machine Learning, 2001, 45(1):5-32.
[29]	Breiman L. Stacked Regressions[1]. Machine Learning, 1996, 24(1):49-64.
[30]	Ting K M, Witten IH. Issues in stacked generalizationfJ]. Journal of artificial intelligence research, 1999, 10: 271-289.
[31]	Bamwal A, Bharti H P, Ali A, et al. Stacking with Neural Network for Cryptocurrency investment[C]// New York Scientific Data Summit (NYSDS), New York, USA, 2019 :l-5.
60
[32]	Matlock K, Niz C D, Rahman R, et al. Investigation of Model Stacking for Drug Sensitivity Prediction[1]. BMC Bioinformatics, 2018, 19(3):71.
[33]	Liu J, Shang W, Lin W. Improved Stacking Model Fusion Based on Weak Classifier and Word2vec[C]// 17th International Conference on Computer and Information Science (ICIS), Singapore, 2018:820-824.
[34]	Zhang X M, Wang Z J, Liang L P,et al. A Stacking Algorithm fbr Convolution Neural Network[J]. Computer engineering, 2018,4:243-247.
[35]郝益勇.提升移动网络用户体验质量的理论与方法研究D].北京：北京邮电大学, 2012.
[36]孔敏.基于用户体验的异构网络资源分配策略研究[D].浙江大学,2016.
[37]李睿.杭州移动通信用户满意度及提升研究[D].江西财经大学,2016.
[38]赵倩，尚学群,王淼.基于seeds集和频繁项集挖掘的半监督聚类算法[J].计算机工程 与应用,2010, 46(08):123-126.
[39]周志华.基于分歧的半监督学习[J].自动化学报,2013, 39(11):1871-1878.
[40]尹学松，胡思良，陈松灿.基于成对约束的判别型半监督聚类分析[J].软件学报, 2008(11):2791-2802.
[41] Han J W, Kamber M 数据挖掘：概念与技术[M].第二版.范明,孟小峰，译.北京: 机械工业出版社,2007.
[42]周星，丁立新,万润泽，等.分类器集成算法研究[J].武汉大学学报：理学版，2015, 61(6):503-508.
[43]伍育红.聚类算法综述[J].计算机科学,2015(Sl):500-508.
[44]	Huang H, Cheng Y Zhao R. A semi-supervised clustering algorithm based on must-link set[C]// International Conference on Advanced Data Mining and Applications. Springer, Berlin, Heidelberg, 2008: 492-499.
[45]	Wagstaff K, Cardie C, Rogers S, et al. Constrained k-means clustering with background knowledgefC]// Icml. 2001,1: 577-584.
[46]朱明.数据挖掘导论[M]- 2012.
[4刀李涛，葛洪伟，苏树智.自动确定聚类中心的密度峰聚类[J].计算机科学与探索,2016, 10(11):1614-1622.
[48]李莺.运营商投诉行为的大数据分析及应用[口通信企业管理,2016(10):67-69.
[49]徐慧丽.Stacking算法的研究及改进[D].广州：华南理工大学,2018.
[50]叶志飞，文益民，吕宝粮.不平衡分类问题研究综述[J].智能系统学报,2009,4(2):148-
156.
[51]谢花花.面向不平衡数据集的分类算法研究及其在通信智能运营方面的应用[D].
61
北京邮电大学,2018.
[52] Chawla N V, Bowyer K W, Hall L O, et al. SMOTE: synthetic minority oversampling technique [J]. Journal of artificial intelligence research, 2002, 16: 321-357.
[53]刘枫，雷振明,刘芳.用户感知的Web业务QoS指标与测量[J].北京邮电大学学报, 2009, 32(2):97-100.
[54]郑勇成.GY网络客户满意度提升研究[D].成都：电子科技大学,2012.
[55]刘志惠，黄志刚，谢合亮.大数据风控有效吗?——基于统计评分卡与机器学习模型的 对比分析[J].统计与信息论坛,2019, 34(09):18-26.
62
