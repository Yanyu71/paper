

第一章绪论
1.1课题研究背景及意义
随着21世纪中国的经济的迅猛发展，交通车辆运输也取得了飞速的发展。 交通作为经济发展以及社会和谐的基础，越来越成为社会进步的重要力量，但与 此同时交通的压力也越来越大，基础设施短缺以及现有设施的低效率所引起的运 输承载能力与需求之间的矛盾成为亟待解决的问题。所以，交管部门在很多方面 比如资金人力包括体制等方面给予投入和支持，这些问题得到了初步的缓解，但 是问题并没有得到根本上的解决。智能交通系统（ITS）⑴应运而生，这个系统 的一个核心理念就是应用高科技技术比如计算机视觉，智能通信等技术去解决在 道路交通系统中出现的各种问题。
ITS具体概念是指借助于先进技术，将对道路交通的管理体系组建成一个智 能的网络，规划城市交通发展方向，改善人们出行，并且引导人们未来出行朝着 智能且低能耗低污染的方向发展。ITS的发展得益于现如今多种高科技技术的发 展，比如机械控制技术，计算机视觉技术，信息通信技术等，ITS发展有三点比 较重要，首先是改善人与交通的关系，从以前交通对人类的服务限制到现在交通 能更好更全面的服务人类。其次人类安全问题，智能交通系统可以改善交通阻塞， 降低交通事故发生的频率。最后是改善人与自然的关系，交通发展到现在对自然 有很多的破坏，通过降低这种破坏，可以有效的保护自然环境。
建立ITS系统首先需要获取关于道路交通的数据信息。目前，获取车辆数据 有很多办法，包括线圈检测，红外线检测，视频图像检测等。本文主要介绍基于 视频图像的车辆检测与跟踪技术。基于视频的方法在获取视频数据之后通过图像 处理以及计算机相关处理技术对视频中交通道路和车辆进行分析，具体可以分为 两个方面，首先是对于车辆来说，通过对视频中车辆进行监控跟踪，可以实时获 得车辆的车速，行车轨迹，各个车道的车流量等基本信息。在得到道路车辆基本 信息之后，通过对这些信息进行分析，确定是否有可能导致违法违章行为，从而 有效降低交通事故发生频率，将不安全因素扼杀在摇篮之中。因此基于视频的车 辆检测与跟踪具有深远的研究意义。
1.2国内外研究现状
视频监控技术发展到今天，在计算视觉领域一直是重点内容，关键思想就是
通过视频图像的处理对运动中的车辆进行检测，目标提取，识别跟踪等。车辆道 路的视频分析是一个重要的研究方向，许多科学工作者致力于这方面的研究，并 且硕果累累。
1.2.1智能交通系统的研究现状
随着人们生活条件的改善以及汽车等制造业的发展，人在享受现代文明带给 我们的便捷的同时，也要面对由此带来的诸多的问题，比如环境的污染，交通堵 塞，以及交通安全问题。此时，人们把关注的目光投向了智能交通系统。在相当 长的一段时间之内，国际各国在这个领域进行了相应独立的研究工作，并且取得 了很大成果和进展。其中，美国是最先对智能交通系统开展研究工作的国家，从 上世纪60年代以来，美国政府强力支持进行智能交通系统的开发和探索。从 1980以来，智能交通系统在生产制造业和电子产业的推动下，有了长足的进步。 在1991年，ISTEA议案被通过，智能交通系统得到美国政府的财政支持从而迅 速的发展起来。从1996起，卡内基梅隆大学开始开发基于视频的监控系统VSAM, 并且取得了较大的成功。日本的智能交通系统发展在全球也属于先进行列。虽然 起步晚，但是日本在1996年，实现了世界上第一个大规模的车辆多信息通信系 统，名为VICS。这个系统从诞生以来得到迅速推广使用，截止到2003年，已经 全面覆盖日本，系统得到包括90多个公司的支持，因此功能十分强大，促进了 当时的交通发展，比如交通事故的处理，解决道路拥堵问题，在更大程度上保证 了人们出行安全和交通顺畅。欧洲各国人口密度较小，但是车辆道路的距离长， 并且车流量也较大，因此智能交通系统在欧洲也得到了发展。1986年，欧洲首 个智能交通系统PROMEHEUS开始建立起来，这个系统从保障欧洲整体的交通 运行效率，人们出行安全以及环境的角度出发，经历初步试水。现如今，在欧洲 英国，德国，法国等诸多国家，已经建立了比较完善的智能交通体系。
我国开始在智能交通系统领域的探索并没有很早，主要的原因是建国之初我 国的车流量比较小，因此在交通拥堵以及安全上的问题并没有像发达国家那样尖 锐，当时我国的工业制造技术以及计算机技术都不够成熟，因此这一领域开始并 没受到足够的重视。从80年代以来，我国开始对智能交通技术进行相关的探索， 虽然没有建立成型的系统产物，但是也为之后的研究奠定了基础。进入90年代 后，随着我国经济的飞跃发展，交通问题在我国越来越凸显出来，因此也促进了 人们把关注焦点转移到交通系统的智能化管理上。为此我国在1999年，在国家 十五规划重点项目中首次加入了智能交通系统项目。21世纪以来，我国己经明 确了未来我国的智能交通系统的发展方向，对相关的重难点问题的研究也相应的 开展起来。
综上所述，我国的ITS方面技术水平还没达到世界领先行列，但在不久的将 来，越来越多的科研工作者会参与进来，相信随着我国综合实力的提升，智能交 通系统定会取得更大的发展。
1.2.2目标检测与跟踪研究现状
在智能交通系统中，比较关键的任务是目标检测与跟踪。其中，目标检测是 车辆检测中的至关重要的一步。目标检测的主要任务是提取图像视频序列中感兴 趣的目标，对车辆检测来说，感兴趣的目标就是车辆，对于行人检测来说，感兴 趣的目标就是人。常用的目标检测算法有帧间差分法⑵，光流法⑶以及背景差分 法⑷等。帧间差分法是利用视频连续帧内运动物体产生的差异像素，通过分割方 法得到目标前景掩码图。这种方法简单有效，但是在背景随着时间快速变化的场 景，这种简单的背景减除法效果较差。而且当前景物体运动缓慢或者较大时，背 景减除法还容易导致鬼影和空洞现象。目前帧间差分法主要有相邻帧间差分法以 及多帧差分法。
光流法的基本思想是为所有像素建立自己的运动矢量，然后计算出目标的运 动场，光流法优点是在复杂的场景下也能取得好的效果并且不需要获取车辆的先 验信息，最大的一个问题就是计算复杂度高，不太适合实时性能要求高的场景。
背景差分法基本思想就是利用视频的当前帧与建立的背景图进行作差得到 目标区域。背景模型需要准确的检测出运动前景，即对变化敏感，称为检测的灵 敏性。同时能够适应背景的变化，即鲁棒性。在前景检测中，如何区分视频帧内 的变化来自前景目标还是背景是一个很难的问题。在过去的几十年里，背景建模 技术一直受到国内外学者的广泛关注，并且各种方法被先后提出，这些方法都有 自己的优缺点。为了解决背景模型应当能够快速适应背景变化的问题，基于统计 学习的方法在近年来得到快速发展，如高斯背景建模法⑸，自适应混合高斯模型 等改进方法不断被提出。根据算法处理像素数据的方式，通常将背景模型算法分 为大致三类，包括像素级方法，区域级方法和帧级方法。
目标跟踪是在对目标进行检测的基础上进行识别和跟踪，即在视频序列中捕 捉运动目标物体，获得目标的运动参数信息等。这里主要有两方面的问题，一是 如何对目标的运动进行表示，也即选用哪种模型来表示目标；二是如何对跟踪目 标建立观测模型。目标的运动轨迹具有不确定性，导致对其运动轨迹建模的困难 性，并且目标的运动会受到诸如角度，尺度变化以及光线阴影和遮挡问题的影响， 这些对目标的观测模型的建立是一个相当大的挑战。为了进行可靠的跟踪，研究 学者们提出了很多方法，主要分为模型跟踪法，目标区域跟踪法，目标特征跟踪 法等。

车辆的检测跟踪是智能交通系统的核心技术，首先，车辆检测中一个难点问 题是对车辆前景的提取，因为视频监控环境的复杂性，以及场景光照变化，运动 阴影，背景改变以及摄像机抖动等外界的因素都会严重影响检测效果。其次，车 辆跟踪时的车辆遮挡，外物干扰等因素也会引起信息不准确从而导致跟踪失败。 以上这些对系统性能提出诸多挑战，通过研究这些重难点问题，不仅能够提升我 国在智能视频交通领域技术的发展水平，还会推动我国智能交通系统的发展，从 而有效解决我国日益凸显的交通问题，降低交通安全事故发生频率，真正意义上 改善人民生活水平。
1.3论文整体安排
从上面的分析看出，对视频中感兴趣的物体进行检测和跟踪，一直是计算机 视觉领域的热点问题。视频是由图像组成的时间序列，通过对视频的分解，可以 得到一帧一帧的图像，因此本文在现在图像处理和计算机视觉领域技术的基础之 上，通过对车辆检测与跟踪中几个关键问题的研究以及提出改进方法，从而形成 一套完整的车辆道路监控系统，具有广泛适用性。
本文共六章，分章情况如下：
第一章是绪论。主要是介绍视频目标检测与跟踪研究背景和意义以及国内外 目前的研究现状情况。最后是介绍论文的研究内容以及行文安排。
第二章是图像预处理算法。主要是介绍典型的图像处理方法，包括后面检测 与跟踪环节会用到的相关算法。
第三章是车辆检测算法，首先介绍前景检测技术背景，重点提出基于改进 Vibe背景建模算法以及融合多特征的阴影分割算法。通过对改进的Vibe算法与 原先算法进行实验比较分析，改进算法的检测效果有了提升。基于改进的多特征 融合的阴影去除算法，根据阴影的特点，在传统特征融合的基础上，完成HSV 无参化，并且加入前后帧关联信息同时与纹理特征融合，从而得到前景运动目标。 最后通过空间一致性调整，得到相对准确的前景目标，通过与其他方法比较，本 方法不仅性能上有了提升，并且具有自适应性，能很好的检测并去除阴影区域。
第四章是车辆跟踪算法。首先介绍目标跟踪领域常用算法，然后阐述本文基 于粒子滤波框架跟踪以及遮挡处理相关改进算法。为了对获取对车辆精准表示的 车辆观测模型，同时适应不同光照，提出了增强HOG和颜色融合的观测模型。 在车辆遮挡处理中，通过利用轮廓检测遮挡与分割线法的处理，一定程度上解决 了车辆遮挡问题。
第五章是系统设计和实验结果。通过对系统各个模块进行总结，以及实验仿
真，得到系统实际结果，并与其他系统进行对比，从而证明本系统的实用性以及 稳健性。
第六章是总结与展望。本文在前景检测，运动阴影检测和目标跟踪三个方面所 做的工作进行了总结，最后阐述了下一步值得研究的方向。
第二章图像预处理
图像是以各种观测技术和手段从客观自然中获取得到，可以直接投射于人眼 进而产生视觉知觉的实体挣〕。通常图像以矩阵或者数组来表示，其中每个元素的 坐标代表相应点的位置信息，元素的大小代表了相应点的特征量。视频是由图像 连续展示得到，帧也就是视频中的一幅图像，由于视频图像是直接从客观世界获 取，因此含有丰富的原始数据，并且视频图像优于单张静态的图像的特点是对运 动信息的获得。视频文件在摄像机采集传输和记录的过程中，常常受到噪声因素 的影响，包括摄像机本身带来的电路干扰，成像失真问题，以及外界光照变化和 阴影等因素卩〕。因此要对视频图像进行变换校正，以消除图像中的噪声或者去除图 像中不感兴趣的部分，从而有利于对目标的信息的获取。相应的图像变换方法称 为图像预处理。图像预处理方法有很多，常用的有图像灰度化，图像去噪，对比 度增强等
2.1视频图像预处理简介
视频图像可以用函数f(x,y)表示,其中的x, y是坐标表达，如果对二维函数 以x,y进行离散化，得到的是数字图像。数字图像可以看作是一个二维矩阵，矩 阵中的数字单元就是像素，数字单元的大小就是该点的灰度值。
图像预处理涵盖广泛，其中主要的内容有图像变换，图像去噪，图像加强， 图像压缩与解码，图像分割与识别等内容。图像变换的目的是方便图像处理，图 像变换是多种图像处理的基础，能够从不同角度获取图像信息，分为可分离变换 和统计变换，可分离变换包括傅立叶，快速FFT以及其它可分离变换，统计变 换包括霍特林变换等。图像去噪是图像预处理里面比较关键的，不论是在模拟处 理系统中还是数字处理系统中，对图像去除噪声都是必不可少的。图像去噪的算 法有许多种，如均值滤波去噪，中值滤波去噪，贝叶斯阈值去噪等。图像增强的 目的为了增强图像里面的有用成分，改善图像的视觉体验，譬如在不同场景下， 往往需要重点突出图像的某些整体或者局部的特性，从而有利于对图像进行识别。 图像增强有空域处理法和频域处理法，其中在空间域处理是将数字图像在灰度空 间内做变换，通过不同的变换函数，得到效果不同的增强图像。频域处理法是将 图像在频域上通过频域相关处理函数如对中，低，高频等不同频段信号的截断等， 控制信号频率域范围，从而改变图像对比度的方法。一般情况下，用空域法增强 图像是行之有效的方法，而用频域变换有可能造成图像失真，并且频域变换法占 用计算机较多内存，效率相对低。图像识别指的是对图像利用计算机视觉技术进 行理解分析，识别出目标物体。图像分割是通过分割算法将图像分割成具有不同 特性的区域，从而得到关于图像结构属性以及感兴趣区域信息的过程。常用的分 割算法依据的主要有阈值，区域，边缘等。图像压缩编解码是在满足一定保真度 要求下，去掉冗余数据，更方便快捷的进行数据的传输和存储。
一般来说摄像机获取的图像多为彩色图像，在许多场景下，需要将彩色图像 转化成灰度图像。彩色图像有RGB,HSV,YIQ等颜色空间，它们之间的转换也是 处理图像常用的方法。图像灰度化是只保留图像的亮度特征，在YIQ空间中，Y 指的是颜色的明亮度，也就是灰度，由RGB图像的到灰度图像，公式为， Y=0.2999R+0.587G+0.114B,其中系数是经实验验证的合理的值。
2.2图像去噪
噪声是图像干扰的一个主要原因，在实际中，图像噪声会影响人们对于图像 信息的感知获取。实际中，图像含有多种噪声，这些噪声的来源也有很多种，可 能在传输时或者量化时等情况下产生的。噪声主要分为三种，第一是加性噪声， 加性噪声与输入图像信号无关，比如在信道传输时的噪声归于这一类。第二是乘 性噪声，这种噪声与输入图像相关，通常会成为输入图像信号的系数影响。第三 种是量化噪声，这类噪声与输入图像没有关联，是量化时出现了量化误差导致的。
2.2.1均值滤波去噪
均值滤波也是一种常用的去噪算法，它的基本原理是对像素点周围邻域像素 点求取平均值来取代此像素点的值，假如像素点位置为(X,/，利用一个模板去 卷积对应位置，该模板对应像素点的邻域像素，通过模板卷积得到周围像素的平 均值，并赋值给此像素点，作为图像去噪后在该点上的灰度值.如图2T所示。

图2-1均值滤波樸板

当前点为(x,y),其余8个像素点是其周围邻域像素，根据下面公式求出模板 中像素的值。
g(x,y)=	—	(2-1)
其中g(x,y)为像素点(x,y)处理得到的灰度值，f(x,y)为(x,y)邻域的各个像 素点，N是邻域点的数目，反映不同的均值滤波模板大小，随着大小的增加，噪 声降低的越显著。均值滤波具有算法复杂度低，易于操作等优点，虽然可以去除 噪声，但同时会造成图像的模糊，隐去图像一些细节信息。
2.2.2中值滤波去噪
中值滤波的操作从原理上看是非线性的，所以它可以避免诸如均值滤波器等 线性滤波操作造成的图像变模糊等问题，缺点就是对于点，线等细节较多的图像, 会造成图像信息的丢失。
中值滤波也是一种邻域处理算法，与均值滤波不同的是，它求得图像邻域像 素的中间值，来代替当前点像素值。中值滤波的基本思想是，将滤波掩膜也就是 滑动窗口，在图像中从左往右滑动，将掩膜中心置于当前像素点处，取出掩膜各 个位置对应的图像像素点值，进行排序，找到所有数据的中间值，并用这个值去 替代中心点的像素值，取中值公式为：
g(x,y) = med(Jx, f2,	(2-2)
其中秫勿函数就是取中值函数。在实际中，滤波模板的尺寸和大小会影响去 噪结果，所以模板的选取也比较关键。典型的模板形状有正方形，菱形，圆形等 类型，模板大小有3x3, 5x5,7x7,具体实际中选取大小可以通过多组实验确定。 中值滤波比较适合处理如椒盐和脉冲噪声等类型的噪声，由它产生的模糊也相对 较少。

图2-2加入椒盐噪声



图2-3均值滤波结果



图2-4中值滤波结果

其中图2-2是在视频图像中引入椒盐噪声的结果，可以看出，噪声干扰下的 图像变得非常模糊。图2-3是利用均值滤波对图像去噪的结果，虽然能去掉一些 噪声，但是会导致图像变得更模糊，效果不太理想。图2-4是利用中值滤波去噪 的结果，噪声得到有效去除，虽然图片质量有略微下降，但是还在可以接受的范 围之内。因此可以看出在这种场景下，中值滤波去噪往往要比均值滤波去噪更有 效。
2.3图像二值化与二值图像处理
2.3.1图像二值化
图像中像素点之间存在着灰度差异，正是利用这一方面差异，可以将图像通 过阈值法划分的方法将像素分为两类，一类是前景目标，一类是背景，这样就得 到了一个二值化的图像。
假定阈值分割法选取的阈值为T,通过这个阈值将图像中像素分为两类，设 输入图像为输出结果为g(x,y),则

上图中图2-5(b)是对视频帧和背景差分图进行二值化操作的结果，从图中可 以看出，通过二值化操作，车辆区域被检测出来。阈值的选取很关键，常用的二 值化方法如最大类间方差算法，思路是当图像分类间方差最小，且不同类别间方 差最大，此时求得的阈值为最佳阈值，可用于对图像进行分割。
2.3.2连通域分析
二值图像的处理包括很多方法，首先是图像连通域分析。在图像中，像素点 位置相邻且像素值相同，这些点构成的区域被称为连通区域。连通域算法的目的 就是对二值图像进行分析，将图像中各个连通区域找出并标记，它是所有二值图 像分析的基础，进一步可以获得连通块的相关参数信息。
从连通区域的定义可以知道，一个连通区域是灰度值满足特定规则的相邻像 素的集合，在图像中，作为最小的图像单元，每个像素周围有若干个像素，常见 的邻域形式4邻域连接与8邻域连接，4邻接一共有4个邻接点，8邻接一共有 8个邻接点。当像素点a与b邻接，称为a与b连通。如果a与b连通，b与c 连通，则a与c连通。直观上看，同一个区域是由相互连通的点组成，不连通的 点构成了不同的区域，而同一个区域就被称为称为连通区域。
对连通区域进行标记的算法分为不同的类型，对图像的遍历次数也不尽相同。 一种常用的连通域遍历方法是两遍扫描法，首次进行扫描时为图像中的每个像素 分配一个标签，这个标签分配的规则下面将会给出，分配完成之后，同一个连通 区域内的像素点有可能含有不同的标签。再次扫描时就是将这些属于同一个连通 区域内并且符合相等准则记录的标签改成同一类标签。具体步骤如下： 1)首先开始扫描时，访问当前像素f(x,y),当/(x,y) = l时，如果f(x,y)的
邻域中像素值都为0,就赋给f(x,y) 一个新的标签Lo

Z = Z+1; f(x,y) = L	(2-4)
如果Rx,y)的邻域中有像素大于1的邻域，则将邻域的最小值赋值给f(x,y)。
f (x, y) = nnn{neighborhood}	(2-5)
同时记录邻域中各个值之间的归属关系，即这些值同属于同一个连通区域。
L_Set[i] = {L_m,	(2-6)
2)第二遍扫描时，访问当前像素f(x,y)如果_/(x,p)>l,则找到L = f(x,y)具有 归属关系的最小标签值，赋值给最终结束扫描时，相同标签的像素 点归属于同一个连通区域。
2.3.3二值图像填充
图像填充是指填充一个不完全连通的二值图像，从而形成一个完全连通的图 像。一般情况下，通过前景检测得到的车辆目标区域常常是不连通的，从而影响 后续跟踪结果，因此需要对其进行图像填充。对图像进行填充有很多方法，下面 介绍一种比较简单且常用的方法，主要分为两步，横向填充和纵向填充。
1)横向填充:首先从左往右扫描二值图像f(x,y)的第m行,找到第一个点(四/) 的灰度值为0,然后再从右往左同样扫描这行，找到这个扫描方向上第一个 灰度值为0的点则在这行内像素点到像素点(秫,；2)之间的所有 像素点就被设置为前景像素点，也即灰度值设置为0。
=	j = n,...,h	(2-7)
2)纵向填充：首先从上到下扫描二值图像f(x,y)第JI列，找到第一个灰度值为 0的像素点対,然后再从下到上扫描二值图像f(x,y)的这一列，找到这个 扫描方向上的第一个灰度值为0的点(y,k),这时像素点0,幻和像素点(v,幻 之间的所有像素点被设置为前景像素点。
(2-8)
从上一小节的车辆前景的提取结果可以看出车辆区域存在很多空洞，通过图 像横向和纵向填充得到填充后的前景图，对车辆空洞的部分填充完整，有利于后续车辆检测等过程。
2.4图像增强
图像增强是图像处理的一个很重要的研究点，增强技术是根据不同的处理需 要对图像中不需要的信息加以去除或者削弱，从而增强地显示图像中的感兴趣的 信息，目的是使得在特定的场景下，处理后的图像相比于比未处理图像更有用。 因为强调图像的整体或者局部特性，所以图像增强可以丰富图像信息，有利于对 图像的理解和判别效果。然而图像增强又是一个失真的过程，因此需要对算法优 缺点和应用场景有个清晰的把握。
随着越来越多专业相机和其他摄像设备的普及，图像数据量日益庞大，在这 些图片里，有些因为场景条件的限制如光线，动态场景变化，会导致图片效果质 量一般，因此需要通过后期的处理手段去调整，图像增强便是人们关注越多的一 个方向，因为这些图像增强方法考虑了人类视觉系统的特性，使得在多种光照条 件下能清晰突出细节。图像增强算法主要分为两个种类：频率域法冏和空间域法, 常用的是空间域方法。
2.4.1空域图像增强算法
空域的图像增强是对图像中像素灰度值进行特定的增强处理操作，一般来说, 空域图像增强主要有灰度变换和直方图均衡化处理方法，下面将对这两个方面进 行介绍。
(1)灰度变换主要是通过变换操作将图像灰度映射到不同的范围内，从而有选 择地增强感兴趣灰度区间的目的。变换函数有很多种，其中线性变换，非线性变 换，分段线性变换是比较常用的几种。假设处理前图像像素的灰度值为 D= /(x,*)为图像坐标，处理后图像像素的灰度值为D'=f(x,y),则 灰度变换的函数可以表达为：
g(x,y)=T[f(x,y)] (2-9) 处理前灰度值D和处理后灰度值D'必须要在灰度表示范围以内，变换函数通过 建立输入灰度值和输出灰度值的转换关系，从而计算得到映射后图像。灰度变换 函数处理的最小单元是单个像素值，整体上通过调整图像像素所在的灰度范围而 使得处理后的图像得到良好的视觉效果，在灰度变换的时候像素点之间的关系是 独立的，并不会加入像素点之间的关联信息。
灰度线性拉伸是一种基本的灰度变换，其中常用的是分段线性变换，如下图所 示：

图2-7分段线性变换

从图2-7可以看出图像部分区域进行了压缩操作，部分区域进行了拉伸，分 段线性变换通过确定不同的分段区间以及不同分段区间各自曲线的斜率等来对 图像中任意灰度区间进行拉伸和压缩。具体可以根据图像的原始灰度分布来确定 是通过拉伸压缩部分哪些灰度区间来改善图像视觉效果。

(a)原图

(C)灰度变换图

图2-8图像灰度变换
图2-8将图像首先从彩色空间转变为灰度图，再进行灰度变换得到2-8 (c), 可以看到灰度变换后图像相比于变换前来说，对比度有显著提高。
(2)直方图广泛应用于各种空间域图像处理技术。直方图均衡化是利用直方图 进行图像对比度调整，当一幅图像对比度不高时，可以通过这种方法把亮度信息 在直方图上分布开，增强图像的局部对比度。假设原始图像用/'(X,7)表达，直方 图均衡化后的图像是跟g(x,y),那么从图像f到g的映射关系用函数表达为： g =心)	(2-10)
假定图像的灰度级是K,以上函数必须要满足两个条件：首先是龙co函数必 须是一个单调递增函数，从而保证原始灰度级次序没有被打乱，仍然符合从黑到 白的次序。其次是变换后g具有与/一样的灰度动态范围。直方均衡化一般采用 的映射函数是累积分布函数，累积分布函数是对概率密度函数的积分表达，在直 方图均衡化问题上计算方法为：
ht (/) =/ n,	f = 0,l,2,上一1	(2-11)
表示灰度级为，时的像素个数，”为图像中的像素总数。通过以上公式可以 知道，直方图归一化之后所有部分的和为1。直方图所做的操作属于一种非线性 拉伸，它改变整个的直方图分布，将原本或密集或稀疏的灰度空间变得均匀分布。
本文中对彩色图像进行直方图均衡化，即将彩色通道中亮度通道进行直方图 均衡化，结果见图2-9,相比于图2-8(a),图像的对比度有了直观的调整。



图2-9直方图均衡化

2.5本章小结
本章是视频车辆检测阶段比较关键的一步，先后介绍了图像去噪，图像二值 化和二值图像处理，图像增强等预处理方法，为下一章车辆前景的准确提取奠定 了基础

第三章车辆检测模型
在对视频图像进行预处理操作之后，如何准确的进行车辆检测也是一个非常 基本的问题，因为有效的车辆检测是车辆进行准确跟踪，以及车辆道路检测，车 速检测等的前提。
基于视觉的车辆检测方法仍然面临着巨大的挑战，因为在真实的车辆场景中, 很多的因素都会影响最终车辆检测的跟踪效果，比如摄像机抖动，光照的变化， 背景树叶的晃动，以及车辆或者周围物体的阴影。车辆检测算法必须能够有效应 对这些问题，完成对车辆前景的完整检测。
本文对车辆检测领域的基础方法进行了介绍，主要是对原理的阐释以及根据 实验仿真结果分析各个算法的优势以及劣势，在原有基础算法上进行改进，并且 对车辆检测中出现的阴影问题进行研究分析，提出改进策略，从而提高检测结果 的准确性。最后对车辆前景轮廓进行处理，得到相对完整的车辆前景二值掩码图， 为车辆的跟踪奠定基础。
3.1车辆检测算法介绍
视频序列具有时间连贯性和空间连贯性，因此根据视频序列的这些的特点， 对视频中的目标车辆进行检测，就是需要在时空上去描述目标。首先需要通过对 视频图像进行分割，得到背景和前景，然后从前景目标部分通过后续的阴影去除 步骤得到真实的车辆前景。
3.1.1帧间差分法
帧间差分法是比较常用简单的前景检测算法，基于在视频图像序列中相邻帧 图像具有时间和空间上的相关性而提出。主要思想就是通过相邻视频的后一帧图
像与前一帧图像作差，得到一个差分图像，用公式表达为:

公式中比较关键的一个参数就是阈值T,如果大于阈值7,则图像像素被认 为是前景点，如果小于阈值r,则像素点被认为是背景点。



图3-1帧间差分法流程图
该算法对光照的变化不是很敏感，因此比较适合在动态场景下使用，并且算 法复杂度很小，能够满足系统实时性的要求，但是算法的不足之处就是当运动目 标静止或者较大时，会造成比较低的准确度，但是当车辆运动过快时，会造成最 终检测的目标车辆区域大于真实的大小，并且如果当运动物体内部的灰度相对较 均匀的话，也容易产生空洞现象。



图3-3帧间差分法
图3-2是分别选取了交通视频的第65帧和150帧原始图像，图3-3是通过帧 间差分法得到的前景检测效果。从以上视频结果可以看出，帧差法能够检测出车 辆的大致位置，但是由于受到场景噪声以及参数的影响，比如当阈值选取比较大 时，容易造成目标检测不完整，如图3-3所示图中部分车辆区域在检测时并未检 测出来。另外一方面阈值如果选取的较小，也会加重场景噪声的影响。当目标车辆灰度一致时，会容易造成车体空洞现象，图中可以看出，车体部分存在明显的 缺失，并且图3-3中左侧图检测出来的车辆区域比实际车辆尺寸要大，以上这些 问题都会导致检测的不准确。现如今针对这些问题提出的一些改进算法，比如三 帧差分法回，通过将视频图像相邻的三帧进行差分，然后通过求与操作得到最终 的结果，能够有效去除一部分噪声，但是仍然存在目标不完整以及参数调整等诸 多问题。
3.1.2光流法
光流法主要是利用物体光流场随时间变化的特性。十九世纪五十年代，光流 场的概念被Gibson提出，在计算机视觉领域是重要的突破。当物体运动时，图 像序列中的灰度分布会变化，光流场法是通过图像中的模式运动速度，来反映图 像上每一个像素点的变化趋势。因为外界的运动场景变化会在人的眼睛里产生连 续'光’的流动，因此称为“光流"。在1981年，Hom和Schunk[10]提出了一种光流 场的计算方法。光流场是一个二维矢量场，包括场景物体的三维结构，各个像素 点运动速度矢量等信息。
具体来说，利用光流法检测运动物体的原理是：整个图像形成一个运动矢量 场，每个像素点都有自己的速度矢量，从而在投射的三维空间内根据速度矢量特 征，对图像中的像素点进行动态分析。由于目标相对于背景的运动引起矢量不一 致，从而对运动目标进行检测。具体计算方法是：假设E(x,y,t)是图像中像素点 (x,y)在时刻7的灰度表达，那么假设在，+也时刻该点运动到(X +必迎+ *),它的 光照强度为E(x + dx,y + cfy,t + dt),对应于同一点，根据光流约束方程：
E( x,y,t) = E(x + dx,y + dy,t+ dt)	(3-3)
其中 Ex = dE/dx , Ey = dE!dy , Et dE/dt, u = dx!dt , v = dy /dt a 每个图像 的像素点的运动矢量为(払v),并且需要注意的是，这里的速度是一个矢量，包 含运动大小和运动方向信息。在摄像机固定不动的情况时，理想条件下，只有前 景的运动才会有光流动，因此可以计算出亮度的梯度方向，也即sqrt^+v1), 而通过光流约束方程，比较容易求到梯度的光流速率。
V = abs(Et / sqrt{Ex xEx + Eyx Ey))	(3 -4)
通过设置一个阈值T,当/〉7时，像素点(xj)被认为是前景点，当丫＜T, 像素点是背景点。

图3-4光流法检测
在没有获取场景信息的情况下，光流法仍然可以检测物体的运动，并且光流 法的前提是物体表面光的入射强度是一致的，因为如果不满足这个条件，将无法 应用光流约束方程。光流法有很多缺点，从图3-4可以看出，实验结果受到噪声 的影响比较大。光流法比较容易收到光线环境的影响，对噪声相对敏感，并且光 流法的计算量偏大，运算复杂，因此不适合对实时性要求高的场景，这个方法只 适合在简单，较少变化且实时性要求不高的场景下。
3.1.3背景建模算法
在运动目标检测领域，背景建模是比较常用的算法之一，它的基本思想就是 对视频序列的背景通过建模，利用当前图像与背景的进行作差对比，可以得到前 景目标位置。背景建模算法自提出以来，存在诸多挑战如光照变化，背景的变化， 运动物体的阴影，以及场景噪声等，因此许多改进算法相继被提出。下面是背景 建模算法主要流程框图：

图3-5背景建模流程

(1)平均背景模型
平均背景模型【叫计算方法简单，且计算速度快，但是这种方法对环境光照变 化以及背景的变化比较敏感。其基本思想是通过对连续*帧的图像中每个对应的 像素点求取平均值得到背景模板的像素BAx,y),具体的计算公式为：
i+k
Bk(x 7 >-			 (3-5)
k
当检测当前视频帧时，只需要将图像像素值I(x,y)与背景模型中对应位置的 像素值Bk(x,y)作差，得到差值D(x,y),再将其与合适的阈值进行比较得到最 终的输出图像。
D(x, y) = /(x, y) 一 Bk (x, y)
\ \D\>TH
0? otherwise
关于77/的选取，则要借助于差值图像每个像素的平均值和标准差，具体计算 方法是：
E(x,(3-8) 1 M
Udlff(x,y) = — ￡	(3-9)
z=inter+l
J
7~\	插	A
- z (月(早)-。姆(时))2	(3-10)
\ /=inter+l	丿
通常为了保证求得的平均值和标准差的准确性，M值得选取要相对大些。此 时阈值TH可以通过公式：
TH = U.(x,y) — B*di0”d	(3-H)
与此同时要进行背景模板以及相关信息的更新。
L> (x,丿)=(1 一 q) xD(x, y) + ax 7(x, y)	(3-12)
U奶(x, y) = (1 - 口) * Udlff + □ x 日(x, y)	(3-13)
d飢a (x, _y) = (1 - a) x diffstd (x, y) + ax 冋 x, y) - U'顿(x, y)\	(3-14)
此处的a是学习率，通过调整学习率的大小可以控制背景模型更新的快慢，一 般a越大，对背景的变化的适应更快。
(2)单高斯背景模型
单高斯背景模型的基本思路就是把图像中所有像素点都当成是一个个的随机 分布，如果每个像素点的出现的概率是满足一个均值为",，方差为0的高斯分布, 用公式表达为：
1	一 E)2
P(Z(x,j,r)) = -7—e 潟	(3-15)
伊0
对于t时刻的像素值I(x,y,t),可以通过以下公式判断是否是背景像素：
号(X,》)=(1 一 a) x 度J (x, y)+ax (J(x, y, t) -u, (x, y))2	(3-16)
O(x,y,0 = ￡'	IK"。*-心，力I < Ox %(时)	(3.]7)
[1, otherwise
对于图像序列的初始背景模型的建立也比较重要，这里初始的均值和方差通 过下面公式计算：
uQ(x,y) = 7(x,^,0)	(3-18)
= std _inif	(3-19)
之后更新的策略是
u, (x, y)=(l-a)x ”,_i (x, y) + axl(x, y, t)	(3-20)
号(x, y) = (l-a)x	(x, p) + a x (7(x, y, 0 -ut (x,、))	(3-21)
算法具体的流程如下：
a.首先利用第一帧图像根据公式初始化背景模型
b.通过公式判别是否为前景像素点
c.依据背景更新策略更新背景模型
d.根据更新后的背景模型重新返回b步骤，进行检测
(3)混合高斯模型
由于在实际中，背景环境可能存在着多种扰动，如光照，树木的晃动等，会 导致背景像素值的不固定，而单高斯模型中将单个高斯分布作为像素值的概率密 度分布，这不利于处理多模态背景问题，因此在单高斯背景模型的基础上，混合 高斯模型做岀改进，对于一个背景像素点用M个高斯模型来表示，进而通过加 权平均这些高斯概率密度函数来近似表达任意形状的概率密度函数，所以每个像 素点出现的概率可以表达为：
= ￡w；Q(x,u")	(3-22)
i=l
其中讨为在时刻，第，个高斯分量的权重，对于这M个高斯分量，满足以 下公式的前n个高斯分布被认为是背景模型。
"=argmin 伍叫 >丁｝	(3-23)
b I-
其中T如果选取的较大，则可以描述相对复杂的背景，『如果选取的太小,则模型就成为单高斯背景模型，通常，选取『为0.7。
如果当前像素值其乂。与选取的前〃个背景模型中的第L个高斯分布匹配， 也即I(x, ys t)在 以；-zxb；,”；+zxcr；]范围内，通常z设置为2.5,则I(x, y, t)被 认为是背景点，反之就是前景，此时输出图像表达为：
O(x, W) = (°’ 此-腿31(可刃)W + *；	(3_24)
[1, otherwise
当像素点被检测为前景像素点，表示没有与这n个高斯分布匹配，因此选取 一个新的高斯分布代替当前高斯分布中权重最小的一个，这个新的高斯分布的期 望值就是当前像素值。当像素点被检测为背景像素点，此时就对该像素的权重信 息以及与之匹配的高斯分布的均值和方差进行更新，更新算法如下：
w； =(l_a)xw「'i <L	(3-25)
u, =(1 —+ eq)	(3-26)
(#)2 = (1 —0)x(用-y + QxQQ) — ")	(3-27)
其中a是权重学习因子，月是均值方差学习因子，都在0?1之间。如果当前 像素分布与第，个高斯分布匹配，则妬为1,否则为0。
从混合高斯分布的原理以及更新策略可以看出，这种方法有效的降低了噪声 的影响，混合高斯分布尤其适用于检测运动缓慢的物体，因为在短时间内不会形 成新的高斯分布，这样就比较容易被检测出来。混合高斯分布优于普通的二值化 分割方法的原因是由于图像中每个像素的运动特性都不同，这种情况下，每个像 素点分割所需要的阈值不尽相同，而二值化分割统一阈值会导致分割结果的不准 确，混合高斯分布通过对图像进行局部分割，更加精确。
⑷ ViBe
在2011年,Olivier Bamich[12]等人提出一种新的背景建模算法，即ViBe算法。 该算法是一种快速进行背景和前景目标检测的算法，现在的许多算法是通过收集 大量的点进行建模，并在模型找出匹配的多数点，通过当前点与多数点的值进行 最终的分类，而ViBe算法通过把背景像素点集合在一起作为背景模型，当前的 点需要与背景模型中的各个点进行比较，寻找色彩空间中距离相近的点。ViBe 算法通过视频的第一帧完成建模，效率高，实时性好。
ViBe背景建模算法通过为每一个像素点建立一个包含有N个背景像素点的模 型，表达为
M{x) = \vx,v2,...,vn]	(3-28)
其中v,为背景模型中第z?个像素点的值，模型的这N个像素值来自于前一帧， 一般N取20,像素点的分类就是对M(x)分类，在欧几里得色彩空间空间建立一 个半径为R,以v(x)为圆心的圆SR(v(x)),在圆的内部寻找距离像素点x小于R的所有点，并统计其数目为。，如果满足以下公式：
6?{Sr(v(x)c(3-29) 此时当前像素点被分类为背景，反之则是为前景。

图3-6欧几里得空间背景模型以及待分类像素点的分布

从图3-6可以看出在圆内，其他点都在圆外，如果编为2的话，则两 个点都是背景点。下面将介绍ViBe主要的算法思想：
a.ViBe的初始化
ViBe算法将初始化放在第一帧进行，主要思想是从视频的第一帧中的每个像 素点的周围邻域像素点随机抽取，从而建立背景模型。通过实验表明，选取八邻 域像素点会取得较好的结果。假设对于第一帧，用N(x)代表邻域像素点，则需 要建立的背景模型为
M(x) = (v(y I y g N(x))}	(3-30)
其中v(y|yeN(x))需要随机多次，一般随机次数取20,这样就构成了 20维 度的背景模型。
b.ViBe模型的更新策略
关于模型的更新，有三点是比较重要的，首先是随机更新策略，当像素点x 被分类为背景像素点，则随机地从该像素点的背景集合选择一个像素点匕，用x 来代替V,,这种策略能有效提高背景点被保存的概率。其次是时间的二次抽样， 因为在视频帧的处理中每帧都会进行更新，当更新频率过于频繁的时候，会导致 运算速度降低，并且也没有必要，因此可以通过二次抽样降低更新的频率，具体 是对于被判定为背景点的像素，根据一定概率决定是否对其进行更新，通常概率 为l/w，〃一般为16。最后是传播背景点像素，不仅x点的值会更新自己的背 景模型〃(x),也会对x点的邻域背景模型M(yeA^(x))进行随机更新，其中, 是从邻域点中随机选取，并且更新的值也是从x的背景模型中随机取得。这样做 的好处是，当摄像机发生抖动等变化时,不会造成大量的误检，从而保证准确性。
-二

图3-10 Vi Be背景建模检测结果

图3-7中显示图像来自是三个交通视频。图3-8, 3-9, 3-10分别为平均背景 模型，混合高斯背景模型以及ViBe背景模型的检测结果。下面主要从两个方面 进行对比，首先从检测效果上，三种背景建模算法能大致检测出车辆的位置以及 轮廓，平均背景模型和混合高斯背景模型在去噪能力上效果不如ViBe算法，混 合高斯模型对于前景车辆的检测最为完整，ViBe算法较完整，而中值滤波算法 检测的车辆比较不完整。其次从算法复杂度即运算速度上来说，ViBe算法的处 理速度最快，经实验统计，ViBe处理速度约为247仙，因此可以满足系统实时 性要求。
以上分析可以看出，ViBe算法具有较好的抗噪性，抗抖动能力，并且处理速 度快，因此本文系统在此基础上进行背景建模。


3.2改进的ViBe背景建模算法
ViBe算法利用第一帧进行初始化，但是如果第一帧的视频序列里面出现车辆, 那么车辆的像素点信息会被初始化为背景信息，在后面检测车辆过程中，当车辆 离开那个位置，仍能在此位置上检测出这个车辆，根据文献网，鬼影是由于将背 景点错误检测为运动物体而产生。
由于鬼影产生的本质原因是在第一帧初始化时将运动车辆像素点错误引入 进背景模型中，因此为了消除鬼影，必须要通过加入后续帧的信息，才能准确判 断第一帧图像中车辆是否存在运动。本节主要针对ViBe算法的鬼影问题进行改 进，具体的改进思想如下所示：
首先初始化一幅灰度都为0的灰度图片f(x,y),图片中的每一个点有一个计 数器和一个标志位，计数器和标志位都初始化为0o对相邻视频序列进行帧差, 获得二值前景图，如果当前二值图中像素为0,则对应像素点的计数器加1。当 达到一定阈值C并且当前的标志位为0时，就把当前视频灰度图像帧中的像素 值赋值给f{x,y),并把对应点的标志位置1,如果检测到f{x,y)灰度为0的像
-, 7 26

3.2.1背景建模算法实验对比
帧间差分法虽然简单有效，但是噪声以及参数对结果影响较大，光流法的运 算复杂度高，不能满足实时性要求，因此不适用于实时道路车辆检测。下面对几 种背景建模算法的仿真实验对比，通过多组实验视频的实际对比效果以及各个算 法的速度对比，选取检测效果相对稳定并且实时性高的前景检测算法。

图3-7原始视频帧



图3-8平均背景模型检测结果



图3-9混合高斯背景建模检测结果
素点的个数小于一定阈值H,则车辆背景图建立完成，通过这个得到的车辆背景 图对ViBe的背景模型进行初始化。
通过改进的算法建立背景图像来对车辆进行分割，有效的解决了 ViBe出现 鬼影的问题。

(b)
图3-11 ViBe检测算法中的鬼影问题
图3-11是ViBe算法检测的前景结果图，从图中可以看到被标记出来的车 辆前景都是鬼影，因为在真实的图像场景中对应位置没有相应车辆，当鬼影出现 时，会被误检为车辆前景，从而使得检测到的车辆外观特征出现改变，并且车辆 变多，影响跟踪计数等功能。从图341(b)可以看出鬼影现象直到视频的第150 帧还是没有完全消除，严重影响整体效果。
图3-12是改进算法的结果图，可以看出，在第35帧时，鬼影现象已经完全 消除，有效的提高了检测的准确度。

图3-12 ViBe鬼影抑制
因此改进算法通过加入后续帧的相关信息去除鬼影现象，可以有效的抑制 鬼影，并且去除的时间足够短，实际应用良好。

3.3阴影分割
3.3.1阴影特点以及阴影检测现状
阴影是从光源发出的光线被物体部分或全部遮挡之后形成的黑暗区域。主要 分为以下几种：
(1)按是否运动进行划分，分为静态阴影和动态阴影。
(2)从阴影投影位置划分，分为自身阴影和投射阴影
(3)根据阴影造成的遮挡现象，分为本影和半影
由于阴影并没有改变投影物体表面的物理属性，比如纹理特征，尺寸大小， 材质等特征。同时阴影会导致投影表面相对之前的亮度降低，但是色度基本不变。 在车辆检测系统中,主要是车辆运动阴影，运动阴影除了具有阴影的基本特点外， 还有一个特点就是阴影的运动属性与车辆基本一致，因此会当作前景目标检测出 来，无论是运动阴影还是背景阴影都会导致图像质量下降，使得图像中信息减少， 造成对图像中物体的识别率降低，因此阴影检测在视频车辆前景提取中也是非常 关键的一步。近年来，许多学者致力于运动阴影检测，主要分为两类，基于模型 的方法和基于特征的方法〔巧，由于基于模型的方法通常需要场景光照以及目标等 先验知识，并且需要对样本进行训练，操作比较复杂，依赖于样本选择。基于特 征的方法，主要是利用阴影本身的特点，如阴影的颜色，纹理以及几何特征去检 测阴影，因此具有更加广泛的适用性。
3.3.2阴影检测基本算法介绍
(1)基于颜色的阴影检测
利用颜色特征对阴影进行检测的主要思想是对背景像素和运动目标阴影的 亮度(V)，色度(H),饱和度(S)特征进行比较，H的取值范围为0°~360° , V和S 的取值范围是0~1。对于阴影来说，色度和饱和度的变化不大，亮度信息变化 较为明显，因此可以利用图像的HSV颜色特征进行检测侦，首先需要把图像从 RGB颜色空间转到HSV空间。
"=吨海	 	.	(3-31)
2xJ(R_G)2 + (R_B)x(G_B)
3
S = 1			G, 8)]	(3-32)
R + G+B
f = ?x(R + G+8)	(3-33)
经典HSV的阴影检测方法利用检测点与背景点的亮度比，色度以及饱和度差的特点进行判断是否为阴影，基本公式如下：
mhsv =1，a < <P^Is(x,y)-Bs(x,y) < 0S ^\lh(x,y)-Bh(x,y)\ < 0h 伝由)
0, otherwise
其中Bk(X,y)tBs(x,y),Bv(x,y)代表图像背景像素点HSV颜色空间特征， Ih(x,y), Is(x,y), Iv{x,y)表示当前帧对应像素点的HSV颜色空间特征。其中 参数a,”的取值范围是0?1之间，其中a主要依据阴影的强度，当阴影的强度 越弱时，相对a越大，相反则越小，"主要降低噪声的影响，从而提高阴影检测 的准确度。劣和劣主要为色度和饱和度的阈值，但根据经验得知，它们对结果 的影响不大。
(2)基于纹理的阴影检测
根据阴影的特点可知，阴影区域和背景区域的纹理特征很相似，在实际中， 可以利用纹理相似度网进行判断，其中最常用的纹理算子是LBP算子。LBP是 1994年由T. Ojala, M.Pietikainen和D. Harwood提出，LBP特征具有旋转不变性 和灰度单调变换不变性，主要提取图像的局部纹理特征，它反映了每个像素点与 周围像素点的关系，根据中心像素点的值对其周围像素点进行二值编码，具体形

其中戸表示以x。,％为圆心，以r为半径的圆，如果圆的半径越小，则对于图 像的纹理描述越好，但此时比较容易受到噪声的影响，如果圆的半径越大，则对 图像的纹理描述越弱，比如一些边缘细节，而受到噪声的影响会变小。&表示 像素点气,龙的像素值，g?表示距离中心像素点半径为尸的尸中第』?个像素点的 值。LBP常用的是3x3的模板，3x3邻域的8个点通过比较运算产生8位的二 进制数，从而得到该窗口像素点的LBP值。
70	　　29		I	1			I	2	4 ,
2K		　　27		I	f-	0			g
而		18		0	0	0			32
(a)		(b)		(c)
图3-13 LBP算子



图3-13(a)表示图像中3x3区域的像素值，图3-13(b)表示对此像素点进行二 值编码，假如邻域像素点比中心像素值大的像素被置1，比中心像素值小的像素 被置0,然后按照顺时针方向进行排序，从而得到编码为11000011,从图3-13(C) 可以看到整个编码的权值，贝！J最终场的值为(2°+2】+26+27)。
对于给定的当前帧像素I(x,y)以及背景像素B(x,y),通过上述LBP纹理算子 计算方法计算这些像素点以及其周围像素点的LBP特征值，并且统计邻域的LBP 特征的直方图信息，通过直方图交运对1(x,力与B(x,y)以进行纹理相似度判定， 假设所对应的直方图为內和加-
NT
p = ^min(/2；,A；)	(3-37)
z=0
其中Q是相似度系数，N表示直方图柱的数目，5分别代表当前帧像素点 和背景像素点第i个直方图柱的信息。
根据求得的纹相似度信息可以判断Z(x5y)是否为阴影，从而获得阴影的二值 掩码图。

其中皿表示在在t时刻视频帧阴影的二值掩码图，7日是对阴影判断的阈 值，可以根据不同场景设定。
(4)两种方法的结果对比
图3-15(a)为视频原图，图3-15(b)是通过ViBe检测出的视频前景图，可以 看出阴影对检测结果的影响很大。在HSV空间的阴影检测效果如图3-14(c)所 示，从结果可以看出，这种方法可以检测出大部分的阴影区域，但是由于其主要 依赖亮度信息，因此在光照强度整体比较低或者车辆的颜色特征与背景差别比较 小的时候，目标车辆也会比较容易被检测为阴影，因此只利用颜色特征并不能取 得令人满意的效果。
视频帧通过LBP纹理特征进行的阴影检测结果如图3-15(d)所示，从图中可 以看出，车辆的大部分阴影都可以被检测出来，但是由于部分车辆区域的纹理特 征与背景纹理特征存在相似性，所以会被误检为阴影。



图3-14阴影检测结果
(5)改进的阴影检测算法
基于HSV空间的阴影检测算法假设监控环境背景是固定的，而改进的无参化 算法加入了相邻三帧色度差信息，当背景存在变化时，相同位置上的光线的反射 系数大致相同，因此可以适用背景出现变化的场景。在同一帧内，由于H,S信息 对结果的影响不大，因此在判别时只考虑了亮度信息，具体思想是：
M严=上。，蘇(3-39)
0, otherwise
其中I^x,y)与B\x,y)表示在视频的第f帧的像素点的亮度值，I，和咯表的是 视频的第，和帧像素点的色度信息。在实际中，除了阴影会让图像的亮度值 发生改变以外，由于目标的运动，在很短的时间内，某一像素点的投影也会发生 改变，通过加入前后帧的亮度变化，并结合当前帧像素与背景像素亮度比，不仅 能适应背景的变化，而且使得HSV阴影检测无参化，不再需要根据不同视频场 景去调整阈值参数【却，因此比较操作简单，具有广泛适用性。
无参化的颜色特征检测法是基于阴影的颜色信息，并不能克服颜色信息本身 的不足，而单一的纹理特征检测也不能很好的检测阴影，通过无参化颜色特征和 纹理特征LBP检测的融合，可以使得阴影去除算法能够相互补充，尽量弥补各 自的不足，共同作用检测阴影。下面是对融合算法的介绍：
a.首先通过无参化颜色特征检测算法进行阴影检测得到第t帧的阴影二值掩码 图〃冲。
b.其次利用LBP纹理检测算子检测阴影得到第t帧的阴影二值掩码图M皿。
c.通过对两个模板求与得到初步的阴影二值掩码图心如如。
d.对得到的二值掩码图利用图像连通分量标记以及形态学处理方法得到较为完 整的车辆前景图。
最后的操作主要是通过连通分量标记算法标记各个连通区域，在检测出的阴 影区域中，利用尺度小的滤波器去除被错误划分的小区域，对检测出的目标区域， 也进行同样的操作。然后再通过形体学腐蚀膨胀操作获得最终的阴影检测结果，
最终检测到的车辆前景如图3-15所示


图3-15去除阴影的车辆前景图
从图3-15可以看出，相比于之前的检测算法，改进算法可以很好的去除阴影,
并且较为完整的保存车辆信息，这为后续车辆跟踪奠定了良好的基础。
3.4本章小结
本章主要介绍了视频车辆前景检测的基本算法，给出各个算法原理，并且仿 真实验，对比了各个算法的优缺点，重点对背景建模算法做了详细阐述，选择 ViBe算法作为系统车辆检测算法，针对ViBe容易导致的鬼影问题分析其原因并 给出改进策略。实验结果显示，改进算法可以在保证实时性的条件下，有效的抑 制的鬼影的产生。同时本章还介绍了车辆检测中易出现的阴影问题，介绍了阴影 的形成原因和研究发展现状，主要阐述了几种常用的阴影检测算法，提出无参化 颜色空间与纹理特征融合的阴影检测算法，改进算法不仅操作复杂度降低，并且 相比之前算法，阴影检测更加准确，最后通过后期处理操作能够分离出较为完整 的车辆前景，从而有利于后续跟踪。

第四章车辆跟踪模型
对检测出来的车辆进行跟踪，是智能交通系统中比较关键的一步，因为车流 量统计，车速判定以及轨迹分析等都要通过车辆的准确跟踪获得，所以车辆跟踪 具有重要的研究价值，受到近年来学者的广泛关注。
车辆跟踪系统要求能够对交通车辆进行快速的跟踪，并能有效处理车辆遮挡 等情况。目前许多的跟踪算法都是根据车辆的空间距离来判定连续两帧内的两个 车辆是否为同一车辆，空间距离有很多种，比如欧几里德距离，加权距离，棋盘 距离或者巴氏距离等。
4.1车辆跟踪类型简介
对车辆的跟踪大致可以分为四类，主要有基于车辆模型的跟踪，基于车辆轮 廓的跟踪，基于区域的跟踪，基于特征的跟踪，因此对车辆的跟踪相当于对车辆 的模型，轮廓，区域，特征等信息进行获取以及匹配，从而定位车辆。
a.基于车辆模型的跟踪
基于模型的跟踪算法网需要根据历史车辆的运动信息建立车辆结构模型或 者运动模型，并求得模型的参数，后续帧利用模型及其参数，进行车辆的匹配， 由于已对车辆运动或者结构做了很好的建模，因此能够比较准确的对车辆进行跟 踪，对遮挡现象处理具有较强的鲁棒性，但是基于模型的方法比较依赖于先验信 息，需要样本数据量足够大，才可以建立准确的模型，导致运算复杂度很高，满 足不了实时性的要求。
b.基于车辆轮廓的跟踪
基于轮廓的跟踪方法主要是利用对目标边缘点进行跟踪，又叫做变形模板跟 踪。在1987年，Kass等人提出了 Snake模型四，这是一种非参数化变形模板， Snake模型的思想很简单，首先通过构造一个初始的轮廓线，这个轮廓线上包含 一些控制点，然后控制参数曲线变形，最小化能量目标函数，得到的具有最小能 量的闭合曲线，从而进行跟踪。
Snake模型具有许多优点，当选择了合适的初始控制点，可以自动的收敛到 能量极小值状态，恰恰这也是它的缺点所在，因为初始位置的选择对结果的影响 比较大，并且Snake极有可能收敛到局部极小值，甚至不收敛。
c.基于车辆区域的跟踪
基于区域的目标跟踪㈣就是通过匹配目标区域进行跟踪。首先要确定车辆区 域，区域的获得可通过人为设定或者自动检测，然后计算模板和候选区域匹配程 度，搜索出匹配度最高的候选区域作为最终目标车辆区域，具体的搜索方法就是 在视频的每一帧从左到右，从上到下扫描。
这种方法在目标区域没有发生遮挡的时候效果较好，但是在目标产生诸如变 形或者遮挡时，准确度下降，并且基于区域的方法需要进行全帧扫描，非常耗时， 有可能无法满足实时性要求。
d.基于车辆特征的跟踪
基于特征的车辆跟踪就是建立对车辆的特征观测模型，通过相邻两帧的特征 匹配，找到最优匹配车辆，进行后续跟踪。基于特征的跟踪算法首先需要从车辆 区域中提取特征信息，如各种直方图信息，纹理特征，边缘拐角特征等，然后利 用这些特征形成车辆区域的特征向量，在下一帧找到对应的特征区域。
基于特征的跟踪算法的优点是当车辆发生遮挡时，车辆部分区域特征仍然可 以被用于跟踪，并且可以有效的解决光线变化问题，以及车辆在视频场景中远近 大小变化的问题。但是这种算法一般对噪声比较敏感，可通过设计合理的特征观 测模型，尽量降低噪声的影响，越复杂的特征观测模型，会导致系统处理速度下 降，因此需要进行根据系统要求进行有效选择。
4.2车辆跟踪主要算法
4.2.1卡尔曼滤波
卡尔曼滤波是一种最优化自回归数据滤波算法【2%它的基本特征是通过状态 方程描述状态的转移过程，然后利用观测方程得到状态的预测信息，因为这种方 法只用前一时刻的状态估计值加上这一时刻的观察值在满足线性无偏最小方差 估计的准则下，就可以进行最优估计，不需要保存很多历史运动信息，所以计算 量和存储量较少，算法的模型相对简单，大体上能满足实时性的要求。
卡尔曼滤波跟踪是在线性，高斯噪声的条件下。假设后验概率
为高斯分布，则描述离散时变线性系统的状态方程和观测方程为：
xt=Ax xt_} + Bx uk_x + -wk	(4-1)
zk =Hxxk +vk	(4-2)
其中乂上为k时刻的系统状态，为k-1时刻的系统控制量，A是系统状态 从左-1时刻转到上时刻的转移方程，B是可选输入控制矩阵的增益矩阵，H是状态变量与对观测向量Z*的增益矩阵，凹和*分别表小系统过程噪声和观测噪声, 卡尔曼滤波要求这两种噪声是互不相关且均值为零。
卡尔曼滤波器的计算原理为：定义￡［代表已知状态变量下对*时刻的先验状 态预估，丸表示已知测量变量下上时刻的后验状态预估，求得先验和后验的估计 误差为：
A 一
= xk- xk	(4-3)
A
=xk~xk	(4-4)
据此可以得到先验估计误差和后验估计误差的协方差计算方法：
仄=珥纭纭，］	(4-5)
Pk =^k-ef］	(4-6)
并且得到后验状态估计毎.：
A A~~	A-
xk =Xk + Kx(zk-Hxxk)	(4-7)
可以知道它是由先验状态估计￡［和观测变量与&的加权差的线性运算求得。
由于卡尔曼滤波常被用来跟踪单个目标，多目标的跟踪需要建立数据关联以 及管理跟踪的操作。通过一组卡尔曼滤波器来跟踪未知数目的目标，每出现一个 新的观测物体，它会和现在正确跟踪的车辆进行关联操作，或者如果它是一个新 的目标，就会为它建立一个新的跟踪器。这种预测方法比较单一，意味着每出现 的新的观测物体只和当前存在的跟踪物体相关联，如果错误关联发生的话，系统 不能够从这个错误中恢复，因此当处理比较拥挤的场景时，不能直接为一个新的 跟踪物体匹配某个跟踪目标，可以利用诸如最近邻准则去优化分配，当一个新 的待定目标出现时,所有当前已经跟踪记录的物体进行映射，根据这个准则，选 取离新出现目标最近的跟踪目标，也可以如网通过利用卡尔曼滤波器的预测功能, 事先预测当前帧的搜索区域，这样做可以大大降低计算量。但是卡尔曼滤波跟踪 算法的问题也比较明显，首先是卡尔曼滤波在处理目标物体尺寸比较大的情况下 不够理想，并且当目标运动模式是非线性或者非高斯的时候，卡尔曼滤波常常会 跟踪失败，后来学者针对这些问题又提出扩展卡尔曼滤波器，无迹卡尔曼滤波器 等优化算法，但是只适合系统和观测噪声比较小的情况。
4.2.2粒子滤波
20世纪40年代由Metropolis等人提出蒙特卡洛方法，70年代使用了一种序 贯重要性釆样的算法 S7S'(sequential importance sampling),在 1999 年，SIS 这类算 法总结成粒子滤波的概念被Carpenter等人提出。
粒子滤波算法网的基本思想是利用一组带有权重的随机样本点，来估计后验概率密度。假如使用M个粒子的集合为｛成成｝,这些粒子是从后验概率分 布的状态空间中抽取而来的，各个粒子的权值为｛w；,...,就｝, M个粒子的累加 和为1,在时刻上的后验概率密度表达为：
川）=￡试心* -**）	（4-8）
;=1
因此对函数/（x°,D的期望表达是：
E（/Go,D）= ￡M，（x?）	（4-9）
kl
由于直接从后验概率密度中抽取合适的样本比较困难，如果粒子样本选取的 不够有效，会增大估计方差，从而严重影响跟踪效果。重要性釆样可以提高釆样 的效率，解决了从后验概率分布中抽取样本的困难，具体方法从己知且比较容易 釆样的分布q（x°* lm）中釆样得到：
E（f｛xO ky）= J f（x0k）p（x0 k \yu）dxO k
=f，（如g（*°* I 財％	（4T0）
=_|7（工倾）>%冬（气* I yXJ［）dxo k
最后通过公式推导得到重釆样之后的N个粒子及其权重为：
试=”场业（乂 W	（4-11）
0（* I Xfi%）
其中％代表马尔科夫假设，p（yk |X；）是似然函数，P（WIK『4）是概率转移 函数，4（出工52土）是重要性采样分布。一般比较常用的分布是先验分布。
g（K I Xf 2,乃）=P（xk I <1）	（4T2）
对于上述算法来说，由于采样粒子数有限，在经过若干次迭代之后，很多粒 子的权值变得很小，最后只有很少的粒子的权值比较大，这也就是所谓的粒子退 化现象，然而退化的现象对于重要性采样来说不可避免，因此接下来还需要对粒 子进行重釆样操作。
重釆样的基本原理是在t-1时刻，粒子近似拟合了先验概率，通过系统的观 测计算出权值，对那些权值比较大的粒子重新釆样出若干新的粒子，并舍弃权值 较小的粒子，从而形成一组新的粒子去预测，时刻目标的状态。重釆样算法对每 次得到的粒子重釆样N次，用产生的新的粒子集合描述后验概率密度函数，其 中SZ7?（Sampling Importance Resampling）归一?化粒子权重作为概率从粒子集合中 均匀的抽样，使得粒子被映射成新的加权粒子。
知基于粒子滤波的跟踪算法不受非线性非高斯的限制，能很好的解决这些情况 下的视频车辆跟踪问题。为了能够提高跟踪的准确性，下面将通过改进观测模型， 提高粒子滤波在不同环境下的鲁棒性。
4.2.3改进观测模型的粒子跟踪算法
利用粒子滤波对车辆进行跟踪，首先要建立观测模型，其中目标核函数颜色 直方图比较常用，因为在实际中，颜色直方图特征是一种全局特征，并且容易求 得，但是在光照较弱或者对比度相对低的环境下，颜色特征描述算子不能准确的 对车辆信息进行表达，并且颜色直方图信息缺失对空间信息表达。HOG特征岡 即方向梯度直方图特征，通过统计计算图像局部的梯度直方图信息形成特征，广 泛用于行人车辆检测中，由于某些交通视频经常会出现光线差等问题，因此通过 将改进HOG特征与颜色直方图结合起来，建立EC770G(enhanced-color HOG)观 测模型，可以使得观测模型具有较强的鲁棒性。
HOG特征通过把图像分成较小的连通区域单元，称为cell,然后通过计算cell 内像素点的方向梯度直方图，形成区域的特征描述器。具体算法实现过程是：
a.归一化图像
首先进行Gamma压缩，这种压缩可以降低局部的阴影和光照因素的影响， 并且将图像转为灰度图，便于后续处理
b.计算图像梯度
图像的梯度计算分为横坐标和纵坐标梯度计算，最后求得像素点的梯度方向， 具体计算方法为：
gxy)=/(x+^y)~ f(x - y)	(4-13)
gy (x, y) = f(x, y + 1)-/(x, y -1)	(4-14)
其中&和g＞分别为图像像素点(x,y)在横轴和纵轴上的梯度-f(x,y)代表像素点 (x，V)的像素值，据此可以计算出点(x，v)梯度的方向Z和幅度3：
A = arctanCg^, (x, y} / gx (x, y))	(4T5)
B = J(g；(x,〉) + g；(x，N))	(4T6)
c.构建方向梯度直方图
首先对图像进行细胞元划分，例如每个ce〃是8x8,则32x32像素区域包含 16个cell,通过直方图去统计每个cell的信息，通过计算每个像素的梯度方向映 射到不同区间内，假设直方图前”为9,也即梯度方向分为9个小方向，在映射 的时候通过梯度幅度加权映射，从而得到这个ce〃的方向梯度直方图，是一个9维的特征向量。
d.构造HOG描述符
将相邻cell特征向量集合成block块，假如4个cell组合成一个block块，则 这个block是一个16x16的区域，每个ce〃是一个9维特征向量，32x32的图像 区域包含9个block块，当然这些block块之间是允许有重叠的，则这幅图像区 域可以用一个324维的特征向量来表示。
改进的HOG特征通过加入图像中心block块和周围block块的差异信息，能 够让目标特征在外界环境对比度低的情况下也能很有效。如图4-1所示，block5 与其他block进行比较，公式如下
(0 = scenter(0 -Sj(0,丿= 1,2 ......9, j center	(4-17)
其中代表中心block块的第i个bin, Sj(i)表示第j个block的第i个 bin,这样图像区域的差异梯度特征为一个288维的梯度向量。
一 j—":三菱
_」	,…「 j ‘. .		■
图4-1改进HOG特征
颜色直方图特征通过计算图像的勿直方图信息得到，有一点值得注意 的是，bin的数目的选取太大或者太小都会导致差的对比度效果，在本文车辆跟 踪系统中，为H通道分配8个bin, S通道分配12个bin以及「通道分配3个 bin,整个HSV颜色空间描述器的维度是288。
改进方向梯度直方图描述器与釦HSV颜色直方图描述器相互结合，形成粒 子滤波的观测模型。在目标匹配阶段，主要的工作是找到当前帧的目标在上一帧 最匹配的跟踪物体，因此需要求得观测模板和待选区域的相似度，这里主要釆用 相似度度量Bhattacharyya系数来计算，用必/?,”)代表模板直方图和检测区域直 方图相似度函数。
N-1
dd 宇￡据	(4-18)
/~0
其中时表示观察区域第丿个粒子对应直方图特征的第［?个bin值，匕丿表示匹 配模板第丿?个粒子对应直方图的第，?个bin值。因此可通过上述公式计算出3D HSV 颜色空间直方图和HOG特征直方图权重d嬴,“和瞄史对于差异HOG特征的 权重以油皿“计算方法如下：
38
DT	,
以(4T9) i=0
利用上面三种特征的权重求出最终第j个粒子的权重：
& = (d%s"X ^HOG,n ) / ^RDHOG,n	(4~20)
粒子的权重反映了候选框和匹配模板之间的相似度程度，当d.和瞄 增大或者Dg”减少时，粒子滤波权重会增大，反之降低。





图4-2观测模型中特征提取示例
图4-2显示了对视频第1224帧图像进行改进HOG特征和釦屡卩特征提取 的具体过程，对提取到的车辆区域首先调整大小为32x32,图4-l(d)和(e)是提取 车辆的直方图信息，图4T(f)是车辆区域的HOG特征提取。
改进的观测模型被应用于粒子滤波框架中去，具体的粒子滤波跟踪流程见下 图：

4.3遮挡问题处理
车辆遮挡包括车辆部分遮挡和完全遮挡，通常车辆由于其他运动物体或者背 景的遮挡，将会导致车辆信息出现较大改变，引起检测或跟踪的不准确，从而对 系统造成较大影响，因此遮挡处理也是非常关键的一步。对于遮挡的研究近年来 已经成为智能交通系统中热点和难点，并且很多解决这类问题的方法也被提出来, 由于遮挡发生的场景存在很大的不同，许多学者针对不同场景下的问题提出了针 对性的解决办法，但是一个普遍适用的方法研究还没有太成熟。

总结起来，对车辆遮挡处理主要分为基于特征，模型以及轮廓的方法。其中 特征法主要包括车辆局部特征点，纹理特征等，虽然这种方法能有效的利用特征 去实现遮挡检测和分割，但是由于特征的计算量比较大，并且当分割所需要车辆 局部特征被遮挡时，会导致分割失败。基于模型的方法包括三维模型，统计模型 等，这些模型都需要通过对车辆信息进行建模,并且有时会需要一些未知的参数, 这样不仅复杂度高，而且在实际使用中存在难度。基于车辆轮廓的方法根据车辆 的几何形状进行遮挡区域判断，然后通过对遮挡点的分离，找到分割线，从而分 割遮挡车辆，这种方法比较简单，不需要太多车辆历史信息，因此计算速度快, 但是这种处理方法对于多车遮挡的处理效果不如两车遮挡效果，后面将在基于轮 廓形状的基础上改进从而提出新的遮挡分割算法。
4.3.1遮挡检测
车辆在发生遮挡时，通过前景检测后的车辆区域会出现异常，具体表现为车 辆区域的占空比和长宽比的改变，又因为通常用于道路交通检测的摄像头在水平 方向上与车辆保持一致，因此可以用这种方法来进行遮挡检测。
通过前景检测以及阴影相关的处理，会得到车辆目标的二值掩码图，对于每 个用外接矩形框框起来的区域，前景部分的面积与矩形的面积比值就是占空比, 表示为

另外长宽比久 就是外界矩形的长和宽的比值。对于占空比而言，如果没有 发生遮挡，车辆的占空比相对较小，当发生遮挡时，占空比会增大。同样地，发 生遮挡的时候，区域的长宽比一般情况下也会变大。下面根据对实际车辆信息的 统计给出没有发生遮挡的车辆占空比和长宽比的概率曲线：




图4-3单辆车的长宽比以及占空比概率函数
从图4-3中可以看出在长宽比大于4=1.5 ,占空比小于4=0.7时没有发生 遮挡的概率逐渐降低，因此选定两个值为阈值，当检测区域满足其中任何一种条 件时即darea>Td或者Ahw<Ta时，被判定为可能存在遮挡。对遮挡区域，通过遮


挡分割算法再进行进一步的遮挡处理，对与未遮挡区域，通过粒子滤波预测当前 帧车辆的位置。
4.3.2遮挡分割
对于遮挡区域，首先将得到的图像区域块进行增强对比度，具体操作是先对 图像区域直方图均衡化，直方图均衡化能够提高图像对比度，然后在此基础上进 行灰度变换，得到强对比度图像。视频图像中某个时刻的光线总是从一个角度投 射过来，因此对于车辆来说分为阴面和阳面。
利用一维最大嫡分割法对得到的强对比度图进行分割。图像的燜是对特征的 一种统计形式，焼反映了图片中信息量的多少，对一幅灰度图像来说，由于灰度 范围是0到255,假设p?表示灰度级为，在图片中所占比例的大小，则此图片的 灰度嫡为：

H = -￡ Pi In Pj	(4-22)
而在图像分割中，需要把图像中的前景和背景目标分割开来，即把图像区域 分成两个区域，目标区和背景区。在灰度图像中，假设存在阈值T对图像进行 分割：



阈值T将图像分为灰度区间在为0-T和T-255的两个区域，对于灰度区域
0~T的区域来说，概率分布为
四)= (￡%)/"
/=0
则该区域的燜为-尸G)lnF(/),则最后总的信息嫡为
= -F(t) In F(t)-(1-F(ty)ln(l- F(0)	(4-25)
当目标可以从背景中准确分割出来，则对应的信息炳最大，因此可通过求信 息炳最大化法找到阈值T,从而完成分割，得到二值掩码图。图4-4(a)中#3号 车通过遮挡检测操作发现存在车辆遮挡问题，(b)图是将这部分遮挡区域单独提 取出来，(c)和(d)分别是对车辆进行直方图均衡化和灰度变换操作的结果，(e) 是通过最大炳分割得到的图像，可以看出得到的二值图像车辆之间不再互相粘连。 但是车辆的分割线还没确定，通过利用椭圆拟合的算法拟合二值图中车辆前景目 标，同时近似得到遮挡分割线。
图4-4车辆遮挡处理中对比度增强和最大靖分割操作
椭圆拟合常用方法是最小二乘算法，最小二乘是一种数学优化算法，主要的 思想是通过求样本数据的最小化误差平方和找到最优匹配函数，通常来说，二次 曲线方程的表达方式是：
F(a,x) = axz +bxy + cy2 +dx+ey + f -Q	(4-26)
若记A = \a b c d e刀'代表曲线的参数，u = [xj xjyj yj xt yt 1]，,其中 表示的是图像像素点坐标位置。由于对于椭圆拟合，有可能因为样本点缺失 或者周围噪声作用的因素的影响，对二次曲线的拟合有可能会退化成双曲线，对 于椭圆方程来说，必须要满足的一个条件是b2-4ac<Q ,这里将这个约束条件 简化为4ac-b2 =1 o

求最小二乘椭圆的问题可以表达为下面的公式：
a = argm$_S||i	(4-27) (4-28)
其中Q代表了进行椭圆拟合的样本点，对公式运用拉格朗日乘数法得到
DrDa = ACa
(4-30)
以上问题就转化为广义特征值求解问题，通过推导求解得到
(4-31)
其中人和为是求得的特征值和特征向量，求得a之后，椭圆相关的参数就确定 下来，比如长轴短轴信息，中心点位置等。
通过椭圆拟合操作，可以得到遮挡区域车辆信息，因为同一车道内的车辆一 般是沿着同一方向行驶，因此光照对车辆造成的影响大致相同，所以最后拟合的 椭圆长轴近似平行，如图4-5所示

图4-5椭圆拟合分离遮挡区域
遮挡分割线为位于椭圆长轴之间中心位置且平行于椭圆长轴的直线，它将遮 挡车辆真实前景图分割开，从而进行后续粒子跟踪相关过程。
4.4本章小结
本章先主要介绍了常见的车辆跟踪类型，并且分析各种跟踪类型的优势和劣 势。最后主要阐述了经典的目标跟踪算法，即卡尔曼滤波和粒子滤波，在对二者 的原理介绍之后，对二者在多目标跟踪场景下的适用性进行研究，由于卡尔曼滤 波在在非线性非高斯条件下不能很好的跟踪，因此车辆多目标场景下选择基于粒 子滤波的跟踪算法，同时改进粒子滤波观测模型，结合差异HOG特征与颜色30 HST特征建立观测模型。最后针对车辆遮挡的情况，根据车辆区域轮廓特征进行 遮挡检测，传统的凸包遮挡分割技术有一个很大的问题就是不能处理多车遮挡问 题，本章提出的基于一维最大炳分割和椭圆拟合的遮挡分割算法,能有很好的对 多车遮挡区域进行拟合并完成分割，分割效果基本满足要求，这种方法适用于很 多场景下的车辆遮挡问题，提供了一种广泛适用的可行方法
第五章实验及结果分析
5.1系统设计平台
前面章节主要对车辆检测，跟踪理论以及相关的算法进行的探讨研究，从而 形成一套车辆检测跟踪系统。本系统如果要在真实交通道路场景下使用，首先必 须要满足以下要求：
a.实时性
由于基于视频的交通道路车辆的检测与跟踪必须能够保证实时性才能真正 有较大实用价值，因此对各个模块的算法复杂度以及性能有一定的要求。
b.可实现性
系统中涉及到的所有算法在实际中可以真正实现，通过一定的设备平台可以 实现车辆检测与跟踪。
c.可移植性
系统中涵盖的算法不能依赖于一个单一的平台，必须可以在不同的平台之间 可以移植使用
通过对以上要求进行分析，系统需选择合适的软硬件环境实现。其中硬件平 台PC环境，配置为i5英特尔处理器，3.3GHz中央处理单元，3GB的RAM。 软件平台是C++以及OpenCVo
OpenCV是Intel公司在1999年建立的一个开源计算机视觉平台，它可以在 许多主流操作系统上运行使用。OpenCV早先主要的开发语言是C和C++,并包 括了多种接口，如Python, Matlab等，现在许多更新版本新加的算法主要是基 于C++开发，同时还有了 GPU接口版。OpenCV发展到现在，从最开始的OpenCV alpha3到现在的OpenCV 3.0,己经在计算机视觉领域取得了广泛应用，它提供 丰富的计算机视觉处理函数，使用很方便，并且由于OpenCV对C代码进行了 优化以及使用Intel的IPP高性能的多媒体函数处理库，执行速度的提升非常可 观。
本系统所用的C++开发平台是Visual Studio 2012,使用OpenCV时需要将其 头文件以及其依赖的动态和静态链接库加到环境变量里，从而在Windows下进 行基于OpenCV的检测跟踪系统开发。
5.2系统设计框图
下面框图是整个系统流程框图：

图5-1系统流程图
首先读取视频每一帧，对其通过图像预处理，包括图像灰度化和图像中值滤 波去噪，预处理之后的图像更有利于背景建模。然后基于帧差计数法进行背景图 建立，当建立完成时，用这个背景图去初始化ViBe算法，抑制了鬼影的产生， 从而二值的前景检测图像，并且更新背景模型。
前景二值图中不仅包含车辆区域还会包括阴影区域，通过无参化HSV与LBP 融合算法检测出阴影区域并去除,算法不需要参数调整的过程，具有广泛适用性。 最终检测的车辆前景区域是去除阴影的车辆目标区域。
对车辆的跟踪是基于粒子滤波框架的，在跟踪过程中可能存在车辆遮挡现象,
因此还需要遮挡处理，遮挡处理主要分为遮挡检测与遮挡分割，通过基于轮廓的 遮挡检测算法检测出遮挡区域，对于遮挡区域，首先通过直方图均衡化和灰度变 换增强图像块对比度，然后利用一维最大嫡进行分割，再利用椭圆拟合分割后的 遮挡车辆，并找到分割线，实现对遮挡区域进行分割。车辆跟踪釆用一种基于差 异HOG特征与3D HSV特征融合的观测模型，通过粒子滤波的状态转移方程以 及观测方程匹配出车辆，如果检测出是新出现的车辆，则分配一个新的车辆ID 号，已经出现过的车辆，釆用匹配的上一帧的车辆ID号。
5.3实验结果以及分析
a.实验设计
本文提出的车辆检测与跟踪系统需要在真实视频场景下测试，对于视频场景 的选取，需要尽可能包含多种情况，因此在本实验中主要包含以下场景，视频一 的场景代表了车流量较少或者中等的情况，视频二的场景代表了车流量中等并且 存在车辆移动阴影的情况，视频三的场景代表了车流量密集并且存在较多遮挡的 情况。通过对以上几个视频的实际实验性能比较分析，得出最终的实验结果。
b.对比算法
本系统的实验结果最终要和两个相似的系统在测试视频上进行对比，首先是 Lien"】提出的车流量计数系统，该系统主要是基于纹理特征对目标分割以及跟踪。 Scharcanski^］提出利用瑞利分布并在粒子滤波跟踪框架下，完成对遮挡进行检测 以及对车辆进行跟踪。本文提出的系统是在粒子滤波框架下，基于改进的观测模 型，并利用提出的遮挡检测和分割算法进行遮挡处理，最终￡艮踪目标车辆。
c.性能参数
为了对跟踪的效果进行评估，检测方法主要包含三个因素：正确跟踪帧数 CT (correct tracking),错误跟踪帧数 FT (false tracking),丢失跟踪帧数 MT (missing tracking),总帧数为N,则可得知跟踪正确百分比为(CT/N)xlOO%,跟踪失败百 分比为((FT+MT)/N)x 100%

图5-2视频一跟踪结果

图5-2中三张图是视频一场景下第636帧，第638帧以及第640帧的实际跟 踪情况，可以看出视频中#48号，#49号与#51号车辆能够在连续不同帧内实现 准确跟踪，表示本系统是可以在真实场景下正确跟踪车辆。
表5-1车辆跟踪性能对比
视频序 列	跟踪算法	正确跟踪数	丢失跟踪数	错误跟踪数	正确跟踪百分 比(%)	失败跟踪百分 比技)
视频一	　　本文系统	3146	55	49	96. 8%	3. 2%
Lien	2935	234	81	90.4%	9. 6%
Scharcanski	3020	138	92	92. 9%	7. 1%
视频二	本文系统	450	8	4	97.4%	2. 6%
Lien	436	7	19	94. 3%	5. 7%
Scharcanski	424	25	13	91.7%	8. 3%
视频三	本文系统	280	8	12	93.3%	6. 7%
Lien	260	11	29	86.6%	13.4%
Scharcanski	281	10	9	93.6%	6.4%

图5-3中三张图分别是视频二场景下第165帧，第171帧以及第226帧的跟 踪结果，可以看到存在车辆运动阴影的场景下，具有不同ID号的车辆可以被准 确记录，并且随着视频帧的增加，为车辆分配的ID号也在不断增加，从而可以 统计一定时间内车辆数量信息。
图5-4中三张图分别是视频三场景下第20帧，第90帧以及第97帧的跟踪 结果，其中展示了车辆#3号和#4号遮挡前，遮挡中以及遮挡后三个时刻的跟踪 情况，可以看出系统对遮挡车辆进行了分割，并且能够对遮挡车辆进行准确跟踪, 视频三的场景下车流量比较大，因此遮挡的情况相对于视频一和视频二要严重， 跟踪结果显示了系统的稳健性。
本系统与其他两个检测跟踪系统的性能对比通过表5-1中三个视频场景的实 际结果统计得出。首先三个视频的帧数分别为3250, 462和300o本文在此基础 上对视频正确跟踪帧数，丢失跟踪帧数，错误跟踪帧数进行统计。
从表中可以看岀，本文系统在视频一和视频二场景下的跟踪准确度比其他两 个系统都要高，其中在视频三的场景下与Scharcanski系统准确度相差了 0.3%, 这是因为Scharcanski系统主要针对遮挡问题进行算法设计，但是这个系统所用 的遮挡处理方法不能被应用与其他跟踪框架，具有局限性，而本文的遮挡分割算 法适用于其他跟踪框架-Scharcanski系统在视频二中跟踪准确度要低于其他两个 系统，这是因为它没有对光照较弱或者阴影场景下的车辆跟踪问题进行处理。 Lien的无背景模型系统在可以三个视频场景下对车辆进行跟踪，但是准确度相对 较低，因为Lien系统主要依据纹理特征对车辆进行跟踪，其中视频一内的车辆 纹理比较相似，因而跟踪准确度相比视频二内有略微下降。表中显示Lien的系 统在处理视频三时准确度低于90%,这是由于它没有针对遮挡问题进行处理，导 致错误跟踪车辆数目比较多。本文系统在遮挡较多时的跟踪结果比车流量小的视 频场景准确度要低，这是因为遮挡处理操作虽然能有效检测出遮挡车辆并分割， 但是遮挡检测和分割存在误差，并且系统不能有效处理完全遮挡的情况。需要说 明的是，由于三个视频的时长即总帧数存在差别，因此统计出来的准确度可能会 存在偏差，比如本文系统在视频二中的准确度比视频一中的准确度要低0.6%o 当样本数即视频帧数足够多时，统计偏差才会相应降低，也更接近于真实测量值。
实验表明，本系统跟踪效果优于其他两个跟踪系统。本系统能够在阴影和遮 挡场景下有比较高的准确度，充分体现了本系统的鲁棒性。实际中，本系统运行 速度大致在20帧每秒，符合实时性的要求。其中有一点值得注意的是，当车辆 在视频场景中较远位置，并且比较小的时候，此时车辆的特征和空间位置关系不 能被准确的提取，从而导致丢失跟踪以及错误跟踪，一种解决办法就是在视频图 像中间区域设置感应区，避免视频边缘的物体对系统的影响,从而提高系统性能。

第六章总结和展望
6.1总结
随着计算机视觉的发展，智能交通中视频监控技术也得到了飞跃的进步，现 如今已经在军事和民用方面等取得了广泛的应用，并且国内外许多科硏工作者也 已经投入到对视频检测跟踪技术的研究中去。
本文的研究内容主要包含两个方面，首先第一个方面主要是通过背景建模的 思想快速准确地对车辆前景目标进行提取，并且对前景提取中阴影区域通过提出 的阴影检测算法给予去除。第二个方面是对检测的前景车辆通过改进的粒子滤波 框架以及遮挡处理，完成车辆跟踪。在大量已有研究的基础上，本文对其中几点 重要内容提出改进，主要是：
(1)对ViBe背景建模算法和阴影检测算法进行改进
传统的背景建模算法中如平均背景建模算法对环境光照以及背景变化比较 敏感，高斯背景建模算法在运动目标非线性，非高斯运动时不能有效跟踪，ViBe 背景建模算法效率比较高，抗抖动和干扰，并且实时性好。本文主要在ViBe背 景建模算法上进行目标检测，对ViBe引起的鬼影问题进行改进。由于前景检测 到的车辆区域有可能存在阴影，本文结合传统的基于HSV和基于LBP阴影检测 算法，进行改进，提出无参化HSV与LBP进行融合检测阴影算法，能够有效的 去除阴影，从而得到准确的车辆前景。
(2)改进观测模型的粒子滤波跟踪算法
车辆跟踪类型主要有基于模型，基于轮廓，基于特征的几种，基于模型的方 法需要大量数据样本，复杂度高，实时性不强；基于轮廓的方法比较容易受到初 始点选择的影响，并且有可能收敛到局部极小值，甚至会不收敛；基于区域的跟 踪方法对目标物体产生诸如变形，遮挡等问题时效果比较差，而基于特征的方法 能够利用目标物体各方面信息，通过合理特征设计，有效解决光照变化以及遮挡 等问题。本文提出差异化HOG特征与3D HSV直方图融合进行车辆匹配跟踪， 在光线比较暗，并且在对不度不高情况可以准确提取车辆信息进行跟踪。
(3)改进的车辆遮挡处理算法
本文的遮挡检测主要基于车辆轮廓，通过车辆的占空比和长宽比进行判别。 由于现在的车辆的许多遮挡算法都比较依赖于特定场景，不具有广泛适用性，基 于车辆轮廓的方法可以适用于很多场景，许多基于轮廓的算法可以较好处理两车 遮挡问题，但无法处理多车分割。本文提出的遮挡分割算法首先利用直方图均衡 化和灰度变换增强对比度，通过一维最大炳分割以及最小二乘椭圆拟合得到不同车辆区域，根据拟合椭圆中心区域最终得到分割线。经实验证明，本文提出的遮 挡处理算法能够很好的对遮挡车辆检测和分离。
6.2展望
本文提出了改进的车辆检测与跟踪方法，以及改进的阴影检测和遮挡处理方 法。但是由于理论水平以及研究时间的限制，系统还存在一些不足之处，需要后 续进行深入研究，主要是以下几个方面：
第一，本文的系统基于背景建模进行目标检测，比较适合在摄像机固定场景 下使用，但是智能交通领域车辆自置摄像头情况下下，摄像机是随车辆一起运动 的，此时需要改进目标检测方法，适应在动态背景下的车辆检测，这也会是以后 研究的一个重要方向。
第二，车辆遮挡分为部分遮挡和完全遮挡等类型，本文提出的车辆遮挡算法 主要基于车辆轮廓特征，对车辆部分遮挡效果很好，但是无法解决车辆完全遮挡 情况，可以考虑与车辆运动模型结合在一起进行预测检测，从而更大程度上提高 系统准确性。
第三，本文的基于改进观测模型的粒子检测算法包括车辆遮挡检测利用了车 辆的许多特征，会影响车辆系统的实时性，可以通过优化算法如利用多线程并行 计算等技术，提高程序代码执行效率，保证系统实时性。
总之，车辆检测与跟踪是智能交通系统中很重要的一个方面。并且随着计算 机视觉技术的发展，会推动智能机器人，无人机，自动驾驶等领域的进步，车辆 的检测与跟踪是其中一个具有很高研究价值的课题，将是人们一直关注的热点。

参考文献
[1]Tomizuka M, Automated highway systems-an intelligent transportation system for the next century [J]. IEEE/ASME International Conference on Advanced Intelligent Mechatronics, 1997,(1):1-4.
[2]Seki M, Fujiwara H, Sumi K. A robust background subtraction method for changing background [A]. // Proceeding of IEEE Workshop on Application of Computer Vision Piscataway [C]. USA: IEEE, 2000: 207-213.
[3]Herisse B, Hamel T, Mahony R. The landing problem of a VTOL Unmanned Aerial Vehicle on a moving platform using optical flow [A]. // IEEE/RSJ International Conference [C].Taiwan:IEEE?2010:1600-1605.
[4]Kamijo S, Matsushita % Ikeuchi K, Sakauchi M. Traffic monitoring and accident detection at intersections [J]. IEEE Transaction on Intelligent Transportation Systems, 2000, 1(2):703-708.
[5]C. Stauffer, W? Eric, L. Grimson. Learning patterns of activity using real-time tracking [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22(8): 747-757.
[6]高守传，姚领田.Visual C++数字图像处理与工程应用篇[M].北京：中国 铁道出版社,2006.
[7]李弼程，彭天强，彭波等,智能图像处理技术[M].北京：电子工业出版 社，2004:7
[8]Gorai A, Ghosh A . Hue-preserving color image enhancement using particle swarm optimization [A]. // Recent Advances in Intelligent Computational Systems(RAICS)[C]. Trivandrum:IEEE, 2011:563-568
[9]Yoo S. Speech Decomposition and Enhancement [D]. America:University of Pittsburgh ,2005.
[10]Harase S, Bonaaud L, Desvignes M. Background estimation for dynamic video scene [J]. Proceedings of IEEE Industrial Electronics, 2006:3519-3524
[11]Mcfarlane NJB, Schofield CP. Segmentation and tracking of piglets in images [J].Machine Vision and Application, 1995,8(3):187-193
[12]Yongqing Li, Wanzhong Chen, Rui Jiang. The integration adjacent frame difference of improved ViBe for foreground object detection [A]. // Proceedings of 7th International Conference on Wireless Communications, Networking and Mobile Computing[C]. New York: IEEE, 2011:1-4.
[13]Shaikh SH? Saeed K, Chaki N. A Practical Adaptive Approach for Dynamic Backgroxmd Subtraction using an Invariant Color Model and Object Tracking [J]. Pattern Recognition, 2005, 26(1): 5-26.
[14]张杰，丁广太.运动人体阴影检测算法计算机工程与设计[J] .计算机工程 与设计，2010:1519-1522
[15]Cucchiara R, Grana C, Piccardi M, et al. Improving shadow suppression in moving object detection with HSV color information [A]. // Proceedings of IEEE Intelligent Transportation Systems[C]. Oakland, CA :IEEE,2011:334-339.
[16]Javed O, Shah M. Tracking and object classification for automated surveillance [J]. Lecture Notes in Computer Science. 2002:343-357.
[17]Comaniciu D, Rameshand V, Meer P, Real-time tracking of non-rigid objects using mean-shift [J]. Computer Vision and Pattern Recognition. 2000: 142-149.
[18]MAGEE D. Tracking Multiple Vehicles Using Foreground Background and Motion Models [J], Image and Vision Computing.2004 ,22(2):143-155
[19]Kass M, Witkin A, Terzopoulos D. Snakes : Active contour models[J]. International Journal of Computer Vision, 1988,1(4):321-331
[20]Setchell C. Application of Computer Vision to Road traffic Monitoring [D]. University of Bristol: Bristol Department of Computer Science, 1997.
[21]Maybeck P.S. Stochastic models, estimation, and control [J]. Mathematics in Science and Engineering. 1979, 10(5):282.
[22]Bar-Shalom Y. Tracking and data association [J]. Mathematics in Science &Engineer.l987? 5(3):168-190.
[23]Dellaert F, Thorpe C. Robust Car Tracking Using Kalman Filtering and Bayesian Templates [J]. Intelligent Transportation System. 1998:72-83
[24]Arulampalam M.S, Maskell S? Gordon N, and Clapp T. A tutorial on particle filters fbr online nonlinear/non-gaussian Bayesian tracking [J]. IEEE Transactions on Signal Processing, 2002, 50(2): 174-188.
[25]WU B, KAO C, JEN C, et al. A relative discriminative histogram of oriented gradients-based particle filter approach to vehicle occlusion handling and tracking
[J]. IEEE Transactions on Industrial Electronics.2014, 61(8): 4228-4237.
[26]Lien C.C, Tsai T.T, Tsai M.H., and Jang L.G. Vehicle counting without background modeling [A], // 17th International Conference on Advances in Multimedia Modeling[C]. Berlin : Springer-Verlag, 2011:446-456.
[27]Scharcanski J, Oliveira A.B, Cavalcanti P.G, Yari Y. A Particle-Filtering Approach for Vehicular Tracking Adaptive to Occlusions [J] .IEEE Transactions on Vehicular Technology, 2011, 60(2): 381-382
短短两年半的研究生学习生活即将结束了，回首两年多的研究生生活，我感 触颇深，收获颇丰。在本论文完成之际，在此我要感谢我的老师，同学，朋友及 家人两年来的教育、陪伴、关怀和鼓励。
首先我要感谢北京邮电大学的刘勇，杜海清，袁宝库三位老师。刘勇老师治 学严谨，广博的知识，在多媒体通信领域有深刻的造诣和敏锐的目光，在科研研 究和人生道路上给我很多启迪。杜海清老师认真负责的工作态度，严谨的治学与 育人的态度,敏锐的洞察力，创新的科研思维和他的人格魅力以及对学生的关怀, 必将对我今后的学习和工作产生深远的影响。袁宝库老师具有实事求是的科研精 神以及广博的知识体系，给予我精心的指导和热情的帮助。在此，特向三位老师 表示由衷的感谢！并祝愿他们工作顺利、身体健康！
感谢实验室同学梁丛伟，刘雅楠，胡益铭，王嘉伦，在我的研究生期间，他 们给予了我大量的指导，正是他们的帮助，才使我更好的完成了实验室的项目和 相应的课题研究工作，希望他们在今后的工作和学习中能不断的取得新成就。感 激唐舟进师兄的严格要求，使我有了更大的进步。最后，再次向所有爱我的对帮 助过我的人说声谢谢!在未来的人生道路上，我会继续努力的。

攻读学位期间发表的学术论文目录
[1] Huihui Liu, Ybng Liu , Haiqing Du. A Robust Framework For Vehicle Detection and Tracking Based On Particle Filter[C]. 2015 Joint International Mechanical, Electronic and Information Technology Conference, Chongqing ,2015.
