2.2.1尺度维度的设计与优化
小目标检测难度之所以大，正是因为它太“小”了，如果将“小”目标变“大”了， 那么相应的检测效果自然上去了。如何将小目标变成大目标呢？围绕着目标的尺 度问题，许多学者相继在特征尺度和图像尺度提出了相应的优化方案。本节主要 介绍FPN和SNIP：
(1)在特征尺度上，以FPN为主要代表。它是一个集自底向上提取特征， 自顶向下上采样，侧边融合于一体的横向连接网络。通过这三个结构，网络将低 分辨率但语义强的低层特征与高分辨率但语义弱的高层特征融合在一起,最终获 得高分辨率，强语义的特征，有利于小目标的检测。图2-5展示了利用特征尺度
11
的四种常见方式结构。
图2-5利用特征尺度的四种常见方式结构图
图2-5 (a)是一个图像金字塔模型，它将图像缩放到不同尺寸，然后分别对 这些不同尺度的图像执行目标检测操作，最后将所有的检测结果结合到一起。这 种方法的缺点是计算量大，需要大量的内存。图2-5 (b)是对图像金字塔的一种 改进思路，学者们发现利用卷积网络本身的特性，可以获得不同尺寸的特征图， 这样其实就类似于在图像的特征空间中构造金字塔，最后利用最高卷积层上的特 征图进行预测。它的缺点是仅仅关注深层网络中最后一层的特征，却忽略了其它 层的特征。图2-5 (c)所示的架构就是同时利用低层特征和高层特征，分别在不 同的特征层，同时进行预测。它的缺点是获得的特征不具鲁棒性，都是一些弱特 征。而FPN的架构如图2-5 (d)所示，它在图(c)的基础上得到每一层的特征 图，之后采用自顶向下的方法将小的特征图上采样之后与上一个特征图融合，融 合之后再做预测，依次如此，即可得到多个预测结果。
FPN算法大致结构如图2-6所示，它包含了三个步骤：自底向上的特征提取、 自顶向下的上采样(upsampling)和横向连接。
在特征提取的过程中，特征图的大小在经过池化层后会变小，而在经过卷积 层的时候不改变，这里将特征大小相同的层统一为同一个stage,越往后的stage 中的特征较前一 stage小，这样就构成了特征金字塔。在上采样的过程中，原文 为了方便采用的是最近邻上采样，一般的上采样有三种方式：最近邻上采样、反 卷积、线性插值，可以根据网络模型的复杂度选取具有不同计算量的上采样方式。 在横向连接的过程中，先使用1x1的卷积核是为了减少特征图的个数而不改变 特征图的尺寸大小。然后将上采样的结果和自底向上生成的相同大小的特征图进 行融合。在融合之后还会再采用3x3的卷积核对每个融合结果进行卷积，目的是 消除上采样的混叠效应。
(2)在图像尺度上，以SNIP为主要代表。SNIP利用了多尺度训练(Multi- ScaleTraining, MST)的思想，即训练一个检测器时采用不同尺度的图像进行训 练。但在MST方法中，单纯的将小目标放大也会影响检测效果，因为随之变大 的还有大目标，大目标变得太大而超出检测范围，导致MST性能并不理想。因 此SNIP的做法就是只对尺寸在指定范围内的目标回传损失，这样就能减少 domain-shift带来的影响。又因为训练过程采用了类似MST的做法，所以每个目 标在训练时都会有几个不同的尺寸，那么总有一个尺寸在指定的尺寸范围内。
图2-7 SNIP算法示意图
SNIP的算法过程如图2-7所示，它采用三个尺度的图像输入，并通过RPN 生成相应的候选框，但每个分支的RPN只负责一个尺度范围的候选框生成，不 在范围内的候选框直接舍弃，这样的设计保证了每个CNN分支在判别候选框是 否为前景时，只需针对最易分类的中等尺寸的候选框进行训练。在anchor的选 取上，如果ground truth的大小在该分支指定的范围内，就被标记为有效，否则 就被标记为无效。在生成anchor并给anchor分配标签的时候，检查该anchor是 否和某个无效的ground truth的交并比超过0.3,若存在，则该anchor会被视作
13
无效；若不存在，则会被视为有效。这些无效anchor在训练的时候梯度并不会被 反向传播。这就相当于在每个分辨率上，只对大小合适的目标进行训练。最后将 多个分支上的预测结果进行重塑(rescale),并进行NMS,得到最后的预测结果。 不管是特征金字塔还是图像金字塔，都是从尺度维度去解决小目标信息匮乏 的问题，FPN、SNIP的思想都可以很好的嵌入到Faster R-CNN的检测模型中， 使得小目标检测性能提升很高。
