5.1.2同人关系传播算法最终实现
算法设计
因为本文所要分析的数据量比较大，而第一次改进的标签算法初始时需要给每一个节点分配一个特有的标签,显然对于海量数据来说此算法显得比较笨拙也不太合理。
同人关系传播算法的最终实现初始时不再给每一个虚拟身份设置一个独立的标签，而是将每一个虚拟身份看作是不同的标签，然后将属于同一个使用人的虚拟身份关联起来，相当于对整个的输入文件的所有行进行了取并集操作，即属于同一使用人的所有虚拟身份出现在同一行。整个算法需要进行迭代计算，迭代结束的标志是当输出文件的行数不再发生变化。因为当行数不再发生变化时，说明每两行之间没有共同的元素，不同使用人的虚拟身份也就完全分开，程序实现也很简单，只需要判断文件的行偏移量就可以。过程原理图如表 5-1 所示从表 5-1 中可以看到当迭代进行到第四轮时，输出文件和第三轮的输出文件-·模一样，此时程序运行结束。所得到的结果即为每--行所列出的虚拟身份组分别属于不同的使用人。
Hadoop实现
该算法的MapReduce 实现也是需要两个 Job，两个 Job 串联执行且会循环多次。伪代码如下:
综合表5-1 原理图和伪代码进行具体分析，首先可以看到整个算法需要两个Job 串行执行，且执行的次数也会根据数据量的大小和数据之间的内在关系有所不同。
第一个Job的 Mapper 阶段是将两两出现的虚身份分别当作 key，这样能保证不会漏掉任何一个虚拟身份。而 value 值有所不同，排在前一个的 key 对应的 value 为整行，而排在后一个的 key 对应的 value 只是第一个虚拟身份(后续的暴力解决也可以将它的 value 设置为该整行)。这样如果某两行存在相同虚拟身份则在合并的过程中也不会丢失数据;在 Reducer 阶段对相同 key 的 value进行拼接合并，同时会对相同的虚拟身份进行去重。
第二个 Job 的 Mapper 阶段首先判断第一个 Job 输出的 value 中虚拟身份的个数，如果 value 中只有一个虚拟身份的话，就让其与它的 key 进行比较(compareTo)，如果小于 key 就将 key 和 value 交换位置，这样做的目的是防止产生多余的行而使得算法无限循环，导致程序崩溃:在 Reducer 阶段也是进行简单的 value 列表中元素的拼接合并，同样的，也会对虚拟身份进行去重，最后只将 value 输出接着进行下一轮的迭代运算。
随着算法的不断进行，文件的大小和行数不断的发生变化，而程序会对每次输出文件的行数进行判断，如果发现前后两次输出文件的行数相等则程序终止。因为如果某两行存在相同的虚拟身份，则程序会将它们合并成一行，使文件的行数发生变化。如果行数不在发生变化说明输出文件的每两行之间不再有重复的元素，不同行所列出的虚拟身份即属于不同的使用人。
