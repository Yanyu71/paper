3.3.4显著区域特征提取
本文结合RPN网络，采用了一种更为简单的机制去产生显著区域的候选框：
对CNN的特征图上添加一个显著性判别分类器，该分类器将产生一个新的特征 图，以阈值滤除响应较低的位置，以能覆盖住剩下位置的最小矩形框作为显著区域的 候选框。
图3-11展示了输入图像与分类器产生的特征图的位置对应关系，图中较暗的位 置为分类器产生的特征图滤除的部分，越亮的部分表示特征图上响应越强的地方，我 们用能覆盖住响应的最小矩形作为显著区域的候选框。
25
*
图3Tl显著区域特征提取示意图
最小矩形的计算可表述为图3-12所示。首先挑选一个响应对应的矩形，判断他 是否与另一个矩形相接，如果相接则融合成一个较大的矩形；重复这个过程直到所有 矩形都不相接或者只剩下一个矩形。
图3-12最小矩形计算示意图
显著区域特征提取主要流程按如下进行：
（1）首先对于一个在ImageNet^上预训练好的网络，我们去掉全连接层然后在 最后一个卷积层之后加上两个Inception结构用于特征的调整，在Inception之后加上 尺寸为Ixixc的卷积层和softmax用于分类，C为类别数，本文将交通工具、人即人 脸、动物、杂物作为需要判别为显著区域的类别，外加一个背景类别，构成了一个5 分类的分类网络。以AlexNet网络为例，假设图像输入尺寸为MxM,而这个网络将
26
产生一个尺寸为M/32xM/32xC的特征图。
（2）用一个高度为1的SPPM层将该特征图下采样至IxlxC,表示预测标签。
（3）将Inception结构之前的层学习率都置为0,将图像按一定梯度进行缩放后 作为网络输入（本文中将输入图像从128以32为步长放缩至256）,再使用交叉燧 损失来训练该网络。使得网络能够通过调整新添加的Inception结构对不同大小图像 输入也能正确给出预测。
（4）对于视频中的一帧，我们将其等比放缩至短边长为224像素，将其通过网 络得到softmax层可以得到一个短边长为7的概率分布图，每个通道对应了原图中相 应类别的分类概率。我们以阈值划分滤除响应较低的位置，融合相邻的位置（包括对 角），最终得到的区域即为显著性区域。
（5）由于由最后得到的概率分布图短边长只有7,无法对较小区域产生强响应, 所以利用了更为浅层的特征图搭建了相同的显著区域检测结构，该检测结构输入的特 征图短边长为14,感受野和原始图像上的步幅均为较小特征图的1/2,同样添加了两 层Inception结构和softmax分类器，用相同的方式进行训练。检测输出会与较小特征 图产生的结果进行合并，合并方式先由非极大值抑制以置信度大小的排序为优先级去 除重合度较高且同类别的的区域，然后融合剩下依然重叠的区域，所有不同类别的区 域不会进行抑制和融合。
（6）在完成显著性区域检测后，所有的区域按特征图响应机制映射到需要提取 特征的特征图上，对每个区域的映射结果进行Max Pooling,得到最终结果。
图3-13中显示了整个显著区域检测网络训练和显著区域特征提取的流程。
27
预训练	预训练 'L ..
的网络 \	/ 的网络 \
训练	测试
图3T3显著区域特征提取示意图
