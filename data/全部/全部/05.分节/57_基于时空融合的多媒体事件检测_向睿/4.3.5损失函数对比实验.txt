4.3.5损失函数对比实验
1	.实验设置
本文比较了不同的损失函数对netVLAD方法结果的影响。netVLAD网络采用了 12归一化。
在进行Softmax loss训练时，采用与上述归一化实验中相同的方式。
在采用Hinge loss进行实验时使用L1范数作为损失衡量方式,这与线性SVM的 优化公式是一致的，并且采用Sigmoid函数来代替Softmax进行类别预测，因为 Sigmoid相比于Softmax去除了置信度上的相关性，本文在用于Sigmoid进行预测时 的mAP会比使用Softmax时高出约1%。
在采用Triplet loss进行实验时，去掉用于分类的全连接层，Triplet loss直接作用
54
于VLADcore的输出，样本以五元组形式作为输入，包括两个来自相同类别的视频、 一个不同类别视频、两个背景样本，每个五元组将在损失层形成三个由三元组计算而 来的损失，这三个损失的平均作为网络的输出和梯度计算的基本单元，在网络训练完 成后，将每个视频的局部特征用netVLAD网络提取视频级特征，然后训练SVM分 类器，对测试视频进行类别预测。
三种损失函数在SMALL_90EX数据集上的mAP如表4-8所示。
表4-8损失函数对比实验结果
方法	mAP
Softmax loss	0.498
Hinge loss	0.525
Triplet loss	0.382
2	.实验结果分析
由上述实验中，Hinge Loss为训练netVLAD网络的最佳方案，其原理可等价于 线性SVM的求解过程，只不过优化方式使用随机梯度下降法实现而并非SMO算法。 Hinge Loss只优化分类边界而并非像Softmax Loss依据样本全体的置信度，在某些特 定的任务中有着优势，这也与VLAD在使用SVM进行类别预测得到的高准确率是一 致的。
而Triplet loss适合于特征学习，但由于事件检测目标是给出相应的视频在各个事 件上的置信度，需要用额外的分类器进行类别预测，而分类器的训练和Triplet loss 训练均是有监督的训练，若使用同一批训练样本则会使netVLAD网络提取出的特征 会向训练集偏斜，使得最终准确率降低，而不使用同一批样本意味着需要将训练样本 进行切分，变向降低了训练样本数量，也会引起最终的准确率降低。所以TripletLoss 从原理出发不会得到较好的结果，而实验结果也证实了这一点。
