3.3.5显著区域特征提取与其他方法的对比实验
1	.实验设置
本文比较了三种不同的CNN特征提取方法，在CNN特征提取方法比较的实验 中，均采用caffes框架，使用了 GoogleNetl2988c卬］网络，视频帧采样频率均为每5 帧取一帧。
(1)全局特征
在提取全局特征时，将原始帧按照crop方式输入网络，提取了最后一个Average Pooling层的输出，得到1024维全局特征向量。
(2)密集局部特征
在提取密集局部特征，同样将原始帧按照crop方式输入网络，在最后一个卷积 层之后添加了 3个Max Pooling层，得到大小分别为1 X 1,2X2,3 X3的特征图，构成 共50个1024维密集局部特征。
(3)显著区域特征
在提取显著区域特征前，首先需要进行RPN网络的训练。本文的试验中从 ImageNet上收集了约2000张关于“人”“动物”“交通工具”“规则物体”共四类并且带有
28
Bounding Box的图片，在SUN[43]上收集了约2500张风景照。利用随机裁剪的方式 对样本进行扩充，对于ImageNet上的图片，与原Bounding Box重合度小于0.3的样 本被作为负样本，重合度大于0.7的样本作为正样本，介于0.3与0.7之间的样本被 丢弃；对于风景图片的剪裁全部被加入到负样本当中，以此样本被扩充到越20000 张图片。同时对图像进行尺度上的扩充，分别以128、224作为图像等比例放缩后的 短边长度的最小值和最大值，最终训练样本大约被扩充至越十万张图像。对于样本的 剪裁和尺度变换能够使显著区域检测时得到的特征图响应对目标遮挡和尺度变换具 有更好鲁棒性。
在训练时，本文采用每30张图像进行一次权重更新的方式。
在训练完RPN网络后，对视频帧进行显著区域特征提取，每帧可得到若干个1024 维特征。需要注意的是，本文认为对于较为复杂的事件，视频中的背景环境同样可能 有助于视频分类，所以在显著区域的候选框集合中始终添加一个全局的候选框，使得 对每帧视频的特征提取时总会“看一眼”该帧的整体，但该候选框有助于加强算法鲁棒 性，但由于每帧只会产生一次全局的候选框，对视频的特征表达产生主要影响的仍是 显著区域。
CNN特征采用了由PCA降维和VLAD进行特征聚合用来表示视频，其原理可参 照多媒体事件的时空表示部分。由此得到的视频特征使用SMALLJ0EX数据集训练 支持向量机并进行类别预测，在此基础上得到的CNN不同的特征提取方式在验证集 上的mAP如表3-7所示。同时由于PCA投影矩阵和VLAD码数训练时需要从训练集 中采样，所以训练集视频帧级别的特征不可避免地需要存储在硬盘当中，所以存储消 耗被列入了特征提取的一项评测标准。
表3-7特征提取方法对比实验结果
方法	存储大小	mAP
全局特征	13G	0.481
密集局部特征	367G	0.497
显著区域特征	46G	0.495
2	.实验结果分析
由上述结果可以看出，显著区域特征和密集局部特征两者结果显著高于全局特 征，由于密集局部特征和显著区域特征都是利用特征图响应机制提取的局部特征，能 够表示出更多的细节，所以也响应地提高了结果。
29
密集局部特征和显著区域特征相比，本文认为密集局部特征更优，首先在mAP 上略微胜出，同时由于其形式简单，不许要额外的训练过程，同时由于不需要进行显 著区域的判别，可以很容易地将该方法泛化到其他视频分类或检测的应用场景当中」
本文将密集局部特征提取作为基本的帧级别特征提取方法，在本文其他实验中， 若不做特殊说明，默认使用密集局部特征并沿用其模型、取样间隔、预处理等设置。
然而对于一个小规模的平台，显著区域特征能够在几乎不降低准确率的情况下有 效地减少存储消耗，也是一种候选方案。
本文认为密集局部特征的提取过程中，多尺度的Max Pooling始终会包含显著区 域，但会包含更多的非显著区域；而在显著区域特征提取当中，这些大量的非显著区 域被显著性区域判断给滤除了，所以最终得到的特征占用的存储空间大大减少，并且 这些非显著区域并不会对结果有较多的帮助，所以也没有引起准确率的显著下降。
30
