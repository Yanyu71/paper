3.3BP神经网络算法
BP神经网络，即反向传播网络，是一种有监督的多层前馈网络算法，它的 特点是信号前向传播而误差逆向反馈。BP网络是使用了逆向反馈的方法对算法 的权值以及偏差进行不断调整，从而能够使输出的向量尽可能的接近期望向量。 BP网络的结构包括输入层、隐层和输出层，它的结构图如图3-1：
图3-1 BP神经网络结构图
BP神经网络的训练过程包括前向传输和逆向反馈两部分，其中前向传输是 逐层波浪式的传递输出值，即按照公式逐层计算神经元的输入和输出，逆向反馈 是反向逐层调整权重和偏置，即根据公式对权值和阈值进行修正。前向传输的工 作原理是：首先输入一组数据X］、X2...Xm到输入层，然后通过与隐层的连接 权重产生一组数据Si、S2........Sn作为隐层的输入，然后通过隐层节点的激活函 数后变为f(Sj)其中Sj表示隐层的第j个节点产生的输出，之后隐层的输出与输出 层的连接权重产生输出层的输入，再通过激活函数产生输出层的输出，这里j是 指输出层第j个节点的输出。逆向反馈是从最后一层即输出层开始，目的是为了 调整BP网络的参数，即权值和偏值。逆向反馈调参的依据是网络的输出层的输
26
出值与真实类别之间的差异，通过不断调整参数来缩小这个差异，从而得到合适
的参数。BP算法的流程如下:_______________________
输入：训练集口 = {(八/。犬〉;学习率列
过程：
1：在(0, 1)范围内随机初始化网络中所有连接权和阈值
2： repeat
3： for all	G D do
4：	根据公式计算当前样本输出力；
5：	根据公式计算输出层的神经元梯度项勿；
6：	根据公式计算隐层的神经元的梯度项外;
7：	更新权值和阈值
8： end for
9： until达到终止条件
输出：连接权与阈值确定的多层BP网络________________
在对BP网络进行训练之前首先需要对数据进行归一化处理，归一化处理可 以采用最大最小标准化或者零均值标准化等方法。其中，最大最小标准化方法是 根据原始数据集中的最小值和最大值来对原始数据进行的线性变换，其公式为：
x* =	(3-9)
公式中，/nin为样本数据中的最小值，/n口为样本数据中的最大值。经过最大最 小标准化的数据映射结果在0和1之间，但当有新数据加入时会影响%min和/nax 的值得大小，需要重新定义。而零均值标准化方法是根据原始数据的均值和标准 差来对原始数据进行变换，其公式为：
X* =瞪	(3-10)
其中〃表示样本数据的均值，c表示样本数据的标准差。经过零均值标准化处理的 数据符合标准正态分布，即均值为0标准差为1的正态分布。
激活函数是BP神经网络构建中重要的一个环节，可以理解为给BP网络加 入一些非线性元素，从而神经网络可以更好的解决复杂问题。常用的激活函数有 Sigmoid函数、Tanh函数和ReLU函数等。Sigmoid函数公式为：
f(x)=E	(3-U)
它的优点是可以将输出映射在0与I之间、单调连续、优化稳定且求导容易，缺 点是输出不是以0为中心，容易饱和从而产生梯度消失导致训练出现问题。Tanh 函数即双曲正切函数，公式为：
tanh(x) =	(3-12)
27
相对于sigmoid函数它的优点是收敛速度快，且输出是以0为中心的，能够将数 据压缩到-1至U 1之间，但是仍然会出现梯度消失的情况。ReLU函数即线性整流 函数，公式为：
f(x) = max(0,x)	(3-13)
具有实现简单，收敛速度快，梯度不会饱和从而缓解了梯度消失的问题以及在无 监督时也有良好表现的优点。ReLU函数在训练时可能会出现神经元权值无法更 新的情况，可以尝试用设置合适的较小的学习率来解决这一问题。Sigmoid函数 和Tanh函数适用于解决分类问题，ReLU函数适用于解决逼近问题。BP神经网 络中神经元的结构见图3-2：
图2-3神经元结构图
BP神经网络具有很强的非线性映射能力、自学习能力、泛化能力以及容错 能力等优点。在非线性映射能力方面，BP网络的实质实现了从输入到输出的映 射，对内部情况较为复杂的问题比较适合。在自学习能力方面，BP网络在训练 时可以通过学习自动的提取数据间的规则，从而反映在网络的权值中。在泛化能 力方面，BP网络可以对有噪声污染的情况仍然进行正确的分类。在容错能力方 面，BP网络即使在某些神经元受到破坏的情况下依然可以有较为准确的预测结 果，能够正常的进行预测工作。
将BP网络应用在工程中，会出现容易陷入局部极小化以及误差收敛速度慢 等问题。首先，BP网络需要解决复杂非线性函数的全局极值求解的问题，但它 本质上可以理解为是局部搜索的优化方法，因此容易陷入局部极值的情况，从而 导致训练失败。其次，BP网络需要进行优化的目标函数也特别复杂，但算法其 本质上用的是梯度下降法，因而会出现BP网络的收敛速度慢这一问题。此外， BP网络还具有样本依赖性的问题。为了解决以上问题，在实际应用中可以选择 加入正则项或者采用共轨梯度法、动量算法等方式对BP网络进行改进。
