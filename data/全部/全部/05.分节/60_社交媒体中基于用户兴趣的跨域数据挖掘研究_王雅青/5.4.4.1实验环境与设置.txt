5.4.4.1实验环境与设置
(-)数据集选取
为了评估本章所提方法在处理动态跨域数据情况下的优势，此处选取了三个包 含用户行为时间信息的跨域数据集来评估模型的性能。
Movielens-20M:包含了用户在MovieLens网站上对于不同类别的电影的点评记 录。数据集中提供的电影的类别信息，可以被用来构建不同的跨域数据集。本实验选 择了有相似主题且评论信息较多的一对类别Thriller-Action (TA)作为跨域数据集。
Goodreads[31h为从goodreads网站收集的包含不同类型的图书，且包括大量的 评价记录。提取其中的Children和Comics (CC)类别作为跨域数据集。
DoubanEventP41：包含了用户在Douban网站上对于电影、音乐和书籍域的评分 行为序列。本实验提取了电影和书籍域的评分记录，构建了 Movie-Book (MB)跨域 数据集。
每个数据集都包含了用户ID、项目ID、时间戳和评分。由于Movielens-20M和 Goodreads中每个项目都有多个类别标签，因此TA数据集和CC数据集都包含跨域 重叠项目。而DoubanEvent中的每个项目都只属于一个域，因此MM数据集中没有 跨域重叠项目。
对于每一对跨域数据集，按域对数据进行预处理。首先利用30min为间隔，将每 个序列都划分为不同的会话。删除包含评分总数小于10的项目、包含项目数低于3 的会话和包含会话数低于5的用户。三个跨域数据集的统计数据如表5-8所示。然后, 使用两种不同的策略来生成训练集、验证集和测试集。策略1主要针对不同模块性 能和整体性能分析设计的，将三个跨域数据集中各个域中最后3个月的会话作为测 试集，剩余的数据作为各个数据集的训练集。同时，过滤掉在测试集中出现但没有 在训练集中出现的项目和项目数低于3的会话。另外，将各个训练集中最后3个月 的会话作为验证集。策略2是为了评估各个方法在面对单域的数据稀疏性问题时的 表现而进行设计的，通过随机地删除原始训练集不同比例的数据来构建不同稀疏度 (^ = <10%,30%,50%,70%))下的训练集的变体。测试集和验证集与策略1中相同。
114
表5-8 三个跨域数据集的统计数据表
数据集	Children-Comics (CC)		Thriller-Action (TA)		Movie-Book (MB)
域	Children	Comics	Thriller	Action	Movie	Music
事件数	3,509,683	2,737,285	1,675,208	1,756,233	2,610,110	1,142,677
用户数	27,606	20,152	12,985	12,804	8,371	6,836
项目数	62,848	51,875	2,714	2,281	32,320	54,021
会话数	376,429	267,377	127,149	124,432	265,607	150,133
重叠项目数	661		789		0
重叠用户数	5,786		11,329		5,177
(二)对比方法选取
为了验证本章所提方法的有效性，分别将其与单域推荐方法和跨域推荐方法进 行对比。
单域推荐方法
1.	BPRP5］： 一种未考虑时间信息的矩阵分解方法。
2.	HRNNW： 一种个性化的基于多层RNN的方法，通过联合建模会话内和会话间 的动态信息来捕捉短期和长期兴趣。
3.	GRU4REC+3］： 一种基于RNN的方法。该方法集中于短期兴趣的建模，通过 引入新的排序损失函数以克服梯度随样本数量增加而消失的问题。
4.	卷积序列化嵌入的推荐模型(Convolutional Sequence Embedding Recommendation Model, Caser)以］： 一种基于卷积的序列嵌入方法，通过对用户的行为序列进行 卷积运算来建模短期兴趣的动态变化。
5.	分层门控网络(Hierarchical Gating Networks, HGN)［33］： 一种分层门控神经模型, 该模型通过应用两个门控模块来捕捉有代表性的短期信息和项目特征。
跨域推荐方法
1.	CDIE-C：第4章提出的基于嵌入的跨域推荐方法，通过捕获短期行为模式来学 习跨域项目表示。采用一种简单而有效的方式来引入长期兴趣信息，使用用户 交互过的所有项目的表示的平均值作为长期兴趣的表示。
115
2.	域切换感知的整体循环神经网络(Domain Switch-Aware Holistic Recurrent Neural Network, DS-HRNN)［13］：一种基于RNN的跨域方法，目的是捕捉短期的跨域 序列化模式。
3.	CDHRM： 5.3节提出的方法。利用多层循环神经网络来捕捉用户的全局兴趣动 态性和单域内的用户兴趣变化模式，但忽略了由于捕捉跨域动态行为而损失的 单域行为链接。
4.	CDRGM：本节提出的方法。为了进一步评价模型中的不同模块对模型整体 性能的影响，设置了 CDRGM的不同变体。定义CRN为只使用CRN模块的 变体；CRN-f为使用CRN但删除了融合层的变体；CDRGM-i、CDRGM-s和 CDRGM-1虽然都同时引入了 CRN和CGN。区别在于，CDRGM-i在CGN模 块的输入层中删除了基于项目级的长期兴趣表示部分，CDRGM-s在CGN模块 的输入层中删除了基于会话级的长期兴趣表示部分，而CDRGM-1为删除了跨 域兴趣正则化函数后的变体。
实验中，BPR和CDIE-C中的嵌入维度都设置为100.基于RNN方法(HRNN, GRU4REC+, DS-HRNN、CDHRM和CDRGM)的每一层RNN的隐藏单元数也统一 设置为100。对于学习率，基于RNN的方法、BPR和CDIE-C的学习率设置为0.1 时性能最优，Caser和HGN的学习率设置为0.001时性能最优。为了获得最好的性 能，基于RNN的方法、BPR、CDIE-C和Caser的最小批设为100, HGN的最小批 设为4096。各个方法的其他超参数将按照论文中的原始设置进行设定。CDRGM的 。、。和为在CC跨域数据集中设为0.7/0.6/0.5,在TA数据集中设为0.3/0.3/0.5,在 MB数据集中设为0.4/0.3/0.5。此外，设置/和£/都为3,项目嵌入维度为100。另 外，由于使用多层RNN并没有显著提高模型的性能⑶，因此本章提出的方法使用单 层RNN。为了平衡训练时间和实验性能Ml,设定负样本的数量为128。CDRGM和 CDHRM都是在python的Theano框架四］下实现的。所有的基于RNN的方法都是在 配备24GB的GPU内存的NvidiaM40服务器上进行训练。
(三)评价指标设置
实验中采用两个在会话型推荐中广泛使用的评价指标来评估各个方法的性能。具 体地,Recall@K度量候选列表中正确结果位于前K个结果中的比例，Ke{10,30,50}。 Recall@K认为结果排序中的前K个候选项目组成的集合中的所有项目的重要性程度
116
都是相同的。MRR中使用正确结果的倒数排名来强调在所有结果中排名较高的结果 比排名较低的结果更重要。
