5.3.4.1实验环境与设置
(一)数据集选取
为了验证本节所提方法在处理动态跨域数据情况下的优势，构造了三个包含 用户行为时间信息的跨域数据集来评估模型的性能。三个跨域数据集分别为基于 Movielens-20M数据集构建的Comedy-Romance数据集、Thriller-Action数据集和基 于 DoubanEvent 构建的 Movie-Music 数据集。
Movielens-20M①由Grouplens组织进行收集。包含了用户在MovieLens网站上 对于不同种类电影的点评序列。包含了用户ID、项目ID、时间戳和评分。数据集中 提供了电影的类别，常被用来构建不同的跨域数据集［21-23］。本实验选择了有相似主 题且评论信息较多的两对类别作为两个跨域数据集，即Comedy-Romance (CR)数 据集和Thriller-Action (TA)数据集。由于每个电影都有多个标签，因此CR数据集 和TA数据集都包含跨域重叠项目。
DoubanEvent124］包含了用户在Douban网站上对于电影、音乐和书籍域的评分 行为序列。包含了用户ID、项目ID、时间戳和评分。本实验提取了电影和音乐相关 的评论信息，构建了 Movie-Music(MM)跨域数据集。由于DoubanEvent中的每个项 目都只属于一个域，因此MM数据集中没有跨域重叠项目。
使用带有跨域重叠项目和没有跨域重叠项目的数据集的实验可以有效验证 CDHRM方法对于各种跨域场景的通用性，例如具有相似功能的跨域场景(如 Youtube和Netflix都是电影类的域)，具有不同功能的跨域场景(例如Pandora和 Youtube分别是音乐域和电影域)。
图5-7展示了实验部分的具体步骤。对于每一对跨域数据集，将两个不同域的序 列化数据输入，并按步骤1进行预处理。具体地，我们首先利用为间隔，将每个序
① https://grouplens.org/datasets/movielens/20m/.
98
列都划分为不同的会话。为了更好地验证各方法的性能，只保留域中评分总数超过 10的项目。除此之外，还过滤掉包含项目数低于3的会话和包含会话数低于5的用 户。接下来，将两个处理过的序列合并成跨域序列。三个跨域数据集的统计数据如 表5-1所示。然后，步骤2使用两种不同的策略来生成训练集、验证集和测试集。通 过迭代测试用户、会话和其中的项目进行评估。该模型为测试会话预测其中每个项 目的下一个可能的项目。
表5-1	三个跨域数据集的统计数据表
数据集	Comedy-Romance (CR)		Thriller-Action (TA)		Movie-Music (MM)
域	Comedy	Romance	Thriller	Action	Movie	Music
事件数	2726412	1052982	1675208	1756233	2610110	1031952
用户数	15196	10422	12985	12804	8371	4866
项目数	5220	2522	2714	2281	32320	37116
会话数	167110	93289	127149	124432	265607	127328
重叠项目数		1230	789		0
重叠用户数		10176	11329		3958
步爨2：构建实验数据集
步骤3：实验
步骤1
预处理
策略1
针对问题1、问题2 ,和问题4的训练一
输入
策略2
训练集
测试集
验证集
什对问题1、问题2、问跑3— 和问题4的测试
■针对问题3的训练■
针对问题1、问题2、 问题3和问题4的 参数谖优
跨域推荐	)
图5・7	实验流程图
构造训练集、验证集和测试集的两种策略如下：
1	.针对融合性能、整体性能和时间性能分析，目标是为每个用户预测在每个域中 的下一个顺序行为。针对CR数据集和TA数据集，将各个域中最后6个月的 会话作为测试集，针对MM数据集，各个域中最后3个月的会话作为测试集。 剩余的会话数作为各个数据集的训练集，并过滤掉在测试集中出现但没有在训 练集中出现的项目和项目数低于3的会话。另外，将CR数据集和TA数据集 的训练集中最后6个月的会话作为验证集，将MM数据集的训练集中最后3个 月的会话作为验证集。
99
2	.为了验证各个方法在应对单域中数据稀疏性问题时的表现，通过随机地删除原 始训练集不同比例的行为记录来构建不同稀疏度(& = ［10%,30%,50%,70%］) 下的训练集的变体。测试集和验证集与1)中相同。
最后，步骤3利用策略1产生用于问题1、2和4的实验集，使用策略2产生用 于评估问题3的实验集。
(二)对比方法选取
为了证明本节提出的CDHRM的有效性，将其与先进的单域推荐方法和跨域推 荐方法进行比较：
单域推荐方法
1.	BPRP5］： 一种未考虑时间信息的矩阵分解方法。该方法通过随机梯度下降法优 化一个成对排序的目标函数。
2.	Item2vec［26］： 一种基于word2vec模型的项目嵌入方法。将项目序列看作是单 词序列。
3.	序列化过滤的基于会话的最近邻(Sequential Filter Session-based KNN, SF-SKNN)W：基于会话的最近邻方法。它设计了一个评分函数，在计算相似度时 考虑会话中项目的顺序。
4.	GRU4RECU9］： 一个基于RNN的方法，通过引入基于排序的损失函数使其更适 用于会话型推荐任务。
5.	分层循环神经网络(Hierarchical Recurrent Neural Networks, HRNN)［3］：一种个 性化的基于多层RNN的方法，分别建模了单域中的会话间和会话内的兴趣演 化模式。
6.	GRU4REC+。。］： GRU4REC的扩展版本。通过引入新的排序损失函数以克服梯 度随样本数量增加而消失的问题。
跨域推荐方法
1.	基于典型相关分析的跨域推荐(Cross Domain Recommendation using Canonical Correlation Analysis,CCA-CDR)tnl ： 一种基于典型相关分析(Canonical Correlation Analysis, CCA)的跨域推荐方法。该方法分别独立学习每个域中的用户和项目
100
的向量化表示，然后将每个域的向量空间投影到基于跨域重叠用户对的公共向 量空间中。
2.	CDIE-C：第4章提出的基于双聚类的跨域稀疏兴趣嵌入模型的跨域推荐方法。 通过使用双聚类来提取跨域的基于类别的关联，然后联合利用单域会话和跨域 会话来学习项目的跨域综合表示。由于它适用于匿名环境，为了更公平地进行 比较，通过引入用户信息来扩展CDIE-C,使用用户交互过的项目的表示的平 均值作为用户的表示。
3.	CDHRM：本节提出的方法。通过联合利用用户的跨域序列化行为来学习到用 户的跨域动态兴趣表示，以提升推荐的性能。此外，基于用户级RNN的不同融 合方案设置了 CDHRM方法的不同变体。CDHRM-n为不使用融合机制的版本; CDHRM-c使用基于连接的融合方式来描述用户行为；CDHRM-p采用了基于 乘积的方式捕捉交互模式；CDHRM-cpl和CDHRM-cp2为分别使用基于连接 和基于乘积的方式1和方式2来探索基于连接和基于产品的融合性能。此文中, 将 CDHRM-cp2 也称为 CDHRM□
针对单域推荐方案，根据每个域单独训练模型并分别为每个域推荐相应的项目-针对跨域推荐方案，联合训练两个域的数据，然后基于互补的信息联合为两个域来 推荐相应的预测项目。SF-SKNN方法中的邻居会话数在三个跨域数据集中都设置 为100。对比方法中的嵌入维度设置为100。实验中每一层RNN的隐藏单元数设置 为100。使用具有动量的AdaGrad^］来优化基于rnn的对比方法，迭代次数设为 10o由于使用多层RNN并没有显著提高模型的性能网，因此本文提出的方法使用单 层RNN。本文利用MRR在验证集上来监控CDHRM方法的收敛性。上述方法的所 有超参数和学习率都是基于网格搜索在验证集上进行调优的。为了保证实验的可重 建性，基于CR和TA数据集上实验的超参数如表5-2所示。由于CR和TA数据集的 性质相似，两个数据集使用相同的超参数。根据用户级GRU、会话级GRU和初始化 的顺序选择HRNN方法中的Dropout概率。根据跨域6应九八域感知的6位/念、跨 域GRU四和域感知的GRU腹中的融合层以及GR% 的初始化的顺序选择，分层次 地选择CDHRM的Dropout概率。为了平衡训练时间和实验性能皿】，选择128个负 样本。此外，由于增加少量负样本后，GRU4REC和HRNN方法的性能也会略有提 高（这与文献［2。］的结果一致），所以在对比实验中也为这两种方法增加了采样部分。
（三）评价指标设置
101
表5-2 CR和TA数据集中的超参数设置表
方法	CR and TA datasets
最小批	Dropout 值	学习率/ Momentum 值	额外采样数
GRU4REC	100	0.2	0.1/0.5	128
GRU4REC+	100	0.2	0.2/0.1	128
HRNN	100	0.1/0.2/0.2	0.1/0.1	128
CDHRM-n	100	0.1/0.2/0.0/0.1/0.2	(M/0.0	128
CDHRM-c	100	0.0/0.2/0.1/0.1/0.1	0.1/0A	128
CDHRM-p	100	0.0/0.2/0.1/0.1/0.2	0.1/0.0	128
CDHRM-cpl	100	0.1/0.1/0.0/0.1/0,2	0.1/02	128
CDHRM	100	0.0/0.1/0.0/0.1/0J	0.1/0.2	128
许多在推荐任务中使用的指标（如召回率、精确度、F1和MRR）［3J9,20,28］也可 以用在会话型推荐任务中。在某些实际的应用场景中，不强调推荐项目的顺序区别。 因此首先采用了一种广泛使用的度量指标Recall@K。Recall@K认为只要正确结果 在前K个候选结果中即可，不强调正确结果的排名。同时，也有一些推荐场景中更 强调排名靠前的结果的重要性（例如，排名较低的结果只有在滚动之后才能看到）。 因此，本实验才用的第二个指标为MRR,它认为正确结果在候选列表中的不同顺序 代表了不同的重要性。具体来说：
•	RecaIl@K度量候选列表中正确结果位于前K个结果中的比例,Ke {10,30,50}。
•	MRR中使用正确结果的倒数排名来强调在所有结果中排名较高的结果比排名 较低的结果更重要。
