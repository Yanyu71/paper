5.5.2强化学习改进性能分析
本节进行了一系列的对比实验来评估强化学习模型的表现。包括本文设计实 现的模型和其它经典模型的准确性、模型复杂度和训练时间消耗的比较。这些都 是利用Tensorflow框架在树莓派4B上完成的。
数据集都是在前文的数据集上做了变化以求证强化学习的效果，用到了两种 变化，一是抽油机有杆泵示功图的坐标置换数据集，其中每个任务由坐标的固定 排列转换而成。二是抽油机有杆泵示功图的旋转数据集，其中每十个一组的旋转 角度都是在0到180度之间的固定值。
用来对比的模型有：(l)DNN,跨所有任务训练的单个全连接网络；⑵CNN, 第四章使用到的预训练的卷积神经网络；⑶梯度情景记忆a】 (Gradient Episodic Memory, GEM)； (4)渐进式神经网络网(Progressive Neural Network, PNN)； (5) 本章使用到的动态可扩展网络RCL。
通过考虑所有任务的平均测试精度、模型复杂度和训练时间来评估每种比较 方法。通过训练所有任务后模型参数的个数来度量模型的复杂度。本文首先对比 了各组模型的测试准确率和模型复杂性，结果如图5-1和图5-2。
经过所有任务的平均測试准确率
图5-1测试集在不同模型上的平均测试准确率
图5・2不同模型上的网络参数数量
此外通过固定大小和可扩展网络之间的比较，可以很容易地发现，具有固定 大小网络结构的方法，如DNN、CNN和GEM,具有较低的模型复杂度，但是它 们的预测精度比那些具有可扩展网络的方法差得多，女口 PNN和RCL。这表明动 态扩展的网络确实可以极大地提高模型的性能。
(a)测试集为坐标置换示功图集	(b)测试集为角度旋转示功图集
图5-3不同模型准确率随任务数的变化
为了更好评价我们的模型对旧知识的识别性能。图5-3显示了随着学习更多 任务，对第一个任务测试数据的测试准确度的变化。RCL和PNN表现出基本无 遗忘，而不扩展网络的方法则产生灾难性遗忘。此外，由于GEM在学习新任务 时会重新训练先前的参数，因此不能完全防止遗忘。
(a)测试集为坐标置换示功图集	(b)测试集为角度旋转示功图集
图5-4奖励设计中参数a的影响
测试精度和模型复杂性之间的平衡结果如图5-4所示。本文通过奖励函数中 的系数a来控制模型性能和复杂性之间的平衡。随着a的增加，模型复杂度显著 不降，而模型性能也逐渐恶化。有趣的是，当a较小时，精度的下降要比参数个 数的减少慢得多。这一实验结果有助于在实际应用中根据需求选择合适的a,使 得中等规模的网络仍然可以获得相对较好的模型性能。
