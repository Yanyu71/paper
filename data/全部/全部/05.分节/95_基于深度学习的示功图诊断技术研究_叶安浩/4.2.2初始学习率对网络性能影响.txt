4.2.2初始学习率对网络性能影响
初始学习率，即是网络在每一个epoch中前进的间隔，以最经典的有监督随 机梯度下降算法来为例分析，其梯度原理如式4-2。
wt+i = wt-r］活心刃(x,Wt)	(4-2)
其中九是batchsize, 77是学习率，初始学习率如果过小，会导致模型收敛速度 慢甚至无法学习，过大，可能跨过最优解导致模型无法收敛。因此，在本节将使 用搜索法来找到最合适示功图识别的模型初始学习率。
虽然数据集在浅层LeNet-5模型的结构上收敛并整体状态良好，但是最终的 准确率仍不是很符合预期。考虑到可能浅层模型网络的容量较小，不足以表征示 功图的特征，因此参考到VggNet的深层次卷积神经网络，本文考虑采用加深网 络的做法，将卷积层和池化层的组合层叠的次数由两次改为三次。
表4・2初始学习率实验网络结构
网络层
激活函数
维度
步长
dropout
Input
-
224*224
-
Convolution 1
Relu
224*224*32
2
Maxpooling
-
112*112*32
0
Convolution2
Relu
112*112*64
2
Maxpooling
-
56*56*64
0
Convolutions
Relu
56*56*128
2
Maxpooling
-
28*28*128
0
Flatten
-
28*28*128
-
FullyConn
Relu
FullyConn
Softmax
卷积核的大小在经过上一节的实验后确定为5*5,本节实验模型结构整体相 同，只不过多增加了一层卷积层和池化层，进一步提升模型的学习能力，随后再
34
连接了两个全连接层对感受野特征进行降维，最后通过Softmax层进行分类，具 体的网络结构如表4-2所示。
根据上述网络结构，利用搜索法，对于学习率从10的-5次幕到10的0次幕 进行了枚举实验，得到的收敛loss如图4-4o
Learning rate(log scale)
图4-4收敛时Loss和初始学习率关系曲线
从图4-4可以看岀，大约在初始学习率为0.01时，能够获得最低的收敛时 Loss值。下图记录了 learningrate=0.01时的模型收敛曲线，从如下图4-5(a)可以 看到，网络减少到只需要大约300轮训练后收敛，准确率也提高到了 0.966,从 图4-5(b)可以看到，网络的loss收敛在0.0928,总的来说，三层卷积层和池化层 交替的模型性能大大优于两层卷积层和池化层交替。
(a)初始学习率0.01时准确率	(b)初始学习率0.01时损失
图4-5初始学习率0.01时模型性能
