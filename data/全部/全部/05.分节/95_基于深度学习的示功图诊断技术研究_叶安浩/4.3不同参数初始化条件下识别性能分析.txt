4.3不同参数初始化条件下识别性能分析
根据VGGNet的实现方式，初始网络权值对于网络后续的训练和收敛影响 都很大。VGGNet中神经网络的权值初始化是采用到了小模型预训练的方法。通 过VGG中层数更少的A模型，进行训练调整，得到网络权值的初始值。然后当需要用到正式的VGG模型时，使用之前已经训练好的A模型的权值初始值，对 VGG模型的浅层进行权值赋值。借鉴此思路，考虑到在第二章中进行自编码器 增强时，选用了卷积自编码器，其编码层正好是简单的卷积层，训练后已经能够 表征部分示功图的特征，因此在本节，将具体研究常见初始化方法和自编码器初 始化对于网络收敛性能，识别率的影响。
常见的初始化方法有Xavier"?】和MSRAH8］初始化。在Glorot提出的Xavier 初始化方法中，主要针对对于每一层网络神经元初始激活值，这些值要满足两条 经验性准则，一是每一层的平均值要保持为0,二是每一层的方差要相同。但是 Xavier的初始化要求神经网络的激活函数关于0对称，但是本章考虑的卷积神经 网络用到relu激活函数，所以暂不考虑Xavier初始化方法。MSRA初始化由 Kaiming提出，只考虑输入的个数n, MSRA的初始化和Xavier初始化不同的 是，针对对于所有网络神经元初始激活值，这些值整体分布满足均值为0,方差 为阿^的高斯分布。
因此在实验得到的基础模型结构的基础上，设计了对比实验共三组，⑴无初 始化组(2)自编码器编码层参数初始化(3)MSRA初始化。
网络采用5*5的卷积核，釆用卷积层和池化层交替构建，卷积层和池化层交 替次数改为三次，随后连接两个dropout层和两个全连接层，最后通过Softmax 层进行分类三组模型的准确率和Loss收敛表现如图4-7。
(a)不同初始化方法下准确率	(b)不同初始化方法下损失
图4-7不同初始化方法下模型性能
可以看到无初始化(随机初始化)情况下，网络大约在400步左右收敛,MSRA 初始化方法下，网络大约在300步左右收敛，而通过自编码器的编码层参数初始 化方法下，网络大约在200步左右收敛。
由此可见，这样的预训练带来的好处是，自编码器的编码层参数已经学习到 表征一部分示功图的特征，随后的训练其实是在这些已经带有示功图特征的参数 上进行微调(finetuning)的过程，这样既能够避免陷入局部最优解，又能节省了 时间和计算资源。预训练能够很好的使得模型迅速收敛，从而只需要微调使模型 更加优化。
