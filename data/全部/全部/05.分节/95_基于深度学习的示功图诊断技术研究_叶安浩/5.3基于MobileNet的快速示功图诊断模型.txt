5.3基于MobileNet的快速示功图诊断模型
本节借鉴了 MobileNet网络的基本思路，它在卷积神经网络的基础上做出了 卷积层分解并引入了倒残差结构，其目标是为了对CNN的模型结构轻量化以适 应移动端的嵌入式设备。考虑到在第四章中设计实现的模型结构，利用到了三组 卷积层和池化层组合的层叠结构，本章将引入卷积层分解的思路来优化这样的卷 积模型，使其能够在树莓派上完美运行。接下来将详细介绍思路。
MobileNet的vl模型主要提岀了深度可分离卷积的思路，标准卷积其实是 将输入的图像像素矩阵与卷积核直接进行卷积运算获得结果，深度可分离卷积利 用了矩阵论中的矩阵分解思想，把卷积核的矩阵进行分解成为两个小矩阵依次与 输入图像的像素矩阵进行矩阵乘法运算，这样的做法能够在矩阵乘法时节约很多 计算次数，使得硬件需求降低，更适用于嵌入式设备，下面详细分析。假设标准卷积层是输入一个DF XDFX M维度的特征映射F,其卷积核K的 维度为DKXDKXMXN,输入图像像素矩阵与其进行卷积计算，输出成一个 Dp x DF x N维度特征映射G。
按照如上定义，标准卷积的输出特征映射的计算应如式5-1。
(5-1)
因此可以推断，标准卷积层需要的计算量总共为DK XDKXMXNXDFX DF.可以看到总计算量是与上述参数都是乘法关系的。
深度卷积的维度DKxDKxl,逐点卷积的维度是lxlxM。按照上式来计 算，深度卷积层来提取特征需要的计算量总共为DK XDKXMXDFXDF,逐点卷 积来对这些特征进行线性组合需要的计算量总共为M XNXDFXDF.
即用来对标准卷积进行矩阵分解后，总共需要的计算量为：DKXDKXMX DF x DF + M x N x DF x DF。
通过卷积核矩阵分解的方法，将总计算量与网络结构参数的乘法关系改为了 加法关系，这样做比可得减少的计算量大概如式5-2。
DKXDKXMXDFXDF+MXNXDFXDF _ £	1	(5 2)
D^xD^xMxNxDpXDp	N D^2	， )
表5・1深度可分离卷积网络结构
网络层
激活函数
维度
步长
dropout
Input
-
.224*224
-
Dw Conv
Relu
224*224*1
2
Conv
Relu
1*1*32
2
Maxpooling
-
112*112*32
0
Dw Conv
Relu
112*112*64
2
Conv
Relu
1*1*64
2
Maxpooling
-
56*56*64
0
Dw Conv
Relu
56*56*1
2
Conv
Relu
1*1*128
2
Maxpooling
-
28*28*128
0
Flatten
-
28*28*128
Fully Conn
Relu
256
-
0.5
Fully Conn
Softmax
64
-
0.5
Output
-
10
-
-
在本节的工作中把第四章的模型结构建立在本节提到的深度可分离卷积上 进行了更新，模型结构如表5-1所示。除了全连接层的每一层之后都使用到了 batchnorm和ReLU非线性激活函数，最后输入到softmax激活函数进行输出分 类。这里将深度卷积和逐点卷积都设置为单独的层。
此外，尽管基于MobileNet改造后的模型架构已经比较小，本节工作中还引 入了宽度参数a和分辨率参数p来适用于方便根据实际应用需求调整模型的性能。
43 宽度乘数a的作用是将卷积层的输入通道数改变为aM,输出通道数改变为aN, 达到不调整模型结构以控制卷积层大小的目的。分辨率参数Q的作用是在对输入 图像的分辨率进行调整，使得卷积框的大小变为PDF。引入了上述两个调整参数 后，模型的总计算量为：DKX DKX aM x pDF x pDF + aM x aN x pDP x pDF.
其中a 6 (0, 1),常用取值是),其中p = 1 时 为基础模型，对应示功图分辨率为224*224,通过调整p<l的值，使得模型输入 的示功图常用分辨率取值为224, 192, 160, 128。引入这两个参数的作用是可以 在几何倍数上将计算量和参数个数减少，按照实际需求对模型进行轻量化，从而 达到适配嵌入式设备的目的。
