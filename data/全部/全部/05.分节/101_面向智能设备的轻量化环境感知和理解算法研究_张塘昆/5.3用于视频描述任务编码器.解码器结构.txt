5.3用于视频描述任务编码器.解码器结构
近年来，视频描述技术已经取得了很大的进步，但是主流的方法仍效率较低。 在视频描述领域，现在主流的方法是encoder-decoder框架，视频数据通常由编码 器部分，一般是由卷积神经网络构成，编码为序列向量，视频的描述结果通常通 过解码器部分，一般是由循环神经网络构成。当使用RNN的结构的情况下，单 个序列输入的当前的输出与过去的输出均有相关，确切的表现方式是神经网络模 型会对前面的信息进行记忆保存，保留在神经网络的内部状态中，并在计算当前 输出的时候被使用，即神经网络的隐藏层之间的节点不再是孤立的而是有相互的 关联性，并且隐藏层的输入不单单包含输入层的输出同时还包含了上一时刻隐藏 层的输出。近来兴起的Transformer模型，解决了 RNN时序依赖的问题， Transformer不依赖于过去的隐藏状态来捕获对先前单词的依赖性，而是整体上 处理一个句子，以便允许并行计算，减少训练时间，并减少由于长期依赖性而导 致的性能下降。
Transformer结构近年来在自然语言领域取得了巨大的成就，也有很多的其他 的领域采用transformer的方法去解决问题，但是Transformer在很多领域取得了 巨大的成果，但是弊端也存在。Transformer的参数量巨大，Transformer主要由 多头自注意力模块和前馈神经网络模块组成，其中多头自注意力机制的计算成本
51
是n的2次方，这种量级的计算量显然无法在低算力设备上部署，因此原始的 Transformer结构进行多模态的特征的融合是不现实的⑴］。为了解决这个问题， 本文将跨模态的自注意力机制和Transformer的轻量型变体DeLight52进行结合, 构建出跨模态的轻量型自注意力机制的结构用于视频描述。图5-3为原始的 Transformer架构，图5-3为Transfomer的轻量型变体DeLighB】。
图5-3.原始的Transformer结构°习
DeLighT的核心是DExTra转换，使用带有扩展-缩减策略的组线性转换来有 效地改变DeLighT块的宽度和深度。由于这些转换本质上是局部的，所以DExTra 使用特性变换（类似于卷积网络中的通道变换）来在不同组之间共享信息。这种广 泛而深入的表示方式有助于用单头注意力和轻量级前馈层替换Transformer中的 多头注意力和前馈层，从而减少了总网络参数。DExTra将一个％维的输入向量 映射到一个高维空间，然后使用N层的组变换将其缩减为一个D。维的输出向量 （缩减）。在这些扩展和缩减阶段，DExTra使用组线性变换，因为它们通过从输入 的特定部分导出输出来学习局部表示，并且比线性变换更有效。为了学习全局表 示，DExTra使用特征变换进行组线性变换，在不同组之间共享信息
提高Transformer的表现力和容量的标准方法是增加输入维度。机。但是，线 性增加％也会增加标准Transformer中多头注意力的操作n2Dm,其中n是序列 长度。相比之下，DeLighT为了增加的表现力和容量，通过扩展和缩小阶段来增 加中间层的深度和宽度。这使本文能够使用更小的维度来计算注意力，需要更少 的操作。
图5-4. DeLighT结构
假设本文有一个n个输入序列，每个序列的维数为。冲，这些n个Dm维的输 入首先被输入到DExTra变换以产生n个D。维的输出，其中D。＜ Dm.然后使用 三个线性层同时投影这些n个D。维的输出，以产生D。维的查询0、键K和值几 然后，使用缩放点积注意力为这n个序列之间的上下文关系建模。为了使用残差 连接，该注意力操作的D。维输出被线性投影到D讥维空间。DeLighTblock计算成 本比标准Transformer降低了響倍阿。
在前馈神经网络中，Transformer中的FFN相似，包含两个线性层。由于
53
DeLighT块已经使用DExTra变换合并了更广泛的表示形式，因此可以在变换中 反转FFN层的功能。第一层将输入的维数由降维到。机〃，第二层将输入的维 数Dm/r扩展到D机，其中r为降维因子，比如把维数减少了 4倍，相当于参数量 减少了 16倍呵。
本文中，将结合DeLighT和上述部分的跨模态的注意力机制，构成了本文使 用的结合跨模态自注意力机制的轻量化的编码器-解码器结构。具体操作如下所 述，本文将多头注意力机制模块和跨模态注意力机制模块在原有的Transformer 形式上进行改进，改成DeLighT版本的多头注意力机制模块和跨模态注意力机 制模块。首先，将输入的各个特征序列进行升维，然后利用N层的群变换进行降 维，之后进行自注意力操作，在将维度升为原始的特征维度,送入前馈神经网络， 前馈神经网络中进行降维再升维，以到达减少参数的目标。
