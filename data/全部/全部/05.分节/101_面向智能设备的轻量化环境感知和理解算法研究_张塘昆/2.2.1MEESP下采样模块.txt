2.2.1MEESP下采样模块
More Extremely Efficient Spatial Pyramid of Depth-wise Dilated Separable Convolutions （更为高效的深度可分离空洞卷积金字塔），如图2-2所示，本文首 先将传统的标准卷积核分解为两个低秩卷积核，同时将以池化代替步长进行下采 样，本文在MNIST手写数字分类数据集上验证了这种方式的有效性，该模块在 降低复杂度的同时，引入了一种动态的多分支卷积得分机制。本文发现这种方式 能够使神经网络更为有效的选择感受野，从而动态地关注更为有效的分支。
中间支路:在下采样阶段,本文首先使用了0 = 4的pointwise group convolution （逐点分组卷积），将较高维度的投射到较低的维度。在ESPnetv2中，下采样操 作由标准的步长为2的3 * 3卷积核完成［列。在本文的神经网络模型中，本文将标 准的N * N卷积核分解为N * 1, 1*N卷积核，同时将下采样工作由maxpool （最大 池化）和avgpool （平均池化）完成。和ESPnetv2中的EESP模块一样设计四条 支路，因为这种方式既可以扩大感受野的大小，也可以通过设置不同的空洞率来 消除dilated convolution （空洞卷积）所带来的The Gridding Effect （栅格效应）。 本文将第一，第三支路设置为 3*1 depth wise convolution + maxpool + 1 * 3 depthwise convolution （3 * 1深度卷积+最大池化+ 1*3深度卷积），将第 二， 第 四支路 设置为 3*1 depth wise convolution + avgpool + 1 * 3 depth wise convolution （3*1的深度卷积+平均池化+ 1*3的深度卷积）。 相比于原始的ESPunit,本文的MEESP模块可以将复杂度进一步下降。例如， 当M = 64, g = 4时，参数的数量下降了为原来的0.8。本文在神经网络的每个 group convolution （分组卷积）后面都加入了 channel shuffle （通道混洗）以减轻 分组卷积分割通道，产生的通道相关性的负影响。经过这些操作，整个下采样模 型的计算量将会下降，整体计算量比较如公式2-1所示。
原始计算量_ Md/g+（n2+d）dK
目前计算量 ~ Md/g+（2n+d）dK	2_1
在完成了下采样操作之后，本文没有选择将各个支路的特征图进行直接拼接, 而是在前面操作之后引入一种多分支打分机制。四条支路输出的特征图分别为支 路1的输出outl,支路2的输出out2,支路3的输出out3,支路4的输出out4, 并和输入的特征图进行相加操作，得到了fusion feature map （融合的特征图像） =分支1输出+分支2输出+分支3输出+分支4输出。然后本文使用 global avgpool （全局平均池化）和global maxpool （全局最大池化）分别生成两
18
种1*1*C的张量。然后本文使用一个特征转换分析模块，它由两部分组成分别 为F1和F2,它的目标在于将经过global pooling的生成的全局特征进行特征映 射，将每个通道的得分值映射出来。在F1代表ReLU激活，B代表BatchNorm Layer (批量归一化层)，X为全局的特征变量，W为1*1的常规卷积，将高维的 数据映射到低维。之后，再由F2从低维映射到和各个支路channel数目之和。在 经过前面的操作后，最后使用Softmax函数使数值归一化，得到了每个通道的相 应得分。整体流程如如下公式所示。
FM = Sti out：	(2-2)
耳core(FM)	=	a * Avgpool(FM) +	* Maxpool(FM)	(2-3)
Fi(x) = ReLU(B* %))	(2-4)
F2(X) =a)2*x	(2-5)
Score = F2(^IW)	(2-6)
在完成上述的操作之后，神经网络将会得到每条支路的归一化的分数值，假 设SI, S2, S3, S4分别代表各个支路的分数值，分别将各个支路的分数与各个 支路的输出相乘，代表将每条支路的输出根据这条支路的重要程度，乘上一个可 变的控制因子，用于衡量每条支路的重要程度。完成控制因子的相乘之后，最后 再将经过控制因子影响的各个支路的输出进行拼接。
Score = So/tmax (Score)	(2-7)
outi = Si®out[	(2-8)
s.t.	= l	(2-9)
左支路：在下采样模块的左边支路本文在卷积操作之后加入了通道注意力和 空间注意力机制，在基本不增加整体网络参数的大小的情况下，提升精度。
右支路：将原本的ESP模块中的平均池化替换为最大池化。整个下采样模块 将右支路与中间支路的输出结果进行拼接操作，再和左支路的特征图进行相加， 最后通过激活函数，这里的激活函数本文选用PReLU函数。
该部分的神经网络详细结构图如2-2所示。在进行完下采样的之后，本文采 用Mobile SOSA Module进行特征重组和映射。
19
图2-2 M-SOSANet中使用的MEESP模块
