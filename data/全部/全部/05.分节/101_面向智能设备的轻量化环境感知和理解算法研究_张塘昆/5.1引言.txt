5.1引言
对于任意一段视频流数据，利用神经网络模型去自主地生成一段概括该视频 片段的语句，被称为视频描述任务。不同于对图像的检测和分割，视频描述任务 要求算法模型能够学习到视频内容的主体的行为，动作，以及主体和其他人或者 物体之间的关系和行为，即为让神经网络模型去理解视频内容的关键内容并利用 语言反馈回来，视频描述任务可以很好地把计算机视觉任务和自然语言处理处理 任务连接起来，从视觉任务的感知级别的语义信息提升到更深层的理解级别的语 义信息。
目前，医学领域已经证实人类的大脑不是单模态并行的，不同类型的信息载 大脑中的信息处理的时候是存在相互影响的。受这种启发，在人工智能领域，很 多任务效仿人脑的工作方式，进行多种模态的信息处理，并通过各种方式进行融 合，实现目标要达到的效果。以往地视频描述任务中，往往是仅仅利用视频的图 像信息，进行信息的提取，而人类在观察世界的时候，往往是眼睛和耳朵并用， 分别代表着视觉信息和听觉信息。因而，本文在视频描述任务中，将会利用视频 数据的三种模态信息，分别是图像模态，视频模态，音频模态，进行特征的提取， 提取出来的特征表征分别代表着视觉，动作，音频语义信息，并将各类的语义信 息进行融合，提取出最终需要的结果。
因而，利用在视频描述任务上的实验效果可以很好的反映算法模型的对视频 内容理解的程度，本章节主要在面向智能设备上，如何利用采集到的环境视频中 多种模态的信息提取到的特征表征，并将多种模态的特征进行融合，从而更好地 进行视频描述任务。
