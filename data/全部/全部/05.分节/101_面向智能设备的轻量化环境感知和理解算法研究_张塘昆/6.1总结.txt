6.1总结
随着深度学习技术和硬件算力设备的提升，以及各种类型视频数据爆炸性增 长，以往基于图像的感知技术已经无法满足智能设备的智能化增长需求。现有的 面向智能设备的环境感知和理解算法，往往是利用边缘侧设备，进行数据的采集， 然后将采集得到的视频数据打包发回服务器进行算法处理，得到结果之后进行返 回，这种方式往往无法实时处理视频信息，在数据传输延时大和一些实时性要求 高的场景下无法使用部署。基于这些因素，本文提出了一种面向智能设备的环境 感知和理解算法。该算法系统旨在利用环境中采集的视频数据多种模态的信息， 同时考虑到算法模型的使用效率，进而实现在智能设备部署的目标，同时保证精 度的可用性。具体言之，本文的主要工作和成果如下：
(1) 在处理环境采集的视频的单帧图像数据的特征，本文提出了面向低算力 设备的轻量型卷积神经网络M-SOSANet,介绍了该网络的两大模块分别是 MEESP下采样模块和SOSA模型的设计特点和优势，将会进行常见计算机视觉 任务图像分类数据集CIFAR-10, CIFAR-100,图像分类领域benchmark数据集 ImageNet-lOOOK上进行多组实验分析验证使用该网络模型进行图像分类的实验, 在 CIFAR-10 达到了 95.64%, CIFAR-100 达到了 78.6%, ImageNet-1000k 达到了 72.8%的精度，仅有290M的计算量消耗；为了验证网络的泛化性，使用该网络 进行语义分割的实验，在PASCAL VOC 2012上达到了 67.8%的mIOU,仅有 0.82BFlops的算力消耗；为了分析神经网络在真实设备上的实时性，分别在 TITANX, 15-8400,取得了不错性能。
(2) 针对环境中采集的视频数据的处理问题，本文对2D的卷积神经网络进 行改进，将轻量型2D的卷积神经网络拓展为轻量型3D的卷积神经网络特征提 取网络，从视频数据的输入策略到网络的设计，进行分析实验。在此基础上设计 了轻量型的视频行为识别算法，动作分类算法，在SomethingSomethingV2进行 实验，达到了 45.07%的精度，相比一些其他算法，计算量和参数量均下降至少8 倍；为了验证网络对局部动作信息的提取能力，在大规模手势分类数据Jester进 行实验验证，达到了 90.1%的精度；为了验证网络的迁移泛化能力，在UCF-101 进行实验，最终达到了 87.4%的top-1精度。
(3) 为了利用采集视频数据中的音频模态数据，同时为了解决大规模数据集 训练困难的问题，本文使用的结合知识蒸憾的音频分类模型的训练方法，将会音
57 频场景分类数据集UrbanSoundSK进行实验分析，验证模型和训练方法的可靠性。 最终神经网络精度达到了 92.3%,计算量仅由0.8GFlops,参数量5.2M。
(4) 针对采集的环境视频数据，搭建了多模态神经网络模型的视频描述框 架，研究了如何利用不同模态的数据特征进行特征融合，从而更好地去指导视频 理解任务的执行，重点介绍跨模态的注意力机制，以及transformer的轻量化，并 在视频描述数据集上3S行实验分析，验证模型的准确度和效率。其中BLEU@3 达到了 4.59, BLEU@4达至U 1.97, METEOR达到了&96,参数量仅有30M。证 明了使用本文的多模态特征提取网络和融合网络的性能。
