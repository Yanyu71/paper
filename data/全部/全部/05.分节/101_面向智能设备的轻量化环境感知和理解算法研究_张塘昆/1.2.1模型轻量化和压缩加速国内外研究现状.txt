1.2.1模型轻量化和压缩加速国内外研究现状
移动智能设备部署神经网络模型存在很大的挑战，主要表现在在移动智能设 备上，计算能力，存储资源，电池电量都是受限的，所以移动端智能设备必须满 足模型尺寸小，计算复杂度低，电池耗电量低等特点。
模型的压缩和加速并不是相辅相成的，有的时候压缩并不可以带来加速的效 果，有时候二者是相辅相成的，压缩的重点在于减少网络的参数数量，加速则是 侧重于减少计算的复杂度。可以主要分为三种层次：（1）算法层，大致可以分为 六种方式：网络剪枝，参数共享，量化，网络分解，知识蒸谯和精巧的结构设计。
（2）框架层，主要在于对于深度学习框架Tensorflow, Pytorch和依赖底层库 CUDA, CUDnn的优化加速。（3）硬件层，这个层次主要是对各种硬件GPU, FPGA, ASIC针对深度学习算法进行优化。下面主要介绍算法层次的方法：
神经网络剪枝：网络剪枝早期是用来删除网络中冗余参数，降低网络复杂度, 从而提高网络泛化能力，并防止过拟合⑴。1989年，Lecun发表（Optimalbrain damage》⑶，最早提出了剪枝的概念，将神经网络的任意权值参数看作是单个参 数并进行非结构化的剪枝，但是剪枝代价高，效果不明显。2015年，Han发表 论文⑷，研究发现可以根据神经元连接权值的大小确定训练后的神经网络的不重 要连接 o2016 年 Wen 发表了《Learning Structured Sparsity in Deep Neural Networks》
[5] ,使用Group Lasso （组岭回归），将权值参数看成组来看待，实现将成组的权 重参数约束到0附近，实现学习到的神经网络参数尽可能的结构化稀疏。2017 年，Molchanov发表论文回，研究发现可以从众多的网络参数之中选择一个最优 的组合，使得被剪枝的神经网络损失函数的值最小。2018年，Han发表新的论 文⑺，利用了强化学习的方法，舍弃了人工设计剪枝策略，利用算法来实现神经 网络的自动化压缩。综合各类方法，剪枝从剪枝的主要对象往往可划分为：修剪 单个权重参数、修剪卷积核、修剪神经网络通道数等。不同剪枝方法从不同的角 度出发，在实际训练操作过程中往往会产生一定的区别，对不同类型的神经网络 的最后效果也会产生差异⑴。神经网络剪枝的一般流程如图1-5所示。
网络参数共享：主要思想是让神经网络中多个参数共享同一值，如果能够让 一个m * n阶的矩阵能够只用少于m * n个参数来描述，通常这样的不仅能减少内 存消耗，同时通过一些特殊的运算方法显著推理和训练速度。2015年，Han在 Deep Compression中提出［勺，将神经网络的权值大小和梯度大小进行聚类，同时 用哈希图记录下来，从而提升深度卷积神经网络的计算效率，同时大大地降低参 数量的大小，具体操作如图1-6所示。
图1-6 一种权值共享压缩方法示意
权值量化：主要思想是降低单个参数所需要的比特位数来压缩原始网络。对 于卷积神经网络，神经网络参数一般使用float32或者float64表示。低精度方法 使用更低位数的float型或int型对模型进行训练、测试和存储。编码方法对原有 数据进行重新编码，采用更少的位数对原有数据进行表示，实现了模型的压缩［匕 2016年，Dettmers提出低比特参数量化理论同，将32比特的梯度和激活值压缩 到8比特，在保证模型精度情况下，提出的方法取得两倍的传输加速。2015年， Courbariaux发表论文切，认为可以更加极端的量化，以极端的策略对神经网络的 权值进行量化，限制权值大小为+1或者-1。2016年，Rastegari发表论文卩°】，研 究认为将神经网络的输入和权值均进行二值化的处理，从头进行训练一个二值化
7
神经网络，而不是在已有的训练的神经网络进行二值化。2017年〔⑴，Zhou发表 研究论文，认为给定任意结构的全精度神经网络模型，将其转化为无损失的低精 度二进制模型，增量式网络的量化方法，权值划分，分组量化，重训练。神经网 络权值量化一般如图1-7所示。
网络分解（张量分解）：深度卷积神经网络的组成成分，主要包括卷积层，f 全连接层以及池化层，近年来批量归一化层也逐渐普及。一般而言，卷积层往往 计算成本较大，同时参数量较少，全连接层与之相反。一般可以使用SVD分解， 将三维张量分解成二维张量。2016年，Denton发表《Exploiting linear structure within convolutional netowrks for efficient evalution》问，这篇文章中对多种张量 分解的方法进行了实验分析，例如奇异值SVD分解，三维张量转化为二维张量 分解。卷积层的大量参数存在冗余，作者通过这些网络分解的操作以求获得近似 原始卷积计算过程，较大地减少了计算成本的大小，在保持了精度了情况下，取 得了近两倍的加速。
知识蒸憾：2014年，Hinton首次引入知识蒸憾［⑶，研究发现使用教师模型
（预先训练完成的复杂模型）和学生模型（目标训练的小模型）。学生网络模型 分别学习类别输出和目标真值的交叉爛。同时，还要学习自身网络模型类别的概 率上的输出和教师网络模型类别的概率上的输出的交叉爛，使得教室网络模型信 息可以传递到学生网络模型中山。2015年，Romero发表《Fitnets:hints for thin deep nets》a】，针对了当神经网络层数较深的情况下，学生神经网络直接模拟教师神 经网络的输出比较困难的问题，文章提出在神经网络模型的中间部分，再次增加 有监督的信息，使得学生模型和教师模型的神经网络中间层部分的激活响应尽可 能的保持一致。因此，知识蒸憾的训练方式一般分成两步，首先利用教师网络中 间层输出信息训练学生模型的神经网络前面部分参数，再利用教师网络的最终输 出信息训练学生模型的全部网络的参数⑴。2018年，Saurabh Gupta发表《Cross Model Distillation for Supervision Transfer》【⑸，提出跨模态迁移知识的方法，即 在RGB数据集学习到的网络参数信息也能迁移到深度估计的场景中来。知识蒸 憾的一般流程如图1-8所示。
图1-8神经网络知识蒸馆流程
网络设计：包含两个子方向：（1）人工设计精妙的神经网络结构。（2）基于神经 网络搜索的方法。轻量级神经网络架构的设计已经取得了一定的成果。Google在 2017年提出了首代mobilenet轻量型卷积神经网络，通过深度卷积Depthwise Convolution和 逐点卷积Piontwise Convolution的组合"深度可分离卷积"代替 标准卷积，减少神经网络模型的参数量和计算量"I。随后，Mobilenet借鉴ResNet 系列[⑺的设计思想，将残差连接引入进来，提岀了含有逆向残差模块的 Mobilenetv2[18]o 2019年，又在前作的基础上，利用NAS神经网络搜索技术，同 时引入新的激活函数，提出了 Mobilenetv3。2017年，旷视发表论文〔⑼，采用了 channel shuffle （通道混洗），pointwise group convolutions （逐点分组卷积）以及 深度可分离卷积，提出了 Shufflenet模型，保证精度的情况下，大大提高了效率。 随后,又在Shufflenet的基础上，提出了 ShufflenetV2[20\ 2019年,谷歌发表了 EfficientNetl21h针对卷积神经网络中的网络深度，网络宽度，输入图像分辨率大 小，通过神经网络搜索的技术，获得针对于不同环境下的一组最优参数。2020年， Facebook 发表《Designing Network Design Spaces》[22],提出了一种新的网络设 计范式，在神经网络搜索设计网络架构更进一步。
122基于视频数据的感知和理解算法国内外研究现状
视频数据因其携带丰富的信息内容成为当前深度学习领域的研究热点之一，
视频感知算法可以看做是常见计算机视觉算法如目标检测，语义分割在视频数据
上的延伸，这种情况下往往需要考虑算法的时效性，基于视频数据的感知算法往
往要保证精度的同时追求更好的实时性。视频理解技术在社会生产中具有广泛的
用途。在安防领域，可用于对异常行为的检测；在人机交互领域，可以通过丰富
的模态的信息去理解人的行为语言和动作；在互联网业务中，视频理解技术可以
服务于短视频，长视频，直播平台，为视频在线实时打标，推荐进行有效分发，
舆论监控，广告投放；在自动驾驶领域，可以帮助车辆识别不同的物体，其丰富
9
的模态信息可以提供信息去预警。面对海量需要人类浏览和分析的视频数据，利 用视频理解技术可以最大限度地去解放人力。目前，仅理解图片内容已经无法满 足日益增长的需求，在二维的图片数据领域，神经网络模型取得达到不输甚至超 过人类的成绩，但是目前让计算机去理解视频内容的空间和时间信息仍然充满着 挑战，视频内容理解的概念比识别分割单个目标更加复杂，需要计算机去学习更 加高级的语义信息，如交互对象，场景环境，人类姿态，语义理解。理解视频不 仅仅要去分析图像的空间信息，更要去分析时间维度的信息。
图1-10单帧图片的感知（左）和多个连续帧的内容理解（右）
目前，对环境视频的内容的研究主要包含识别，分类，检测，预测以及理解。 主要可以概括为：1、动作检测，2、行为识别，3、时序动作检测，4、行为预测， 5、视频摘要。
2014年，Karpathy最早提出使用单流神经网络进行视频动作识别任务，探
10
索了多种方法使用预训练的二维卷积神经网络从连续帧中融合时间信息㈡]。 Simmoyan和Zisserman在2014年研究发表了双流网络〔约，考虑需要学习动作 特征，引入了使用光流去建模视频的时间特征。因此，论文中有两个单独的网络， 分别是学习空间特征的图像输入卷积神经网络，学习时间特征的光流输入卷积神 经网络，最终将两个神经网络的输出进行融合，取得了不错的精度，但是，计算 开销比较大。2014年，Du发表了基于3D卷积的方法的论文a®,首次将三维卷 积神经网络作为特征提取器，依靠3D卷积同时学习视频的空间和时间特征。 2016年，Wang发表了 TSN的论文㉔〕，文章对双流的架构进行了优化，采用稀 疏采样的方式获取更长时间信号的建模，解决了长时间建模困难的问题。同时， 针对视频级别的预测，探索了多种的组合策略。2017年，Girdhar发表了
《Action VLAD: Learning spatio-temporal aggregation for action classification》[27], 文章认为，可以通过VLAD的方法学习到视频级别的特征聚合，并通过视频的 聚合特征训练端到端的模型，用来捕捉长期的依赖。此后，为了解决3D卷积神 经网络计算开销大的问题，I3D【28】，P3D〔29], S3D[30], R(2+l)D【3i], MFfiet[32]等一 系列基于三维卷积方法的3D卷积神经网络算法提出，研究如何更好地节约计算 成本，同时达到更好的精度。
同时，音频也是视频里面一种重要内容数据，仅使用单一的图像模态，算法 无法学习到所有的视频场景。引入音频信息内容，可以基于音频进行事件检测， 也可以提取音频中的ASR信息。将音频转化为文本，根据文本的关键词进行筛 选，从而进行更高级语义信息提取等等。声音的分类可以根据任务目标的不同， 划分为不同的任务。对于一段长音频，目标可以是一个全局的标签，也可以是每 个音频段各自有一个标签。在音频信号处理领域，构建适当的特征表示和分类模 型通常被作为两个分离的问题。这种做法的一个缺点是人工构建的特征可能对于 目标任务可能不是最优的。深度神经网络具有自主提取特征的能力，因此可以将 上述两个问题进行联合优化。Google在大型音频事件数据集AudioSet进行了尝 试，利用log-mel音频特征，研究出了 VGGish模型Bl。视频中的音频信息往往 冗余度很大，如何对音频信息进行分析处理对于整个模型的特征也会起到很重要 的作用。
在获得视频内容中的多种模态的信息之后，如何对各个模态的信息进行特征 的提取，以及如何运用对提取出来的特征信息，在不同场景的任务中去使用，这 是多模态模型融合的关键问题，为了使模型进一步加强对内容的理解，它需要具 备解释多模态特征的能力。表征(Representation)：找到某种对多模态信息的统 一表示，每个模态各自映射，然后用用相关度距离来约束表示，或者是多个模态 一起进行映射。翻译(Translation): 一个模态映射到另一个模态，分example-based
11
（有候选集，如检索任务），generative （Decoder-Encoder）»对齐：寻找不同模态 子成份之间的关系，如某词对应某区域，分显式对齐和隐式对齐，例如注意力机 制。融合（Fusion）,指的是如何整合信息，常用的方法有早融合，晚融合。联合 学习（Co-learning）：通过利用丰富的模态的知识来辅助稀缺的模态，例如迁移学 习,zero shoto
常见的多模态融合方式有：Pixel level,对原始数据最小粒度进行融合；
Feature level,对抽象的特征进行融合，包括早融合和晚融合，代表融合发生在特 征抽取的早期和晚期，如图l-llo早融合是指先将特征融合后再输出模型，缺点 是无法充分利用多个模态数据间的互补性，且存在信息冗余问题（可用降维等方 法缓解）。晚融合分为融合和不融合两种形式，不融合类似集成学习，不同模态 各自得到的结果了之后再统一打分进行融合，好处是模型独立鲁棒性强。融合的 方式即在特征生成过程中（如多层神经网络的中间）进行自由的融合，灵活性比 较高，如特征金字塔融合。或者是Decision level对决策结果进行融合，类似于 集成学习。Hybrid level混合融合多种融合方法。
a.早融合
图1-11两种的不同的特征融合方式
目前基于视频的研究主要是对图像，音频，视频三种模态数据的处理的研究。 之所以要对不同的模态进行融合，是因为不同模态的数据表现方式不一样，看待 世界的角度也会存在一些差异，所以存在一些交叉（所以存在信息冗余），互补 （比单特征更优秀）的现象，甚至模态间可能还存在多种不同的信息交互，如果 能合理的处理多模态信息，就能得到丰富特征信息。即概括来说多模态的显著特 点是：冗余性和互补性。
一般多模态需要处理的任务主要如表1-1有：
12
表1-1多模态算法的应用
应用
表征
翻译
主要难点
对齐
融合
联合学习
音频-视觉语音识别
