3.4实验验证与结果分析
(1) SomethingSomethingV2
36
SomethingSomethingV2是一个著名的视频片段数据集，该数据集包含了大 量的预先定义的人类和日常物件进行互动的动作行为，该数据集能够让模型去学 习到对现实世界发生的动作行为进行细粒度的理解，该数据集包含220847个视 频样本，其中训练集168913个视频样本,验证集24777个视频样本,测试集27157 个视频样本，共分为175个类别，本文中，将会使用该数据集进行算法模型在视 频数据上的预训练，以方便在后续其他的任务数据集，进行迁移学习。
图3-11. Something SomethingV2数据集数据分布情况
由于Something SomethingV2数据集样本数量大，使用4块Nvidia 3090Ti进 行训练。采用了随机梯度下降优化方法，在进行Something SomethingV2的训练 时，batchsize大小为256。训练约40轮，当训练轮次为10, 25, 30的时候，学 习率衰减0.1,初始学习率大小为0.03o在训练时使用ImageNet的预训练模型 去填充2D部分的卷积核，T维度的卷积核参数进行初始化，并且使用Kinetic- 400进行少量轮数的训练，对于训练数据，采样常见的随机缩放，对每个视频进 行稀疏采样8帧进行训练，图像的大小为160*160,在Something Something V2 数据集的验证集上，实现了 top-1精度45.07%, top-5精度76.5%的精度。
37
表3-1.经典算法在Something Something V2的top-1和top-5精度以及计算量和参数量对比
Model
Top-1精度
Top-5精度
计算量
参数量
TRN-Multiscale
(2) Jester
Jester数据集〔即是目前最大的手势行为分类数据集，在这个数据集的每一个 视频数据中，一个人将会在摄像头前进行预先定义好的手势动作行为，视频背景 相对固定，数据集包含148092个视频样本，共分为27个类别，数据集同样由训 练集，验证集，测试集组成，分别包含118562个，14787个，14743个视频样本， 本次实验的测试结果将使用训练集数据训练，并在验证集上进行评估，验证。本 文将在Jester数据集上去验证3D卷积神经网络模型在局部动作上的捕捉能力。
图3-12. Jester数据集数据分布情况
数据集是在大量不同工作者的帮助下收集的。相比现有数据集的数量要大得 多。本文按&1：1的比例将测试集分为训练集、验证集和测试集。这么做的原因 是为了确保同一个人的视频不会同时出现在训练集和测试集中。视频片段持续时 间为3秒。每个片段都包含一个来自一组25个常用于人机界面的测试的真实标 签，包括一个无手势类和一个对比类。手势是动态的和运动的，在许多情况下不 能从单个帧中辨别出来。该数据集的目的是对现有的手势识别方法进行基准测试, 并帮助人们能够建立实时的端到端手势识别系统。有25个手势类和两个类。“无 手势"类别内容显示为一个人静止坐着或站着的视频。“做其他事情”类别是各种 活动的集合，如伸展、转头、咀嚼、玩头发等。数据集不含有给定手势类中所示
38
以外的动作。
在神经网络模型的训练过程中，采用了随机梯度下降优化方法。对于训练过 程中，参数设定如下：Batchsize大小设置为128,动量系数为0.9,权值衰减参 数为1x10-3。训练网络的时候使用上文SSV2数据集所得为预训练模型，学习率 初始值为0.1,每到达一定的轮次数目，学习率衰减0.1。
在进行训练的时候，将分别对视频单帧图像的大小，单个视频样本的采样数 进行变量控制实验。经过研究发现，在对单个视频进行8帧的抽样，算法模型的 精度与计算量之间的均衡可以达到最好，此时计算量达到2.3Gflops, top-1精度 达到90.9%, top-5精度达到99.10%。在抽取4帧的情况下，虽然模型的计算量 仅有0.6Gflops,伴随着代价是top-1精度下降了大约10个百分点。在采样16帧 的情况下，模型将会消耗3倍多的计算量，仅带来约4个点的top-1精度提升， 达到这种规模的计算量，在智能设备中部署是困难的。综上所述，本文选取单个 视频样本抽取8帧的采样策略，在进行推理时候，结合上述的关键帧提取技术， 可以将模型的计算量和精度达到较为理想的程度。单个视频样本上分别抽取4帧, 8帧，16帧实验的数据，如表3-2所示。
表3-2. 160*160图像大小下不同的采样率对3D-CNN模型精度核模型计算量量参数量的对
比
Top-1精度
Top-5精度
计算量Flops
在计算机视觉任务中，输入到卷积神经网络中的图像大小对于模型的计算量 也产生了重要的影响，输入的图像大小不论在2D神经网络还是3D神经网络都 是影响整个模型计算量的重要因素，神经网络的输入可以定义为B*C*T*H*W, 上述实验中，本文将算法模型的输入视频帧数，也即为T定为8,对于视频数据， 一般都为彩色图像通道数C定为3,下面本文将会探讨视频帧H和W对算法模 型的影响，本文分别在视频抽样数为4, 8, 16的三种情况下，实验了两种不同 的图像大小112*112, 160*160对3D卷积神经网络模型的精度和计算量产生的 影响。实验结果如图3-13所示，由图可发现，在增大采样数的时候，算法模型 将会出现精度的提升，但是随着计算量的指数型增长，在相同的采样数的情况下， 提升图像的大小可以带来极微小的精度提升，但是会带来计算量的成倍增长。因 而，结合上述的实验结果，本文将本文所使用的3D卷积神经网络的输入采样数
39
定义为8帧，图像的大小为112*112。
B top-1 Acc ; top-5 Acc 乩 Flops(G)
图3-13.不同的采样率和图像大小对算法模型精度和计算量的对比
表3-3.实验结孑
丘分析对比
top-1精度
计算量FIops(G)
参数量(M)
ResNetl8-3D
16*112*112
-
ResNet50-3D
16*112*112
-
SqueezeNet-3D
16*112*112
Mobilenetv2-3D
16*112*112
Shufflenetv2-3D
16*112*112
Ours
16^112*112
Ours
8*112*112
(3) UCF-101
UCF-101数据集⑷堤从大型视频网站YouTUBE收集的具有101个动作的真 实动作视频的行为动作识别数据集，包含13320个视频，采集的分辨率为320*240, 涉及运动，乐器，人物交互等行为，该数据集在数据的采集上具有很大的多样性， 包括相机运动，外观变化，物体比例变换等，是在视频动作行为识别领域著名的 基准数据集。本文将在该数据集验证3D卷积网络的迁移学习能力。图3-14. UCF-101部分类别数据分布情况
为了验证迁移学习的能力，在训练过程中，本文冻结了前面的一部分卷积层 的网络参数，然后对剩余的网络参数进行微调。本实验仍然采用随机梯度下降的 优化方法，训练以0.01的学习率开始，在训练轮数为30和45的时候，将学习 率降低，学习率衰减系数为0.1,再经过15个轮次就完成训练。
本文对比了一些其他的3D卷积神经网络，本文所使用的卷积神经网络在 UCF-101上表现出了极佳的性能，在能够以更少的计算量的情况下，仍实现较好 的算法性能。
表3-4. —些3D卷积神经网络的基于UCF-101的性能对比
top-1精度
计算量(G)
参数量(M)
ResNetl8-3D
ResNet50-3D
16*112*112
SqueezeNet-3D[47]
16*112*112
Mobilenetv2-3D1471
16*112*112
Shufflenetv2-3D1471
16*112*112
Ours
