3.3.2基于模型驱动的深度学习信号检测算法
在基于模型驱动的深度学习方法中，文献［15］最先使用已有的MIMO信号检 测的知识设计了 DetNet信号检测网络，之后有很多文章是按照其神经网络设计 思路设计出相似的神经网络用于解决不同的问题的，文献［16］设计的ScNet在 DetNet基础上进行改良简化最终实现了更好的检测性能。ScNet使用的稀疏连接 方式大大减少了神经网络所需训练的参数，使设计能够实际应用的OTFS信号检 测神经网络成为可能。本小节拟先介绍DetNet再介绍ScNet进行的相应改进。
DetNet〔®被提出用于Massive MIMO信号检测，其解析最大似然(ML)投影 梯度下降进行设计，DetNet依据的公式如式(3-25)所示：
A /匚 f a||y-Hx||2
x*+i = fnL ^k~Sk "-	"
l	铳 “J	35)
其中ZJ・)表示某种非线性函数关系，(・卩表示矩阵的转置，y为接收信号，乞 表示第£次迭代得到的信号检测结果，假设共进行Z次迭代，贝U<k<L,心为 每次的步长，在手动编程解调时步长多为手动设定更新规则，神经网络中可将步 长交由网络自动优化。从式(3-25)中可以看出，接收信号通常不直接出现，而是 以H'的形式参与运算，且有
Hry = HrHx+V^e	(3-26)
其中V”加可以视作零均值加性高斯白噪声，^{-1,+1}为独立等概二进制符号。 为了简化神经网络计算过程，在DetNet网络优化前计算好了 H、和H『H。Hry 作为每次迭代前的输入；HrH每次迭代前与上次输出的更新检测结果乞相乘之 后作为输入，即iTHi”；乞作为需要更新的信息也是网络完成迭代模拟所必须 的输入之一；此外，DetNet加入了一个变量输入，我们记为U*,表示第£个网络
30
中的该变量矩阵的输入状态，该变量初始化状态为全零向量。H、、HrHxx. xt 和U”组成了 DetNet的输入。DetNet类似于DNN,先将输入与更多的神经单元 进行全连接以解析输入向量内蕴含的隐藏关系，再将其通过类似输出层的网络层 以输出下一网络单元所需的输入。DetNet由若干具有相同内部结构的网络单元 串联而成，每个网络单元执行~次对信号信息的迭代更新。DetNet中每个网络单
元的具体结构如图3-2所示:
图3-2 DetNet网络单元问
图3-2中，“concatenate"为连接操作，W都表示权重，b表示偏置，网络会
对心和6更新。该网络单元的数学表达如下:
其中。(・)为非线性函数，此处取为『刃“(・)，$(・)也为非线性函数用于对信息符 号进行处理，具体表达式如式(3-28)所示：
DetNet将式(3-28)的f设置为可训练变量，$(・)可将变量全部转化为[7+1] 内的数据。在$(・)中，当x<-\t\时判决为-1,在时判决为+1,在-|r|<x<|/| 时输出x/\t\,类似于简化的软信息输出。通过调节/大小，可以控制判决范围， |/|过小输出容易震荡，过大容易导致收敛提前。实际设计时为了避免“o除”，会
31 在分母处添加绝对值很小的正数。神经网络最终输出的检测结果会使用s,g"(・) 函数进行判决。
文献［29］则通过对DetNet的分析，将网络简化如下：
图3-3 DetNet简化示意图
如图3-3所示，DetNet可以大体简化为三层网络，假设MIMO中接收信号 y的矩阵维度为刃xl,发送信号x维度为HX1,则信道矩阵H维度为mxn,输入 向量中H「y维度是“xl, iTHi*维度是”xl,乞维度是nxl, U”在DetNet中设 置为了 2“xl,即输入层维度为5nxU隐藏层神经单元个数设置为了 8“xl,隐藏 层激活函数为relu^),输出层中，输出殳出时激活函数为？(・)，输出U"时未设 置激活函数，输出层维度为3"X1。
DetNet的损失函数考虑了所有层的输出，并且采用了规范化，具体表达式如 式(3-29)所示［⑸：
Lg =	⑷占2斗	(3-29)
A F-XL5||
其中心$为输入信号的LS估计，有
=(HrH) Hry	(3-30)
DetNet每个网络单元输出都乘以了系数添加到最后损失函数中，越靠近最 终输出层的输出对检测结果的影响越大，因此系数更大。损失函数具体推导过程 见文献［15］。此外，如果需要知道各个单元的结果，可以提取每层的输出计算误 比特率，这样就可判断神经网络使用多少层时已经收敛。文献［15］中使用30个网 络单元完成DetNeto
ScNet为DetNet的改进版，在文献［16］中提出。ScNet致力于简化DetNet, 简化后的网络能更好地实现大规模MIMO的信号检测。其做出的主要改动在三 点，分别为简化网络输入、使用稀疏连接代替全连接、简化损失函数。
ScNet的结构可以简化如下：
32
k+l
图3-4 ScNet简化结构
如图3-4所示，ScNet删除了 U- 的作用是添加偏置以表征可能出现的 非线性因素，但是神经网络通过激活函数已经获得了非线性特性，所以U*能发 挥的作用有限。加之6作为网络的输入以及每一层网络单元的输出，增加了网 络开销，占用了大量的资源，如果删去则网络单元连边数立减为原来的一半。
ScNet的设计更契合ML投影梯度下降公式，公式(3-25)中 +	所包含的三个输入为一一对应关系，并不需要隐藏层映射
到高维以进一步挖掘特征，也不需要全连接层使每个输出都用所有输入为自变量。 在三个输入向量中，坐标相同的数据具有显著的函数关系，坐标不同的数之间单 从公式(3-25)上看，无明显联系，故而使用一一对应的稀疏连接代替全连接结构， 并且去除了隐藏层，大大减小了所需训练的参数。ScNet公式可以表达如下：
(
Hry
wo
+ b
(3-31)
k
丿
其中O表示哈达玛积。对图3-3的分析可知DetNet每个网络单元的连边数目为 5nx8n + 8wx3w = 64w2 ,经过减少输入和稀疏连接后，连边数目减小为3”。
DetNet的损失函数计算了理想输出与实际输出后加入了规范化函数项 収-红『，有[叫
||xf权一但吋叭『
=卜-(HrH) 1 (HrHx + V”Q『	(3-32)
=||(H「H)TV爲『
可以将规范化函数项视为未知噪声的函数。文献[29]以噪声项随机性高容易 加大误差、函数运算需要使用LS估计从而进行矩阵求逆操作复杂度高、MIMO 系统中不一定能保证矩阵满足可逆条件等理由删除了规范化函数项，ScNet损失 函数如式(3-33)所示：
(3-33)
损失函数简化后所需的计算量下降，并且检测性能能够得到略微的提升
[16][29]°
33
当将DetNet和ScNet应用于OTFS系统解调中时，DetNet每个网络单元连 边数变为64(W)2,而ScNet的连边数则为3MM,而在OTFS系统中M和N通 常较大，所以ScNet实用性更高，文献[16]中的结果表明ScNet在收敛性和误比 特率性能上都优于DetNet,故拟用ScNet作为对比方法。
