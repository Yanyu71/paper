4.3.2适用于OTFS的信道估计神经网络
OTFS信道估计在延迟多普勒域进行，信道信息可以表示为分布于二维网格 的若干个离散复数值，叠加的噪声为高斯白噪声。OTFS难以使用文献［20］中的 SR网络生成整个OTFS块的时频信道信息，但是，OTFS信道图像可以使用IR 网络去除噪声，以提高信道估计准确性。拟使用DnCNN对二维的信道信息进行 去噪处理，以优化信道估计。
DnCNN最初由文献［49］提出，用于图像去噪，主要使用残差学习的思想，通 过学习噪声图像中存在的噪声，经过相减后，获取更清晰的原始图像，在图像去 噪领域取得了很大的成功。DnCNN主要创新点有两个，一是使用残差学习的思 路学习图像噪声，该处理方法使得DnCNN可以拓展到多个去噪领域；二是将残 差学习与BN相结合，共同提高去噪能力和网络的训练速度。
残差学习最开始提出用于解决随着网络层数增多网络性能不再提升甚至下 降的问题，同时也具有加快网络收敛的优点。残差网络显式学习一些堆叠层的残 差映射，可以比原始的映射方法更容易学习。当残差较小时网络训练简单，当残 差为零时，网络训练目标为恒等映射，非常容易优化收敛。而图像去噪领域中， 噪声图像和清晰图像的残差一般很小，所有残差学习很适合图像的去噪。DnCNN 采用的是残差学习的方法，但是原始的残差网络间隔几个网络层就会进行一次残 差运算，而DnCNN只在最后一层进行残差操作。在DnCNN中，网络最后一层 输出为噪声图像，原始图像减去该输出得到去噪图像。因此，网络的损失函数是 网络的输出与噪声图像的MSE。文献［49］进一步引入了 BN技术，发现其可以稳 定和增强DnCNN的训练性能。在一批图像进入卷积层时，先计算其均值和方差，
47 再进行归一化，然后将归一化后的数据输入卷积层；对于卷积层输出的数据，先 通过学习到的数据的均值和方差将输出恢复到其原先的分布，再通过激活函数。
残差学习和BN可以相互受益，并且它们的集成可以有效地加快训练速度并提高 去噪性能。DnCNN示意图如图4-5所示。
64	64	64
图4-5 DnCNN结构
在图4-5中，DnCNN得到的最后去噪图像为输入二维图像与输出噪声图像 的差值。在DnCNN中所有卷积核大小都设置为3x3 ,第一层使用64个卷积核 使用T“(・)作为激活函数，中间层由卷积层、BN和relu^激活函数构成，最后 一层卷积层用于重构图像。DnCNN不使用池化操作，所有填充方式都为“same”。 卷积核为3x3时，网络每个点的值都由上一层网络对应的大小为3x3区域的值生 成，第一层每个点带有原始图像3x3区域信息，第二层带有第一层3x3区域信息 即带有原始图像5x5区域信息，以此类推，若将网络深度记为比初，则感受野大 小为(2^+l)x(2JCjW+l)o由于网络使用的是零填充，感受野增大时，靠近边 界的点受越来越多零值的影响，但是结果表明DnCNN不会产生边界伪像［49】。中 间层的数量会影响感受野的大小，感受野大时可以有效利用更多底层图像信息， 故设计时需要兼顾性能与复杂度。最终，根据文献［49］的验证，当使用DnCNN去 除高斯噪声时，选择网络深度为17,去除复杂噪声时，深度选为20。
OTFS使用DnCNN优化信道估计时，因为神经网络目前只能直接处理实数， 故可信道的实部和虚部分离设计为两通道的图像，再经过DnCNN优化。在原始 的DnCNN中，网络深度直接取17时，对应的感受野大小为35x35 ,而OTFS中 的信道图像小于感受野时，随着网络深度的增加，网络输出的结果受到零填充的 影响也会增大，故而需要调整网络深度需要根据实际情况进行设计适用于OTFS 信道估计的神经网络。
