2.2.1DNN基本原理
深度学习技术最初被称为感知机，其结构比较简单，除输入层和输出层外， 只有一层隐藏层，故而网络的数学表达也不复杂。当输入与期望输出的关系为较 为复杂时，单层感知机无法得到较理想的结果，因此最初的感知机只能处理简单 的函数运算。网络的函数表达能力与隐藏层的层数有关，DNN©〕采用增加隐藏层 的方式提高神经网络处理数据能力，因此，DNN也被称为多层感知机；复杂函 数关系可能具有多个输出，DNN通过增加输出层神经元个数的方式进行模拟； 神经网络的激活函数不仅影响网络的表达能力还在网络训练时发挥了重要作用， DNN可以使用多种激活函数，根据不同情况做出不同搭配a】。近年来，DNN获 得了越来越多的关注。
DNN模型如图2-2所示，主要由输入层、隐藏层和输出层组成，每一层都 包含了若干个神经单元。输入层只负责数据的输入，隐藏层和输出层的神经单元 12
会执行特定的运算。在基本的DNN中，各层之间为全连接结构。互连神经单元 的边代表一个可训练的权重值。通过训练调整权值，可以生成拟合特定输入输出 关系的神经网络模型。
图2-2深度神经网络结构
输入层的输入信号记为X®，将需要进行操作的数据传入输入层，通常输入 数据为一维向量。输出层的输出记为y°M，输出神经网络处理数据的结果；中间 部分为隐藏层，隐藏层可由不同的网络结构组成，与输入层输出层相连，完成输 入输出关系转化。第「层隐藏层输入记为x(T，为前一层网络的输出，第j层隐藏 层输出记为X®,有
其中为神经网络权重，可表示为二维矩阵，为偏置向量，和 b"T都是神经网络可训练的参数矩阵；£“(・)为神经网络激活函数。由于线性函 数经过组合依旧是线性函数只能表示线性关系，但是实际中的自变量因变量关系 很多情况下为非线性关系，为提高神经网络的关系表达能力，需要引入非线性函 数。激活函数即为非线性函数。激活函数的设置需考虑实际情况。如文献［24］中 输入的是LS信道估计，输出的是LMMSE信道估计，其为LS估计与特定矩阵 的乘积，即网络的输入输出为线性关系，故文献［24］中利用神经网络优化信道估 计时并未使用激活函数。
13
DNN 的激活函数通常有tanh(・)、sigmoid(•)、•和leaky_relu(y)等。 神经网络在正向传播时，从输入层通过隐藏层到输出层输出，反向计算时需要根 据导数对网络权重进行调整。下面介绍各激活函数相关信息Nd%
sigmoid(・)表达式为：
sigmoid (x) = —(2-31)
1 + e~x
该函数输出的取值范围是(0,1),常用于输出层，在二分问题中输出可表示概 率。其使用于信号检测网络时输出的结果可以视作发送比特为0和为1的可能 性，再经过判决可以直接得到原始比特。Sigmoid^的导函数为：
sigmoid©) =(]：一乂)2	(2-32)
该激活函数收敛较慢，求导运算与relu类函数相比，较为复杂，若是大量用 于隐藏层则网络优化难度较大，并且sigmoid函数容易产生梯度消失的问题，故 隐藏层通常不大量使用其作为激活函数。
tanh(・)表达式为
tanh(x) = =[	(2-33)
e+e
该函数输岀的取值范围是(-U)。tanh函数可以由sigmoid函数进行平移和 缩放操作获得，中心在(0,0)处，其他性质与sigmoid函数类似。其导函数表达式 为:
tanhf(x) = (cosh(x)) 2
尸刃吩)表达式为:
其导函数为:
relu函数常用作隐藏层激活函数，可以有效解决梯度消失问题，并且计算速 度非常快，因为只需要判断输入是否大于0就可直接获取输出。实际应用中，relu 函数为使用最广的激活函数之一。但是，当自变量小于0时，函数值为0,这会 导致在神经网络参数初始化较为极端的情况下或者学习速率设置过大时出现梯 度消失问题。
leaky_relu@)表达式为：
14
leaky _ relu(x) = max(x, EX)	(2-3 7)
其中&为一绝对值很小的数，可设置为可训练参数，也可为固定常量。其导函数 为：
, f 1, x>0
leaky _relu (x) = <	(2-38)
—	[s, x < 0
leaky_relu函数是为解决relu函数存在的问题而被设计,当自变量小于0时， 函数值随自变量改变，输出一个较小的值而非恒零值，可以有效避免梯度消失的 情况出现。
DNN为有监督学习，输入的训练样本有相应的标签即期望输出。进行训练 时，输入信号经过网络由输出层输出，输出值与期望输出之间存在差距时，会根 据差距进行反向传播优化可训练参数。前向传播从输入层开始经过隐藏层串联的 全连接线性运算和激活函数处理到输出层，其关系式如式(2-3刃所示：
y out = /DNN (X)
九心(…心 皆 +b®)...) + b(s) (2-39) 其中you,为DNN的最终输出，fDNN(*)为DNN网络输入到输出的函数关系，L为 网络总层数。
DNN模型的训练主要由两部分组成，分别是正向传播过程和反向传播过程。 网络训练前，DNN中的可训练变量会先进行初始化，变量初始值可以指定为特 殊值，如文献[24],也可以赋值为绝对值较小的随机值，如零均值高斯随机变量。 在正向传播过程中，数据依次通过输入层、隐藏层和输出层，与可训练变量一起 进行相应操作，得到输出结果。接着计算此时的输出结果与期望输出的差距，该 差距是使用损失函数度量的，当结果未达到要求时，进入反向传播过程。在反向 传播过程中，根据损失函数沿原来的连接通路逐层依据规则修改可训练参数的值, 以达到降低差距的目的。反向传播过程结束后，再次进入正向传播过程，直到满 足设定的停止条件才结束模型的训练〔26][29〕。
在DNN训练中，损失函数可以计算网络输出与期望输出之间的差距。损失 函数Loss可以表示为：
Loss = fIoa. (yoa,, y 嗣)	(2-40)
根据实际情况设计相应的损失函数。当网络处理的问题为分类问题时，在二 分类情况下常使用的损失函数为交叉爛损失函数，在多分类情况下，常使用对数 似然损失函数。平方误差损失函数多用于回归问题，当神经网络要解决的是预测 具体的数值时，网络的损失函数可取平方误差损失函数[26〕。假设DNN的输出结 果及真正期望的目标分别为和y,&“，则平方误差损失函数可以表示为：
15
Loss = -||you, -yideJ
当输出层激活函数为sigmoid函数时，若使用平方误差损失函数则在输出结 果靠近0和靠近1时，收敛较慢，而对数似然函数可以解决此问题。对数似然损 失函数是对预测概率的似然估计，衡量的是预测概率分布和真实概率分布之间的 差异性。其标准形式为
(2-42)
其中S为总样本数，C为总类别数，％表示第i个样本类别为几 內为第j个样本 类别为/的概率。当总类别数为2时，优化问题简化为二分问题，对数似然函数 简化为交叉爛损失函数，其公式为：
Loss = —-—^(j log p, +(1-力 log(l-口))
5 C
其中八(0,1),必为第i条样本预测为1的概率。
损失函数是一个非负实值函数。通常来说，损失函数越小，则模型拟合效果 越好，学习到的网络表达能力也就越好。神经网络的最终目标就是，通过不断调 整权重矩阵，使得模型的预测值与数据标签尽可能的一致，即找到损失函数的最 小值。而寻找一个凸函数的最小值，最简单的策略就是朝着该函数梯度的反方向 去寻找。DNN从输出层开始，逐层向前传递误差，向梯度方向的反方向调整权 值，使得损失函数不断减少，直到满足要求［29】。
DNN的优化算法主要思想为梯度下降。DNN可通过梯度下降法逐步迭代地 求解损失函数的最小值，以寻找模型中的最优的可训练参数值。首先确定设计的 DNN网络表达式即前向传播函数，视情况设计网络损失函数。设DNN中的模型 参数为u (包括可训练的加权系数矩阵和偏置向量)，损失函数记为Z(u),则梯度 下降公式为：
其中〃e/■表示第力er次迭代；〃表示学习速率，为梯度下降的步长。步长影响网 络参数更新大小，当步长较大时，网络参数每次的更新较大，可以更快地达到收 敛条件，但是容易产生函数在极小值附近来回震荡的问题，从而阻碍收敛；当步 长较小时，可以避免震荡问题，但是会增加达到收敛所需的迭代次数。梯度下降 算法依据损失函数采用的数据量的差异，可以分为批量梯度下降法、随机梯度下 降法和小批量梯度下降法。通常批量梯度下降法很消耗内存并且较慢达到收敛， 因为它是使用整个训练数据集进行优化计算，而训练数据集通常较大；随机梯度 下降法训练时随机地选取一个样本进行优化更新操作，故与批量梯度下降法相比, 内存消耗小收敛较快，但是会由于每次选取的样本自身的特殊性造成损失函数值 震荡；小批量梯度下降法为前两种方法的折衷，其每次训练选取的数据为整个数 据集中的小部分,在保证数据更具有代表性的同时解决了大数据训练收敛慢的弊 端，也是目前最常用的算法之一a】。
传统的梯度下降法设计固定的学习速率，难以快速准确地达到收敛，此外传 统的梯度下降法容易达到函数的局部最小值，为解决这些问题，已有很多梯度下 降法的改进方法被提出。深度学习中模型的更新涉及大量参数，其中会有部分参 数更新频繁,部分参数更新频率少。网络训练时，要达到较快较准确的训练效果， 希望偶尔更新的参数每次学习步长更大一些，减少所需迭代次数，而对于频繁更 新的参数每次学习步长小一些，以免被当前输入的样本特殊性影响。Adagrad。。］ 算法可以自适应调整学习速率，它设置了一个固定的全局学习速率，对于每个参 数，全局学习速率会联合其历史梯度共同生成当前迭代的学习步长，具体实现为 将全局学习速率与历史梯度平方的累积和的平方根的倒数相乘，所以之前更新大 的参数会获得较小的更新而之前更新小的参数可以获得较大的更新。对于学习稀 疏数据，Adagrad是一种有优势的优化算法。然而，Adagrad考虑了参数之前所 有的更新值，随着迭代次数的增加，历史梯度平方的累积和会越来越大，参数的 学习步长变得越来越小，难以实现快速准确地完成网络训练。
Adadelta［31］算法和RMSpropt32］算法是对Adagrad算法的改良。解决Adagrad 算法中历史梯度不断累积的问题的一个行之有效的方法是加大最接近当前迭代 的历史梯度的影响，减少或者忽略太过陈旧的梯度值对当前参数更新的作用。 Adadelta算法和RMSprop算法都采用了一种称为指数加权移动平均卩加习的方法, 设置一个小于1的正数作为衰减因子，将历史梯度平方的累积和转化为历史梯度 的衰减均值，离当前迭代越远的梯度值衰减越大，在非凸问题上能取得更好的效 果。经过该方法处理后，保证了 Adagrad算法优点的同时，不会出现后期参数更 新整体减小的情况。RMSprop算法仍需要手动设置初始学习速率，Adadelta算法 则根据参数变换量自动确定学习速率，不需要手动设置初始值。
Momentum［33］算法仿照动量的原理设计。Momentum算法存储了历史梯度， 因为当前梯度更新与历史梯度有关。当梯度方向一致时，学习速率会变大，可以 更快抵达极小值点；当梯度方向改变时，学习速率大小随之改变，可以有效减小 在极小值点附近的震荡。
Adam®】算法汲取了 RMSprop算法和Momentum算法的思想，结合两种算 法的长处对网络参数进行优化更新。Adam算法使用指数加权移动平均方法确定 更新幅度，利用之前的梯度方向和当前梯度方向确定更新方向。同时Adam算法 具有低内存消耗的优点，是目前神经网络常用的优化算法之一。
17
