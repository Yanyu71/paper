4.3.3基于干扰感知多智能体深度Q学习的异质频谱分配算法
本小节研究使用深度神经网络来拟合传统强化学习中的Q函数，原有的Q 函数变为Q(sn ,an ,ff),其中。为深度神经网络的权重，通过大量的训练得到。 当权重。确定后，即以。为权重的深度神经网络拟合的Q值Q(sn ,an ,ff)也被确 定。深度神经网络的权重通过损失函数来进行更新
49
其中，D为记忆区，以元组（％，a”,，f,%+】）存储智能体历史数据的采样样本,
基于干扰感知多智能体深度强化学习的异质频谱分配算法的基本思想是，线 下训练，线上使用，即通过历史通信数据对神经网络进行训练，得到神经网络的 最优权重卅，然后，将训练得到的权重带入神经网络中，用于实际V2V异质频 谱分配。在这里主要描述线下训练算法，如算法4-1所示。
算法4-1基于干扰感知多智能体深度Q学习的V2V异质频谱分配算法 初始化：初始化车联网通信环境，包括基站、蜂窝用户、V2V用户;
随机初始化深度神经网络；初始化训练次数匕味
训练：
1： 循环：v = 1
2:	V2V通信对町观测周围环境％
3:	V2V通信对基于当前策略选择动作a„ ,即选择通信模
式和频谱资源
V2V通信对执行动作a”,，获取奖励rni
V2V通信对观测周围环境％+] 将（%，a片,乙,，%+i）存储到记忆区D 更新车联网通信环境
从记忆区。中采样历史数据用于训练，更新深度神经网络权重
10:	返回/
