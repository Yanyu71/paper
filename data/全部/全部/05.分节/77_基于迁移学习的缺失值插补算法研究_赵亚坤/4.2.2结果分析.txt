4.2.2结果分析
如表4-2和表4-3是不同算法在是数据集上的缺失值插补表现。其中第一列 是数据集特征列的缺失值比例，表格中的数值是插补缺失值之后整个数据集的指 标，两个表分别为AUC值和Fi值。
从表中可以看出，在数据集的指标测试中，我们的改进之后的算法在多数情 况下明显好于其他三种算法。下面从缺失值比例较低和较高两个方面进行具体分 析。在缺失比例相对较小（51%及以下）的情况下，迁移学习缺失值插补算法并 没有发挥出其优势，这一点与改进之前类似，数据集缺失比例不高时，传统缺失 值算法能够从数据集中获取到足够信息来构建缺失值插补模型。
表4-2不同算法在数据集上的缺失值插补表现（AUC值）
缺失百分比	0值填充	k-NN填充	低秩矩阵 填充	迁移学习填充 （分类模型）	迁移学习填充 （回归模型）
30%	0.640	0.632	0.641	0.630	0.645
37%	0.610	0.614	0.635	0.615	0.624
44%	0.570	0.585	0.591	0.567	0.588
51%	0.532	0.523	0.572	0.544	0.564
58%	0.528	0.515	0.558	0.513	0.572
65%	0.500	0.503	0.525	0.508	0.544
72%	0.500	0.508	0.524	0.507	0.544
79%	0.500	0.500	0.502	0.510	0.557
86%	0.500	0.500	0.500	0.504	0.542
93%	0.500	0.500	0.500	0.510	0.524
100%	0.500	0.500	0.500	0.507	0.522
41
当缺失值比例进一步增大的过程中，其他缺失值插补算法迅速退化，AUC 最终逐渐逼近到了 05 而迁移学习缺失值插补，在缺失值比例大于51%之后， 超过了实验的所有的缺失值插补算法。并在缺失值比例进一步增大的过程中保持 稳定，性能明显好于在其他算法中效果最好的低秩矩阵分解算法。我们可以从图 中得出，改进后的迁移学习缺失值插补算法较于改进之前的提升很大，其原因主 要是改进之后的迁移学习缺失值插补算法能够避免了将数据集中的连续值转化 成离散值这一步，节约了大量的信息损失。
表4-3不同算法在数据集上的缺失值插补表现（Fi值）
缺失百分 比	0值填充	k-NN填充	低秩矩阵填 充	迁移学习填充 （分类模型）	迁移学习填 充（回归模 型）
30%	0.265	0.302	0.302	0.256	0.303
37%	0.233	0.279	0.295	0.222	0.297
44%	0.196	0.254	0.265	0.201	0.246
51%	0.097	0.150	0.234	0.189	0.231
58%	0.073	0.132	0.196	0.156	0.201
65%	0.052	0.098	0.102	0.134	0.185
72%	0.021	0.067	0.078	0.112	0.135
79%	0.013	0.042	0.032	0.096	0.101
86%	0.024	0.021	0.013	0.045	0.084
93%	0.011	0.011	0.015	0.034	0.083
100%	0.005	0.005	0.005	0.032	0.076
