1.1研究背景与意义
当前随着信息的快速发展，互联网，大数据等新技术已经深入到人们生活的 方方面面。数据是信息时代的血液，已经成为了经济、国防、日常生活中最重要 最有价值的资源。在互联网的大环境下，数据获取越来越方便，数据量随着时间 呈指数型增长。然而数据的复杂化对数据管理造成了极大的威胁，尤其是在互联 网的大背景下，信息交流更加频繁，使得这一趋势愈发明显。例如多源数据融合 或者违法记录等问题，导致人们不能完全相信所拥有的数据。比如商家使用了错 误的消费信息会将错误的商品推荐给用户，导致了商铺收益的下降；医疗数据的 不规范记录会导致医疗数据不可靠，耽误了医学研究进展和患者治疗的进程；低 质量的客户数据仍然对美国造成大约6110亿美元的损失。在各个领域中，数据 不准确都浪费着大量的财力物力。如何利用好这些数据，使其为我们的生产做出 贡献，是我们作为大数据挖掘工作的重点。而想要做出有价值的成果必须采用高 质量的数据，数据预处理是数据挖掘数据分析中的第一步也是至关重要的一步。 数据预处理的好坏直接影响到算法实现的性能。
在数据预处理的过程中，对于缺失值的处理又至关重要。在实际生活中，数 据集有缺失非常常见。比如美国的Honeywell公司的设备维护和测试用数据库缺 失值高达50%,医疗领域为了保护患者隐私，或者由于记录的不规范，数据丢失 率能够高达60%以上。数据缺失意味着信息缺失和统计特征丢失，而数据分析是 建立在统计学、信息学上的学科，这些缺失值不仅意味着信息的空白，其对后续 数据挖掘等工作的进行也会造成无法挽回的损失。缺失值给算法会造成极大的影 响，比如在聚类算法中，缺失值会影响距离函数的度量，这会影响最终的聚类结 果；在决策树分类算法中，缺失值会影响叶子结点的划分；在关联规则算法中， 缺失值会影响置信度的计算结果，影响了算法挖掘关联规则的能力。可见，无论 是何种情况，一旦数据发生缺失，都会给数据分析带来诸多困难。因此，如何减 少因数据缺失对后续数据挖掘研究工作影响，并且我们如何避免数据缺失导致的 错误结论，是当下数据科学研究的重要方向之一。
数据缺失问题可以说是无处不在，当然数据分析工作者一直以来都在关注这 个问题，也在从各个方面积极的寻求方法解决。对于缺失值问题，前人有着非常 丰富的相关工作。有基于参数估计的方法，有基于统计的方法，还有基于数学矩 阵的方法等等。这些方法在不同领域不同场景能够相应的达到相对于不插补更加
优良的性能。当然，传统的方法依旧具有局限性。传统的缺失值插补都是基于数 据集中已有的信息，对缺失值所在的缺失信息进行插补。值得注意的是，依据香 农的信息论，丢失的信息是无法挽回的，传统的缺失值插补方法仅仅是针对后期 数据分析的步骤，减少缺失信息所造成的噪声影响，达到提升性能的效果，而并 没有真正的将缺失的信息给插补上。这种方法在大部分场景下都适用，然而当缺 失信息远大于已有信息时，这种方法的效果会急剧下降并逼近未插补缺失值的方 法。因为此时缺失值造成的噪声影响已经大于仅存数据包含的信息了，数据分析 模型无法学习到有效的信息，使得最终结果不好。对于此类问题，迁移学习提供 了一种独特的思路来解决。我们可以通过寻找一个与含有缺失值的数据集（下称 目标数据集）相似的源数据集，来帮助我们训练一个更好的缺失值插补模型，通 过引入源数据集中包含的信息来插补现有数据集中的缺失值，这样从根本上提高 了整个数据集的信息量，对于缺失值比例过大的数据集也适用。
本文的工作主要在于利用外部的源数据集，来提高缺失值比例过大的数据集 中缺失值插补的问题。并与传统缺失值插补方法进行比较，对结果进行评价和分 析。
