1.3.1单一插补法
单一插补算法是利用某种算法针对每个缺失值都计算出一个值来插补，单一 插补法能够发挥作用的基本思路为最可能的值插补缺失值比删除这些缺失值信 息丢失要少。在某些场景，比如数据库规模比较大的时候，如果因为某个属性缺 失值比较多而大量删除，会导致其他属性中有用的信息也遭到破坏，所以在这类 场景下我们选用合适的插补方法相对来说更加有效。单一插补法常用的有如下几 种方法：
1）均值插补：均值插补就是利用该特征列的均值作为缺失值的填补对象，优点 是简单易操作，能够以最小成本来保存尽可能多的信息。其中均值的计算大 致分为两种。如果数据均匀分布的话去平均值，如果数据分布不均匀的话取 众数。
2）权重法：权重法可以通过对数据样本增加权重来控制缺失值信息的学习效率。 权重法可以先通过Logistic回归来计算缺失样本的权重个案的权重，机器学 习算法中训练的时候对这些已标记的缺失值进行低权重训练，减少缺失值带 来的偏差。权重法处理缺失值问题也具有较大的缺陷。因为权重的计算很依 赖数据所在的场景，如果权重计算与设定与场景数据分布不符合，或者说不 同类型的数据被赋予了相同的权重，会导致计算的难度增加，预测的精度下 降，这时权重法的效果并不理想。
3）同类均值插补：同类均值插补和均值插补类似，在其基础上，增加了一个类 别的属性。每一个缺失值可能还可以依据某种属性分类，在相同类别下，将 该类别的所有数据作均值，填充到缺失值中去。同类均值插补属于对均值插 补算法的一种改进。
4）数学方法：数学手段主要使用核函数的方法。程誉莹19〕提出了一种基于修正的 Sigmoid核函数的算法用来插补缺失值，相比于KNN和最小二乘法插补，取 得了不错的效果。Johnj"。］等人构建了一种混合核函数，使得核函数缺失值插 补方法可以用来填充离散数据和连续性数据，大大提高了核函数缺失值插补 算法的适用范围。Zhangs。1〕将多重缺失值插补方法和核函数缺失值插补融合 起来，使之能够适用于不同缺失机制下的缺失值插补场景。
5）极大似然估计:如果数据缺失类型为随机缺失,那么根据我们对数据的理解， 观测数据的边际分布，可以得到关于数据的极大似然估计。极大似然估计需 要大样本的数据量作为前提。数据量越大，计算出的似然估计就接近于无偏 估计。但是极大似然估计算法缺点就是容易陷入局部最小值，收敛速度慢。
6） EM算法：EM算法是一种利用极大似然估计或者后验分布在不完整数据情 况下计算的迭代算法。在每一迭代循环过程中交替执行两个步骤：E步和M 步，E步是在给定数据和之前计算的结果的情况下计算数据对应的似然函数 的期望；M步是利用极大化似然函数来计算参数的具体值，用于下一步的计 算。算法通过E步和M步不断地迭代直到参数变化小于一个预定的阈值。当 然EM算法也有一些问题，其收敛速度慢，算法高度依赖初始值的选择。对 于此类问题,孙华艳02］等人提出，在EM算法之前增加KNN算法,使用KNN 算法的分类结果作为EM算法的初始参数设置的参考依据，利用KNN算法 分类的特性，然后按照EM算法迭代反复求精，快速得到缺失值填充结果。 该算法由于集成了聚类算法的稳定性，能够从效率和性能上都能够得到较大 的提升。
7）随机效应模型：于力超和金勇进口刃通过研究，发现采用随机效应模型作为插 补模型时，结果更加准确，并且效应模型的固定对于插补缺失值模型来说相 对简便。固定效应模型适用于缺失比例较小、数据集内部相关性较大等情形 下，否则随机效应插补模型更能够胜任工作。
