2.4.1强化学习基本概念
作为机器学习中的分支之一，强化学习任务可以通过不断地与环境进行交互, 完成对当前环境信息的学习与探索，从而形成某种策略，获取到最优的结果。强 化学习是一种经典的奖励指导行为的方法，目标在于使强化学习智能体在不断学 习的过程中获取到最大奖励。
► Agent
state reward	action
Environment
图2-9强化学习任务中智能体与环境交互示意图
强化学习主要包含状态、动作、转移概率、策略和奖励等五个要素。如图2- 9所示，用马尔可夫决策过程(Markov Decision Process, MDP)阐述强化学习中 智能体与环境的交互示意图。具体来说，该过程会创建一个处于某个特定环境的 智能体。一方面，这个智能体会通过与环境进行交互，感知当前环境从而获取当
16 前状态，将状态映射后生成与之对应的决策；另一方面，智能体能通过完成某个 动作从而对环境产生新的影响，即当智能体完成某个动作后，环境会根据一定的 概率转移到下一个状态中。与此同时，根据奖励函数的激励，环境能够向智能体 反馈奖励。
可以看出，强化学习的主要思想就是使得智能体与环境不断交互、不断学习， 根据策略得到相应的动作和奖励，并随之更新环境并调整其策略，最终智能体会 生成一个最优策略。此时便可以按照这个策略，感知智能体在何种状态下应该执 行何种动作。
因此，在设计强化学习模型时，需要考虑以下几个方面：
(1) 如何定义状态空间和设计相应的动作空间。合适的状态空间能够更好地 帮助智能体完成与所处环境的交互，从而在不断学习中形成合适的策略。相应的 动作空间包含了智能体可能做出的一系列决策。
(2) 如何定义合适的决策方法。正确的决策方法关系到了智能体能否有效完 成决策任务，以达到所预期的提升系统性能的效果。
(3) 如何设计有效的奖励。智能体在完成由当前环境状态到具体动作的映射 过程中，智能体选择的动作是为了保证当前环境下获取到最大奖励，使系统达到 最佳性能。奖励越高，智能体选择相应动作的概率越大；奖励越少，智能体选择 相应动作的概率将会产生削弱。
本文在多Wi-Fi协作下最佳感知链路选择机制的研究中，将多Wi-Fi链路选 择问题转化为顺序决策问题，并选择采用强化学习模型求解该问题。通过建立一 个强化学习智能体，使得智能体与Wi-Fi环境发生持续性交互，不断学习Wi-Fi 信号状态，根据策略得到相应的动作和奖励，并通过更新选择的链路和调整其策 略，最终使得智能体生成一个最优策略。通过这个最优策略在多Wi-Fi协作场景 中完成对最佳感知链路的选择，提升基于Wi-Fi感知系统的精度。
