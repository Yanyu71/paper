4.2.1数据处理模块
原始的CSI数据包含了幅度数据||H川和相位数据厶川。如2.2所述，由于不 同频率的目标行为对CSI幅度||H川和相位差△厶厲在时域的变化会产生不同的模 式，可用于捕捉相关的目标行为。首先利用相邻天线的CSI相位数据厶血计算相 位差AzHp得到多个子载波的CSI数据流［||^||,AzHz］=本章的数据处理模块包 括以下步骤：
(1)去噪：如3.2.2所述，PCA能够通过计算多个数据维度之间的相关性来 消除冗余噪声并保留相关成分，因此本章首先对多个子载波的CSI数据流
［||HZ||,AZHJ使用PCA,并保留第二个主成分的数据，得到基于PCA的去噪CSI 数据流在=［齢,环］,其中好和环分别是在时间步长为t时CSI幅度||H川和相位差 2Hi的第二个主成分。基于此，每个Wi-Fi链路的CSI都能够初步提取目标行 为相关的特征并去除无关的信息。
37
（2）归一化：为了减少计算成本，提高分类性能，本章还对数据集采用零均 值归一化法。具体来说，所提出的数据处理模块使用零均值和单位方差对CSI流 込进行归一化，得到0；:
0：=詈（；=1,2）,	（4-1）
其中，玮和卅分别表示专的均值和标准差。
422强化学习智能体
由于本章将Wi-Fi链路选择制定为一个顺序决策问题，因此相应的解决方案 可以通过强化学习来解决。基于此，本章设计了一个强化学习智能体。对于智能 体的设计需要考虑两方面因素。第一个因素在于Wi-Fi环境复杂多变，环境中目 标发生的微小位移都将对Wi-Fi信号产生巨大影响。因此，智能体需要敏锐感知 Wi-Fi环境中的情景信息。第二个在于因素在于Wi-Fi环境中包含大量的链路。 使用过多的链路不仅会引进过多的冗余信息，还可能包含环境噪音；使用过少的 链路则无法确定该链路是否能为Wi-Fi感知应用提供充足的目标行为信息。因此, 智能体需要一个适当的决策方式，筛选出最优的感知链路用于行为感知。
基于上述两个因素的综合考虑，所设计的智能体包括两个网络：一个是基于 LSTM的情景感知网络，包含一个观察网络和情景感知网络，用于观察当前环境 状态，将智能体的情景信息和历史状态编码成特征向量，帮助智能体从复杂的 Wi-Fi环境信息提取出有效的目标行为特征；一个是策略网络，它在每一步都从 预设的动作空间中生成合适的动作，该动作用于根据当前环境状态选择出一个最 优的链路用于后续的目标行为感知。具体设计如下：
首先使用神经网络将所探索的Wi-Fi环境信息©编码成特征向量。具体地说， 智能体始于一个基于LSTM的情景感知网络，该网络包含一个观测网络人和一个 情景感知网络兀，参数分别为0。和為。为了有效降低数据维度并简化训练过程， 智能体在基于LSTM的情景感知网络的开始阶段使用一组权重和偏置作为观测 网络九。在t时刻，智能体观察到状态：
= fo（.ot；6o'） = Wx + b,	（4-2）
其中兀为线性加权和函数，权重W和偏置0构成参数0。。
考虑到目标行为感知对Wi-Fi环境变化极为敏感，而多层LSTM模型能够学 习和识别其中的关键隐藏信息。因此，智能体还包含一个情景感知网络即在 观测网络之后使用三个LSTM层用于处理序列信息。智能体同时观察当前状态 “和之前的隐藏状态入_1，将其作为情景感知网络的输入，随后生成当前的隐藏 状态心：
38
ht = fh(ht> St； 8(1)。	(4-3)
随后，智能体将t时刻的特征向量输入到策略网络中，利用策略从动作空间 中产生一个合适的动作。此动作能够决定智能体在t + 1时刻的选择的链路。策略 网络由参数血构成的一个全连接层组成，并使用softmax激活函数输出每个动作 的概率值。动作空间〃覆盖所有Wi-Fi链路集合，即动作兔的生成表明智能体在 t时刻选择了与该动作相对应的链路。策略如下：
n(ut\ht; 0U) = softmax(Wht + b),	(4-4)
其中，n(ut\ht; 0u)为动作概率分布，softmaxQ)为softmax激活函数，"和b为 权重和偏置，共同构成参数盅。概率最大的动作Wt = argmaxuji(ut\ht-,9u)则视 为最优的动作。
