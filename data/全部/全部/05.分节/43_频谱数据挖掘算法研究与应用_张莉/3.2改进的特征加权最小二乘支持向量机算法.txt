3.2改进的特征加权最小二乘支持向量机算法
经典LSSVM认为所有的特征维度有一样的贡献程度，然而目标函数与样本 的有些维度上的信息是弱相关或者是无关的，这样就会降低预测器的推广能力。 在一些真实数据集上，确实存在某些特征对预测贡献大，而其他特征对预测贡献 小的情况，所以就提出了特征加权LSSVM算法。特征加权就是用一个特定权重 值来代表该特征的重要性，越重要的特征则该权重值越大，即对于输入数据有一 个特征加权向量用于描述其各个维度数据的重要性。该权重值可以之间在核函数 上进行加权，下文将给出特征加权LSSVM的定义。
定义2：假设K(?)是核函数，"是输入数据的维数，P是输入数据的”阶 线性矩阵，XCRn是输入数据。被特征加权后。(?)表示为：
Kp(%%) = K(x：P,可 P)
矩阵P的不同形式将代表不同的加权方式：
(1)P是n阶单位阵。此时就是没有加权的情形。
(2)F是"阶对角阵。此时P, = Wi(l<z< n)代表第z个特征的权重值，记 imp =时,32，...,3」为特征加权向量。
(3-2)
(3) P是任意e阶方阵。此时称为全加权情形，即组合了特征加权和样本加 权。
(3-3)
n2
本研究主要使用F是e阶对角阵。
定义3：由式(3-1)可得到被特征加权后的高斯径向基函数为:
2a2
将矩阵P引入到核函数中，能实现变化特征空间中不同维度的权重【以，主要 是通过缩放特征空间和输入空间。
引入了特征加权向量后，FW-LSSVM需要确定的超参数有：特征加权向量 7朝=|%心2…此］、正则化参数［和核宽度。。本文针对不同的超参数寻优问题， 提出了两种自适应优化超参数取值的算法。一种是针对数据预处理时，数据未进行归一化，而是按照数据特性分为离散型和连续型不同处理，即输入数据不同维 度的量纲不统一，此时采用类似EM算法的分步寻优方式；令一种是针对数据预 处理时将输入数据的特征都进行归一化，即输入数据都在［-1, 1］的范围国，此时 采用联合寻优的方式。
在LSSVM算法上，引入特征加权向量来调节不同维度特征对模型的贡献程 度，形成了特征加权LSSVM算法，其能更直接快速地调整输入空间中不同维度 数据对训练模型的影响程度。
