3.3改进的基于免疫算法的数据挖掘算法
在经典的LSSVM算法里，所有的特征维度被赋予了完全相同的重要性，这 样会出现一种情况，就是当用于挖掘的输入样本中含有与真正的目标函数之间只 是弱相关甚至是不相关时，这时所训练岀来的预测器的推广能力就会变差。比如 在一些真实的数据集上，有一部分特征确实是对预测器有很大的贡献，而还有一 部分特征是对预测器的贡献较小，为此就在传统LSSVM的上提出特征加权最小 二乘支持向量机算法(FW-LSSVM)?所谓的特征加权就是对每个特征维度的数 据赋予一个数值来表明该特征对目标预测器的重要程度，越大的权值则表示该维 度特征对目标预测器越重要。这样就在原来的LSSVM算法基础上，引入了一个 特征加权向量用于描述其各个维度数据的重要性。
引入了特征加权向量后，FW-LSSVM算法需要确定的超参数有：特征加权 向量沥叩=匝,的,...,3,』、正则化参数T■和核宽度＜7。特征加权向量的引入，将会 提高了寻优算法的复杂度，需要花费更多资源用于寻找合适的参数。而且当输入 样本的维度比较大时，这特征加权向量里的不确定权值数量也变大，寻优过程变 得更加困难。为此，本研究根据免疫算法的特征和LSSVM寻优过程的特征，设 计了本章提出的基于免疫算法的特征加权LSSVM算法。该算法是采用类似于 EM算法的分步寻优思想，主要是分成两部分进行寻优，第一部分是在已知正则 化参数了和核宽度cr情况下，利用免疫算法寻找最优的imp =	；第二
部分是在固定特征加权向量imp =風仲?,...,％］情况下，寻找最优的正则化参数7 和核宽度“，其流程框图如图3-2所示，图中的终止条件1是指结束当前部分寻 优的条件，终止条件2是指结束这个算法寻优过程的条件，终止条件一般是指训 练出的模型是否能达到一定的预测精度和是否达到寻优次数的上线，具体的条件 需要根据实际的应用场景和专业知识经验而定。
图3-2基于免疫的FW-LSSVM算法流程框图
本算法的核心主要是在第一部分即釆用免疫算法寻找最优的特征加权向量
的p =	，其实现步骤如下：
第一步：产生初始抗体群*。随机产生酒个特征加权向量性P （抗体）并加 上记忆库中的冲个特征加权向量，冲,第一步时都是随机产星。
第二步:.对目前群体中的各个特征加权向量（抗体）进行评估，即得到每个 抗体的期望繁殖率P。
（1）抗体（特征加权向量叫）与抗原（目标函数）间亲和力4。4反应 了抗体识别抗原的能力，也就是训练出的模型的性能。本例中使用S折交叉验证 的方法来评价模型的性能。S折交叉验证是指，随机地将原始的训练数据分为S 个互不相交的大小相同的子集，用其中的S-1个子集的数据去训练模型，剩余的 子集测试模型；对可能的S种选择重复进行，最后以这S次误差的平均值作为衡 量该组参数的性能指标（X）3t（y',a',imp'},用此值来表示在参数为/,b时， 模型的准确率。所以亲和力函数4为：
1
cos rC/^cT', imp'）的计算方式如下:
其中:
d =心 g = K( %毛),k,l = 1,...,N(S—X)/S
常用的高斯核函数:
（2）抗体和抗体间的亲和力丫。/反应了不同抗体之间的相似程度，即不
同的特征权重向量的相似性，本例中采用欧式距离来衡量。f的计算表达式如下:
V,=——广?	h =	（3-10）
1+0冲_叫）2
其中，V,表示当前权重向量沥p与库中第/个权重向量w,两者的相似度。
（3）抗体浓度C。。表示已有的特征加权向量中相似向量所占的比例，所
以抗体浓度C的计算表达式如下：
C,=^— ￡ V；	（3-11）
.1, K >T
匕={	（3-12）
[0, others
其中T为预先设定的关于抗体与抗体两者相似度的阀值。
（4）	期望繁殖概率F。每个特征加权向量的期望繁殖概率户受到抗体浓度 G和抗体与抗原的亲和力4同时影响，即：
E佥
其中PS用于评价参数的多样性，/?5G（0,l）o特征加权向量的浓度越大，则其期 望繁殖概率越小；特征加权向量的适应度值越高，则其期望繁殖概率越大。免疫 算法在此引入了精英保留政策，因为在遏制高浓度个体时，容易将那些本来与抗 原亲和度最高的抗体遏制，这样会误删已得到的最优解。所谓精英保留政策是指 在更新记忆库前先挑出与抗原亲和度较高的几个特征加权向量到记忆库中，然后 根据望繁殖概率把其他较好的特征加权向量存入记忆库中。
第三步：判断是否符合结束条件，本例中的结束条件为最大迭代次数，如果 满足则输出最佳特征加权向量；反之继续往下一步操作。
第四步：新特征加权向量的产生。新特征加权向量的产生规则为：
（1）	将模型性能表现较好的特征加权向量，也就是抗原-抗体亲和度,最高 的前k（k < nr）项替换记忆库中原来前*个特征加权向量；
（2）	在剩余的（nr + ns-k）个特征加权向量中挑选出期望繁殖率高的前 （nsk）个特征加权向量，将他们也存入到记忆库中后（冲-幻个位置；
（3）	在所有的特征加权向量中，选择出期望繁殖概率高的前務个特征加权 向量，对其做变异和交叉的操作，产生新的務个特征加权向量组成新的父代抗 体群；
（4 ）将记忆库中的特征加权向量和父代抗体群一起组成新一代抗体群。
（5）	转到执行第二步中。
当通过该算法找到最优的特征加权向量后，固定最优特征加权向量，用耦合
28
模拟退火算法寻找最优的正则化参数7和核宽度b;再接着固定最优的正则化参 数了和核宽度b去寻找更合适的特征加权向量，循环多次后选出最优的特征加权 向量冲羽=时,32,正则化参数7和核宽度“蠢参数作为模型的超参数，其 循环停止的条件是最大迭代次数和衡量模型性能的指标达到要求。
所谓的数据挖掘过程就是通过对历史数据的学习得到一个模型，用该模型来 预测未来某一个时刻的情况。一般来说会有一个历史数据作为训练数据集： ｛（凡必），奶丿2），?X 为：，其中耳是输入数据用于描述样本的特征，一般包含 多个维度的信息，其为输出数据，通常是预测的目标值，可以是一维或者多维度。 学习过程和模型函数以及预测系统的关系如图3-3所示：
图3-3预测问题流程图
