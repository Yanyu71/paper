1.2.2集成分类算法研究
分类预测是数据挖掘的基本课题，近年来，集成学习算法因其能显著提高模型的泛 化能力而成为分类算法重要的研究方向。集成学习算法将多个学习方法组合在一起，通 过对单个分类器的预测结果进行投票表决，得到最终的预测结果，当单个分类器存在差 异时，集成分类算法的提升效果更为显著。
Schapire首次提出了强学习器和弱学习器的概念p5]。Breiman提出Bagging算法， 通过训练不同的模型，采用取平均值或投票的方法得到最终的预测结果。实验表明， Bagging算法在预测精度上有显著提升阳。Schapire还提出了 Boosting算法，不同于 Bagging算法可并行运算，Boosting算法是一个迭代的过程，弱分类器在迭代过程中自
适应地改变训练样本的分布，最终可提升为强学习器12叫Freund等学者提出了 Adaboost 算法，对每次训练错误的样本加权，并基于样本的预测结果对分类器进行权值调整，“惩 罚”表现较差的分类器，而不是采用多数表决的方法。Adaboost算法被证明是最优秀的 Boosting算法之一［27］。Breimant等学者提出了随机森林算法，由多棵通过对样本或特征 采样训练生成的决策树组合在一起，所有决策树的预测结果经过投票来完成最终的预测, 有效地降低了模型的方差网。Breimant还基于Wolpert所提的“堆叠”概念，提出Stacking regressions算法，一种形成不同预测因子线性组合以提高预测精度的方法，其思想是利 用交叉验证数据和非负约束下的最小二乘法确定组合中的系数，在不同大小的叠加回归 树中加入模拟叠加线性子集，实验证明了该方法的有效性UI。Ting研究了 Stacking算法 中的两个关键问题：适合导出更高层次模型的泛化器类型和作为其输入的属性类型，并 证实了高阶模型结合低阶模型的置信度可以获得最佳结果［3瞑
近年来，Stacking算法基础上衍生出很多变体，在不同应用领域取得了良好的预测 效果。Bamwal等学者对一层神经网络进行优化，建立了价格加密货币的方向模型用于 资产方向预测，通过堆叠集成方法提高预测准确性⑶］。Kevin等学者使用Stacking模型 预测单个癌细胞株的药物敏感性，探讨了叠加模型的预测性能以及叠加对预测偏差和平 方误差的影响BL Liu等学者提出了一种新的组合分类方法用于文本分类，将TFIDF训 练的各种弱分类器与Word2vector算法相结合，从多个方面对文档进行表达，充分利用 文档提供的信息。实验结果证明了这种堆叠算法比单独使用Word2vector算法以及简单 的弱分类器组合分类方法都有更好的分类效果R］。Zhang等学者提出了一种改进的多卷 积神经网络堆叠算法，采用卷积神经网络作为基分类器对原始数据进行分类，然后用元 分类器对新样本进行分类。为了降低元分类器中输入数据的维数和相关性，采用主成分 分析(PCA)方法对基分类器的输出进行降维。实验结果表明与传统的堆叠、平均后验 概率和投票相比，该算法在相似网络中的分类精度更高、更稳定Ml。
