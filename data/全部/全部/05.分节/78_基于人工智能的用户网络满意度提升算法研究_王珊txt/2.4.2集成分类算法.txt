2.4.2集成分类算法
相对于单个分类器由单一学习算法构成，集成学习方法(ensemblelearning)又称分类 器组合方法(classifiercombination),通过在原始数据上构建一组由相同或不同算法得
13
到的基分类器，对这一组基分类器的预测结果进行多数表决从而实现最终的分类。集成 分类算法的性能在基分类器的性能优于随机猜测且相互独立且时能得到较好的提升，而 在实践中，很少能达到基分类器完全独立，但是集成方法仍可以有较好的表现。常用的 集成分类算法有装袋(Bagging)、提升(Boosting)、随机森林(Randomforest)等网。
图2-5集成分类算法模型
集成分类算法在数据集D上通过样本抽样或特征抽样创建r个训练集，每个训练集 用于创建不同的基分类器，当对未知样本进行预测时，每个基分类器都会进行一次预测 并返回预测结果，通过投票的方法，产生最终的预测结果。集成分类算法模型如图2-5 所示，集成分类算法的一般过程如表2-2所示：
表2-2集成分类算法
输入：
•	D：原始训练数据集；
•	左：基分类器的个数；
•	T：检验数据集；
输出：一个复合模型。
算法：
1 ： for z=l to k do
2：	由。创建训练集Di
3：	由O创建基分类器C
4： end for
5： for每一个检验记录xW7do
6：	C*(x)=Vbte(Ci(x)C2(x),…,G(x))
7 ： endfor
14
基础集成技术包括以下几种：
（1）最大投票法：每个模型都拥有一票投票权，每个模型的预测都被视为一次“投 票”，大多数模型的预测结果作为最终预测结果，可将此方法视为采用了所有预测的众 数；
（2）平均法：类似于最大投票法，对每个样本进行多次预测取平均作为最终的预测 结果。平均法可用于回归问题的预测或分类问题概率的预测；
（3）加权平均法：是平均法的扩展，为所有模型分配不同的权重，定义每个模型的 预测重要性。
