2.4.1基分类器
基分类器由单个分类算法确定分类模型。常用的基分类器有决策树、支持向量机 (Support Vector Machine, SVM)等。
(1)决策树
决策树顾名思义是一种类似于流程图的树形结构，树的顶端是根结点，存放了与目 标变量最相关的属性，树中每个内部结点表示对一种属性进行测试，经过测试后不同分 支表示不同输出结果，当对一个未知样本进行预测时，由根结点开始，经过多次属性判 断，最终落到一个叶结点内，叶结点内存放的类标号即是对该样本的预测结果。决策树 因其简单快速的分类步骤、直观的表示形式及较高的准确率，是最常用的分类器之一。
构造决策树时，有多种选取分支属性的标准。CHAID决策树依据局部最优原则，利 用/检验作为结点属性选择方法。CART决策树将基尼系数作为检验不纯度的指标， CART树为二叉树且每个自变量可反复使用。ID3算法选取分割后的结点进行分类所需 的信息量最小作为属性选择的标准，这种标准称为基于信息增益的选择。C4.5算法改进 了 ID3算法中倾向选择具有大量值属性的问题，使用具有最大信息增益率的属性作为分 裂属性来克服这种偏倚。上述算法除CHAID决策树外都采用贪心策略，在选择划分结 点的属性时，采取一系列局部最优决策。
(2)支持向量机
SVM最早起源于统计学习理论，它是一种对线性和非线性数据都适用的分类方法， 使用训练实例的一个子集来表示决策边界，将元数据映射到较高维上后，通过决策边界 将样本数据分离。因为具备诸多较好性质，SVM已经成为广泛使用的分类算法之一。 SVM可表示为凸优化问题，不同于基于规则的分类器和人工神经网络都采用贪心策略， 通常只能获得局部最优解，SVM可通过优化目标函数得到全局最优解，相应的其算法 复杂度也较高，需要较长的训练时间。SVM通过最大化决策边界的边缘来控制模型的 性能，同时还需要提供其他参数，其中核函数的选择是算法的关键。目前，SVM在高维 数据的应用中展示了很强的实践效用。
