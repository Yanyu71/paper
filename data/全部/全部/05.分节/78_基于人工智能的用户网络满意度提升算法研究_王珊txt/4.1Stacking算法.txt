4.1Stacking算法
Stacking与Bagging、Boosting等算法均属于集成学习方法，与其他集成方法相比， Stacking是一种更特殊的结合策略，Stacking算法的基础上衍生出很多变体或特例口叫 Stacking集成学习方法一般由两层组成，第一层为多个基分类器，对原始训练集进行学 习，称为初级学习器；第二层以初级学习器的输出作为训练集进行学习，称为次级学习 器，次级学习器的类标记与原始数据集保持一致，经过两轮训练得到最终的预测结果。 Stacking算法的关键在于次级学习器训练集和测试集的生成，如图4-1所示。
X train new=
X_train	X_train	X train		X test	X test X test	X test
q		¥
Modell1	Model 12	Model la		Modell j	Modell?	Model lo
y pred_2				j^pred_2	j^pred_n
yjestj	y_test_2i	y_test_nj
y_pred_22	y_^red_n2		y_test_b	y_test_22	y_testji2
y_pre<L23	UMed1%			y_test_23	y_test
y_pred_L	y^)red_24	y_j>red_n4		y_test_i4	y_test_24	y_test__n4
y户d』	yjpred^s	yj>red^n3		yjesLh	y__tesL-5
yjpred_2m	y	J		\ y_test_lfc	y_test_2k	y_test_Dfc
图4-1 Stacking算法次级学习器训练集与测试集生成示意图
35
Stacking算法在训练阶段，为降低过拟合的风险，一般会拆分为训练集和检验集， 使用交叉验证或留一法来生成次级学习器的训练集，以5折交叉验证为例，Stacking算 法训练阶段的基本结构如图4-2所示：
model_T	probT
初级学习器
次级学习器
图4-2 Stacking算法训练阶段
第一层：将训练数据7>{(X2l),(X2,"),…的,词}划分为互不交叉的5份，标记为 4到。5,接下来对每个学习算法，进行5折交叉训练，每次训练将其中4份数据作为 训练集，经过训练得到一个初级学习器，对剩下的一份数据进行预测，保存预测结果， 即从。5作为检验集，使用口到。4建模预测A；再以。4作为检验集，使用。、6、 。3、A建模预测。4，如此循环，直至A到A都被预测到，将预测结果按照。1、。2、 。3、。4、。5的顺序组合，完成以上步骤便可得到训练集在第一个基分类器上的预测结果。 当选定的T个基分类器都完成上述操作后，便得到T个基分类器对所有训练样本的预测 结果。
每一次训练完成得到的初级学习器都对测试集做出预测，经过5次训练，便可在测 试集上得到5个预测结果，将这5次的预测结果求平均值，作为第一个基分类器在测试 集上的一个预测结果。重复7次上述操作，便可得到测试集的T个预测结果。
第二层：将训练集经过初级学习器训练后得到的T个预测结果作为输入，类标号与 原始数据的类标号相同，训练次级学习器，将第一层测试集的预测结果输入到已经训练 好的次级学习器中，输出测试集的最终预测结果。
36
表4-1 Stacking算法流程
算法：Stacking
输入：
・	训练集。={(玉,弘),(工2，%)，"依，九)}
・	初级学习算法G1，G2「・<7；
・	次级学习算法G
方法:
1: for t=l,2,--,T do
2：	%=q(D);
3: end for
4:Q'=@
5:	for i =	do
6:	for 1 = 1,2,…do
7：	Z"=4(xJ；
8:	end for
9:	£>' = Z>' u ((z” 02,z,7), x)；
\O:end for
11: A'=?(£>');
输出：H(x) = A'(/^ (x), h2 (x), - A (x))
Stacking算法在使用交叉验证构建模型时存在交叉学习现象，如图4-2所示，在构 造次级学习器输入时，如由。1、9、。3、。4构成训练集预测。5,而在预测D1、。2、。3、 04时，又将A作为训练集，这便是交叉学习现象，会影响模型的准确性。
