4.1.3模型训练和指标评估
值得说明的是，实现本文的主体功能，会针对每个意图都设置相应的问句语 料并进行标注，但是并不是对每个实体的具体值都进行标注（那样的话认为的标 注会耗费大量时间，也不利于扩展），Rasa NLU在进行训练时，是针对于实体 类型的训练，不是针对具体实体值的训练，即如果一句训练语料出现了“酒水” 这个具体的dish_type实体值，在训练时就等同于训练了所有dish_type的实体值 （包括“主食”和“干锅”等实体值相当于也有了这样的训练语料），这样就大大降 46
低了对于训练语料的数量要求，只需要针对每个实体类型模拟几条语料即可。同 时，关于对话场景语料的训练也是由许多的小对话场景可以自由组合而成的，这 样我们只需要将对话场景细分到最小，在训练时Rasa框架就能将这些对话场景 进行多次组合生成更多轮的对话场景，其基本的组合逻辑如图4-4所示。
意图语咪斗二	意图语料三	意图语料四
图4-4意图训练语料自动生成图
可以从图中看到一条意图语料就可以涵盖该实体所有值的训练，这样大大减 少了我们需要手动写入的语料数量而且有很好的扩展性。
和意图的语料自动生成一样，对于对话场景的语料其实也有相应的生成办法, 可以通过将多个场景组合的方式生成更多轮的对话，构建出更复杂的对话情景， 当然如果对话场景的组合非常多对于训练的开销也会非常大，所以这个需要根据 实际情况进行灵活地调整。
自动生成一样，对于对话场我们将pgeLine构建好以后对所有的其中的实体 提取器和意图识别器进行训练，其中两个部分的参数都使用Rasa框架的默认参 数，采用交叉验证的方法来评估NLU模型（这样可以比较好地评估模型的泛化 能力避免单个验证集的过拟合）将所有语料分为训练集和测试集，其中训练集占 80%余下的为测试集，得到的CRF实体提取器训练后测试结果如图4-5所示。
47
80
60 -
Entity Confusion matrix
MB hits
■■■ misses
s(D-dEes jo」<vqLunN
40 -
20 -
0
0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00
Confidence
图4-5实体提取器测试集效果图
图中可以看到，训练好的实体提取器在测试集上表现为高置信度的实体提取 正确占了绝大多数，而错误的案例基本属于低置信度导致的提取错误。关于意图 的识别器效果跟实体提取器类似，如图4-6所示。
48
图4-6意图识别器测试集效果图
从图中可以看到意图的识别效果在错误的示例中与实体提取器有相同的规 律，主要是在低置信度下导致的识别错误，但是正确的识别分布没有集中在高置 信度下。
而具体的指标参数如表4-3所示。
表4-3 RasaNLU模型指标数据表
模型名称
数据集
Accuracy
Fl~score
Precision
Recall
CRF实体提取 器
训练集
0. 992
0. 982
1.000
0. 972
CRF实体提取 器
测试集
0. 969
0. 908
0. 955
0. 854
Ski earn 意图 分类器
训练集
1.000
1.000
1.000
1. 000
Sklearn 意图 分类器
测试集
0. 902
0. 876
0. 888
0. 851
上表中的Accuracy表示整体模型的精确度，即正确识别数量/样本总量,
49 Precison表示在模型的准确度，即正确预测数量/预测总量，这里的正确识别数量 表示在预测为该实体或意图的条件下正确预测的数量，而预测总量则是预测为该 实体或意图的总量，Fl-scores是Precision/Recall,而Recall召回率表示正确预测 数量/实际总量，这里的实际总量为真实为该实体或意图的总量，而正确预测数 量与Precision意义相同。从数据值可以看岀模型的准确率和召回率在测试集相 对训练集有一定劣化但是劣化的程度不大，整体模型的指标比较好，理论上达到 了预期，后续的实际效果展示也证明了这一点，在后续章节会再详述。
