3.4.5语音生成模块设计
语音生成模块是最后合成语音输出的地方，其主要的技术点和模型已经在 上文详述了，除了基本的语音波形生成外，还涉及到了和后端中转层中转服务器 的交互，关于后端处理部分，本文的这部分的设计主要在于当语音合成服务器后 端接收到前端的文本信息后选择对应的模型并进行文本的预处理通过模型生成 语音的梅尔频谱再将梅尔频谱传递给声码器模型用于生成语音波形信号文件，存 储在服务器静态目录下后将文件的地址信息传给请求发送方，也就是后端中转层 的请求中转服务器。除此之外还涉及到语音克隆的编码器部分以及关于中文文本 信息转换为音素的处理，模块的整体结构如图3-16。
38
图3-16语音生咸模块结构图
本模块之所以会加入用户语音的额外编码器向量嵌入，是依据语音克隆论文
《Tians伦r Learning from Speaker Verification to Multispeaker Text-To-Speech
Synthesis》的思路，使用多人语音先训练一个音色编码器可以解决单独个人大量
语音语料难搜集且难扩展的问题，且多人语音的训练模型比单音色模型包含的信
息更全面，对迁移训练的支持更好，本文用一个预训练的多人对话的音色编码器
39 结构可以得到一个初步的包含了声音处理特征的语音生成模型，后续对特色语音 的训练只需要做迁移的训练就能达到克隆语音的效果，只需要搜集少量的语音信 息就能生成逼真度高的语音模型，同时本文没有使用Tacotron2文中使用的声码 器，而是单独自训练了 MelGAN和WaveFlow声码器模型目的是保证语音的质量 和即时生成速度，当然也对比了传统的信号处理算法，最后输出的波形文件地址 传递回后端请求处理模块，使得前端界面能引用静态资源链接的方式播放生成的 音频文件。
用户语音区分编码模块其实是一个类声纹识别的模块，主要完成的工作是将 声音波形转换为向量格式，其配合Tacotron2模型的编码器将编码信息嵌入组合 达到将音色信息融入的效果，使得Tacotron2模型能够训练多人语音数据，这样 就解决了单人语音信息不足声音特征覆盖不全面的问题。其基本的结构如图3-17 所示。
图3-17用户语音编码器模块神经网络结构图
该神经网络构建比较简单，主要先由一个ktm长短时神经元将波形信息进 行信息的存储功能，再有一个线性全连接层映射到需要的向量空间，由relu激活 函数完成向量的标准化激活，最后通过一个线性回归的相似矩阵similarity_matrix 完成回归分析，最后由多分类交叉矯损失函数cross entropy loss完成损失函数 的迭代更新，整体功能就是一个具备一定记忆性的多分类神经网络。
40
在前文中介绍了 Tacotron2模型，但是该模型其实处理的是字母型语言文本 到音素表示再到向量化输入最后参与训练得到梅尔频谱，但是中文文本需要将汉 字首先分词再转换为对应的拼音表达，且需要结合音调信息最后做为字母的输入 传入整个模型参与训练。这里关于中文的处理本文设计采用了 jieba分词器完成 分词工作，同时中文转为拼音，按照清华大学方案转为音素，分为辅音、元音、 音调。英文全部大写，转为字母读音。英文非全部大写，转为英文读音。标点映 射为音素。其基本的处理流程如图3-18所示。
图3-18中文文本转换音素流程图
如图中所示，中文文本首先会通过Jieba分词器进行中文的分词，本文釆用
的是默认的分词词库，然后会将每个词汇依据中文词汇与拼音的对应映射表转换
为拼音字母，再将拼音字母进行辅音元音等分割通过查询对应的映射表将拼音转
换为音素，最后查询音素在映射表中的下标索引将其转换为id值，将所有id值
41
整合在一起就构成了一个向量化的输入，该输入可以作为lacotron2模型的输入 进行同英文一样的训练。
同时，因为要既要训练Tacotron2语音合成模型又要训练声码器的神经网络 模型，需要考虑在生成梅尔频谱的时候采用相同的算法，这样才可以比较好地整 合在一起，在训练的时候对于可能出现的训练时长太长问题，也需要进行数据的 一些预处理，例如提前将梅尔频谱的向量和用户音色编码器输出的向量存储为文 件，在模型训练的时候只需要将该向量文件导入就可以在内存中直接处理。
