3.4本章小结
本章的研究重点是提高卷积网络学习长距离上下文信息，获取输入信号全局 语境的能力，以弥补卷积运算只关注局部特征的不足，旨在增加少量训练参数的 前提下提升原有卷积模型的语音增强性能。本章首先给出了一种基于UNet架构 的全卷积神经网络语音增强模型，然后又详细研究了一种新的二维相对自注意机 制的原理，其在图像识别与目标检测领域已经被证明是十分有效的。最后本章提 岀了一种用于单通道语音增强的注意力强化全卷积神经网络，将这种新的二维相
32
对自注意机制应用到全卷积神经网络中，通过灵活调整注意通道的比例，可以在 卷积关注局部细节和自注意力获取全局语境之间找到最优的组合。此外，在提出 的网络模型中，本文采用Huber Loss作为损失函数，它结合了 L1和L2损失的 优点，对噪声有较好的鲁棒性。随后本章详细介绍了与实验有关的数据预处理工 作与网络参数设置，共进行了 7组消融实验和对比试验，实验结果表明，本章提 出的模型性能优于所有的比较算法，能够更好地平衡噪声抑制和语音失真。本章 还将二维相对自注意机制应用到其他语音增强卷积网络中，并提高了网络去噪的 能力，表明这种注意力机制可以作为一种插件应用于基于卷积运算的语音领域， 具有良好的通用性。
33
34
