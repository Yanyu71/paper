3.2.3基于AAUNet的语音增强算法
encoder	decoder
图3-4注意力强化全卷积神经网络(AAUNet)
本文将图3-1中基于UNet架构的全卷积神经网络作为骨干网络，在此之上 嵌入二维相对自注意机制,在图3-4用"AA Block " (Attention Augmented Block) 表示。考虑到内存占用问题，本文只在编码端的最后三层和解码端的前两层进行 注意力强化卷积操作，本文将带噪语音的对数幅度功率谱作为网络的输入，输出 是增强净化后的对数幅度功率谱，然后将带噪语音的相位信息与增强的对数谱特
19 征相结合，重构出新的语音。卷积层的运算过程大致可分为三个步骤。首先，输 入语音(前一层的输出)由当前层中所有二维滤波器进行频率缩放卷积，然后对 输出通道维度进行批量标准化，最后利用激活函数对卷积特征进行非线性变换得 到当前层输出。二维相对自注意机制将卷积特征图与自注意力产生的多头输出沿 通道方向拼接起来生成新的特征图送入下一层网络，而不是通过融合相加或者门 控机制来重新校准原始特征。这一特性允许本文灵活地调整注意力通道所占的比 例，在卷积关注局部细节和自注意力获取全局语境之间找到最优组合。
此外，本文还将Huber LossQ］用作损失函数，其对噪声具有更好的鲁棒性。 神经网络在解决回归问题中，一般采用传统的MSE准则或者MAE准则作为网 络的损失函数，通过反向传播算法更新网络参数。然而这两种准则都有自己的不 足之处，MSE准则受噪声点影响较大，对误差较为敏感，MAE准则的梯度不可 变，且在y~f(x) = 0处不可导，这都不利于模型的收敛和学习。Huber Loss则将 二者结合起来，通过调整超参数在理论上可以融合二者的优点同时消除二者的不 足，具体公式如下：
扣\y-f{x^<8
厶(y-/(x)) = *	.	(3-11)
3\y-f^~82 \y-f{x^>8
其中，3是一个超参数，5的大小决定了 Huber Loss对MSE和MAE的侧重 性，当卩-选择MSE准则，当\y-f(x)\>3,选择MAE准则。
