4.2.2基于SAUNet的语音増强算法
在本小节中，本文提出了一种基于独立自注意机制的单通道语音增强网络 SAUNet,将独立自注意机制嵌入到基于UNet架构的全卷积神经网络中。在上小 节中已经提到，本章目前的工作仅将这种注意力机制用作语音增强模型的独立一 层，与模型中的卷积网络融合，而不是完全替代整个卷积网络，在这独立的一层 中是全注意机制而没有卷积算子的参与，在未来的工作中，可以继续探索完全抛 弃卷积的基于纯粹注意力架构的语音增强模型。本文提出的模型架构如图4-3所 Zj\ O
LN	LN	LN SA Layer	LN	SA l .ayer LN	LN
ELI' EU	ELU	ELI	ELI; ELV
*	编康	>	解码瑤	"
图4-3基于独立自注意机制的语音增强网络SAUNet
与第三章相同，本文将图3-1中基于UNet架构的全卷积神经网络作为骨干 网络，在此之上加入独立自注意机制用作网络的一层，在图4-3用“SA Layer” (Stand Alone Layer)表示。为了方便进行对照试验，同AAUNet保持一致，本 文在编码端的最后三层和解码端的前两层加入独立自注意机制，整个网络将带噪 语音的对数幅度功率谱作为网络的输入，输出的是增强净化后的对数幅度功率谱, 然后将带噪语音的相位信息与增强的对数谱特征相结合，重构出新的干净语音。 本文在模型的最后一层使用线性激活函数，在其他层使用非线性的ELU (exponential linear unit)激活函数。相比于ReLU激活函数，ELU输出的均值在 0附近，更具鲁棒性。二者在x>0时都是比例系数为1的正比例函数，而在虫0 时，ELU函数变为指数形式，在输入为负值的情况下依然有信息输出，Q是可调 节的超参数。ELU激活函数的公式见式(4-9),图像表示见图4-4o
此夕卜，在SAUNet中，本文使用了层标准化函数(LayerNormalization) [54], 在图4-3中用“LN”表示。LN和BN都是一种对输入样本数据做标准化的方法， LN是对同一个输入样本的所有特征做标准化，即在不同通道方向做标准化，而 BN是对所有输入样本的同一特征做标准化，即沿着同一个通道做标准化。LN更
40
多的是用在循环神经网络中，在训练过程中不受批处理大小的影响，而且训练出 的模型更加稳定，本文尝试将其与卷积网络结合用于语音增强技术领域。
图4-4 ELU激活函数图
