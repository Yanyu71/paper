1.2国内外研究现状
语音增强技术是语音分离领域的主要分支，是说话人分离技术的一种特殊情 况。语音增强技术从上世纪六十年代发展至今，已经有六十多年的研究历史，其 中的研究成果从不同的角度来看有许多不同的分类方法。根据语音增强技术所使 用的麦克风数量的不同，可以分为单麦克风（通道）和多麦克风（通道）语音增 强。单麦克风增强技术可以利用语音信号的时域和频域信息，而多麦克风增强技 术还可以实现对空域信息的利用，通过空间分集技术将增强语音从带噪语音中分 离出来，最常使用的是波束成形（Beamfbrming）算法⑴⑵。一般而言，单通道语 音增强问题更具有挑战性⑶⑷。根据语音增强技术是否依赖目标增强语音，可以 分为无监督语音增强和有监督语音增强，根据语音增强技术所采用的基本原理的 不同，可以分为基于数字信号处理的传统语音增强算法和基于机器学习的新兴语 音增强算法。
传统的语音增强技术可以追溯到1978年由Lim等学者提出的Weiner滤波 算法［习，该算法在加性平稳噪声条件下基于最小均方准则设计去噪滤波器，输入 带噪语音信号，输出去噪后的增强语音信号A】。然而，该算法恢复的语音信号会 不可避免地残留一些高斯白噪声，并且在非平稳噪声的条件下无法工作。谱减法 是语音增强领域的另一种经典算法⑺。该算法的思想简单直观，假设背景噪声为 加性干扰且目标语音和噪声信号相互独立，用带噪语音谱减去噪声谱得到目标语 音的频谱，再结合带噪语音的相位信息通过逆傅里叶变换恢复最终干净语音冈。 然而，该算法会因为对噪声的估计不足，出现残余噪声，这种噪声不同于Weiner 滤波中高斯白噪声，其随机频率、幅度以及听觉效果与音乐信号相近，也被叫做 音乐噪声。此后有许多学者对谱减法进行了改进，Paliwal等人于2010年在调制 域上进行了单通道谱减法［9】的探索和研究。上述算法在既定的假设域内可以取得 去噪效果，在真实场景中一旦前提假设不再满足，增强性能将会出现下降。此外 还有基于统计学上最小均方误差（MMSE）的语音增强方法〔I。】，比如基于人耳的 非线性听觉感知特性设计的MMSE对数幅度谱估计器（MMSE log spectral amplitude estimator）〔⑴。然而，基于MMSE准则的方法计算成本偏高，而且受 噪声分布的先验知识影响较大【12〕，在复杂场景下去噪性能会大幅度下降。2001年, Cohen等学者提出了一种适用于非平稳噪声环境的优化修正对数谱振幅估计器
2
(optimally modified log-spectral amplitude estimator, OMLSA)语音增强算法卩习， 2003年作者又提出了一种改进的最小控制递推平均算法(the minimum control recursive average algorithm, IMCRA ) [14],可以用来预测和跟踪噪声信号。据本文 所知，结合了 IMCRA的OMLSA已经获得了传统语音增强算法的最佳性能。
语音增强作为信号处理技术的重要分支，已广泛应用于即时通讯软件IE、电 话会议系统和语音识别系统〔均。基于大数据驱动的机器学习语音增强算法近年 来异军突起，几乎不需要对语音信号和噪声信号做任何假设，克服了传统语音增 强算法的固有缺陷，取得了更优异的去噪水平和泛化能力。一般而言，可以将基 于机器学习的语音增强算法大致归为四类。第一类是基于隐马尔科夫模型 (Hidden Markov Model, HMM)的语音增强算法呵，通过数据训练的方式分别 得到语音和噪声信号的隐马尔科夫模型，然后在分离阶段通过最大化后验概率来 恢复目标语音。2010年，Cooke等人在Ephraim研究成果的基础上又通过训练得 到了各声源信号之间的交互模型，并用于语音分离与识别任务，取得了满意的效 果〔⑻。此外，Veisi等学者在2013年将基于隐马尔科夫模型的语音增强算法扩展 到梅尔域I"】。第二类是基于非负矩阵分解(Non-negative Matrix Factorization, NMF) 的语音增强算法[2°】，该算法假定语音和噪声的幅度谱都可以用各自的一种非负 矩阵来表示，然后通过训练的方法得到上述非负矩阵，并在测试阶段对带噪语音 进行去噪处理，恢复目标语音信号。然而，上述方法没有考虑语音和噪声之间的 相互关系，在实际应用中具有局限性。作为非负矩阵算法的改进和发展，Vu等 人在2016年将非负矩阵和深度神经网络(deep neural networks, DNN)相结合来 实现语音增强和自动语音识别任务，在客观语音质量上取得了显著的改进OH。第 三类是基于浅层神经网络的语音增强算法，1994年Xie等学者将带噪语音的对 数功率谱特征输入到人工神经网络中进行训练，输出增强后的对数功率谱a〕。该 类算法受限于当时计算机运算能力的不足，不能在训练数据量和网络规模上实现 突破，因此并未获得良好的性能，没能撼动传统语音增强算法当时的主流地位， 之后对于神经网络的相关研究便基本陷入了停滞。直到2006年出现了转折点， Hinton等学者提出的受限玻尔兹曼机(Restricted Boltzmann Machine RBM)逐层 训练策略[23〕为构建深层的神经网络指明了研究方向。后来随着计算机运算能力 的日益强大，在语音领域掀起了一股基于深度学习的研究热潮，各种用于语音信 号处理的深度学习模型不断出现，也不断刷新着模型的性能上限，由此出现了第 四类基于深度学习的语音增强算法。
2014年，徐勇等学者设计出基于深度神经网络的语音增强模型【24〕，将带噪 语音的对数功率谱作为网络的输入，采用全局方差均衡和噪声感知训练技术提升 网络的泛化能力，通过输入多帧对数功率谱来预测中间一帧的对数功率谱，然后
3
结合带噪语音的相位恢复增强后的语音波形，在100多种噪声条件下验证了模型 的去噪性能。在之后的研究[⑹中又提出了多目标学习DNN模型，基于对数功率 谱，梅尔倒谱系数和理想二值掩蔽来训练DNN模型，实验证明相比于原来的单 一特征训练，模型将具有更好的去噪性能和泛化能力。然而，DNN其实并不擅 长处理语音增强等时间序列建模的问题，其自身结构决定了增强性能的上限无法 突破，因此在语音领域出现了对循环神经网络(recurrent neural networks, RNN) 的研究，特别是RNN的一种常用架构 长短时记忆网络(long short-term memory, LSTM)O 2016年，Kolboek等学者提出了一种基于深度循环神经网络 (DRNN)的语音增强算法，用于噪声鲁棒的说话人验证，在噪声环境下使用基于 DRNN的LSTM语音增强前端进行测试以】。2017年，Sun等学者提出了一种基 于LSTM-RNN的多目标深度学习语音增强算法，在不可见噪声条件下进行的实 验表明，所提出的框架能够持续显著地提高语音质量和清晰度两种客观指标[27〕。 然而，基于RNN的语音增强模型训练时间过长，参数量过大，更容易出现梯度 消失的问题，不符合模型轻量化和实时化的发展趋势。近年来，生成对抗网络
(generative adversarial networks, GAN)在图像生成领域获得巨大成功，一些学 者开始将GAN应用到语音增强领域上来。GAN由生成器和鉴别器两部分组成， 生成器用于产生与训练数据有相同分布的数据，鉴别器用来判断生成器产生的数 据是否达到真实分布，双方在博弈之中逐渐达到纳什均衡，此时生成器的输出就 是真实数据。2017年，Pascual等人提出了基于生成对抗网络的语音增强算法 SEGAN【28],通过生成对抗训练来学习带噪语音到纯净语音的非线性映射。2019 年，叶帅帅等人提出了一种端到端的基于Wasserstein生成对抗网络(SEWGAN) 的语音增强方法〔29],其生成器和鉴别器分别为全卷积神经网络(fully convolutional neural networks, FCN )和深度神经网络，并基于 Wasserstein 距离利 用多种噪声类型和信噪比对SEWGAN进行训练，在真实场景中具有一定的泛化 能力。然而基于博弈思想的语音增强模型容易发生训练崩溃的问题，且模型的语 音增强能力与其他深度学习网络相比也不具备明显的优越性。
卷积神经网络(convolutional neural networks, CNN)中的计算可以并彳亍进 行，其独特的局部感知和权重共享特性能够有效地捕捉语音信号的局部细节，引 起了研究人员的广泛关注。2017年，Park等学者用卷积层代替了卷积神经网络 中的全连接层，提出了一种基于幅度谱语音增强的冗余卷积编解码网络 (redundant convolutional encoder-decoder network. RCED) [30h 通过输入多帧对 数功率谱预测最后一帧对数功率谱的方式实现从带噪语音到干净语音的非线性 映射，最后结合带噪语音相位，通过逆傅里叶变换得到目标语音波形。然而，作 者并未进行泛化性能的测试。2018年，Ashutosh等学者提出了一种新的时域监
4
督学习语音增强框架⑶],使用频域的损失函数来训练时域的卷积神经网络，适用 于需要频谱映射或时频掩蔽的语音处理任务。2019年，Gautam等学者提出了一 种基于多目标学习卷积神经网络的语音增强技术，能够在智能手机上实时运行 [朝，该方法将带噪语音信号的对数功率谱和梅尔频谱作为主要特征和辅助特征, 使用基于映射的卷积神经网络从带噪语音频谱中去除噪声。此外Fu等人提出了 一种基于端到端的全卷积网络语音增强框架mi,把短时客观可懂度[34](short-time objective intelligibility, STOI)作为模型的损失函数，将整段语音作为网络的输入, 无需考虑复杂的预处理和后处理过程，克服了基于频谱映射的方法忽略了相位的 情况。然而，由于卷积运算本身具有局部性，上述基于CNN的方法很难捕捉到 语音信号的全局上下文，限制了模型进一步提升语音增强的性能。此外还有关于 结合多种神经网络的研究，最典型的例子是卷积循环神经网络(convolutional- recurrent neural networks, CRNN) [35][36] o
注意机制是捕获远程上下文信息的重要发展，在机器翻译a】、图像分类和目 标检测Sim]等问题中得到了广泛的应用，可以在许多场景下作为RNN的代替。 据本文所知，注意力机制在语音领域的应用还较少，目前的方法主要是通过门控 机制或加法操作来重新校准原有特征。2019年，Hao等人将传统的注意力机制与 LSTM相结合，生成带噪语音谱的掩蔽值(mask)【呦；2020年，Lan等人在冗余 卷积编解码网络(RCED)中引入了挤压-激励机制(squeezing-and-excitation mechanism),帮助模型聚焦有用信息，抑制无用的信息刚；Dou等人将自注意力 机制与RDL[42] (residual-dense lattice)网络结合起来用于单通道时域语音增强问。 上述基于注意力机制的语音增强方法均提升了原有架构的增强性能，获得了较好 去噪能力。
