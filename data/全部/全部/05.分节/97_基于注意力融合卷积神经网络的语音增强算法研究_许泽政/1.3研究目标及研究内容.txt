1.3研究目标及研究内容
本文的研究目标是在充分分析语音信号声学特征、噪声信号统计特性的基础 上，通过注意力机制来提升全卷积神经网络学习输入信号全局语境的能力，帮助 卷积网络捕获有用特征，抑制冗余特征。在只增加少量网络参数的前提下提升原 有卷积模型的语音增强性能，能够在低信噪比和非平稳噪声条件下消除带噪语音 中的噪声干扰，还原出纯净的人声信号，在短时客观可懂度(STOI)和语音质量 感知评价(perceptual evaluation of speech quality, PESQ)删等指标上取得优异表 现。语音增强技术的研究领域可以分为单通道语音增强和多通道语音增强两个方 向，其中单通道语音增强由于缺少丰富的空间信息使得对纯净语音信号的恢复更 加困难。基于此，本文将主要研究加性噪声条件下的单通道语音增强问题。
本文的主要研究内容如下：
5
首先阐述了卷积神经网络的基本原理。对卷积运算，感受域，卷积核，通道 数，池化操作进行了介绍分析，并由此引出一个经典卷积网络的示例。接着介绍 了近期计算机视觉中流行的注意力机制，对硬注意力，软注意力，全局注意力， 局部注意力以及自我注意力原理进行了研究分析。
其次，在卷积网络和注意力机制的基础上，对基于UNet架构的全卷积神经 网络进行了详细的阐述，本文也将UNet作为骨干网络。受谷歌大脑团队启发, 本文仔细研究了一种新的二维相对自注意机制，这种机制在自注意力基础上将输 入数据维度扩展至二维，并加入了相对位置编码方案，在图像识别和目标检测中 已经被证明是十分有效的。在此基础上，本文提出了一种注意力强化全卷积神经 网络AAUNet,将二维相对自注意机制应用到全卷积网络中，具体做法是将卷积 运算与注意力机制产生的输出在通道方向拼接起来生成新的特征图，通过调整注 意力通道所占的比例，可以在卷积关注局部细节和自注意力获取全局语境之间找 到最优组合。在实验中本文采用Huber Loss作为模型的损失函数，结合了 L1和 L2损失函数的优点，对噪声具有较好的鲁棒性，可以使网络模型更快地收敛。
最后，针对AAUNet在实验中存在的问题——当自注意力机制的通道数占 比为100%,即全注意力机制时语音增强的性能出现下降，本文又提出了一种基 于独立自注意机制的语音增强模型SAUNet,相比于二维相对自注意机制，独立 自注意机制可以自由设置运算区域的大小，并通过多值矩阵提升基于距离的感知 能力，只需要增加少量的网络参数，就可以在语音质量、可懂度和未知噪声抑制 等方面获得显著的性能提升。为了验证模型的有效性，本文选取了语音质量感知 评价(PESQ),短时客观可懂度(STOI),信号失真(SIG)的复合测度，噪声失 真(BAK)的复合测度以及整体语音质量(OVL)的复合测度这5种指标用作评 估方式，评估模型性能。
