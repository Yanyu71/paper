3.3.1数据预娅及实验配置
在本论文中，本文选用TIMIT语料库作为语音数据集。TIMIT语料库是目 前语音识别、语音分离与增强领域常用的英文数据集，它取样于630位来自美国 八个不同自治州的说话人，大部分为成年男性，每人说同样的10句话，共6300 条句子，规定其中462人说的话用作训练集，剩下的作为测试集，所有语音的采 样频率为16kHz,长度不一。在本实验中，本文随机打乱TIMIT语料库，并取其 中的4620句话用作语音训练集，又随机选择了另外200条不在训练集中的句子 作为语音测试集。为了保证训练效果的同时减少训练的数据量，本文将所有的原
20 始语音统一切割成2秒，并将其下采样到8kHz,这样便减小了一半的数据量。 与此同时，为了最大限度克服静默段对训练结果的影响，本文使用语音活动检测 （VAD）算法去除了所有语音的开始和结束部分的静默帧。本文选用NOISEX- 92噪声库来模拟现实场景中真实存在的噪声环境oNOISEX-92噪声库是1990年 由欧洲相关语音研究所采集自现实生活中的15种不同种类的噪声，所有噪声的 采样频率统一为19.98kHz,时长为235秒。所以为了与语音数据集匹配，本文需 要对其进行重新处理，包括音频切割，重采样等操作。本文从中选择了 4种不同 类型的噪声作为训练噪声，分别为白噪声（white）、工厂噪声1 （fkctoryl）、坦克 内部噪声（ml09）以及F16座舱噪声（fl6）。此外，为了验证模型的泛化能力， 本文选择了另外2种失配的噪声类型作为测试噪声，分别是粉红噪声（pink）和 工厂噪声2 （factory2）0下面本文将具体阐述训练集和测试集的构造过程。
对于训练集，本文将选取的TIMIT语料库中的4620句话，在-2.5dB、OdB、 2.5dB、7.5dB和12.5dB这五种信噪比条件下，与NOISEX-92噪声库中的4种背 景噪声（white、factory 1> ml09和fl6）混合，合成具有4种噪声类型和5种信 噪比水平的训练集，即4620X4X5=92400条带噪语音。此外，本文又随机选取 训练集数据中的20%作为验证集，以防止网络训练时发生过拟合现象。在测试集 中，本文加入了不匹配的噪声和不匹配的信噪比来衡量模型的泛化性能，把选取 的两种失配的噪音类型（pink和短ctory2）在一种匹配的信噪比水平（OdB）和三 种不匹配的信噪比水平（-5dB、5dB和10dB）上对另外200条纯净语音进行一 对一随机破坏，合成200条带噪语音测试集。最后，本文将使用短时傅里叶算法 对所有语音进行时域到时频域的变换，得到可输入网络的数据。本文用长度为 32ms （256点）的汉明窗，16ms （128点）的重叠移动，即50%的overlap对语 音波形进行分帧加窗，随后进行256点的短时傅里叶变换，得到语音信号的复数 频谱特征，提出其中的幅度谱特征，并取其对称的一半（129点）特征数据，再 平方取对数后得到语音信号的对数功率谱，就得到了本文输入到网络模型中的特 征数据。
网络模型的输入和输出都是124点时间帧，129维频率点的二维对数功率谱 特征。模型主要由14个卷积层组成，卷积核的大小为3X3,卷积步长的大小为 1X2,每个卷积层的通道数依次为 8-16-32-64-128-128-256-256-128-128- 64-32- 16-1,每一层的时间维度通过补零填充操作保持不变。在编码端的最后三层和在 解码端的前两层上执行注意力强化卷积操作。注意力头的数量为2,注意力通道 数占当前层所有通道数的比例是25%,即JV</C = 0.25,并取dg/k=dv,注意力 机制内的卷积核的大小为3X3,卷积步长的大小是1X1。在训练阶段，本文使 用Adam优化器进行模型的训练，并将初始学习率设置为0.005, 0严0.9,
21
02 = 0.999 , £ = l.Oe-8 o根据经验，本文将Huber Loss的超参数设置为8。epoch 的数量设置为15, mini-batch的大小设置为10。当验证集的损失超过2个epochs 之后不再下降时，本文使用学习率衰减策略将学习速率减少一半，最小至l.Oe"。 需要指出的是，上述网络模型参数设置以及训练策略在下一小节的实验中通用， 当涉及到控制变量实验时，如需微调上述参量，在实验开始部分会给出说明。
本文采用最佳修正对数功率谱估计器(OMLSA)结合最小控制迭代平均 (IMCRA)算法、UNet全卷积神经网络与本文提出的AAUNet进行性能比较。 此外，为了验证二维相对自注意机制在卷积网络中的通用性，本文将其融合到其 他的卷积网络(CED)中进行实验。CED网络也是一种编解码网络，主要有三点 不同：第一，通道数量不同，每层的通道数量依次为16-32-64-128-256-512-126- 128-64-32-16-1；第二，跳跃连接为融合相加而不是特征拼接；第三，损失函数采 用MSE准则，其他条件与本文提出的模型相同。
