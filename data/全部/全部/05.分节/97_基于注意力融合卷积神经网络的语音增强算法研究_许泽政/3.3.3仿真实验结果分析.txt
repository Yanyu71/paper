3.3.3仿真实验结果分析
在3.2节中已经详细阐述了注意力强化全卷积神经网络的基本原理以及实现 方法，本小节将通过消融实验、对比试验来检验所提出语音增强网络模型的整体 性能和泛化能力。本小节中得到的所有结果均为各自在测试集上得到的平均值, 与训练集的数据结果无关。下面本文将进行具体的实验结果分析。
保证算法的收敛性是其他所有仿真实验的基础，在此基础上讨论算法的性能 才有意义，因此本实验将对所提出的AAUNet语音增强算法的收敛性进行测试。 结果如下图所示：
迭代欢數
图3-5 AAUNet语音增强算法收敛图
上图表示的是AAUNet语音增强算法的收敛性曲线。横坐标代表训练的轮 数epochs,这里一共训练了 40轮。纵坐标代表损失函数(HuberLoss)的值。可 以看到，在开始的几个训练轮数下网络收敛较快，在整体上随着训练轮数的增加, 网络的损失值逐渐下降，最终达到收敛状态。虽然在第17个epoch之前，损失 值呈震荡状态，并在第15个epoch ±呈现出较大误差，但在整体趋势上整个网 络的训练仍是收敛的。由此可见，本文提出的注意力强化全卷积神经网络 AAUNet的收敛性是有所保证的。
本组消融实验将探究AAUNet在是否嵌入相对位置信息的条件下，注意力 通道数在整个通道所占比例对网络模型整体性能的影响。信噪比水平为-5dB,这 里选择PESQ和STOI作为评估指标，AAUNet分为有位置信息(position)和无
位置信息(no-position)两种模型，每种模型的注意力通道数所占比例又包含5 种可能(0, 25%, 50%, 75%, 100%),其中“0”表示不进行注意力强化卷积操 作，是常规的UNet网络，100%表示全注意力通道，即没有卷积通道。综上，本 组实验一共测试了 10种AAUNet网络模型，具体结果如下图所示：
;1 .G !J)也逍数
图3-6 PESQ与注意力通道比例的关系
图3-6表示PESQ与注意力通道所占比例的关系。纵轴表示PESQ分值，得 分范围为-0.5〜4.5分，横轴表示通道比例系数。图中共有两组曲线，分别表示有 相对位置信息嵌入(position)和没有相对位置信息嵌入(no-position)的情况。 从图中本文可以观察到，对于有位置信息嵌入的情况，当注意力通道数比例为25% 时，也就是注意力通道数与卷积通道数的比例为1： 3时，PESQ分数达到最大 值，当注意力通道比例继续增加时，PESQ分数逐渐减小，表示网络模型的性能 呈下降趋势，说明注意力通道数并不是占比越高越好。对于没有位置信息嵌入的 情况，PESQ分数随着注意力通道数比例的提高而提高，在75%占比的情况下达 到最大值，全注意力模型仍旧没有达到最好的性能。但二者相较于原始的UNet, 模型的性能已经有了较为明显的提升。纵向比较，没有位置信息嵌入的模型在注 意力通道占比75%的情况下取得了最优的性能，这表明输入特征图中隐藏神经 元之间的位置信息对语音增强性能的提升并不是不可或缺的，此外也可以发现， 二维相对自注意机制只有和卷积操作结合时才能发挥更好的性能，全注意力模型 并不是最优解。
图3-7表示STOI与注意力通道所占比例的关系。纵轴表示STOI分值，得 分范围为0〜1分，横轴表示通道比例系数。从图中本文可以观察到，对于有位置 信息嵌入的情况，当注意力通道数比例为25%时，STOI分数得到最大值，当注 意力通道比例继续增加时，STOI分数逐渐减小。对于没有位置信息嵌入的情况，
24
STOI分数在75%占比的情况下得到最大值，但二者相较于原始的UNet,随着通 道数比例的增加，在整体上呈现下降趋势，这表明即使在position with25%和noposition with 75% 情况下，模型的STOI分数得到提高，但二维相对自注意机制对 语音增强性能的影响并不总是正向的，在全注意力情况下STOI分数甚至有了明 显的下降。也由此可见，语音信号的质量和可懂度之间并不是正向的关系，语音 质量的提高并不意味着可懂度的提高，在设计系统性能时应作出权衡。
注邈力適道数
图3-7 STOI与注意力通道比例的关系
本组消融实验将探究AAUNet在是否嵌入相对位置信息的条件下，注意力 头的数量对网络模型整体性能的影响。信噪比水平为5dB,这里选择SIG和BAK 作为评估指标，AAUNet分为有位置信息(position)和无位置信息(no-position) 两种模型，每种模型的注意力头数有4种可能(1, 2, 4, 8)„综上，本组实验 一共测试了 8种AAUNet网络模型，具体结果如下图所示。
图3-8表示SIG与注意力头数量的关系。纵轴表示SIG分值，得分范围为 1~5分，横轴表示注意力头的数量。图中共有两组曲线，本文可以从中观察到， 对于有位置信息嵌入(position)的情况，随着注意力头数量的增加，SIG分数逐 渐提高，在注意力头数量为8个头时达到最大值，表明二者是呈正相关的，带有 位置信息的注意力头数量对目标语音的质量有积极的作用。值得注意的是，8个 头相比于4个头的情况，SIG分数只有是有略微的提高，但却要付出较高的计算 成本，相比之下，4个头的注意力机制或许是更好的选择。对于没有位置信息嵌 入的情况(no-position),除了注意力头数为2时SIG分数出现了下降，其他情况 可与嵌入位置信息的得分相差无几，再一次表明在语音增强领域上，注意力机制 会带来性能的提升，但是否嵌入隐藏神经元之间的位置信息是不重要的。纵向上
25
来看，两条曲线都在注意力头为4的情况下取得了较好的SIG分数，本文将其设 置为模型的最佳参数。
注意力头数
图3-8 SIG与注意力头数量的关系
图3-9表示BAK与注意力头数量的关系。纵轴表示BAK分值，得分范围为 1〜5分，横轴表示注意力头的数量。两组曲线从整体来看，除了注意力头为2的 情况，没有位置信息嵌入的模型要全面好于有位置信息嵌入的模型，在每个注意 力头（1, 4, 8）的条件下都获得了更高的BAK分数，这表明对噪声的抑制能力 更加出色。两条曲线都在注意力头为8时达到了 BAK的最佳值，但同样，相比 于注意力头为4时未有较大的提升，表明注意力头为4仍是模型兼顾性能和计算 参量的最优解。
注意力头数
图3-9 BAK与注意力头数量的关系
26
表3-1 OVL与注意力头数量的关系
position
no-position
表3-1表示整体语音质量OVL在四种信噪比(-5dB, OdB, 5dB和10dB)条 件下与注意力头数量(1,2, 4, 8)之间的关系，又分为有相对位置信息(position) 和没有相对位置信息(no-position)两种情况。从整体上来看，no-position的整体 语音质量得分仍普遍好于position的得分情况，同样，在注意力头为8时双方都 取得了各自的平均最优值，然而相对于注意力头为4的情况，得分到的提升并不 明显，但在四种信噪比条件下，注意力头为4和8的得分要明显好于1和2的情 况。综上，本组实验得出的结论为：带有4个注意力头的不嵌入相对位置信息的 注意力强化卷积网络模型，在兼顾计算参量的情况下可以获得语音增强性能的最 优值。
(a)	跳跃连接
图3-10两种拼接型特征图的跳跃连接方式
(a)注意力强化特征图跳跃连接；(b)原始卷积特征图与注意力强化特征图分别跳跃连接 本组消融实验将探究AAUNet在是否嵌入相对位置信息的条件下，特征图 的跳跃连接方式对AAUNet语音增强性能的影响。信噪比水平为OdB,这里选择 PESQ, STOI, SIG和BAK作为评估指标，AAUNet本身采用了特征图拼接的方 法，在此基础下又有两种特征图的跳跃连接方式，一种是只对注意力强化的特征 图进行跳跃连接(aat skip-pos, aat skip-np),另一种是将原始卷积特征图和注意 力强化特征图分别进行跳跃连接操作(Conv-att skip-pos, Conv-att skip-np ),具体 如图3-10所示，各自又分为有位置信息和没有位置信息两种情况，所以本组实 验一共测试了 4种AAUNet网络模型，具体结果如图3-11所示。
图3-11 4种跳跃连接模式在4类指标上的平均得分
图3-11表示4种特征图的跳跃连接模式在4类指标上的平均得分。横轴表 示4类评估指标，纵轴表示4类指标的得分范围，"aatskip-pos”表示带位置信息 的注意力强化特征图跳跃连接方式，“aat skip-np”则表示不嵌入相对位置信息。 “Conv-att skip-pos”表示带位置信息的原始卷积与注意力强化特征图分别跳跃 连接的拼接方式，“Conv-attskip-np”则表示不嵌入相对位置信息。对于注意力图 跳跃的拼接方式，带位置信息的模型在四种指标上的得分普遍高于不带位置信息 的模型，而对于原始卷积与注意力强化特征图分别跳跃连接的拼接方式来说刚好 相反。从整体上来看，四种模型的PESQ、STOI、SIG、BAK得分相比于带噪语 音(noisy)的得分均有明显的提高，而Conv-att skip-np模型不论在语音质量、 清晰度以及噪声抑制能力上均取得了最高的分数，表明不嵌入位置信息的原始卷 积与注意力强化特征图分别跳跃连接的拼接方式可以取得较优的语音增强性能。 在 STOI 指标上，Conv-att skip-np 的得分为 0.8328, Conv-att skip-pos 的得分为 0.8228,四种模型的得分相差无几，这表明它们对带噪语音语音可懂度(0.7201) 的提高能力是近乎相同的。
本组对比实验将探究AAUNet分别使用三种损失函数用作训练的条件下， 检验模型的收敛性以及对语音增强性能的影响。本组实验在信噪比水平为-5dB 条件下进行，选择PESQ、STOI、SIG作为评估指标，本组实验一共测试了 3种 AAUNet网络模型，它们之间仅在训练时的损失函数不同，其他所有参数均保持 一致。3种模型的收敛性如图3-12所示，对语音增强性能的影响如图3-13所示。
图3-12表示三种损失函数(MSE, MAE, Huber Loss)的收敛曲线图。纵轴 表示损失值大小，横轴代表训练的轮数。从图中本文可以观察到，单从收敛性上 看,结合了 MSE和MAE优点的Huber Loss具有更快的收敛速度，相比于MSE,
28
Huber Loss对异常点（epoch=15）的鲁棒性更强，同时又克服了 MAE在零点不 可导的缺点。综上，三者的收敛性在模型的训练中均有保证，但H uber Loss的收 敛性更好，且对异常值不会过于敏感，在训练过程中的表现优于前者。
图3-13 3种损失函数在3类指标上的平均得分
图3-13表示在-5dB信噪比水平下，上述3种损失函数训练的模型在3类指 标（PESQ,STOI,SIG）上的平均得分，从测试的角度对3种损失函数进行评价。 纵轴代表评估分数，横轴代表3种评价指标，同时附上了三种损失函数的平均得 分数据表。从整体来看，3种损失函数训练的模型，相对于带噪语音（noisy）而 言，在STOI得分，PESQ得分以及SIG得分上均有明显的提升，表明它们具备 恢复带噪语音质量，提升语音可懂度的能力。仅比较三种损失函数，从分值上来 看，Huber Loss在PESQ和STOI指标上取得了略高的分数，MSE在SIG指标上
29 取得了略高的分数，Huber Loss次之。但其实对于人耳来说，是无法在恢复的目 标语音中分辨出三者的区别的。最后需要指出的是，由于Huber Loss的超参数是 基于次优的经验值设置的，有一定主观误差性，如果采用网格搜索法找到最优的 超参数，本文相信Huber Loss在收敛性和去噪能力上仍会有进一步提升的空间。 333.6增强语音波形及其语谱图分析对比
本组实验给出了经过AAUNet网络模型增强后的一条语音时域波形图，以 便更加直观地观察语音增强后的效果，同时给出了对应的对数功率谱，并与UNet 进行纵向对比，以探究经过注意力机制强化后的卷积网络相比于原模型有哪些方 面的改善。
图3-14AAUnet增强后的语音时域波形图
图3-14展示了测试集中的两条条语音，在OdB信噪比水平下被噪声破坏的 带噪语音的恢复情况。图中共有六条语音时域波形，最左侧两条波形为被噪声破 坏的带噪语音，中间两条是取自TIMIT语料库中的原始干净语音，最右侧是经 过AAUnet去噪后的两条增强语音。所有语音已经提前切割成2秒，下采样到 8kHz,通过VAD算法去除了开始和结束的静默帧。从图中可以十分直观的看到， 和带噪语音相比，增强语音在语音活动单元已经得到了很好的恢复，成功抑制了 大部分的背景噪声，不过在静默段仍有微弱的噪声残留，但己经不会影响整体的 语音听觉质量。
图3-15展示了一条在OdB低信噪比水平下被“工厂2”噪声破坏后的测试 语音的4种对数功率谱。（a）图表示该条测试语音的带噪对数功率谱，（b）图表示 该条测试语音的纯净对数功率谱，（c）图表示该条测试语音经UNet网络去噪后的
30
增强对数功率谱,(d)图表示该条测试语音经AAUNet去噪后的增强对数功率谱。 对数功率谱的横轴代表时间，纵轴代表频率，从图中可以看到，相比于带噪功率 谱，两种语音增强网络均较好地恢复了目标对数谱。相比于UNet, AAUNet在 细节方面更好地还原了测试语音的特征谱，特别是在图中被矩形框标出的部分。
图3-15 一条测试语音的4种对数功率谱对比
在本组实验中，本文将对不同的语音增强算法的整体性能进行对比与分析, 一共选取了 5种语音增强算法，包括OMLSA-IMCRA, UNet, AAUNet, CED和 AACEDo其中OMLSA-IMCRA是传统单通道语音增强的最佳算法，在下述实验 中将用简称OMLSA表示。选择另一种全卷积编解码网络CED的目的是为了验 证二维相对自注意机制对卷积网络增强效果的通用性。本组实验一共在2种不可 见噪声和4种信噪比(-5dB, OdB, 5dB, 10dB)条件下进行，覆盖了从极低信 噪比到高信噪比的常见范围，其中除了 OdB外其他三种均属于不可见信噪比。网 络的参数配置详见3.3.1节，5种算法的具体对比分析如下表所示。
表3-2表示含噪语音及3种不同增强算法(OMLSA, UNet, AAUNet)在4 种信噪比水平下SIG, BAK和OVL的平均得分。本组实验旨在进行模型的横向 对比和纵向对比，验证所提出模型AAUNet的语音增强性能。从表格中本文可以 看到，在所有信噪比水平下，AAUnet在三个指标上的得分都超过了 OMLSA和 Unet,而且远远超过了 OMLSA传统算法。只看纵向实验，在语音失真SIG方 面，AAUnet比带噪语音和经Unet增强后的语音分数分别高出30.0%和4.7%, 在抑制背景噪声BAK方面，AAUnet的分数则分别提高了约43.1%和4.6%,对
31 于最后整体处理后的语音质量OVL,AAUnet得分则比带噪语音得分高出33.6%, 比UNet得分高出4.4%o实验结果表明，基于注意力强化卷积的语音增强算法 AAUNet对未知信噪比和背景噪声具有更好的泛化能力，可以更好地平衡噪声抑 制和语音失真，具有较好的语音处理质量。本文提出的网络模型只需要增加少量 的训练参数就可以获得去噪能力的提升，取得了比所有对比算法更好的性能。
表3-2含噪语音及不同增强算法在4种信噪比下的SIG, BAK和OVL得分
SIG
BAK
OVL
noisy
OMLSA
Unet
AAUnet
noisy
OMLSA
Unet
AAUnet
noisy
OMLSA
Unet
AAUnet
-5
表3-3含噪语音及不同增强算法在4种信噪比下的PESQ和STOI得分
标
PESQ
STOI
noisy
OMLSA
CED
AACED
Unet
AAUnet
noisy
OMLSA
CED
AACED
Unet
AAUnet
-5
表3-3表示含噪语音及5种不同的语音增强方法在4种信噪比下的PESQ和 STOI平均得分。从表中可以看出，在可见信噪比（OdB）和不可见信噪比（-5dB、 5dB、10dB）的情况下，本文提出的算法模型AAUnet对平稳噪声和非平稳噪声 的抑制能力超过了所有其他方法。AAUnet的平均PESQ和STOI评分与带噪语 音相比分别提高了 28.3%和11.1%,与0MLSA相比分别提高了 18.0%和18.6%, 与Unet相比分别提高了 4.0%和1.6%。另外，通过比较CED网络和AACED网 络（AACED是CED经过注意力强化后的网络模型）的两项评估指标的得分，可 以证明注意力强化卷积模块（AABlock）可以作为一种插件集成到其他卷积网络 中，从而提高模型的整体性能。本文还注意到，与CED相比，UNet的PESQ得 分更高，而STOI得分稍低，而当两者都通过注意力强化后，AAUNet的STOI得 分已经完全超过了 AACED,这表明本文提出的网络模型在语音可懂度方面有着 更好的表现。
