1.1研究背景
随着信息技术的发展，近年来，由智能手机、相机等移动设备产生的多媒体 数据呈爆炸式增长，大量的多媒体数据被用户产生与消耗。各种购物网站、视频 网站、社交网站、论坛等利用这些数据为用户提供更优质的服务，用户在获取信 息的同时也在分享着自己的数据。据统计，截止到2013年，社交网站Facebook 每天平均上传的图片数量在3.5亿张以上，YouTube每分钟上传的视频时长超过 100小时〔I Twitter每天的博文发表数量也超过L4亿条。这些由用户产生的多 媒体数据并不是孤立存在的，呈现明显社交化的特性。一方面不同类型的多媒体 数据经常依赖共存，共同表达相同的语义;本文中,将这种具有相同语义的文本、 图片、视频等不同模态的数据称为“跨模态数据”。另一方面这些数据与用户紧 密连接，形成复杂的社会交互。比如：图像分享网站中用户分享图像的同时会配 些文字加以说明，视频分享网站中视频大多伴有声音信息且经常伴有用户的评论 与分享等信息。
面对海量复杂的多媒体数据，高、精、准地检索出有价值的信息，对提升人 们的学习与工作效率具有十分重要的意义。目前，大多数信息检索都采用基于文 本或人工标注的方式，将复杂的多媒体用统一的文本进行表示，但随着多媒体的 不断爆炸式的增长，人工标注多媒体耗费大量的人力物力，而且人工标注不能有 效表示复杂的语义，很难取得令人满意的结果。为了解决人工标注存在的问题， 一些研究开始利用相关算法自动生成文本描述，但是目前算法的准确性仍存在一 定问题。因此，基于内容的多媒体检索研究成为该领域的研究热点。目前基于内 容的多媒体检索研究大多针对单一模态的数据，无法满足不断增长的用户需求。 有时候用户希望通过输入一张图片，希望检索到与图片相关的视频等，或者输入 一段音频检索出描述音频的文字，这种跨模态的检索是一种基于内容的面向多种 媒体检索方式，即利用一种模态的信息检索出与之相关的其他模态信息。例如： 购物网站中，用户可以通过输入商品的图像检索到该商品的相关信息；或者通过 输入一些图像，匹配到一些相应的音乐，以满足用户的娱乐需求。
近些年，跨模态检索受到了学术界的广泛关注，相关研究大多针对跨模态数 据间的关联展开的，利用数据间的共存与互补特性，研究跨模态数据的语义理解 与关联表达等。但现有研究的跨模态检索仍然很难得到用户满意的结果，主要有 两方面的原因。一方面，数据的有效表达是跨模态检索的基础，由于语义鸿沟[2] 的存在，计算机提取的形状、颜色、纹理等特征不能有效映射到人类所理解的高
层语义上。同时，不同模态数据的底层特征处于不同的空间中，仅仅利用数据中 简单的共存与互补关系，很难有效捕捉数据的本质结构，也就不能有效提取不同 模态数据的关联特征表达，解决存在的异构鸿沟问题。另一方面，现有研究缺乏 对用户查询意图的理解，查询结果不能满足用户个性化的需求。
用户与数据越来越复杂紧密的社会交互，给跨模态检索带来了一定的机遇与 挑战。对于跨模态数据来说，感知相关的社交信息，利用模态内与模态间的社交 关联可以增强数据的语义关联，进而提高数据的关联特征表达，有效弥补数据间 的异构鸿沟；对于用户而言，感知社交媒体中的行为信息，构建用户画像与社交 图谱，可以更好的理解用户的兴趣爱好，以便为用户提供个性化的服务。因此， 本论文在跨模态检索中引入“社交感知”这一计算范式⑶，一方面，可以提高跨 模态数据的关联表达，更好的挖掘跨模态数据之间的关联；另一方面，可以准确 理解用户的长期兴趣，为用户提供个性化的服务。然而，相应的数据分析处理并 不容易，存在着以下几点挑战：
•关系复杂多样：随着信息技术的发展，用户可以随时随地产生与消耗数 据，用户与数据、用户与用户以及数据与数据间存在着多种多样的关联 关系，比如：用户与数据间的上传、分享等关系，用户之间的好友关系， 跨模态数据之间的时间、空间以及内容关系（如数据间的依赖共存关系） 等等；有效利用存在的关联关系，可以提高对数据以及用户的分析与理 解。
•数据异构：作为信息的载体，数据通常以文本、图像、音频、视频等不 同媒体形式呈现，不同形式的数据经常表达了相同的语义，但处于不同 的特征空间中。如何解决不同模态数据的空间异构问题，是一项非常具 有挑战的工作。具体来说，本文中不同模态数据的异构性，体现在两个 方面：一方面是如何计算处于异构空间中不同模态数据间的相似性，实 现跨模态检索；另一方面是如何有效融合异构模态的数据，来挖掘用户 的兴趣。
•数据噪声大：用户产生的数据质量较差，不同的用户产生的数据也不同， 比如，图像的拍摄角度、亮度等。即使对相同图像，不同用户也有着不 同的描述，而且用户发布的文本经常不能表达相应的图像或视频。此外， 一般文本模态具有较高层次的语义特性，然而图像或视频中含有大量的 冗余信息，不能有效表达语义含义。这种低质量的数据给相应的处理与 分析带来巨大挑战。
数据的关联复杂、异构、噪声大等挑战，也给相应的分析与处理提出了更高 的要求。因此,跨模态检索不仅具有巨大的学术价值,而且具有潜在的商业价值。
本研究依托于北京市教育委员会的科学研究与研究生培养共建的科研项目一一 基于社交感知的跨媒体数据分析与挖掘研究。对于跨模态的检索研究以及个性化 用户需求的理解也已经成为计算机领域的研究热点问题，相关的研究成果有助于 提升人们对多媒体内容的个性化需求，具有非常重要的现实意义。
