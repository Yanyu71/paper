2.4.1高斯图结构学习
高斯图结构的基木模型是假设观察样本服从均值为山协方差为£的多元高斯 分布[241, X = (X1…Xp)〜这个模型也包含高斯线性模型，比如，X1是 响应变量，Xk(2 WkSp)是预测变量。假设£非奇异，且条件独、九£的分布以 方便的表示成•个图模型G = (V,E),如果I1的第ij个兀素是0,那么变吊:”j变 最/条件独立。令。= £-i, S是经验协方差矩阵，这个问题的最大似然函数对数 形式：
log det® - tr(S。)-	(2-5)
假设均值H已知。0T是非负定矩阵，tr是矩阵的秩，II创11是k范数,即£T中每 个元素的绝对值之和。
公式(2-5)是凸问题，已知均值日下的高斯最大对数似然，只需考虑£或XT, 令亚是£的估计值，使用块坐标下降法，通过优化W的每一行和对应的列来求 解问题。分割W和S：
必2的解满足：
%2 = argmin{yTW#v： ||y - sRL < p]	(2-7)
y
这是一个箱约束二次规划问题(QP),可以用内点法来解决，置换行和列，那么 目标列总是在最后，对于每一列在每个阶段更新W的估计值，重复操作指导收 敛。使用凸对偶，公式(2-7)的原优化问题可以写成对偶问题：
1	2
min{| Wf^-b +川BI|J	(2-8)
其中，b = W；1s3, 0可以通过上式(2-8)求解获得，那么Wi2=Wi$就可以 解决原问题(2-7),公式(2-8)与lass。回归特别像。我们可以证明公式(2-5)
和公式(2-8)的解是等价的，且关系为W0 = L具体的表现为：
13
现在对公式(2-5)求子梯度：
w-s-P-r = o	(2-10)
10gdet G)的微分是= w, rt7 e sign(e>ij),也就是如果日4中0,坛=sig九⑼)， 如果= 0, Lj e L-1,1]O
公式(2-10)中矩阵右上角元素满足：
W12 - S12 _ P . 712 = 0	(2-11)
公式(2-8)的子梯度：
WiiS - s12 + p , v = 0	(2-12)
其中v esign(6)，假设(W,r)是公式(2-10)的解，(w12,y12)> (2-11)的解， 那么0二W1W12，V =-匕2是公式(2-⑵ 的解。任何符号项从(2-9)中可知 W11012 + @12^22 — °，那么有= -G22^11w12^ 因为。22 > °，那么Sign(B]2)= -signtW^w^) = -sign(P),因此公式(2-5)与公式(2-8)的解等价。公式(2-8)的优化问题可以认为是L正则的最小二乘问题。事实上，如果W"=S11，8的 解可以很容易地看作是第p个变量的lass。估计。一般地，W11芋S",使用快速 坐标下降算法可以使得lasso问题的解。根据内积的概念，第P个变量的lasso估 计将Su和Si2作为输入，更新w并循环所有的变量直到收敛。从公式(2-10)可以 看出，对于任意"优化问题的解wn = sa+p。因为0“>0,所以0 = 1,为了 方便我们称这样的算法为图lassoo图lasso的具体算法步骤如下：
(1)初始赋值为W = S + pl,在任何情况W的对角线元素保持不变。
(2)对于'每个变量j = l,2,…,P,使用lasso求解公式(2-8)问题，输入为W* 和Si?的内积，即lasso(Wu，Si2，P)，输出8的前P-1个矢量值，使用Wi2=Wi/ 填补W中对应的行和列。
(3)循环迭代知道收敛。
值得注意的是公式(2-5)的优化问题并不是p个独立的正则回归，而是p个 耦合的lasso问题，它们有相同的W和。=W-i,用Wii代替Su共享问题之间 的信息，是一种比较受欢迎的方法。在步骤(2)中对于每次迭代周期置换相应 的行和列使得目标列总是在最后一列，其lass。问题也可以使用坐标下降法有效 的计算得出，令丫 = Wii，u = s12> 0的更新形式：
印—S。/*&舟户	C2-13)
其中,Soft是软阈值，Soft(x,t) = sign(x)(\x\ — t)+=最后，当W的平均变化 值小于t,ave|S-diag|停止迭代，S-diag是经验协方差矩阵，是S的非对角线上的 元素，t是固定的阈值，默认为0.001。
14
