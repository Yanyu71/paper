2.4.2因果图结构学习
在新兴的网络科学领域中，网络节点的演变不仅与自身节点有关，而且与其 他节点有关。多元时间序列正好包含了网络拓扑和动态性等重要信息、，矢量自回 归(VAR)1251是一种最常用的模型来刻画时间序列之间的关系，在这个模型中， 每个节点的状态是由一个时间序列来刻画。在某一时刻一个节点的值是过去世界 自身节点和其他节点值的线性组合，一般把这种关系称作Granger因果关系。通 过估计模型的过度转系矩阵，有助于理解节点之间的Granger因果关系。
因果转移图过程模型：
xt = Axt_x + £t, 4〜N(O,EJ	(2-14)
工是p维矢吊:，何:个元素对应动态网络中一个节点的时间序列,p是网络的节点 个数，A是转移矩阵，j是随机噪声。广义的VAR模型对应着m阶，当前.状态 ■ m个状态的线性组合。另一方面,通过重定义恰当的节点变吊:，任何■ VAR模型都"以转换成一阶VAR模型，因此我们更专注于m=l的情况。
给定网络的n个样本Xi，…,xn, A的最大似然估计为：
L(A|x1(..,xn) = n?=2	(%1
=	(2-15)
最大似然估计需要解决非线性优化问题，为了简便，研究人员经常使用条件似然， 即久1的初始状态假设固定。由于正态分布的特性，条件似然可以写成：
Lc(4) =	= 口之2(21)-P/2 &|T/2exp{—一
—i)T4|T(Xt——.1)1 (2-16) 那么，A的估计可以转换为：
呼扛屋区 一5-11|：	(2-17)
令丫=[嬉，居…，媒]。X=[xT)xTi xT_i]T)b = A\那么优化问题的矩阵形式 为：
Bml = argmin L(B) =|||Y-XB||；	(2-18)
实际上，X通常是高度共线性的，尤其是当一些节点有相似的动态行为而观 察样本的个数是有限的。单纯的最大似然估计并不产生稀疏的解，因此求得的模 型很难解释。为了提高预测的准确性和模型的可解释性，增加一个惩罚项或约束 项，惩罚最大似然函数(PML)可以写成：
Bpml = argmin L(B) +	P(%,旬)	(2-19)
B
15
bjj描述了节点i与节点j之间的有向连接强度,P。是B中每个元素的惩罚函数， 人,是对应的正则参数。比较受欢迎的是Lasso方法，其使用的是。范数，那么上 述优化问题是凸的，可以使用相应的Lasso统计优化软件包因］求解得到。
