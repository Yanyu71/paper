4.1依赖树递归神经网络多模态模型
在2.4节中，本文利用RBM模型的特性，通过一个模态的数据重构出另外 一种模态的特征，从而通过特征之间的比较完成信息的检索。在这一节中，图片 也是利用卷积神经网络完成特征提取，而文本的句子则通过3.1节中依赖树递归 神经网络建模，因此还需要定义损失函数学习文本特征与图片特征的映射关系， 同时训练递归神经网络中的参数。
在一个模态中，利用输入特征去检索己有数据中的特征时，希望正确结果 在输出队列中处于较前的位置。而在检索数据时，输入特征与数据库中的特征可 以进行比较，获取相似程度。根据这种思想，对于两个模态之间的互相检索，同 样需要正确结果处于前列，不同模态的数据可以进行相似性比较，因此定义一种 排列损失函数去完成特征融合。
首先，图像的特征与文本特征处于不同的特征空间，因此本文对图像特征进 行转换，使得其维度与文本特征相同，如式(4-1)所示。
=WjXf	(4-1)
x,是第i张图片的4096维特征，v,?则是线性转换后的特征。假如每张图片对应 着一个句子，通过递归神经网络得到的特征为y,由此得到排列损失函数：
丿(仍，。)=￡ ￡ max(0, A
'加	(4-2)
+Z Z max(0, △ - V；乃 + 诺光)
J E
0是递归神经网络的参数，不同模态特征之间的相似程度通过内积表示。损失函 数的第一项是根据图片去检索句子，max函数中的v,表示正确的图片-文本组 合的相似程度，诺力表示同样是给定图片i时，与错误的句子j之间的相似性。 根据正确的结果应该处于前列的思想,损失函数要求正确结果的内积比错误结果 的内积大。假如满足该条件，那么max函数的结果为0。△是内积的相差程度， △越大，那么模型对于正确与错误的分辨性能则越高，但过大的△会使得模型无 法收敛。损失函数的第二项则是给定句子去检索图片。损失函数是非负的，假如 损失函数为0,那么说明所有正确的内积都大于错误的内积，模型的训练是最小 化损失函数。
在给定N个句子和对应的N张图片时，可以得到图像特征与文本特征的内
积矩阵SclRgN,该损失函数的训练算法如下：
算法4-1损失函数前向传播和后向传播算法 输入：相似矩阵S,区间△
输出：损失值/qss,导数矩阵AZ
初始化： loss = 0, AL = 0, count = 0
前向传播：
for i = 0 to N do
for j = 0 to N do
if J then
loss = loss + max(0, A - S[很]+ 5[f,y])
count — count
end if
end for
end for
loss = loss / count
return loss
2、	后向传播：
for z = 0 to AT do
for 7 = 0 to AT do
if i^j then
mdist = A-5[z,z] + S[z, j]
if mdist > 0 then
z] = AL[i, z] -1 / count
AL[i9j] = l/ count
else
皿丿]=0
end if
end if
end for
end for
return AZ
该算法中，矩阵S对角线上的值作为正确组合的分数与同一行的其他分数比 较，计算损失函数的输出。后向传播中，假如max函数非0,导数则非0。假如 S中每一行对应一张图片与多个句子之间的关系，那么该算法是计算式(4-2)中的 第一项，第二项需要对矩阵S进行转置后再使用算法4-1进行计算。根据M可 以简单得到图像参数仍的导数，而求递归神经网络导数的算法则与算法3-1相 同。
