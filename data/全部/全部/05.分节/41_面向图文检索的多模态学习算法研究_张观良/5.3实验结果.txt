5.3实验结果
实验基于Flickr8k的测试集，有1000张图片，每张图片有5个句子，因此 在利用文本检索图片时，是遍历5000个句子，每个句子从1000张图片中找出结 果。利用图片检索文本时，是遍历1000张图片，每张图片从5000个句子中找出 结果。本文使用［42］中的评价标准，提供排列中值(median rank, Medr),即所有 测试集获取到正确结果后进行排序，获取其中的中位数。例如有5个测试集，其 正确结果分别位于2、10、2、13和14,那么Med r为10,该值越低越好，用于 评价模型整体的检索性能。R@N,指前N个结果中，有正确结果的比例。例如 有100个测试集，其中有50个测试集可以从自身检索的前5个结果里找到正确 的结果，那么R@5为50/100*100%=50%,因此该值越高越好。
表5-2的细粒度模型中,EB-50 RCNN和EB-60 RCNN表示分别使用IoU为 0.5和0.6的非极大值抑制对EdgeBoxes生成的边界框进行过滤，用R-CNN的 CNN网络获取图像特征。SS VGG-16表示使用SelectiveSearch算法生成边界框， 用VGG-16获取图像特征。SS finetune VGG-16表示使用SelectiveSearch算法生 成边界框，用微调后的VGG-16获取图像特征。SS RCNN表示使用SelectiveSearch 算法生成边界框，用R-CNN的CNN网络获取图像特征。
从实验结果中可以看出基于Selective Search和R-CNN的细粒度模型有最好 的结果。EdgeBoxes在提取候选边界框时速度快于Selective Search,但由于 47
EdgeBoxes的边界框是根据边缘生成，因此会聚集在图片边缘丰富的位置。使用 IoU为0.5的非极大值抑制时，可以过滤大部分的集中边界框，但还是有明显的 聚集现象。使用IoU设定为0.6时，有部分边界框开始标记一些场景，但有许多 是无意义的位置，如图5-1所示。
表5-2图文检索
Sentence Retrieval
模型	R@1	R@5	R@10	Med r
随机排列	0.1	0.6	1.1	631
DeViSE〔4i】	4.8	18.0	28.6	32
Deep Fragment1421	12.6	32.9	44.0	14
Multimodal DBM	3.3	15.3	25.2	34
多模态对数双线性模型	8.2	26.2	32.4	30
依赖树递归神经网络	10.0	29.9	44.4	13
细粒度EB-50 RCNN	13.2	34.8	45.0	13
细粒度EB-60 RCNN	15.1	35.9	50.1	9.8
细粒度SS VGG-16	12.3	33.1	44.5	21.7
细粒度SS
finetune VGG-16	15.4	37.6	51.2	10
细粒度SS RCNN	16.2	38.9	53.4	8.6
Image Retrieval
随机排列	0.1	0.5	1.0	500
DeViSE"	5.9	20.1	29.6	29
Deep Fragment?	9.7	29.6	42.5	15
Multimodal DBM	4.9	17.1	26.9	32
多模态对数双线性模型	7.6	25.0	33.4	31
依赖树递归神经网络	7.4	24.9	36.3	21
细粒度EB-50 RCNN	9.4	29.8	42.3	18.6
细粒度EB-60 RCNN	10.2	30.5	43.3	14.2
细粒度SS VGG-16	8.2	27.4	39.5	20
细粒度SS
finetune VGG-16	10.5	31.6	43.1	18
细粒度SS RCNN	11.5	32.8	44.9	15.6
从实验结果也可以看出,IoU为0.6的检索精度高于IoU为0.5的检索精度。 本文还比较了细粒度模型中，使用VGG-16和R-CNN的CNN网络在提取图片 特征时的效果，从实验中可以看出，由于R-CNN的CNN网络是基于物体识别 进行了微调，因此可以更能反映出物体本身的特征。但在对VGG-16的全连通层 进行微调后，可以发现明显的检索精度的提升。根据论文［12］中的介绍，对conv3-l 以上的网络进行微调可以得到更好的效果。Deep Fragment同样是对从图片中提 取物体，但在文本建模上是利用单词在依赖树的关系形成词组，寻找与物体之间 的关系，实验表明双向循环神经网络优于依赖树的建模。
在众多模型当中，多模态深度玻尔兹曼机的效果较差，主要原因在于文本建 模上。当两个句子有着相似单词的情况下，由于字典大小的限制可能会出现文本 特征相同的情况，这会造成在检索结果上的混淆，但依然可以检索到相似结果。 该模型的优点在于特征重构上，可以利用数据库中的特征预先建立索引，提高检 索速度。另外RBM模型可以利用大量无标记数据进行预训练，还具有提升空间。
依赖树使用单一特征表示句子和图片，因此在检索结果上比细粒度模型差， 但由于使用了依赖树和词向量对文本进行建模，所以优于多模态深度玻尔兹曼机。 在图片特征提取上没有物体识别和提取多个图片特征的流程，因此速度比细粒度 模型快。
自然语言多模态模型在检索上使用困惑度作为图片与文本之间的匹配评价 标准，因此需要连续计算句子中下一个单词的出现概率才能完成一次困惑度的计 算，所以检索速度较慢。但自然语言多模态模型可以根据图片生成文本，其效果 与训练集有关。
(a)	(b)	(c)
图5-1边界框，(a)是使用Selective Search提取边界框后，利用R-CNN过滤后的19个边 框图。(b)是EdgeBoxes算法得到的，而(c)是使用IoU为0.6的非极大值抑制过滤后的边框 图。可以看ii Selective Search能够将球和女孩标示出来，而EdgeBoxes则将重点放在球 上，经过过滤后才能标示出女孩，但有部分边间框处于无用位置上。
使用多模态模型检索的结果如图5-2所示，尽管模型无法将最为正确的图片 结果处于最前位置，但依然能够获取非常相似的图片。在细粒度多模态模型下,使用文本去检索图片得到的前3个结果如图5-3所示，其中将每个单词和单词找 到的物体关联起来。从图5-3中可以看到，单词”children”都获得较高分数，同时 在第1、3张图片中占绝大部分分数。第二张作为正确图片，关键单词的分数分 布比较均匀，例如"naked”、"showering”、"containers”与"children”有着相近分数， 使其能够进入结果的前3位。图5-4是使用图片检索文本的例子，检索的前3个 句子都是对应句子，展示方式和文本检索图片一样，但在实际当中是20个边界 框去找最适合的单词。在图5-4的全部图片中，单词”red”和”ball”都指向红色的 球，这相当于为红色球找到对应的文字解释。另外动词”chasing”指向包括了狗和 球的边界框，刚好阐述了这个动作的含义。在图5-3的第二张图片中也有类似的 情况，形容词”naked”指向了小孩的身体。从图5-3和图5-4中还可以看出，句子 中的许多介词与图片之间的关系基本上小于0,这是由于在训练中介词没有特定 的图片-文本组合，因此也没有学到任何关系，这也说明式(4-4)和式(4-5)学习到 了图片坷文本之间的隐藏特征。根据图5-3和图5-4可以得到，细粒度多模态模 型除了能够提升图文检索精度外，还建立了视觉特征与文本语义之间的关系。
图 5-2 检索结果，检索句子为 a bus driving on the street next to a Victorian style building,前两个结果是错误，第三个是正确目标。从这里可以看到三张图片差异较小，唯 —的差别只在于最后的三个单词Victorian style building,模型可能无法学习到
Victorian style,但能够确定bui Iding,因此返回相似图片。
(b)
(c)
图5-3文本检索图片，第二张是正确结果，评价分数从上往下降低。
