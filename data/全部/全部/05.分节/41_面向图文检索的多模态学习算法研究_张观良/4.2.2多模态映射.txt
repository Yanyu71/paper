4.2.2多模态映射
与4.2.1节中的多模态映射一样，本节使用排列损失函数训练文本与图片模 型的参数，但是需要重新定义多模态细粒度特征之间的相似性评价标准。在4.2.1 节中，其相似性利用了两种模态特征之间的内积，但正确图片-文本对之间的特 征是一对一，而本章的细粒度特征则是多对多。同时图片中的物体与句子中的单 词没有预先给出对应关系，因此这种对应关系是该模型的隐藏特征。
为解决这种细粒度特征多对多的问题，本文利用正确的物体-单词组合在训 练数据中出现频率高于错误组合的情况，定义如下相似性评价函数：
v = WnS.CNNe{IbS\ + bm	(4-3)
S” =￡max%	(4-4)
f^gl
仏	(4-5)
i商
式(4-3)中，从物体图像K中通过CNN网络得到特征后，利用线性转化使得与文 本特征处于同一维度。在式(4-4)中，&表示第k张图片的边界框索引集合，i 表示第i个边界框，因此匕表示图片中的第i个边界框的特征，假如第k张图片 有20个边界框，那么& ={1,...,20}。同理幻表示第/个句子的单词索引集合，特 征之间的相似度评价依然使用内积。max函数是要求在给定句子中的单词t时， 找出与s,内积最大的图像特征所对应的边界框，形成单词与物体之间的对应关系。 对所有单词求和后得到的&就是在给定句子/并且为每个单词找到对应边界框 后，句子/与图片k的相似程度，式(4-4)也用于给定句子检索图片。同理式(4-5) 是给定图片k并且每个边界框找到对应单词后，得到图片k与句子/的相似程度， 可用于给定图片检索文本。由于物体与单词存在着对应关系，例如狗的图片与单 词”dog”，那么这种组合的出现频率会高于其他错误组合，因此模型会更倾向于 将狗的图片与”dog”关联，从计算结果来看，就是内积的值更高。
根据式(4-2)、式(4-4)和式(4-5),可以得到细粒度多模态模型的排列损失函数：
丿(°)= Z￡max(0, △-，.》+&) +
k /	r/
￡Zmax(0, △，&+&)
k I
当上=/时，表示正确图片-文本组合，该函数的训练方法与算法4-1相同。
