4.2.4双向循环神经网络实现
Caffe中的网络在初始化后不能再作修改，因此无法直接处理不定长的句子 输入。为解决该问题，网络需要预先定义序列长度，本文使用的序列长度是33, 长度较小的句子通过0补齐，过长的句子可以通过多次计算补齐。对于双向循环 神经网络，沿着传递序列看就是一个深度网络，每一层都有输出。因此根据该特 点，配置文件可以定义一个深度为33的神经网络，但共享同一组参数。
输入的序列一般有较长的无用数据(置0的数据)，但在计算过程中，偏置 项会使得没有单词的部分变成非0,影响后续的计算。为解决该问题，本文加入 蒙版输入，在适当位置将无用数据置为0o例如固定长度为L,句子长度为h时， 那么蒙版向量的维度为L,但只有前h维是1,其他为0。假定一个句子的特征 是，仁祀8, D是特征维度，表示一个单词的特征。与蒙版输入运算后，单词特 征的第1维到第h维保持不变，其他变为0。蒙版主要用在隐藏层的状态传递序 列上。
将双向循环神经网络展开后可以发现其中的层数众多，并且大多数参数设定 相同。为减少配置文件的编写困难，本文通过Protocol Buffer在python中的代码 库，利用代码生成网络的配置文件。其中需要在配置文件中预先定义好网络的关 键参数，包括亿、出、仇和仇。假定输入特征为t,其大小是(n,L,l,D), n是 训练时的batch大小，表示有n个句子。利用Caffe中的Slice层将每个句子展 幵得到特征',i = l,...,L,匕的大小为(n,l,l,D)o t,就作为图3-4中虚线部分网络的 底层输入。最终利用隐藏状态得到一系列的输出，通过Concat层将其重新整合， 作为多模态模型的细粒度文本特征。
