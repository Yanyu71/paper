3.1依赖树递归神经网络
在词袋(bag-of-the-words)模型中，每个句子的特征是关键单词的出现数目， 这种模型忽略了句子的结构。而在许多语言模型应用当中，例如语音识别、文本 压缩中，句子结构都有着重要作用。5】。因此这一节当中，通过依赖树(dependency tree)。】获取句子结构。句子的依赖树是根据单词之间的语法关系建立的，如图3-1 所示。在树结构中，每个单词都有自己的词向量，通过依赖树对词向量进行整合， 可以分辨两个有着相同单词而不同结构的句子的特征。
因为依赖树是根据单词关系建立,所以在单词整合上也应该对这种关系进行 建模。这也相当于在两种不同的单词组合中，假如在依赖树中的关系相同，则应 该使用一样的参数。利用这种思想，本文利用递归神经网络(Recursive Neural Network^】预先定义一组权重参数来对应依赖树中各种单词的依赖关系，之后对 句子中的单词进行整合。
对于一个简单的句子"Students ride bikes at night.",可以得到如图3-2所示的 依赖树结构，该树根据单词的顺序确定其左右关系。根据图3-2可以得到单词1, 3和5是没有子树，直接对单词的词向量进行非线性转换，如式(3-1)所示，/是 非线性函数。为获取句子特征处，需要计算缶，计算方法如式(3-2)所示。根据式 (3-2)可以看出特征％先通过吒映射到隐藏层的特征空间后，佑通过线性转化与 其结合，最后再对结果进行非线性变换。
4"(F，c = l,3,5	(3-1)
hA=f(Wvx4+Wr}h5)	(3-2)
在式(3-2)中,矩阵吧6职*"中的rl表示节点5是节点4在右边的第一个节点， 因此递归神经网络是对节点的左右位置进行建模。左右节点的权重参数数目预先 设定，假如在测试集中，左右子树的个数超过训练集的个数时，则直接使用单位 矩阵。现在己经得到內所依赖的所有隐藏层特征，根据式(3-3)得到句子特征。
fh = f(WvX2 +岡也 +乙佑 + 仍2用)	(3-3)
模型训练过程包含前向传播和后向传播。前向传播中，需要利用树的后序遍 历算法思想，计算每个节点左右子树的隐藏层的值后，才能得到本节点的值，其流程和计算图3-2依赖树的姻一样。后向传播则是树的中序遍历，以计算图3-2 的依赖树为例，算法如下(忽略矩阵转置)：
算法3-1依赖树中序遍历算法
输入：损失函数误差de沥(丿)，单词特征x,?和隐藏层特征九
输出：△%,△作"仍2，A%】，△坊2
初始化：△气，△化"化2,△怡,△。为0
1、	对奶求Wv,Wn,Wr},Wr2的偏导，可以得到：
g(h2)= delta(J)*%
△吸+ = g饱)工2
△銘i+ = g(&)4
A%+ = g(始九
△忻+ = g(妇4
2、	根据中序遍历，先遍历左子树，即计算4。对九求亿的偏导：
g(4) = (g")*4
grad(%)+ = g(E
4节点没有其他子树，返回为后遍历右子树佑，计算流程与步骤2 相同，只需要替换参数。
3、遍历为后到达禹，同样可以得到：
g(4) = (g(妃吧 2)*〃
豳j = g(如)工4
△?i+ = g(4)4
节点4有右子树也，同时4没有子树，因此&的计算流程与步骤2 相同。
从后向传播算法中可以看到，每一个节点都计算完吨和左右参数后，将导 数累积到相关缓存中，再遍历其他节点。遍历完依赖树后，则可以得到全部相关 参数的导数，根据训练算法更新参数。另外对于损失函数中的max函数，当max 函数为0时，跳过该次迭代。
