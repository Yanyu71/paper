5.6本章总结
本章中所提到的特征选择算法从特征处理上来讲分为两类，一类是在原始特 征的基础上去除冗余的特征而不改变原始特征，另一类是将特征经过矩阵的变换 运算映射到低维的空间中从而达到特征选择和压缩的目的，这种情况下原始的特 征在低维空间被改变。据此分类，信息增益、信息增益比及基尼指数均属于第一 种类别的特征选择算法，而LDA和PCA属于第二种需要改变原始特征投影的特 征压缩算法。
就信息增益、信息增益比和基尼指数三种特征选择算法比较，虽然在一定情 况下这三种方法都能达到较好的准确率，但信息增益和基尼指数算法对多值特征 的分类样本是有偏的，当样本数量很大时，基尼指数的算法的树模型训练时间长, 且它更倾向于数量等同的分类和基于提升纯度的角度进行分类。这三种算法常用 -于决策树中的特征选择，它们属于分类算法的一部分，同分类算法一起使用，而 后两种算法常用于数据分类前的数据处理。LDA同PCA相比较，LDA在类内离 散度矩阵非满纸的情况下需要先进行PCA特征选择，再进一步筛选特征。但LDA 最终选择的特征维数只能不大于类别数减一，这有时会导致特征过分压缩。
43
44
