5.2信息增益算法
信息增益°8】(IG Information Gain)特征选择算法基于炳的概念。信息嫡的定 义如下：
N
H(X) = - J/7 ) loSP (xi)	(5-1)
i=l
37
其中，汉*£）表示事件％发生的概率。信息炳反映的是变量的不确定性。信息 增益的定义如下：
IG（p,X）= H（p）-H（p\X）	（5-2）
其中，£歸P（p旱。表示类别的炳，在定位中表示参考点的信息 炳，通常在样本空间确定时，该值为确定值。H（p\X）表示特征X存在的情况 下，分类的不确定性，也就是在存在特征%的情况下对改变类别的信息炳的不确 定性所做出的贡献，具体定义如下
H （冲Q = P（x）H（p\x） + P（x）H（p | x）
z	z	（5-3）
=尸（*）£尸（，,闵1。酬（，切）+尸（力£尸（，区）1。叶（0号）
i=l	f=l
其中，P。）表示特征X出现的概率，pfelr）表示特征X存在时，样本属于以参考 点的条件概率，相对应的P（对表示特征X不出现的概率。信息增益的大小表明特 征X对改变分类不确定性做出的贡献，贡献越大，信息增益值越大，说明该特 征越有助于确定分类。
单纯的信息增益算法有个缺点，当训练样本各个分类的分布不均匀时，某些 特征的重要性会增大，原因在于某一类样本的数量所占比例增大而导致条件炳增 大。另一种情况，假设当某一特征在每一类中均有出现，且每一类中的之都不同， 那么按照值来计算的该特征的信息增益值将会很大，但这种特征并不能对预测起 到更积极的作用，应该尽量避免选择这种特征。因此，在信息增益的基础上便引 入了信息增益比网的概念（IGR, Information Gain Ratio）□
对于某一特征而言，该特征在样本中的炳值定义为：
H 仗 IX）=-救（R | X）logP（Pi | X}	（5-4）
也就是样本中出现某一具体特征的条件嫡。信息增益比的公式如下:
在这种情况下，当某一特征分布范围较广且对分类没有太大帮助时，或者样 本分布不均匀会导致某一特征被过分高估时，信息增益比的算法便可以起到一定 的作用。决策树算法中的ID3和C4.5算法分别是根据信息增益和信息增益比的 方式选取特征，具体的实现办法请参见第3.2节。
38
