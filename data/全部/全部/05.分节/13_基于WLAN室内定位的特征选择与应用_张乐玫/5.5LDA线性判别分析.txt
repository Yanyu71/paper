5.5LDA线性判别分析
LDA（Linear Discriminant Analysis）线性判别分析，也称作Fisher线性判别 （FLD, Fisher's Linear Discriminant）,是统计学习、模式识别和机器学习邻域的常 想算法，常用来寻找区分两类或更多分类的特征的线性组合。
一与PCA类似，LDA同样基于数据样本呈现正态分布，以及各个特征之间具 有的相关性为线性相关性的假设。然而，PCA在去除特征线性相关性的同时， 并没有考虑数据之间的类别关系，而LDA考虑的更多是不同，其处理过程的最 终目的是为了寻找最大类间距离、最小类内距离且彼此之间不相关的特征。
假设训练数据集为…*，& E It*,其中号=£ R, p/Z表示对应参考点标志。LDA线性判别分析假设資（芯|卩=应）呈现均值方差分 别为的正态分布，其中從而数据样本的总均值定义为 卩=幸零•号。此时，类间离散度可定义为
Z
Sb=*3-—-卩V
1=1
类间离散度可理解为每个类别对总体的偏离程度。对应的，类内离散度定义为
类内离散度可理解为每个样本与每一类别的离散程度的总和。
之后引入Fisher判别准则
切，^ （月一〃）（月一＞）亳	帰评
听W） -江£顷（zM f）「厂g
令矩阵證=乎「3-心,表示向量3_闵在低维空间超平面上的投影，则 乎T。--研乎=A矽可以看做投影距离的平方。同理，分母可以看做类内距 离投影的平方和。因此，Fisher判别矩阵可解读为求解一个新的样本空间，在该 空间中使类间距离之和与类内距离之和的比值最大，即使类间距离尽量大而类内 距离尽量小，用数学公式表示为
(5-20)
由式5-20可知要求&非奇异，因此在解上式之前通常需要使用PCA方法降 维。对式5-19利用求导解得的方程式应满足
42
(/s*) sb(p = (<pTSb<p) Sw(p	(5-21)
式5-21括号内的部分为常数，而方程只需关心方向，因此上式可写为
(p*ocS；&	(5-22)
则，$禮=；1^寧解得的特征向量组成矩阵即为所求矩阵。因此，解得的矩阵 的秩小于跚*耳的秩，即小于类别的个数减一，r-i,因此，解得的特征向量的 个数不会超iiT-io
LDA的局限性：
1.数据根据LDA投影后最多只能保留分类个数减一维特征，那么对于那些 特征维数较多且分类个数少的数据集可能导致特征压缩过大，数据信息 损失过大的情况；
2.LDA也是基于数据特征呈现高斯分布的假设条件下进行推导得出的结 论，若对于非高斯分布的数据这种特征压缩方式并不适用；
'3.对于有方差而非均值来区分的数据集合LDA方式也无法处理。
