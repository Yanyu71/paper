4.3基于提升算法的室内定位算法
当下的许多分类问题会遇到被称为“维度灾难”的情况，即因为特征种类、或 某个特征属性的可能值有很多选择而造成的分类算法收敛速度慢甚至无法收敛 的情况。这同样会影响算法的性能和训练模型的泛化能力。神经网络算法和支持 向量机等算法在训练的过程中都需要考虑样本中出现的每一种特征和每一个特 征值，因此，当遇到维度灾难，这些算法的性能会大大降低，而提升算法最早就 是为了解决这种问题而出现的算法。提升算法通过只选取少量的特征来达到优化 训练过程，从而达到算法收敛较快的目的。
在文本和图像处理领域提升算法中最常用的是AdaBoost, Adaptive Boosting,直译为适应性增强算法的简称，最早由Freund在1990年提出，当时 称为 Boost-by-majority algorithm, 1995 年，Freund 和 Schapire 提出了 AdaBoost 算法和名称，两年之后的1997年Schapire和Singer发行了通用版本的AdaBoost, 直到2001年AdaBoost算法在人脸识别领域取得的成果才使该算法得到广泛的关 注。本文将提升算法引入室内定位模型，生成基于室内定位的提升算法模型。
室内定位提升算法建立在CART决策树的基础上，将重新调整权值后的数据 样本重复通过相同的决策树模型，在每次定位结果的基础上增大错分样本的权值 而减小正确定位样本的权值，从而不断强化模型对错误定位样本及对应接入点的 关注，最后将各个决策树模型乘以对应权值相加而获得最终的定位模型。
假设决策树定位模型可表示为％(X,.)，Y =｛匀,七,...,吒肩,％ cA ,每棵级联的 决策树的权值可表示为貽琦ER,则最终的室内定位提升算法训练模型可表示成:
34
，T	、
f(X)= sign 京AX)	(4-1)
\	>
其中，T表示训练器的数量。
给定样本数据集7 = {(X］，W，(X2，P2)，・“，(Xn，Pn)}A 索“，定义经过决策 树定位之后样本的误判概率为勻=F(4(X/)H0),初始化每个样本的权值分布为 40丿)=号,丿=1,...0景，提升算法的训练过程简述如下：
1.调整第士棵决策树模型的输 出样本分布为
Dzi(X/) =坚立■expl-aphAXj)),其中，耳为正态分布常量。
Z
2.将样本输入到第土棵决策树模型中进行定位，同时使加入权重的定位错误 率达到最小：
九=argminhjeH£j = £已(*•)［月。4(羽)］	(4'2)
3.若定位结果满足停止条件，如气等，则停止训练，得到最终的室内定 位提升算法模型为
(T	\
f(X)= sign £%4(X)	(4-3)
\ i=l	丿
4.若不满足停止条件则调整每个样本的权值％为％亏m(芝) >恥然后再 跳到第一步继续优化。
提升算法的训练步骤如图4-1所示。
提升算法的优势：
1.易于实施；
2.对高维特征的处理釆用选取部分特征的方式，避免了“维度灾难"问题；
3.算法收敛速度快，可以达到相对较好的性能。
室内定位提升算法那同样有很多缺陷：
1.对噪声样本和异常值较为敏感，可能会产生过拟合现象；
2.缺少系统的理论背景的支持。
35
初始化生成样本训练数据集7,样本权值分布为DO(X)；
离线阶段：
1.设置决策树深度痂叶子节点个数也决策树棵树
for n=l to K,
2.将样本数据输入生成第n棵决策树模型加停；
3.根据输出定位结果计算错误率e ,并依据定位错误率调整第n个决策树的权值a ；
end if e <0. 5
else
4.样本权值分布Dn,循环继续；
5.生成定位模型f(X)o
图4-1室内定位提升算法训练步骤	’
