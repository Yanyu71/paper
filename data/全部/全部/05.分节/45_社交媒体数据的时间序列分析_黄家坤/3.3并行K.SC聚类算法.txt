3.3并行K.SC聚类算法
由于热点事件的数据量较大，而且每一个事件的时间维度也较高，如何高 效地对时间序列聚类也是研究的重点。低复杂度的算法往往意味着要牺牲一定 的准确度，而且数据量极大的情况下低复杂度并不能解决根本的问题。采用并 行计算技术实现算法并行化，是一种很好地解决方案。Hadoop平台是目前最流 行、最具代表性的分布式处理框架，其中HDFS和MapReduce是它的两个核心 基础，是专门为海量数据应用场景设计的文件系统和并行计算框架。这种方式 可以在用户不了解并行处理机制的情况下完成分布式任务，大大提高了开发效 率和并行计算能力。
在数据量特别大的情况下，尤其是海量数据的场景，相似度计算需要接近 0(疽)的时间复杂度，而且聚类的过程需要不断地迭代，因而直接使用K-SC聚 类算法性能会很差。本文提出了一种适用于海量数据场景的基于MapReduce的 并行化聚类算法，主要步骤如下：
(1)设定聚类的个数，初始聚类中心，以及迭代停止阈值；
(2)Map过程计算每个热点事件时序与聚类中心的相似度，把相似度最大的聚类中心作为它的类别，每个样本与类别一一对应，输入为聚类中心与每 个热点事件样本的时序，输出为Key为聚类中心，Value为属于当前聚类中心 的时序样本，并将Key-Vaule输出交给Reduce过程；
（3）	Reduce过程的输入为Map过程的输出，两个过程中间会把具有相同 Key的Value合并，即将属于同一个聚类中心的时序样本合并到一块，然后再 输入给Reduce过程。Reduce过程利用聚类中心更新算法，得到每一个类别的 新的虚拟聚类中心，输出为新的聚类中心与每一个时序样本，并作为下一个迭 代Map过程的输入；
（4）	根据相似度计算方法计算每一个样本与其类别中心的相似性，并求和 作为算法整体的相似性，如果它小于停止阈值，则代表算法收敛，停止迭代， 将聚类中心作为聚类模块的最终聚类结果，如果大于停止阈值，重复（2）.（3） 过程；
对于Hadoop上的K-SC聚类，首先使用Map操作并行地将原始时间序列 数据转换成可聚类的格式，并给不同的服务器分配互不重复的时间序列数据（这 个操作步骤是用…个Map操作并行执行的）。然后，对这些时间序列数据开始 进行按样本划分以及类别划分、聚类中心更新的迭代操作。主服务器根据指定 的k值随机选取k个时间序列作为初始聚类中心，然后将聚类中心和样本分配 到各个服务器，每个服务器的聚类中心相同，样本平均分配。
在Map阶段，每个服务器首先分别读取本地的时间序列，完成时间序列到 编号key的映射，并计算每个时间序列到各个初始聚类中心的距离（通过计算 相似度），将其划分到最近的初始聚类中心（该步操作是并行进行的），再将本 次聚类结果在Reduce过程中返回。每个服务器在Map阶段读岀位于本地的数 据集，并行计算每个时间序列对应的聚类中心，大大缩短了聚类的时间。输入 为聚类中心与每个热点事件样本的时序，输出为Key （Map映射的编号）为聚 类中心，Value为属于当前聚类中心的时序样本，并将Key-Vaule输出交给 Reduce 过程。
Reduce阶段过程得到所有Map过程类别划分的结果，对各个服务器返回 的聚类结果进行合并以后，在每个聚类中计算与当前类别所有样本距离最小的 点（通过计算相似度），作为新的聚类中心（虚拟中心）。输入为Map过程的输 出，两个阶段之间会把具有相同Key的Value合并，输出为新的聚类中心与每 个时序样本，并作为下一个迭代过程Map阶段的输入，结束迭代。
重复执行上述Map-Reduce操作，直到聚类中心不再变化或者样本与聚类 中心的相似性差异降低到设定的阈值以下，就结束迭代操作，输岀为每个时间 序列的聚类信息。这样，就将原本逐个计算相似度的串行计算过程，分配给不同的服务器并行执行，提高了计算效率。
