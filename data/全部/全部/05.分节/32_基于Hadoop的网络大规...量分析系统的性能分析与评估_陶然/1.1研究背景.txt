1.1研究背景
近年来，随着网络的普及，移动互联网、云计算以及逐渐兴起的物联网都在 迅猛地发展，当今社会的数据规模呈指数型增长趋势，数据类型多种多样，包括 文本、语音、视频等［1］。根据IDC的研究报告:整个地球数据量在2009年是0.8ZB, 到2020年，会上升至35ZB,这十年将增长44倍，年均增长率达到了 40%左右 ［2】。由于数据规模的庞大，传统的数据分析与处理工具已经不足以满足当前的数 据分析需求，如何管理和使用这些数据，逐渐成为了一个新的领域。因此，“大 数据”的概念应运而生，大数据时代己然来临⑶。
大数据时代的来临给我们带来了巨大的机遇，处理与分析海量数据，发现并 提取数据的深度价值，为各行业提供高附加值的应用和服务［句。但与此同时，大 数据也给我们带来了巨大的挑战。面对爆炸式增长且结构日益复杂的数据，传统 的数据处理技术巳经不能实现有效的将数据进行存储并快速的处理和响应高并 发的数据［5】。自2003年以来，Google公司相继发表了三篇论文，向全世界分别 介绍了三个技术概念：分布式文件系统GFSm〕、分布式的编程模型MapReduce^ 以及分布式的结构化数据存储系统Bigtable^,并以事实证明了该框架在处理海 量网页数据方面具有强大的优越性。ApacheHadoop"］正是对Google提出的这一 优越框架的开源实现。Hadoop是一个开源的分布式计算平台，它的核心技术主 要包括分布式文件系统HDFS、分布式计算框架MapReduce及YARN。在大数据 领域，Hadoop可以在由普通PC组成的集群上获得良好的运行效果，因此大大的 节省了企业IT设备成本。Hadoop凭借其低成本、高性能、高可靠性的优势，得 到了全球大量有大数据处理需求的用户的支持。
