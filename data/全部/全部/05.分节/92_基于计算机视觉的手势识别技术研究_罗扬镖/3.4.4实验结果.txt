3.4.4实验结果
(1) 微调训练方案对比及正则化参数实验
本文使用Jester和IsoGD两个公开的大型手势识别数据集进行多组实验，其 中Jester数据集仅包含RGB视频一种模态,IsoGD数据集则同时含有RGB手势 视频和深度视频两种数据模态。RGB视频和深度视频是两种物理意义具有较大 差异的数据形式，因此在Jester数据集上训练得到的模型并非完全可以用于 IsoGD数据集上的深度模态进行微调训练。同时，IsoGD数据集的RGB视频和 深度视频虽然属于两种不同的数据形态，但其属于同一个数据集，数据特征的分 布可能具有一定的相似性。因此本章设计了三种微调学习方案来验证不同数据集 预训练方法在IsoGD手势识别数据集深度视频中的有效性，三种具体的微调训 练方案为：(1)方案1 ： Jester数据集的RGB形态预训练模型微调至IsoGD数据 集的深度视频形态进行训练；(2)方案2： IsoGD数据集的RGB形态训练模型 微调至其深度视频形态中训练；(3)方案3：不采用任何预训练方法而直接在 IsoGD数据集深度视频形态上训练模型。实验(1)中在微调训练时仅对模型最
32
后一个全连接层神经网络不进行权重迁移。在训练中设置IsoGD数据集模型的 L2正则化参数惩罚系数为0.0004,在Jester数据集上预训练时设置L2正则化系 数为O.OOOL将以上三种微调训练方法在IsoGD数据集的深度模态上进行微调 训练。其微调训练模型在验证集上的识别准确率及其分类损失曲线如图3-8（上） 和3-8 （下）所示。
图3-8 IsoGD数据集深度模态微调学习方案对比：识别精度（上）、损失曲线（下）
可以看到，三种微调训练方案的训练结果具有较大差异。其中，基于Jester 数据集和IsoGD数据集RGB形态预训练的微调学习方法具有更快的训练收敛速 度和更高的识别准确率，且方案（2）的识别效果优于方案（1）,说明在IsoGD 深度模态下基于其RGB视频形式的模型预训练方法比基于Jester数据集的预训 练方法更加有效。尽管RGB视频与深度视频模态具有不同的物理意义，但其时 空特性具有一定的相似性.Jester数据集虽然具有更大量的训练样本，其微调学 习效果不如IsoGD自身的RGB数据集预训练模型。而方案（3）由于没有采用 预训练微调操作，其模型训练的收敛速度和识别准确率不如前两者。
本文实验中Jester和IsoGD两个数据集具有不同的数据分布，而IsoGD数 据集的RGB视频和深度视频两种模态也具有不同的表现形式，因此在实验中设 置不同强度的L2正则化参数惩罚强度是必要的。为了探究不同强度的L2正则化参数惩罚对模型泛化性能的影响，本文对IsoGD数据两种不同的数据模态设 置了不同的L2正则化参数惩罚来对模型进行训练。本文在Jester数据集上设置 了强度为0.0001的L2正则化参数惩罚系数对Jester数据集进行了 30轮的模型 预训练，将Jester数据集上训练好的模型迁移至IsoGD数据集的RGB模态进行 正则化参数微调学习实验，再将最佳的RGB模态模型迁移至其深度模态中进行 微调实验，其RGB模态和深度模态微调训练的实验结果如图3-9所示。
图3-9不同L2正则化系数对IsoGD数据集微调学习识别准确率的影响
由图可知，适合用于IsoGD数据集两种数据模态微调训练的最佳L2正则化 系数分别为0.0003和0.0004,其在RGB视频和深度视频模态下的识别准确率分 别达到了 54.62%和55.11%。在本文后续的实验中，将使用该参数训练所有基于 IsoGD数据集的手势模型。
(2) 验证时空多尺度特征融合算法独立模块结构的有效性
时空多尺度三维卷积神经网络利用时间维度上的膨胀卷积结构设计，获得不 同时间尺度的手势时空特征，结合常规三维卷积结构支路共同提取到不同时间尺 度的手势三维时空结构特征，通过连接1X1X1大小的卷积核在通道层面上对不 同时间尺度的手势时空特征进行融合。为了验证本章时空多尺度三维卷积神经网 络在特征提取上的有效性，本文通过实验对比结合了三维卷积神经网络与卷积长 短期记忆网络的其他优秀算法。其中，论文［50］使用了 “Res3D + ConvLSTM + MobileNet”的串行网络结构，其使用三维残差卷积网络代替传统3DCNN进行特 征提取操作，提取了深层次的手势动态特征。本文通过实验对比其三维卷积模块 在本文方法中的网络参数量变化及其在IsoGD数据集验证集上识别准确率的情 况验证本文模型中三维卷积神经网络单模块结构的有效性。为了验证单模块结构 的有效性，实验中采用控制变量法设置模型结构，并采取相同的训练策略，即首 先在Jester数据集上进行模型的预训练，再微调至IsoGD数据集，对比各个模型 在验证集上的识别准确率情况。其中用于对比的三种模型结构为：(l)“Res3D + ConvLSTM+ MobileNet”网络结构，即三维残差卷积神经网络结合卷积长短期记
忆网络的模型方法。（2）使用本文的常规三维卷积神经网络结构代替三维残差卷 积神经网络模块，即“3DCNN + ConvLSTM + MobileNet”的模型方法。（3）使 用本章提出的时空多尺度三维卷积模块代替三维残差卷积神经网络模块，即
“3DCNN&T-Dilated + ConvLSTM + MobileNet”的模型结构。其识别精度的实验 对比结果如表3-4所示。
表3-4三维卷积网络模块识别精度对比（％）
表3-4中的参数量为三种模型结构中的卷积神经网络模块的参数量对比。可 以看出，本文提出的时空多尺度三维卷积神经网络极大地降低了三维卷积神经网 络模块的机器学习参数量，其参数量仅为三维残差卷积神经网络结构的三分之一。 在将三维残差卷积神经网络替换成常规三维卷积神经网络结构后其RGB模态的 识别准确率有轻微下降，其原因是机器学习参数量的减少导致了模型学习能力的 降低，而在替换成时空多尺度的三维卷积神经网络结构后，本文模型在IsoGD数 据集的两种数据模态上的识别准确率均有所提高，在Jester验证集上的识别准确 率也非常接近，证明了本文时空多尺度三维卷积神经网络模块可以在明显降低机 器学习参数量的同时提升动态手势识别的精度。
在以图像序列作为输入的三维结构动态手势识别算法中，除了三维卷积神经 网络可以用于提取手势的三维时空特征外，卷积循环神经网络结构也可以使用。 其在提取手势视频时序关系的同时也对手势的空间特征进行着卷积记忆操作，提 取手势的空间特征。然而直接利用卷积神经网络来扩充循环神经网络内部的空间 特征处理不仅导致了机器学习参数量的直线增加，还可能导致模型变得过于复杂 而产生过拟合风险。本章第3.2.2小节提出了空间一致加权的卷积门控循环单元 结构变体，为了验证该变体结构的有效性，采用控制变量法分别对比了如下三种 网络结构模型的参数量及其在数据集验证集上的识别准确率：（1）论文［50］中使 用的“Res3D + ConvLSTM + MobileNet”网络结构。（2）本文基于时间维度膨胀 卷积的时空多尺度特征融合方法，即“ 3DCNN&T-Dilated + ConvLSTM + MobileNet”模型。（3）本文将卷积长短期记忆网络替换为空间一致加权的卷积门 控循环单元结构变体的时空多尺度特征融合模型，即“3DCNN&T-Dilated + ConvGRUvariant+ MobileNet"方法。该对比实验用于验证本文提出的卷积循环
35
神经网络变体结构在动态手势时空特征融合中的作用，实验对比结果如表3-5所
zj\ O
表3-5循环神经网络模块识别精度对比（％）
表3-5中的参数量为三个不同模型中循环神经网络模块的机器学习参数量， 由表可以看出，由于去除了卷积循环神经网络内部对于空间中每个像素点的记忆, 机器学习参数量得到了明显减少，因此本文提出的卷积门控循环单元结构变体提 高了动态手势的识别计算效率，降低了模型的计算成本。同时，由表可以看出其 手势识别精度也得到了提高，包括动态手势的RGB和深度视频两种数据模态模 型，由此证明了本章基于时空多尺度特征融合的ConvGRU变体模块的有效。
（3）对比现有其他手势识别方法的准确率
以上实验分别验证模型 “3DCNN&GDilated + ConvGRU variant+ MobileNet” 中时空多尺度三维卷积网络以及卷积GRU变体结构两个模块的有效性，验证了 本文提出的时空多尺度特征融合方法在降低机器学习参数量的同时，提升了手势 识别的效果。本文还对比了现有其他基于卷积神经网络的手势识别模型，对比结 果如表3-6所示。其中，ResNet50[51]是二维残差卷积神经网络，PyramidalC3D[52] 是三维金字塔卷积神经网络，C3D®]是Yunan Li等人提出的基于三维卷积神经 网络的手势识别模型，Res3Dei是三维残差卷积神经网络。
表3-6与其他模型在IsoGD验证集上的识别精度对比（％）
表3-6可以看出，本文提岀的基于时空多尺度三维卷积神经网络结合卷积门 控循环单元变体的网络结构在动态手势识别中具有优势，其对比二维残差卷积神 经网络、三维神经网络以及三维残差卷积神经网络等独立模型，识别精度具有较 大提升，而对比三维卷积神经网络结合卷积长短期记忆网络的其他模型，本文模 型不仅有效减少了网络的学习参数，提高了模型计算效率，还有效地融合了手势 视频中的时空特征，提高模型的泛化能力和动态手势识别的准确率。
