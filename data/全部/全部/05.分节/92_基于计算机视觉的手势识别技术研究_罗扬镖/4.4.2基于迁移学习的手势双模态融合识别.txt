4.4.2基于迁移学习的手势双模态融合识别
在基于注意力机制前置的手势识别中，RGB模型和深度模型属于两个不同 的手势识别任务，其输入的RGB视频和深度视频两种模态在时空特征上具有一 定的相似性。本章基于迁移学习的手势识别模型利用两个独立模型输出特征进行 联合学习，迁移双方领域的知识来提升单模态的手势识别精度，在单模态手势识 别模型的基础上联合微调训练模型10轮，并将批次大小设置为8,其他参数保 持不变。SSA损失系数几设为50x10-3,正值聚焦参数/?设为2。
基于注意力机制的时空多尺度特征融合模型利用多任务迁移学习的方法从 单模型的中间层特征数据迁移学习另一模态的手势时空特征分布。本文在此基础 上进行了手势双模态的后端融合技术研究，在得到多任务迁移学习的单模态识别 模型后利用其最后的Softmax函数输出概率计算其手势类别的平均值融合、最大 值融合以及乘积融合三种后端融合方法的手势识别准确率。将本文方法与现有效
49
果较好的手势识别模型进行比较，其对比结果如表4-2所示。其中“Res3D + ConvLSTM + MobileNet” 和 “Res3D + ConvLSTM variant + MobileNet” 方法呦 是Liang Zhang等人提出的三维残差卷积神经网络结合卷积长短期记忆网络及其 变体结构的手势识别模型，MultiD-CNN方法【621是Elboushaki等人提出的RGB- D多维度特征双模态融合识别算法，对比方法中其他模型的后端融合策略均采用 平均值融合办法。
表4-2与其他模型在IsoGD验证集上的识别准确率对比
表4-2中本文方法在IsoGD数据集验证集上的RGB和深度两种数据模态上 的识别准确率分别达到了 56.04%和56.48%,对比进行双模态联合训练前的单模 态注意力模型其手势识别精度有所提高。基于RGB模态的手势识别模型识别准 确率比基于深度模态模型的识别准确率提升更大，也验证了本章手势双模态迁移 学习方法的有效。
本文还对比了三种基于注意力模型的手势后端融合方法的识别准确率，其中 平均值融合、最大值融合和乘积融合的手势双模态融合识别的识别准确率分别达 到了 70.41%、67.06%和68.23%,说明本章基于注意力模型的三种后端融合方法 中平均值融合的效果最佳。对比其他手势识别方法，本文方法具有更高的手势识 别精度，对比同结构的结合三维卷积神经网络和卷积长短期记忆网络的模型，本 文方法具有较大的识别精度提升。因此，基于注意力机制的本文模型可以对动态
50
手势进行很好的识别，其单模态和双模态的手势识别模型都具有更高的识别准确 率，证明了本章结构的有效性。
