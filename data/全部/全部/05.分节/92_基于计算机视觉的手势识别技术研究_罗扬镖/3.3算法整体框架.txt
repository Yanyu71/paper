3.3算法整体框架
本章提出的算法整体框架基于Liang Zhang等人提出的“3DCNN + BiConv- LSTM + 2DCNN ”结构，该结构充分结合了三维卷积神经网络、卷积循环神经 网络以及二维卷积神经网络三者在动态手势识别中的优势，提取动态手势视频中 的时空特征以及对时空特征进行有效融合，在很大程度上提升了动态手势视频的 识别准确率，该框架的结构如图3-5所示。
输入规范化
图3DCNN+BiConvLSTM+2DCNN” 网络结构
首先最底层的输入层对输入数据进行规范化，再通过一个三维卷积神经网络 结构提取手势的浅层时空表征,将浅层时空特征送入到两个串行的双向卷积长短 期记忆网络(BiConvLSTM)中，利用二维卷积神经网络计算每一个时间步上的 时空特征，即具有不同长度时序记忆的二维空间特征，最后利用全连接神经网络 以及Softmax函数对动态手势进行综合分类。
本章基于时空多尺度特征融合的算法结构为“3DCNN&T-Dilated + Conv- GRU variant + 2DCNN"结构，基于时间维度膨胀卷积的时空多尺度三维卷积神 经网络作为前置，与空间维度一致加权的两层卷积门控循环单元结构变体结合， 进一步融合了手势的长短期时空特征，接着通过一个二维卷积神经网络结构计算 不同时序长度的时空特征融合结果，最后利用全连接网络以及Softmax函数对手 势进行最后的分类。Softmax函数的公式如式3-17所示，其中彳为第i个类别节 点的特征输出值。C为全连接神经网络的输出神经元个数，即为手势的类别总数。 通过Softmax函数可以将多类别的输出值转换到［0, 1］的概率区间，所有类别的 概率和为1,即为手势分类的概率分布。
Softmaxiz^ =花一	(3_17)
同时，为了进一步减少机器学习的参数量，保证模型的识别性能，本章结构 中还使用了深度可分离的卷积神经网络代替传统二维卷积神经网络结构。深度可 分离的卷积网络将二维特征图的空间维度与通道维度分离，分别计算每个通道上 的特征图卷积结果，再利用1X1卷积核对特征的通道数进行变换，在本文第2.3.2 小节卷积神经网络常用技术中已作介绍。
数据流经过最后一个卷积神经网络模块之后，具有时间、空间(长、宽)以 及通道四个维度，本章利用全局平均池化函数来进一步融合输出特征的长短期时 空特征，即在时空维度上进行平均池化操作，仅保留其时空特征的通道特征，该 特征代表了动态手势视频不同时空尺度上的特征融合。连接全连接神经网络训练 手势的分类器，将手势特征映射到手势类别的一维向量，代表手势属于各个类别 的概率值，选取最大可能性的手势作为最后的分类结果。在模型训练时使用多分 类的交叉爛损失函数来计算模型的分类误差，其公式如式3-18所示，其中，夕为 模型预测真实标签时的输出概率。
•Loss = -log®)	(3-18)
实验中计算的准确率和损失值为数据集验证集上的模型效果，即正确分类数 在总数据集上的占比，以及验证集上样本损失的平均值。
