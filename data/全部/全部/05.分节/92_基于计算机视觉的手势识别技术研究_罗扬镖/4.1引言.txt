4.1引言
时空多尺度特征融合网络就三维卷积神经网络与卷积循环神经网络结构设 计了一种结合两者优势的手势识别模型，在明显减少学习参数量的同时实现了手 势识别精度的提升。该方法从整体结构上对手势视频的时空特征进行了提取，而 在手势视频中，手部通常位于摄像机视野的一定范围内运动，且在运动过程中手 部也有可能偏离中心位置而靠近边缘，甚至可能会超出摄像机的录制范围，因此 需要对手部进行检测定位。在传统的动态手势识别技术中，其流程包括手部检测、 手势特征提取和手势分类三个步骤。手部检测是为了检测手势的空间位置，排除 无关背景噪声等干扰。在OkanK等人研究的实时手势识别方法［旳中，动态手势 识别也被分为两级神经网络结构，第一级网络结构采用轻量级的卷积神经网络来 判断当前数据流中是否包含手势，第二级卷积神经网络则采用大型的网络结构对 数据流中的手势进行具体分类，该研究工作保证了输入到动态手势视频分类器中 的图像序列包含具体的手势行为。在计算机视觉方法中，基于深度学习的注意力 机制也可以让模型关注到图像中手势的具体位置而应用在端到端的动态手势识 别算法中。本章方法基于时空多尺度特征融合网络结构“3DCNN&T-Dilated + ConvGRUvariant + 2DCNN"引入时空注意力机制前置，采用改进的时空注意力 机制对手势的视频数据输入进行处理，代替手部空间位置检测以及手势视频关键 帧提取的操作，设计了针对视频输入的时空注意力机制数据处理办法。接着本章 还针对手势识别数据中的RGB和深度两种模态进行了手势双模态识别的技术研 究，利用RGB-D两种数据模态的手势识别模型进行多任务迁移学习训练，实现 其知识互补，提升单模态以及双模态手势融合的识别精度。最后通过实验验证本 章方法的有效性并对本章内容进行总结。
