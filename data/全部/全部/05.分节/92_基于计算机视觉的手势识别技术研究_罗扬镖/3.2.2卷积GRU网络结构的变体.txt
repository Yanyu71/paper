3.2.2卷积GRU网络结构的变体
在本文的第二章已经介绍了深度神经网络中经常使用的卷积神经网络以及 循环神经网络结构。其中循环神经网络非常适合用于时序信息的处理中，为了使 循环神经网络适应三维结构的输入，研究人员在循环神经网络结构的基础上加入 了空间维度卷积功能，实现了卷积循环神经网络结构。而随着循环神经网络发展 出了许多优秀变体，如本文在第2.4.2小节中介绍的长短期记忆网络LSTM以及 门控循环单元GRU等，在适配三维数据输入的循环神经网络结构中，同样具有 卷积长短期记忆网络(ConvLSTM)与卷积门控循环单元(ConvGRU)等优秀变 体结构，其中，ConvLSTM的公式如式3-1至3-6所示：
其中，“ * ”表示二维卷积，“。”是哈达玛乘积。在卷积长短期记忆网络中， 利用输入的原始图像以及隐藏层的二维特征拼接后进行卷积操作，分别计算得到 二维结构的忘记门、输入门以及输出门三个记忆参数，再与上一个时间步的特征 图进行像素级哈达玛乘积得到更新后的特征图，对特征图的每个像素点进行单独 记忆。在门控循环单元中，则是分别计算二维结构的更新门以及重置门，利用这 两个门控单元对隐藏层的二维特征以及输入图像进行更新记忆。在卷积循环神经 网络的结构中，用作记忆加权的门控单元、直接参与计算的原始图像输入以及隐 藏层神经元输出都是具有二维图像数据结构，在进行记忆的过程中，通过卷积操 作获取每个像素点的记忆权重，通过哈达玛乘积完成对每个特征像素点的记忆， 并通过循环功能向后传递。
在本文的模型结构中，采用时间维度膨胀卷积的时空多尺度三维卷积神经网 络提取了不同时间尺度上的手势时空特征，该特征表示了手势的空间信息以及短 期时序关系，但没有对手势序列的长期关系进行建模，在时间尺度上没有进一步 融合。本章基于该短期时空多尺度特征，利用卷积循环神经网络进一步融合手势 视频的长短期时序关系。而传统的卷积循环神经网络在进一步融合时序关系的同 时也对空间信息进行了过多的卷积记忆操作，为了减少机器学习参数量、降低学 习成本，并保持循环神经网络在时序关系建模上的优势，本文设计了一种卷积门 控循环单元结构的变体(ConvGRU varient)来对动态手势的时空特征进行高效 融合，该变体公式如式3-11至3-16所示。变体采用全局平均池化功能在空间维 度上进行平均池化，仅保留时序及通道维度作为手势的短期时空关系表征，计算 卷积门控循环单元内部的更新门与重置门，接着采用全连接神经网络单元代替二
26
维卷积运算得到当前时间步的记忆更新参数，其中的权重是与通道数相等的一维 向量，在空间维度上对所有像素进行统一的记忆加权操作从而弱化空间维度上的 像素独立记忆，进一步减少机器学习的参数量、增强模型的泛化能力，并强化了 卷积门控循环单元在时序关系上的特征融合能力，使循环神经网络结构发挥出其 在时序上建模优势。
Xt=GlobalAvgPooling(Xt)
(3-11)
Ht_x = GlobalAvgPooling(Ht^x)
(3-12)
Z严b（化•区+%.耳1+氏）
(3-13)
"b（昭•同
(3-14)
r, = tanh(殓 *Xt+rto (Whh *
(3-15)
(3-16)
