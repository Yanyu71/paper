3.3.2时间序列的K近邻算法
在网络流量时间序列中，不一样的检测方式或者不一样的检测区间对网络流 量的特性就有不同的差别，例如，从整天的网络流量来看时间序列的数值差别会很 大,而从局部的一小段时间内看，网络流量的差别并不大,具有一定的稳定性。
网络流量的异常值，是指相对来说，流量显得异常突兀的值，这里的参考系 即之前的网络流量的值，这也是本文选择K近邻算法(K Nearest Neighbors, KNN) 来辅助检测异常值的重要依据四。
该方法的思路是：“在样本集的特征空间中，若某个样本的K个最相似的 样本，即特征空间中最邻近的样本中的大多数属于某一个类别，则该样本也属于 这个类别”［⑸。其中，待测值所需要的多个邻近值是经过正确分类的事物。一般 来说，KNN算法在分类时只参照近邻值，可以是一个近邻值，也可以是多个近 邻值，以此来判断该待分类事物的类别，而与其他值无关。从数学上分析来说， KNN算法虽然采用了极限定理的数学思想，但是在分类时，待分类值只与一部 分邻近值有关。
KNN算法运用场景很灵活，不仅仅局限于对事物进行分类，也能够用做回 归分析。得到某个事物的K个最邻近样本数据后，将这K个样本值的属性值按 照一定的权重赋给该样本，较常用的算法是根据距离的远近来计算对待测事物的影响因子，从而确定权重。
然而，虽然KNN算法有诸多优点，但是，KNN算法也有一些尚待优化之处。 首先，当某个场景中的样本值倾斜很大，即某个特定类的样本数量占了绝大多数 时，可能出现一个新样本的K个邻近数值都是属于该特定类的，这样显然会导 致分类结果失真。无论怎样，样本数量不应该影响分类结果。其次，KNN的特 点事实上也可以算是一个缺点。由于确定新样本的K个最邻近数值时需要对全 局样本进行计算欧式距离，从而导致计算任务特别繁重。为了提高性能，可以在 分类计算前先按一定规则过滤掉一部分，再通过赋予不同的权重来消除样本数量 的影响。总的来说，KNN算法较适合大规模的，精度要求不是特别高的分类， 样本太少可能误差比较大，分类效果不好。
KNN算法过程如下：
1首先我们事先定下K值（就是指K近邻方法的K的大小，代表对于一个 待分类的数据点，我们要寻找几个它的邻居）。
2根据事先确定的距离度量公式（如：欧氏距离），得岀待分类样本和全部 已分类的样本点中，距离最短的K个样本。
3在该K个样本点中，待测特征的值。根据k个样本中，待分类样本的数 学统计量，来判断把这个数据点定为什么类别。
其中K值选择比较重要。若选择的K过小，则训练样本集过小，随机误差 增大，导致最后的模型太狭隘，无法完成总体的分类任务；若选择的K过大， 极端情况下，和样本数一致，则导致所得模型太宽泛，没有合适运用部分样本的 有价值的信息去进行建模预测，只是简单比对样本在训练样本集中的类。所以， 在实际运用KNN算法时，选取合适的K尤为重要。可以对选取的K进行测试 比对，来确定最优值。
