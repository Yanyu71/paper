4.2.1数据采集模块
Storm本身不负责规定所要处理的数据来源，即Storm可以处理的格式可以 是多样的，例如日志文件、数据库、消息队列或者直接连接socket等。Storm的 输入多种多样，只要Spout实现相应的接口，即可从任何所需的地方获取数据。 然而，Storm也并非万能的，其处理文件格式存在一个问题：数据可能存在不同 的位置，不同服务器中，而Spout无法从多个来源获取数据。即使把所有数据集中到同一台机器上，则分配给Spout任务接口的并发度只能为1,无法发挥Storm 分布式的特点，因此，如何实现Storm处理文件的完全并行化是本系统要解决的 一个问题。本文采用在Storm前加一个Kafka消息队列集群的方案来解决Storm 获得多个源数据的问题。
Kafka的目的是提供一个发布-订阅模型的解决方案，它可以处理生产者产生 的所有动作流数据。这种流动作通常需要进行实时的处理，Kafka接收各种流数 据是比较可行的。生产者不断的将外部源数据读入消息队列，Storm作为消息队 列的消费者主动从消息队列拉取数据进行处理，实现Storm的实时消费。
使用Kakfa做消息中间件，将不同数据源的数据放入消息队列，Storm作为 消息队列的消费者来处理数据，这样做有几个好处。首先，解决了 Spout读取文 件不能并行化的问题。其次，这种结构可以很方便的使得不同的拓扑结构共享数 据源，提高了系统的可扩展性。再次，通过消息中间件Kafka,掩盖了外部数据 源格式的不一致性，实现了数据的归一化。最后，Storm提供了从Kafka读取数 据接口 KafkaSpout,减少了 Storm使用Kafka编码的复杂性，我们只需要实现 producer即可。虽然引入Kafka会增加整个系统的开销及复杂性，但是当数据量 达到一定程度时，增加Kafka集群而导致的系统的性能损耗是可以忽略的。数据 收集部分结构如图所示。
Storm集群
图4-1数据采集模块示意图
