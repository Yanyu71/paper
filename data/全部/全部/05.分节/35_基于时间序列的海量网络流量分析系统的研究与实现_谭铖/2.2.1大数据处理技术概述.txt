2.2.1大数据处理技术概述
Hadoop
Hadoop源于Google提出的GFS (Google File System),是谷歌公司为了存 储海量数据而设计的文件系统，后来由Apache开源而普及开来［8】。Hadoop是开 源的、分布式的并行计算框架，是海量数据处理的首选平台。Hadoop的核心是 HDFS (Hadoop Distributed File System)和 MapReduceo MapReduce 是一种编程 思想，即先将数据分块成多个独立的小块数据，再去对每个小块数据单独进行逻 辑运算囲，这样就可以极大的利用集群的资源，处理海量数据速度也非常快，体 现了 “分而治之”的思想。HDFS (Hadoop Distributed File System, Hadoop 分布 式文件系统)是容错性很高的文件系统，由于其部署成本低，易于维护，非常适 合用来存储海量数据。随着Hadoop的发展，也催生了一大批依赖于Hadoop的 工具，如基于Hadoop的Hive,非关系型数据库Hbase等。这些工具组成了 Hadoop 自己的生态圈，互相补充，共同发展。
HDFS由一个主节点Namenode和多个工作节点Datanode组成。Namenode 管理着文件系统的命名空间，维护文件系统树及其中的元数据。Datanode是文件 系统的工作节点，根据一定的调度规则存储和检索数据，并定期向Namenode汇 报。
Hadoop的框架决定了其适合处理海量数据的特性，但是其更偏重于吞吐量、 较高的响应时间、数据预处理较繁琐而决定其更适合处理离线的、静态的数据。 而对于要求实时性较高的场景，Hadoop表现则不尽人意。另外，如果计算要求 迭代或者循环，在MapReduce的计算模型下，很难确定结束时间，且对于吞吐 量也要求较高，故在此情景下，Hadoop也不是最佳选择。
Spark
Spark是由加州伯克利的AMP实验室提出的、类Mapreduce的计算框架。 由Apache开源以后，Spark发展迅速，由于其出色的大数据处理能力，现己得 到越来越多用户的青睐。
Spark是基于Hadoop MapReduce实现的算法，其拥有MapReduce的种种特 性和优点；不仅如此，Spark对MapReduce进行了改良，使Job产生的中间结果 保存在内存中而不是写入磁盘，从而减少了 HDFS读写带来的效率低下的问题， 使其计算速度比Hadoop更快。Spark这种计算特性也很好的解决了 Hadoop所不 能胜任的迭代计算和循环计算。
Spark拥有出色的处理大数据的迭代计算的能力，而数据挖掘和机器学习等 恰恰需要大量的迭代计算。因此，Spark是数据挖掘和机器学习的宠儿。Hadoop 只有单一的Map和Reduce两种接口，简单直接但是功能不多，有一定局限性。 Spark则有多种数据集的操作类型，这些操作统称为转换(Transfbrmation)。同 时也得益于多种操作类型，Spark各个节点间的通信也不只有单纯的Shuffle方 式。用户可以自定义中间结果的存储位置等信息，其编程有极大的灵活性，不受 编程框架的限制。
Spark的核心是RDD (Resilient Distributed Dataset),即弹性分布式数据集。 RDD是Spark特有的数据结构，其高容错性、高并发度的特点可以让用户方便 的进行数据的存储和分区。RDD只能通过已存储的数据集和其他已有的RDD确 定操作来创建，这样的动作即为Transformation.,实质上说，RDD只是一个不可 修改的记录分区的数据集。RDD定义了两种操作：转换(Transfbrmation)和动 作(Actions)。转换指根据现有的数据集来新建一个数据集，而动作指对数据 集进行运算后返回给程序的值。
Spark是基于内存的计算框架，这使得其速度极快，但是缺点也很明显，当 运行过程中断电或者死机，则数据将永远丢失。常规的解决方案是定期设置检査 点，根据日志进行恢复。总的来说，Spark是可能会是下一个大数据的技术宠儿。
Pregel
除了 MapReduce,谷歌还开发出了一种名为Pregel的新型计算框架。据说, 谷歌内部运行的数据处理程序，有80%的框架是MapReduce,剩下的20%用的 框架即为Pregelo Pregel解决了图论计算所需要的分布式共享内存问题，因此被 专门用来处理大规模的图论计算，例如网页排名，图遍历等。
Pregel采用的是Bulk Synchronous Parallel模型，即整体同步并行计算模型。 比较经典的Pregel运行步骤即：首先输入数据，然后把该图进行初始化，接着进 行超步运算，每一次的超步都是独立的，而且是全局的。循环计算直到整个计算 结束，输出结果。
在每一次超步运行过程中，本次的运行结果都能发送到下一次的超步运行开 始，这个过程中还可以修改其其自身的状态信息，包括以该顶点为起点的发散线 的状态信息，或变换整个图的拓扑结构。
Pregel框架很简单，用户所要做的就是针对图节点自定义计算逻辑即可，而 其他的一系列的任务分配、程序维护等均由Pregel系统封装实现。
集成框架YARN
纵观现有的大数据解决方案，如Hadoop, Storm和Spark等，虽然其都是大 数据处理技术，但是有其最适用的应用场景，并不是有单一的解决方案可以涵盖 所有需求。只有在合适的场景下，选用最适合的解决方案，才能完全发挥各种方 案的特点和专长。但是直接在一个集群上装Hadoop> Storm和Spark等，难免会 有所冲突，此时就需要有更高层的框架来将这些框架集成到一个集群中，使得资 源得以充分利用，运维成本也得以降低。Yahoo的YARN很好的解决了这个问题。
老的MapReduce框架在性能上有一定的瓶颈，受限于框架本身，其改变很 难。因此在Hadoop-0.23开始，MapReduce重新构建组成新的MapReduceV2, 也即Yam。YARN诞生的目的是为了修复MapReduce的不足和局限，并提升了 集群的可伸缩性、可靠性和资源利用率等。YARN的基本思想是，把Job Tracker 的两个主要功能，即资源管理和作业调度/监控四，拆分成了两个独立的进程单 元，也就是全局资源管理器RM和针对每个程序的应用主节点AM,应用指的是 MapReduce任务或者是有向无环DAG任务。
Yam的核心是资源管理器(ResourceManager)。RM控制着集群并管理着 集群资源的分配。RM和节点管理器(NodeManager)组成了数据的逻辑框架， 同时RM负责分配资源给NM[10]o NM与应用主节点(ApplicationMaster) 一起 分配资源，与NodeManager 一起执行和监控任务。NM则负责将资源的监控情报， 包括CPU、内存、硬盘、网络等情况，上报给NM和AM。
从某种意义上来说，Yarn已经不单单是MapReduce框架，其更是一种云操 作平台。MapReduce> Storm、Spark等均可以借助Yam共生于一个集群中，共 享数据及计算资源。
