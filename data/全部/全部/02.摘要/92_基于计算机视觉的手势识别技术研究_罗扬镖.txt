摘要
随着电子技术的飞速发展，计算机及智能设备走进千家万户，自 动驾驶及智能控制走进大众生活。在所有智能交互的方式中，手势识 别是最自然的人机交互逻辑。近年来计算机视觉等技术迅速发展，脱 离数据手套繁琐设备而采用摄像头简单设备的手势识别成为其主流 的应用方式。尤其是深度学习在图像识别领域展现出了强大的数据分 析能力，基于深度学习的手势识别技术成为了研究热点。
相比于二维图像，动态手势视频具有更高的数据量，其是一种更 具挑战性的手势识别分类任务，提取繁琐的手工特征在动态手势视频 中具有更大的难度和更高的应用成本。本文基于深度学习，研究动态 手势视频中手势时空特征的提取及其有效融合办法。针对手势时空特 征的提取，本文提出了基于膨胀卷积理论的时空多尺度特征提取。而 后通过卷积门控循环单元进一步融合动态手势的短期时空特征，并基 于此对卷积门控循环单元进行改进，提出压缩手势空间特征的门控循 环单元结构变体，减少模型参数量的同时提高了手势时序特征的融合 能力。
本文还进一步研究了 RGB-D两种数据模态下手势识别的技术方 案，针对手势识别过程中的手部检测及视频关键帧提取流程，本文提 出了基于视频输入的手势时空注意力机制数据处理方法，提高了模型 对视频中手部关键位置的关注度，同时将迁移学习的方法应用于RGB- D双模态的手势识别技术中，提升了单模态的手势识别精度以及双模 态的手势识别结果。
为了验证本文方法的有效性，本文在Jester和ChaLearn LAP IsoGD两个大型数据集上进行了多组对比实验及分析，结果表明本文 提出的方法解决了动态手势时空特征提取及融合的一些有效性问题， 在手势定位、单模态及双模态的手势识别中具有良好效果，获得了较 高的识别准确率。
关键词:手势识别;时空特征;注意力机制;多模态融合
RESEARCH OF GESTURE RECOGNITION BASED ON COMPUTER VISION
ABSTRACT
With the rapid development of electronic technology, computers and intelligent equipments have entered into thousands of households, automatic driving and intelligent control techniques close to public life. In intelligent interaction applications, gesture recognition is the most natural human-computer interaction logic. In recent years, with the development of computer vision technology, gesture recognition method which based on simple camera equipment and separated from data glove or other cumbersome equipments has become the mainstream application. In particular, deep learning technology has shown strong data processing ability in the field of image recognition, and gesture recognition technology based on deep learning has become a research hotspot.
Compared with two-dimensional images, dynamic gesture has a higher amount of data and it is a more challenging classification task. The more cumbersome manual feature extraction method has greater difficulty and higher application cost in dynamic gesture video. Based on deep learning, this thesis studies the extraction of spatial and temporal features in dynamic gesture video and its effective fusion methods. In order to extract spatiotemporal features, this thesis proposes a multi-scale temporal features extraction scheme based on dilated convolution theory and fuses the shortterm spatiotemporal features of the hand gesture through a Convolutional Gated Recurrent Unit. Futhur in this thesis, to improve ConvGRU, a variant structure of the ConvGRU is proposed by compressing the spatial features, which reduces the amount of learning parameters and improves the ability of the temporal feature's fusion.
This thesis further studies the RGB-D two data modalities gesture recognition scheme. Aiming at the hand detection and video key frame extraction process, this thesis proposes a data processing method which is gesture spatiotemporal attention mech-anism based on video input, improves the attention values of the model to key position of the hand in the video. At the same time, the transfer learning technique is applied to the RGB-D two data modalities, improves the accuracy of the singlemodality and dual- modality gesture recognition.
To verify the effectiveness of proposed methods, several groups of comparative experiments and analysis are carried out on two large public datasets, Jester and ChaLeam LAP IsoGD. The results show that the methods proposed in this thesis solve some effective problems in spatiotemporal feature extraction and its fusion methods, get a high performance in hand positioning, single-modality and dual-modality classification. And high recognition accuracy is obtained.
KEY WORDS:gesture recognition;spatiotemporal features;attention mechanism;multimodal fusion
