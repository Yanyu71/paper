第一章绪论
1.1研究背景及意义
1.1.1研究背景
提起智能客服，我们可以从科幻电影、电视和动画片中想到很多智能机器人 的场景，这些智能机器人掌握各个领域的知识，且能够精准地回复我们的问题。 但是真实情况下我们使用的客服系统常常是打入电话后一直在等待客服的回复； 在想要咨询的时候，在线客服己经离线；而就算接通了人工客服，也还有服务态 度差，服务水平不够的问题。
对用户而言，如果低质量的智能客服无法满足需求，我们就越倾向于拨通人 工客服，那么人工客服就更易出现忙线的情况；另一方面，对企业来说，招聘大 量人工客服也需要大量人力成本投入，对于一些中小型公司而言这样的成本支出 是不太现实的，但是业务扩展过程中，各个方向又会产生非常大的客服需求，如 果客户的需求得不到快速有效地满足，也会进一步阻碍企业的发展，总的来说企 业很难去把控这个动态平衡，因此无论是用户还是企业，都渴望智能客服，而且 尤其渴望能解决复杂场景能理解多轮对话语义的真正智能化的客服机器人。
自A^haGo在围棋人机大战后，大家对于人工智能关注量大幅提升。智能 客服作为未来人工智能的一个重要领域，其能给实际生活的方方面面带来巨大的 变革，极大地节省了人力资源成本。尤其是在任务型对话领域，该领域问题相对 具有针对性，易于回答，且问题的种类一般可枚举，同时对于客户而言也是最可 能产生问题的领域。
当下，智能客服的市场还处于起步阶段，但已经成为趋势，发展空间巨大， 随着技术积累及进步，必将广泛地应用到各个行业的业务场景中去。目前智能客 服的应用方式有三种：在线智能客服、热线端智能客服、实体客服机器人。本文 智能客服就指在线客服机器人。最早期的第一代智能客服机器人，只能称之为机 器人，是没有智能的一个简单的关键字应答系统，基于单个关键词的精确匹配， 比如简单电话的IVR,又如回复短信查询信息等。随后的第二代客服机器人有了 一定的进步，它是一个关键词检索系统，可以支持多个词匹配，并具有模糊査询 能力。这就让这个机器人能处理更多的问题，但是关键词的检索精准度依赖用户 搜索的精准性以及词库的存储，且无法联系上下文信息。随后出现的第三代智能 客服机器人，引入了 NLP（自然语言处理）技术。这首次让客服机器人可以处理句 子，而不是孤立的词。这个变化让人机交互变得自然了。然而单一的NLP技术 给机器人带来的智能化水准非常有限，它仍旧是依靠人工设定的规则。
第四代智能客服机器人主要就是基于深度学习技术打造的，以神经网络为基 础，应用最新的深度学习和模式识别等技术，打破了过去所有技术都依赖人工规 则的束缚，让机器暴露在数据中去学习、训练，自主的发现规律，学术上称之为 ，特征”。放到客服领域，深度学习带来的好处是，机器可以更好地适应用户口语 化、而且多变的问法，机器可以处理大多数的问题。
1.1.2研究意义
随着人工智能技术广泛应用于客服系统，目前许多行业领域都需要智能客服 去回答用户意图明确和频繁询问的问题。目前各个互联网公司都有智能客服系统, 且有结合硬件的智能客服语音系统上市，但是目前的智能客服存在语义理解程度 低，多轮问答效果差，语音系统回复机器化等影响客户体验的问题，且无法满足 特定领域进一步的优化需求，缺乏一整套成本低廉的解决方案。本项目本着利用 最新的理论研究成果，构建高智能的模型，实现一个高可用，效果好的智能语音 问答机器人，实现从语音到文字，文字到语音，语言到特色声音合成的一整套解 决方案，整套解决方案的优势和特点在于
1）	本文采用NLP研究中最前沿的注意力机制解决语句的向量化和关联预测 问题，能够更准确地理解整个句子的句意，可用于相同语义的句子理解和识别。
2）	采用意图-实体的提取策略，能够更精确地了解句子的意图和提取其中的 关键实体，让之后的处理具备精准的关键信息支撑；
3）	该系统通过插槽的办法可以将信息存储在插槽中，这样在多轮对话理解 的处理时，关键信息可以一直保持，从而实现多轮对话信息的理解。
4）	在语音生成模块采用成熟的端到端语音生成系统，能够高质量地完成文 字到语音的输出，且配合中文拼音的音调特征，生成语音更加自然真实。
5）	本文采用语音克隆的技术，通过在语音生成前进行音色的模拟融合达到 生成特定特色语音的效果，使得智能客服的交互体验更好更真实。
综上所述，本文提供了一种用于特定领域的，具备多轮对话语义理解和精准 回复的，同时能输出特殊音色语音支持语音到语音对话的智能客服系统，并能扩 展到各个垂直场景中，实现各个领域的智能语音客服。
1.2发展历史和国内外研究及现状
客户服务的概念来源于美国，最早在1956年由泛美航空公司推出客服中心， 用于客户机票预订。此后AT&T推出了第一个外呼中心主要用作电话的营销， 随后RockweH发明自动呼叫分配（ACD）,这种通过电话进行客服、营销以及 其他商业活动的服务形式才逐渐在全球被推广开来。智能机器人的历史最早可以 追溯到上世纪60年代出现的Eliza,智能机器人刚出现时只能做很简单的文字聊
2
天对话，且多用于大学实验室的研究项目没有用于商业活动；到了 20世纪90 年代，贝尔实验室和卡内基梅隆大学相继研发了对话机器人，实现了一些在线服 务功能如机票预订、汽车班次查询；从2002年开始，国际上一些公司意识到， 利用这种聊天对话机器人，可以提供无人在线客户服务，从而节省公司每月昂贵 的咨询热线电话费。因此，基于聊天对话的客户服务机器人诞生。2011年10月， 随着苹果公司iPhone4s手机的发布，其名为Siri的“个人语音助理”应用成为最大 亮点，并且引起了各界的重点关注。2018年，Amazon Connect利用基于AI技术 的Alexa虚拟助理为某家在线零售巨头提供处理联络中心的呼叫和短信服务。 Facebook在F8上发布Messenger's Chatbot Platform,希望用AI来帮助企业解答 用户问题。
90年代末，以呼叫中心为主的客服系统进入中国。而后，随着互联网、移 动互联网、云计算、AI等技术的应用普及，客服系统演化出多种形态。2006年， 国内出现了第一款真正商用意义上的智能客服机器人“海德先生”，它通过Web 网页为载体，提供实时的基于文字互动的科技政策咨询和业务问答服务，并且具 有较高的问题理解能力和回答准确率。时至今日，移动互联网、云计算、大数据 和AI技术的发展，已将传统呼叫中心和客服软件带入了智能化时代，企业通过 搭建智能客服中心，成本大大降低，产品功能更加丰富，应用场景也从客服延伸 到了销售、营销等多个环节。于此同时，智能客服机器人可以协助人工，回答简 单重复性的问题，大大提高了人工客服的工作效率。同时，AI技术也在各个环 节上改变了企业客服的交互方式，加速线上线下客服的智能化升级。而且随着 AI在客服领域应用的逐渐深化，智能客服机器人将为企业客户在服务、管理、 营销、销售体系带来更多的颠覆性变革。可以说，国内的智能客服行业，正在技 术不断发展的驱动下，从单一渠道向多个渠道，深度智能化的方向不断发展。如 今，智能客服的功能己经不单单是解决简单的问题，而是成为了企业方和客户都 需要的强大工具，能够解决一定复杂度的问题。
目前人们对智能客服也有了更多的期望和要求如希望加强人机交互能力和 客户体验，可以根据对话语境进行高准确率的多轮次自然语言理解，可以支持用 户随时打断，保证急切人可以及时灵活相应客户对话，对于打断句子进行二次分 析，优化话术内容；能够提供面向对话交互的可视化流程设计工具，根据场景的 变化自行调整话术流程及流程中的节点参数梳理；支持机器人对话实时监控和在 线学习知识库，系统工作人员可监控多路急切人的同事，在监控过程中可实时转 借给人工服务。
1.3论文研究的内容
基于目前智能客服发展的关键瓶颈问题，如多轮对话的信息存储和对话理解, 对于用户意图的精准识别，以及个性化的语音定制。本文依托机器学习算法着力 于研究对话意图识别，实体提取，多轮对话的语义理解和编码，个性化的实时语 音输出，完成一个端到端的可应用于具体业务场景的人工智能客服机器人，本文 主要以餐厅点餐的智能客服为例，保留高可扩展的结构系统，可以极低成本迁移 到其他领域。主要工作成果如下：
•搭建一个高精度的中文语言模型，包含分词和词向量化功能，为之后的 NLU模块提供向量化和分词支持。
•基于Rasa对话机器人框架NLU模块设计NLU流程负责多轮对话的语义 理解和意图的识别，实体的提取，并结合语言模型进行语句的向量化嵌入和引入 注意力机制编码对话语义向量为对话管理模块提供必要信息。
•基于Rasa对话管理模块和简单知识图谱结构构建对话管理系统，用于管 理对话的有序进行，决定机器人下一步的对话策略选择，且存储管理对话过程的 关键信息，并搭建高可扩展的结构。
•基于Tensorflow框架搭建一个高可用的端到端语音生成系统，并融入中 文拼音音调信息，使得输出音频更加自然和准确。
•结合语音克隆技术在语音生成前构建多音色的声纹识别模块，结合声纹 识别和嵌入语音生成的向量得到高相似度的语音克隆模型，为生成个性化的语音 生成模型提供技术支撑
•通过比对不同的声音梅尔频谱到真实语音的实时生成技术，在生成效果 和生成耗时上选择整体最优的方案提供实时地文字到个性化语音生成。
•基于前端react hook框架和后端python简易服务器框架实现可视化的界 面方便客服机器人的友好交互和展示。
1.4论文组织结构和内容
根据上述研究的内容，本文的组织结构安排如下
第一章绪论主要阐述了课题的研究背景、研究意义、研究现状、发展历史和 国内外研究现状；并且总体概述本文了本文的研究内容。
第二章是关键技术和相关理论介绍，首先介绍词向量模型，然后是解决多轮 对话问题用到的关键技术的介绍，接下来是对话管理模块关于对话的流程控制和 信息存储的介绍，最后是语音生成模块的语音生成技术、语音克隆技术、实时语 音声码器技术介绍。
第三章是对文中使用的模型选型研究，以及各个模块的设计，其中模型包含 SpacyNLP与自训练模型的选型，RasaNLU Pipeline选型、声码器MelGAN模型 与声码器WaveFtow模型的选型，模块设计主要包含前端交互界面设计、后台中 转请求处理模块的设计、RasaNLUPipeline构建，对话管理模块设计、语音生成 模块设计五个部分。
第四章是对第三章各个模块的具体实现以及各个模型的工程应用，详述整个 系统的搭建过程和其中具体的数据结构，也包括其中模型的训练参数细节、使用 的配置项的详细参数信息、简易知识图谱的配置使用信息。
第五章为整体系统的各项功能进行展示，各项技术指标进行比较讨论，对输 出结果展示和成果验证。
第六章为本文的工作的总结以及对未来工作的展望
第二章关键技术与相关理论介绍
本文设计的系统包含五个模块，其中RasaNLU自然语言处理模块和Rasa对 话管理模块基于中文词向量模型和Rasa对话框架进行搭建。个性化语音生成模 块基于Tensorflow深度学习框架、Pytorch框架和音频处理相关技术以及语音克 隆相关技术构建，最后可视化展示模块由前端框架React和TS语言构建，后端 请求处理模块使用Python语言和Abhttp包构建。本章主要介绍了各个模块的关 键技术理论的定义和原理。
2.1 Rasa对话系统构建相关技术
2.1.1 Rasa框架整体概览
Rasa框架主要包含Intent、Stories、Action、Entities和Slot五个核心概念， 其中Intent意图描述用户句子的行为指向，是整个句子的核心属性，由训练语料 中设置好可枚举的意图种类和数量，在数据处理中由意图分类器区分，Entities 表示句子中包含的实体信息，实体的信息由训练语料完成标注，在对话训练和测 试中由NLU中实体提取器进行提取；Slot用于缓存信息，可以为任何结构，一 般缓存实体信息，插槽属于理解上下文信息和存储上下文信息的关键部分，通过 将实体或关键结构进行插槽的存储并在后续对话中展示，能够实现复杂场景的多 轮对话；Stories指具体的对话语料场景信息，是完整的一个交互流程，可以通过 自定义流程的方式来设定对话的交互流程，也可利用交互的方式通过实际和客服 机器人对话产生训练的语料信息作为一个场景；本文主要依赖于RasaX的可视 化对话驱动开发，在真实对话中得到对话场景数据，并作为新的训练语料o Action 是对话管理模块中具体执行的逻辑代码块，可以根据识别的实体信息，slot信息 和意图来做具体的逻辑处理，本文中自定义了点餐机器人的逻辑处理Action部 分并结合简单的Json知识图谱来完成一些复杂的交互任务。达到真实场景可用 和好用的水准。整体的执行流程如下图2-1


图2-1整体流程图
其中用户输入信息先流向NLU的处理模块通过分词向量化后将用户的意图识别 并提取用户输入中包含的实体信息，填充到插槽中，并把当前上下文信息存储在 信息跟踪器中，通过对话管理模块中的策略执行响应的动作执行器，执行器中可 以通过信息跟踪器提取当前对话上下文的插槽信息、实体信息和意图信息，然后 执行自定义的处理逻辑，同时可以改变当前信息跟踪器中的插槽信息，推动对话 继续进行和相关状态信息的更新，并能输出应答语句。
2.1.2 Rasa NLU Pq)eline
Rasa NLU Pye line是由一系列组件通过线性连接的方式实现数据处理的完 整流程。具有高扩展性低耦合各个组件均可插拔的结构，p/eline主要包括以下 部分
•分词器：主要完成特定语言的分词工作，本文采用Spacy自带的分词器， 功能与Jieba分词器类似，可以将中文按词语进行序列化分词。
•向量转换器：主要负责将分词后的输入序列进行向量化的转换，本文采 用Spacy的预训练语言模型进行词向量的转换。
•实体提取器：负责将语句中的声明实体进行提取，本文和插槽进行对应， 主要采用依赖于训练语料的实体提取器、同义词实体提取器、正则表达式实体提 取器等实体提取器，为后续的对话管理提供实体信息并配合插槽的设定，存储上 下文中的关键信息，从而实现多轮对话的信息联动，帮助机器人客服处理更加复 杂的场景任务。
•意图分类器：主要依据上述步骤中的向量化信息和实体信息进行用户语 句意图的分类，由于本文着力于垂直特定领域的任务型对话系统，所以用户意图 属于可枚举型数据，能够将意图全部归类，并在需要时后续增加意图数量。
本文中采用预编译的Spacy流水线推荐格式和自建的流水线格式进行各项 指标的对比分析，并采用最优的方案构建整个流水线结构。
2.1.3 Rasa Policy
Rasa Policy决定在对话的每个步骤中应采取的什么动作，主要接受信息跟 踪器追踪的上下文插槽信息，意图信息，同时为后续对话执行器部分提供支持, 主要的策略如下
•最长历史长度：可以控制模型查看多少对话历史记录，以决定下一步应 采取什么动作，由于整个对话长度可能很长，需要记录和包含的上下文信息很多， 这个长度设置可以规定最长的对话回溯，减少训练耗时，更集中在最近的几次交 流中，同时设置太小也可能丢失重要信息，使得多轮对话的意图识别判断和后续 的动作执行准确度不够。
•数据增强：训练模型时，Rasa Core自身具备增加语料信息的能力，它 通过将stories场景语料信息进行组合从而得到更长的stories语料信息，例如两 组对话场景即使发生在两次对话中，也可以通过组合在一起形成一个新的对话场 景，由此可以解决语料信息不足，对话场景少的训练时问题，增强后的stories在 训练之前会进行二次抽样，因为它们的数量会很快变得非常大，也会影响训练耗 时，所以该属性的调整需要根据实际情况制定，本文中采用默认的数据增强产生 的stories为已知stories数量十倍来平衡训练语料数量和训练耗时。
•动作选择：在进行意图识别时，无法保证识别结果百分之百的正确，所 以需要配置一个最低置信度标准来判断是否进行预设的回答。该策略就是通过一 个置信度来确定是否需要往前回滚，通过再次提问得到一个更准确的用户提问消 息。
2.1.4 Rasa Action
Rasa Action为Rasa框架中动作执行器部分，主要基于信息追踪器的上下文 信息以及对话策略预测的最终意图来真正执行相关逻辑代码，其作为一个单独的 动作执行服务可以单独部署执行，与NLU部分以及策略选择部分隔离开，并提 供接口给NLU模块调用，做到结构上的高度解耦和可定制化，其也是最终做出 对话反馈的模块，能够直接返回回复对话，并能改变插槽中的值来改变信息追踪 器的状态信息，从而影响对话的继续进行。
多轮对话的一个常见问题是，在前文已经提及的对象实体，在后文的提问中 我们会省略该实体信息，这就可能导致信息的丢失，如询问菜品的口味是不是辣
8 的之后再询问价格就不会再带上菜品的名字，这个时候我们就需要信息跟踪器提 供的信息及插槽中存储的信息，结合知识图谱将这些解析为正确的对象。另外， 用户可能希望在对话过程中获取特定领域的信息，例如，点餐系统中询问菜肴的 名称，询问菜品价格贵不贵。为了满足这些跟领域相关的请求，我们的智能客服 系统需要一些预先相关的知识储备。而且这些信息可能增加和减少，因此硬编码 信息不是一个很好的解决方案。为了应对上述挑战，Rasa可以与知识库集成。 要使用这种集成，需要创建一个自定义的知识库对象继承自Rasa提供的模板对 象，并且重写相关的逻辑代码，也可以增加一些自定义的功能。
2.1.5 Rasa X
一直以来对话机器人面对的一个难点问题都是语料的获取和标注，尤其在任 务型对话领域，由于需要结合实体和意图识别，需要标注的地方也特别多，但是 其实对话机器人最不缺乏的就是真实的对话场景语料，只是在真实的场景对话中 没有完成标注任务无法直接变成需要的语料来进行重复训练，而Rasa X解决的 正是直接采用对话的方式驱动模型语料的获取，只需要事先标注好少量对话场景 语料，就可以启动带有可视化界面的对话框来跟机器人进行对话，同时自动提取 对话语句中识别的意图和实体提取信息以及当前状态信息和插槽信息，如果发现 机器人当前提取或者判断的信息有误可以直接在当前页面进行修改操作，最后将 整个对话场景数据一键保存为新的对话情景stories中的一个story语料，用于之 后模型的优化训练，并能将机器人临时发布出去搜集真实用户的对话情况进行简 单处理后生成新的可以训练的语料，真正实现对话驱动开发的目的，解决对话机 器人尤其是任务型对话机器人对话语料难以搜集和标注的问题。
2.2个性化语音生成系统相关技术
为了使得智能客服机器人的回复以及应用场景更加贴近生活和个性化，本文 着力搭建一个高精度的个性化语音客服，主要包含端到端语音生成梅尔频谱模块, 梅尔频谱转换为真实语音输出模块以及满足个性化定制需求的语音克隆模仿编 码器模块。其中端到端语音生成梅尔频谱模块主要负责将中文文字转换为梅尔频 谱本文主要使用工业上高可用的开源tacotron2模型，梅尔频谱转换为真实语音 主要采用信号处理的格林方法以及MelGAN深度学习方法，语音克隆的实现参 考《Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis》⑴中关于编码器部分的改造，来实现少量的音频文字数据就能实现语 音克隆的效果。
2.2.1端到端语音合成Tacotron2
Tacotron是第一个端对端的TTS神经网络模型，我们将文本信息输入，
9
Tacotron可以输出梅尔频谱信息，我们通过一些声码器模型或者算法就可以将梅 尔频谱信息转换为波形。论文《Tacotron: A Fully End-to-End Text-To-Speech Synthesis Model》⑵中模型的总体架构如下图2-2所示：


图2-2 Tacotron整体结构图
总体来说，模型和sequence-to-sequence模型非常相似，大体上由encoder和 decoder 组成,raw text经过 pre-net 和 CBHG两个模块映射为 hidden representation, 之后decoder会生成me 1-spectrogram frame。所谓CBHG就是一种用来从序列中 提取高层次特征的模块，其中使用了卷积+highway+残差链接+双向GRU的组合， 输入序列，输出同样也是序列。输入被CBHG处理之前还需要经过pre-net进行 预处理，而pre-net预处理网络的意图是让它成为一个bottleneck layer来提升模 型的泛化能力，以及加快收敛速度。在解码器方面使用了两个decoder:： attention decoder 和 output decoder, attentron decoder 主要使用 query vector 作为 attention 的输入，然后依赖注意力模块生成context vector,最后output decoder则将query vector和context vector组合在一起作为输入。
2.2.2语音声码器Vocoder
Wcoder声码器模块属于语音合成的最后部分，其基本的工作为将梅尔频谱 信息转换为语音波形信息，语音波形还原的质量和生成时间依赖于具体的声码器 算法或者芦码器模型，本文采用独立训练的方式探索了传统信号处理和音频处理 的griffin-lim方法、生成式深度学习模型MelGAN以及神经网络模型WaveFfow 来比较和选择生成语音质量最好且能满足实时性输出要求的模型，其中 griffin-lim方法为传统的信号处理方法，不需要模型的训练，生成语音质量比较 高，但是最大的劣势在于生成时间较长，如果有实时性语音生成需求该方法很难
10

适用，而另外两种声码器模型能够较快较好地还原语音波形，但是需要搜集大量 的语音数据，需要经过一段时间的训练，在模型的泛性上肯定也没有直接的信号 处理方法好，其中MelGAN是基于GAN生成对抗网络实现的，整体结构不难 理解就是由生成器和判别器组成，整体结构如图2-3所示：

图2-3 MelGAN整体架构图
在图中可以看到，MelGAN生成器的输入是声音的频谱图，输出是频谱图对 应的音频，MelGAN生成器并没有使用全局噪声矢量作为输入，当额外的噪声馈 送到生成器时，所产生的波形几乎没有感知差异。之后的模型选型情况将会在下 文详细介绍。
2.2.3语音克隆编码技术
如果要满足个性化语音的生成，采用传统的训练模型的方法需要搜集大量的 个性化语音数据，而特色语音训练的语音模型也不易迁移训练到其他的语音模型 上，如果要实现多种的特色音色模型那么前置工作将会非常巨大。语言克隆技术 的理论核心在于通过改造原语音生成模型的编码器部分，实现一个声纹识别的模 块，将单音色的语音模型改造成接受多音色输入的多人语音模型。该模型数据来 源更加广泛且易于搜集，模型虽然对于多人音色效果不能达到最佳，但是保留了 声音的基本特征，后续只需要搜集少量的特殊音色数据通过迁移训练的方法就能 得到高品质的特殊语音生成模型。其整体的结构为图2-4：
11


图2-4克隆编码器结构图
图中包含了两个编码器，一个是用于区分输入语音声纹特征并生成声音潜在 特征向量的语音编码器，另一个为语音合成器本身的编码器。这个两个编码器在 进入注意力神经网络前进行了一次组合，将用户音色特征向量嵌入到了原生的编 码器模块中，随后在注意力神经网络中经过序列到序列的映射网络，生成对数梅 尔频谱，然后将该频谱交给声码器vocoder部分转化为声音波形，完成语音的合 成。
2.3前端和服务端技术
基于本项目需要一个前端的演示及必要的调控界面，需要用到网络前端技术, 其中主要会使用React前端框架以及TS语言来搭建前端界面。使用后端的 Abhttp库来搭建后端的服务器部分，同时使用前端基于React的Antd组件库来 搭建高度组件化的页面结构，保持高度的内聚性和低耦合度，同时方便以后进行 扩展。
2.3.1前端React框架
狭义来讲React是Facebook内部开源出来的一个前端UI开发框架，广 义来讲React不仅仅是JS框架本身，更是一套完整的前端开发生态体系,React 框架特点主要包含
•组件的组合模式：简单地说组合模式的概念即为组件之间的组合关系构 建，既降低了组件间的耦合度，又提高了组件的复用性，可以通过不同组件的组 合来构建一个完整的应用。
•单向数据流的设计：React的单向数据流的设计让数据的流动唯一，一 定是从父组件流向子组件，复杂度低，理解简单，页面的UI和数据的对应是唯 一的，我们可以通过定位数据变化就可以定位页面展现问题。
•高效的性能、为实现高效的性能React通过设计Virtual DOM算法，可 以让只有需要改变的元素才去重渲染，降低了渲染频率，增加了整体页面的渲染 效率。
12
•分离的设计：Reactjs现在的版本已经将源码分开为ReactDOM和 React.js<>这就意味着React不仅仅能够在web端工作，甚至可以在服务端 (Nodejs) , Native 端运行。
2.3.2 TS 语言
TS是强类型，面向对象，编译型的语言。同时TS是JS的超集，TS能编译 成普通的JS。换句话说，TS等于JS加上一些额外的特性。TS的特点主要包括
•编译：JS是一门解释型语言。因此，需要跑起来后来测试它的正确性。 这意味着你写了所有的代码后即使有错误也不会有任何输出(来告诉你)。然后， 你可能要花很长时间来查问题。TS编译器提供了错误检查的特性。如果发现某 种语法错误，TS将编译代码并生成编译错误。这有助于在脚本运行前就暴露错 误。
•强静态类型:JS不是强类型的。TS通过TLS(TypeScrqit Language Service) 提供可选的静态类型和类型推断系统。TLS能够推断出无类型变量的类型。
•支持已有的JS库的类型定义：TS的描述文件(以.d.ts扩展名结尾)能 够为现有的JS库提供描述。因此，TS能够引用这些库。
• TS支持面向对象编程概念：能够完整地支持类、接口、继承等面向对象 的编程概念，实现更加结构化的代码组织。
2.3.3 Ant Design 组件库
Antd是属于Ant Design设计体系的React UI组件库，主要用于研发企业 级中后台产品。主要特点为
•基于React前端框架构建，可以无缝融合react框架的应用场景
.•给出了框架的同时也给出了设计规范，其包含了丰富的组件资源，可以 快速构建出页面应用，同时也提供了如头像，图标等常用设计元素的直接使用。
• Antd组件库大范围地使用，己经具备大量的用户社区和实践经历，基于 此搭建应用可以更加方便地解决开发中遇到的问题以及学习到较为成熟的实践 方案。
2.3.4 Aiohttp 后端库
Aiohttp是一个异步的Python网络请求库，其充分利用Python的异步特性， 能够快速地搭建客户端和服务器，足够轻巧没有大框架部署的复杂度，但功能强 大，能够完成一般服务器后端的路由分发，高并发，静态资源跳转访问等一系列 功能，本文使用其能够快速搭建起服务端程序用于与前端的交互，以及与Rasa 服务器、语音生成模块的交互。
13
2.4本章小结
本章重点介绍了设计和实现系统过程中需要使用的理论和关键技术。主要包 括Rasa的NLU模块、对话管理模块，动作服务器模块还有Rasa X模块的技术 原理介绍。也包含了语音合成部分的生成模型、声码器模型、多人语音编码克隆 模型的结构和原理介绍，最后介绍了工程上前后端的使用的技术和框架，将本文 用到的所有技术和框架都做了介绍。
14
第三章系统的设计
本章在第二章技术分析和介绍的基础上，阐述了餐厅语音智能点餐机器人的 需求内容、总体架构的设计，各个模块详细的设计。
3.1设计需求分析
3.1.1用户需求分析
根据项目背景，从用户侧分析，现阶段越来越多的信息服务产生，使得用户 在网络上因为各种不同平台产品的使用或者反馈都需要跟客服进行沟通，但是现 实情况是人工客服接入难而现今的智能客服过于简单化无法满足拟人化客服的 需求，以点餐服务为例，用户需要大量时间浪费在排队上或者需要在手机或其他 终端服务上点选的操作完成整个点餐结账过程，所以一个能够通过语音交互就完 成整套流程的智能客服尤其重要。
一般来说，用户会关注与智能客服交互界面的简单易用、多轮对话中客服对 关键信息的准确理解以及智能客服的语音足够拟人化易分辨。综合上述信息用户 需求归结为下面几个方面，其基本结构如图3-1所示：
(1) 文本对话
用户可以通过类似与人的沟通交流方式与智能客服进行文本的交流，能进行 多轮对话不丢失关键的上下文信息，并向智能客服要求提供各种服务时，智能客 服能准确理解按用户要求执行相关逻辑来完成用户需求。
(2) 语音输入
用户可以通过语音的方式与智能客服进行交流，智能客服能将用户语音转换 为文本信息并理解其需求通过执行相关逻辑完成用户需求，同时其能和文本的交 流交叉进行，不打乱整个交流过程。
(3) 特色语音的选择
用户可以自由选择一种喜欢的语音音色作为智能客服的输出语音音色，同时 特色语音的输出必须保持其吐字清晰和与选择音色高度匹配，满足用户的个性化 需求和及时性要求，并能控制输出语音消息的播放和暂停。


禺笙对话信恳提取

语义理解i


{
上下文伍言综合亘解
语言结果



执行要超腰务


回复消息显示




语音输出控制.



暂停

音色选择
特色语音需求


图3-1用户需求图
3.1.2界面需求分析
系统界面作为普通用户与计算机交互的唯一媒介，界面使用情况也作为了用 户评价系统的标准。本文对界面提出以下要求：
(1) 简易型
界面的简洁可以让用户便于理解、使用，可大大减少用户发生错误选择的可 能性。
(2) 一致性
界面结构保持清晰且所使用的术语、风格与界面内容、界面色调字体均保持 一致性。
(3) 及时性
界面的交互要求及时响应并重新渲染界面，无明显卡顿和响应失效。
3.1.3系统需求分析
(1) 可扩展
随着后期需求的变化与增长，所以在开发过程需要考虑如何应付这些后期变 化。针对本系统，需要考虑采集端支持Windows、Linux系统，需要考虑预测分
16 析模块中模型的更新和替换问题，需要考虑预测结果具有多个程序需要使用的问 题。需要考虑各个模块依赖项的版本详细信息，生成依赖项文本，方便迁移部署。
(2) 健壮性
在系统处理的过程中，有可能其中一个模块偶尔发生错误，不能让这种错误 影响到整个系统，所以各个模块需要分别单独部署为服务，之间解耦合，可以相 互调用，必要时对易出错模块进行备份部署。
(3) 配置分离
各个系统模块的执行和相关配置参数要完全分离，方便观察各种不同情况下 系统的各项功能情况，更好的及时调整和测试。
(4) 准确性
本系统的多轮对话部分需要准确地理解用户语义和回复最相关的信息并能 准确地执行基于语义理解的相关命令，同时语音生成模块需要吐字清晰无歧义， 语速适中，音调高度拟人化。
3.2系统总体设计
3.2.1系统目标
本系统深入研究垂直领域的任务型对话系统业务痛点，解决多轮对话，智能 对话驱动服务、特色语音模拟输出等难点问题，使用了 Rasa框架结合逻辑服务 器及知识图谱用于搭建文字对话系统，应用Tacotron2作为语音合成模型，并结 合语音克隆技术解决特色语音小样本量的迁移学习，使用MelGAN声码器模型 和WaveFtow声码器模型调优语音波形生成并满足语音输出的实时性要求。
3.2.2智能客服机器人总体架构
本系统属于多模块组建的高度解耦系统，各个模块之间高度解耦只存在必要 的调用关系，且互不干扰，本文系统的层级结构如图3-2所示：
17




前端视图展示
前端业务层
丈子制入
对话展示
切换音色
语奁录入
语音转换文字
修正
语音消息播
放










后端中转层
Rasa对话服务器交互

前端请求接收路由

语音生成服务器交互
后端业务层v



数据处理
与模型持久层V
Tacotron 2 语音合成模 型
图3-2智能客服机器人系统层级架构图
•前端视图层：主要为视图显示用到的前端技术，这里包含了用到的React
框架以及Ts语言和开源的前端样式库AntiDesign来完成基本页面样式的呈现。
•前端业务层：包含了前端包含的业务功能点，这里主要是一个基本的聊 天框的设计，所以功能上包含了基本的文本输入、气泡信息的显示、特色语音音 色的切换、语音的在线录音、语音识别文字信息修正和语音回复消息的播放功能，
18 这里的功能实现依赖于后端的数据提供所以同时用到了 Axios异步请求库用作 和后端交互的基本库。
•后端中转层：主要是接收前端的信息请求，进行正确的路由，然后和文 字处理Rasa模块进行交互得到文本的回复信息，再通过和语音生成服务器的交 互得到文本到语音的信息，最后将信息整合返回给前端模块。
•后端业务层：实际处理前端的用户请求服务，主要分为RasaNLU对话 理解模块理解本轮对话通过Rasa Action对话处理服务器具体处理应对逻辑，使 用Rasa策略执行器模块实现对话策略的处理以及对话管理模块管理整体对话的 关键信息插槽和重点上下文信息。在语音生成的处理上主要包含特殊音色模型的 切换和中文语音的实时性生成。
•数据处理和模型持久层：包含了系统运行过程中调用的数据和模型，这 里也是主要包含了对话管理的知识图谱数据信息、对话上下文管理的插槽信息、 中文音调的信息、中文分词器的使用、语音合成模型Ihcotron2模型的使用和 MelGAN等声码器模型的调用。
•数据采集和模型训练：包含了训练各个模型使用的数据集和模型的训练 办法，其中主要有自编的智能点餐对话数据、RasaX对话驱动产生的数据、特 色语音自录音的数据、公开数据集的语音数据（包含了清华大学加thchs3O数据 集和AISHELL-3高保真开源数据集）。模型的训练方法主要为从零开始的监督 训练以及基于现有模型的迁移训练。
上文介绍系统的整体架构，下图3-3展示了系统各个主要功能模块的协同工 作模式以及数据的流动方向
19


图3-3智能客服机器人系统交互流程图
•前端交互界面：前端交互界面负责完成智能客服机器人的交互任务，提 供可视化交互友好的前端页面并能完成文字消息、语音消息、特色语音选择等功 能。
•后台中转请求处理服务器：后端请求处理服务器负责将前端请求拦截并 进行处理，连接对话处理模块和语音回复生成模块，属于后端逻辑业务展开连接 算法模型整理结果以及与前端界面请求交互的关键模块。
• NLU对话理解模块：NLU对话理解模块负责处理单句对话的语义表达 解析。通过预训练或者自训练词向量模型进行语义解构，再通过实体提取器进行 实体的提取以及使用意图分类器进行单句对话意图的分类，并将结果信息整理给 对话管理模块进行下一步处理。
•对话管理模块：对话管理模块主要负责依据NLU对话理解模块传递的对 话中实体信息、意图信息以及存储在上下文中的插槽信息依据对话回复策略决定 调用Action对话处理服务器生成可能的回复信息并返回给后端服务器。
• Action对话处理服务器：Action对话处理服务器主要负责依据对话管理 模块传递回来的信息进行具体的逻辑判断，并使用或者设置上下文的插槽信息调 用底层知识图谱信息来生成最相关的回复，传递回对话管理模块。
•对话回复策略：对话回复策略依据对话管理模块配置的相关信息进行策 略的选择，并根据Action对话处理服务器返回信息进行相应的策略处理，如回
20
退策略和置信度过低的默认回答策略。
• Rasa X可视化对话蜩J交互界面：Rasa X可视化对话驱动交互界面是 Rasa框架的重要组成部分，是对话驱动产生新的训练集的可视化版本，能够通 过友好界面的交互来产生新的对话数据，并能及时在交互界面中进行修改使得产 生的对话数据符合预期的逻辑，并将其作为新的训练语料加入下一轮的NLU训 练。
•语音回复生成模块：语音回复生成模块主要负责将文本的回复转为生成 语音波形，其中构建了 Iacotron2模型以及在其基础上增加了一个用户语音编码 器用来编码语音音色特点，实现小样本的语音克隆，并釆用了多种声码器算法或 模型来保证语音生成波形的高质量和快速。
3.2.3智能客服机器人系统流程
结合智能客服机器人的总体架构设计,该系统运行的整体流程如图3-4所示， 图中编号代表这个模块运行的步骤。
1) 训练离线模型，离线模型的训练包含Rasa NLU模型和Rasa对话管 理模块的模型训练，以及语音合成模块语音生成模型和语音声码器模型的训练， 所有模型训练均先训练完成再投入系统使用使得在系统运行过程中能直接调用 训练好的模型进行预测。
2) 前端接收用户输入，可以为文本输入或者为用户语音信息的输入， 如果是语音输入调用浏览器支持的前端语音识别模块将其转换为文字输入并传 递给后端服务器。
3) 后端服务器得到前端回传的文字输入信息传递给Rasa NLU模块进 行语句语义的理解得到语句中包含的实体信息和意图信息。
4) 对话管理模块根据实体信息和意图信息以及上下文保存的插槽信息 生成可能的回复，和更新上下文存储的插槽信息，并依据对话管理策略进行后续 的处理，最后生成回复的文本信息。
5) 语音生成模块根据回复的文本信息和选择的输出音色实时生成语音 信息，保存在本地作为静态资源，并提供给前端交互界面调用。
21

图3-4系统运行的流程图

3.3模型选型
结合3.2小结介绍的系统总体设计以及第二章介绍的各个模型，本节将详细 介绍系统模型选型和设计。本章主要包含词向量模型的选型、RasaNLU自然语 言理解模型选型、语音声码器MelGAN声码器模型以及WaveFfow声码器模型以 及传统算法选型。同时在进行各个模块的具体设计前介绍了使用的数据集情况。 3.3.1 Rasa NLU P^eline 构建
RasaNLU P feline模型采用链式结构完成整体NLU模块的训练。具体包含：
1）	基础词向量模型：主要完成输入文本的预处理，包含分词和向量化。
a. SpacyNLP词向量预训练模型：预训练的词向量模型已经使用了大量的 文本语料进行训练，具备很丰富的向量化能力且提供分词和向量相似度比较等功 能，釆用预训练的词向量模型能够满足大部分需求将文本中词汇较准确的转换为 向量。但特定场景的语义理解不够精准。
b. 自训练的词向量模型：采用自训练的监督模型能够更好地支持特定使用 场景词法语法，在数据量足够时能够更加精准适配，但需要大量的训练数据来完 成词向量模型的训练。
2）	实体提取器：用于提取实体过程中的实体识别。
a. CRFEntityExtractor实体提取器：通过定义一个模型，接受Sapcy预训练 模型中词向量部分来向量化的结构输入，然后通过观察句子中目标词的文本特征
22 以及周围单词来识别实体，可以是前缀、后缀、目标单词的大小写，如果是数字 等，还可以用此模型的POS标记功能。CRFEntityExtractor将令牌作为输入，提 供一个输出（句子有哪些实体，是什么样的实体，对预测的信心如何），该输出 直接添加到NLU模型。
b. Spacy Entity Extractor实体提取器：spacy模型除了词向量生成外还带有实 体提取器，但是该实体提取器中实体的命名结构和实体跟模型训练时候的标注紧 密相关，不利于自定义扩展，但好处是不需要再参与复杂的训练，默认情况下利 用已知的POS和其他功能在训练示例中定位实体。
3）意图识别器：意图识别器能够识别一句话中的用户意图，为后续对话处 理提供意图信息。
a. KeywordlntentClassifier关键字匹配意图识别器：将训练数据的整句话都 作为关键字，去搜索用户说的话。因此写配置数据的时候，仔细设计那个训练数 据很重要，关键字不能太长，这容易匹配不上意图，也不能太短，缺少意图的区 分度。其匹配模式较为死板不够灵活不能发现相同语义的不同表达，但比较简单， 易于构建。
b. DIETClassifierDIET 模型：Dual Intent and Entity Transformer 的简称，解 决了对话理解问题中的2个问题，意图分类和实体识别。DIET使用的是纯监督 的方式，没有任何预训练的情况下，无须大规模预训练是关键，性能好于 fine-tuning Bert,但是训练速度是bert的6倍。输入是用户消息和可选意图的稠 密或者稀疏向量。输出是实体，意图和评分。DIET体系结构基于两个任务共享 的Transformero实体标签序列通过Transformer后，输出序列进入顶层条件随机 场（CRF）标记层预测，输出每个Token成为BIOE的概率。完整话语和意图标 签经过Transformer输出到单个语义向量空间中。利用点积损失最大化与目标标 签的相似度，最小化与负样本的相似度。
c. SklearnlntentClassifier意图识别器：采用SVM支持向量机来做意图识别， 该支持向量机采用了网格搜索来进行优化，该意图识别器可以利用预训练的 Spacy模型中的词向量化特征器SpacyFeaturizer,在结构和训练耗时上比 DIETClassifierDIET意图识别器有较大优势，且充分利用了已有资源。
结合第一章的项目背景分析和本系统的技术背景，基于本项目自训练语料数 据不足以支撑庞大的词向量模型监督训练和实体提取跟训练文本紧密联系，本文 选用Spacy的中文词向量预训练模型作为基木词向量模型来将文本转换为参与 训练和预测的词向量，同时本文的应用场景下，实体的提取跟预训练模型中的实 体标注出入较大，参考Rasa框架官方推荐和结合小数据集的特点，本文选用 CRFEntityExtractor作为实体的提取器参与整体NLU的训练和预测，结合训练耗
23
时以及和前面词向量模型配合的需要选用SklearnlntentClassifier作为意图识别器 模块。
3.3.2声码器模型选型
声码器作为声音波形生成的关键部分，能够利用频谱信息生成对应的波形, 其中也包含了传统的Griffin-Lim声码器，也包含机器学习算法模型的MelGAN 和WaveFlow等声码器。
1) Griffin-Lim声码器：Griffin-Lim是在仅已知幅度谱、不知道相位谱的条 件下重建语音的算法。算法的实现极其简单。它是一个迭代算法，首先初始化一 个相位谱然后将这个相位谱和已知的幅度谱经过ISTFT变换，得到一个语音波 形，接下来对这个合成的波形进行SIFT变换，得到新的幅度谱和相位谱，最后 丢弃新的幅度谱，用相位谱和己知的幅度谱合成语音，如此重复。
2) MelGAN声码器：MelGAN是Lyrebird基于GAN框架设计的Neural \bcoder 模型，其基本的构建参考论文《MelGAN: Generative Adversarial Networks for Conditional Waveform Syntitesis》卩］
该模型采用了轻量级的架构设计，通过结合GAN框架和空洞卷积将模型的 训练压力转移到判别器上，保持了生成器部分的轻量，加速了整个推理的过程。
其基本的结构包含四层上采样层、残差空洞卷积块和判别器，其中上采样层由反
卷积构成，虽然参数量大，但实际是起到辅助作用；残差空洞卷积块的结构如图
3-5所示


在图中可以看到该卷积结构将三个DHation为3的空洞卷积层相互堆叠组成
空洞卷积块，可以看出其感受野为3的三次方，即前后相关27个点。然后把嵌
入残差结构的空洞卷积块，再堆叠三次，从而得到最后的卷积结果；判别器部分 是该模型训练的关键,MelGAN的判别器部分采用多尺度判别器通过多层的下采 样计算最后的得分。实际操作十分简单，就是用三个输入频率尺度不同的判别器,
打三次分，三个判别器的输入分别是正常采样率语音，下采样过一次的语音，下
24
采样过两次的语音。
3）	WaveFfow声码器:该模型在WaveGfow基础上采用了更小的生成流来对 原始语音进行建模，采取了最大似然估计的方法进行训练。同时提供了针对一维 数据的似然模型的统一视图。生成语音效果可以达到WaveNet, WaveFlow模型 的水准，与此同时取得了高达几个数量级的提速。论文《WaveFfow:A Contact Flow-based Model for Raw Audio》⑷中介绍相比 WaveGfow 小了 15 倍。在单 VI00 GPU上，可以生成22.05 kHz的高质量音频，提速42.6倍。
本文同时使用了 Griffin-Lim声码器算法，并迁移训练了 MelGAN声码器模 型和训练了 WaveFfow声码器模型，结合本系统音频输出清晰自然和实时性的两 个需求，基本选用了 Griffin-Lim声码器算法和MelGAN声码器模型作为本文的 声码器选择，后续章节将会详细说明训练的细节以及相关数据的对比。
3.3.3数据集说明
数据预处理的作用一般有去除重复值、处理缺失值、特征编码、数据标准化 等，如果在高维特征的情况下，还需要降为处理。结合本文实际情况，主要数据 采集分为NLU模块需要的对话语料数据和训练语音合成模块以及声码器模块的 语音数据。
1）	NLU模块数据集：由于采用了预训练的词向量模型，所以不需要训练一 个庞大的词向量模型结构，训练需要的数据均由垂直领域的点餐机器人根据情况 进行模拟数据构建。
2）	语音合成模块数据集：通过剪辑声音的方式搜集了周星驰语音信息数据 250条，总计时长25分钟左右，并通过录音方式搜集了本人声音数据200条， 共计时长20分钟。
3）	声码器训练数据集：使用了搜集的周星驰语音数据和自录音的语音数据、 清华大学30小时普通话语音数据集zhthchs30以及AISHELL-3高保真开源数据 集用于进行MelGAN声码器和WaveFbw声码器的训练（由于清华大学的数据集 音频清晰度不够，主要应用在语音识别，而声码器和语音合成对语音质量要求更 高，所以采用部分高保真数据集进行迁移训练，再用特色语音进行迁移训练）。
3.4系统各个模块设计
结合3.2小结，本系统分成了成八个部分，其中除了 RasaX作为Rasa框架 集成的交互式对话驱动管理模块，不需要代码实现之外，其余的各个模块都需要 代码实现和结构构建。由于Action服务器和策略选择模块跟对话管理紧密相关， 将其也归入到对话管理模块中进行设计阐述，所以，本小节将分成前端交互界面 设计、后台中转请求处理模块的设计、RasaNLU Pipeline构建，对话管理模块设
25
计、语音生成模块设计五个模块进行介绍。
3.4.1前端交互界面设计
前端交互页面是整个系统启动后执行的起点，也是最后执行的终点，承担了 和用户交互完的任务，需要做到简洁易用，与后端分离且连接通信，完成数据传 递、语音和文字消息显示或播放、录音转文字的功能。模块的整体功能设计如图 3-6所示


图3-6前端显示设计图
在设计时将前端交互的界面分为了文字输入框，工具栏和显示框，其中，文 字输入框接收纯文字的输入；工具栏主要包含清空对话（或者叫重启对话），选 择输出音色（本文除了基本的标准音色外还特别训练了周星驰及本文作者本人的 声音音色）以及语音的输入（通过调用前端的语音识别库转换为文字输入）；显 示框负责显示文字类型或语音类型的信息，进行渲染显示，模拟生活场景中常见 的显示方式，包含头像，气泡框，位置区分等细节，整体显示达到自然清楚便于 阅读的目标。具体的设计如下
•文本输入框：接收文本输入，为了减少不必要的更新，在输入时候不对 页面节点进行改动，只有当回车键按下时候触发一次更新，并使用异步请求方式 将输入文本传递给后端，同时将输入信息存储在前端列表型数据结构中，在触发 更新时，显示框读取列表结构将新输入内容展示在页面上，其基本模式如图3-7
26

所示:


图3-7输入框组件执行逻辑图
•信息显示框：类似于一般聊天软件的显示框界面，包含文本和语音消息 的显示，用户消息和机器人回复的区分，主要在感知到前端列表存储结构中的内 容变化触发了页面节点更新时，进行重新渲染更新，基本的样式如图3-8所示：
你好啊
— :;1……I $





你好,
请问有什么需妾帮 忙的瞬？
图3-8前端显示框基本样式图
其中包含基本的匿名人物头像、机器人头像、扬声器等图标样式和气泡对话
框样式，通过遍历列表结构中的信息显示在界面上，所以列表结构中的每条数据
27 应包含是用户还是机器人消息的区分，属于文本消息还是语音消息的区分以及文 本消息对应的消息文本信息和语音消息对应的语音文件url信息。同时语音消息 需要支持播放和暂停功能作为基本的控制。
•选择工具栏：的工具栏部分包含三种基本工具类型，清空对话按钮、选 择音色输出以及语音录入和修正工具，其基本的样式原型图如图3-9所示：

男声 女声
垂严 周星驰 作者本人
我要点f決饭

■■■■Mi
图3-9前端工具栏基本样式图
其中清空按钮只是将列表存储结构中数据清空，触发重新渲染时会让显示框 无数据显示，音色选取列表通过与后端进行交互得到可选择的音色信息，点击选 择后信息存储在前端，不立即对后端模型进行改变，采用懒加载方式。音色录入 工具在前端调用麦克风录入语音消息并调用前端的语音识别模块将语音信息转 换为文字信息并生成输入框可以进行语音识别后的文本修改，最后修改后的信息 会添加到列表存储结构中触发新一轮更新。
3.4.2后台中转请求处理模块的设计
后台中转请求处理模块主要负责将前端传递的文字消息传递给RasaNLU和 Rasa对话管理模块进行语句的理解和返回消息生成，然后将文字回复传递给语 音合成模块，带上选择的音色信息，并将生成的静态语音文件地址和文本回复信 息再回传给前端，完成一个对话流程。综合上述分析，得岀后端处理模块的架构 如图3-10所示。
28

回传文字回复

图3-10后端请求处理模块功能设计图
本模块目前不需要考虑大量请求高并发的情况，重点需要关注回复消息的及 时性，以及和其他各个模块的连接通信的可靠性，本文实现采用同一局域网中各 个服务器部署，在连接可靠性和传输延时上均理论上能够得到较好的保证，但是 具体的性能指标是否满足需求需要后续的测试来证明。同时，该模块由于涉及到 和RasaNLU模块以及语音合成模块的后端http通信，整体系统的稳定性需要得 到验证。
3.4.3 RasaNLU模块设计
本模块的设计图如下所示，该模块基于Rasa框架搭建，将NLU处理详细的 流程分解，并单独配置，达到解耦合和可插拔的使用目的。其接收的文本消息来 源于后端请求处理模块转发的前端输入文本消息，其主要包含了 NLU模型训练、 单轮文本信息理解和重要信息提取以及后端服务器接收文本消息等功能。其文本 信息处理的p^Hne流程图如图3-11所示。
29

輪入文本

实体信息和意图信息

图3-11 RasaNLU Pipeline模块设计功能设计图
该p5)Iine构建基于前文中对于pip line各个功能部分的分析选型，结合本文 实现的点餐机器人系统这一垂直任务型对话领域的特点选用预训练的Spacy中 文词向量模型，其来自官网的基本性能数据如图3-12所示。
30
Accuracy
Type
Score
TOKEN_ACC
97.88
TAG_ACC
90.38
DEP_UAS
70.82
DEP_LAS
65.60
ENTS_P
73.71
ENTS_R
69.20
EFMTS_F
71.38
SENTS_P
78.25
SE忖TS_R
72.72
SENTS F
75.38
图3-12 Spacy模型基本性能参数图
其中UAS （未标记的附件分数）和LAS （标记的附件分数）是评估依赖性 分析的标准指标。UAS是正确分配头部的令牌的比例，LAS是头部已被正确分 配正确依赖标签（主题，对象等）的令牌的比例。UAS=a心节点正确的词数/ 总词数*100%, LAS=核心节点正确且依存关系也正确的词数/总词数*100%。 ENTS-P>ENTS-R和ENTS-F是NER任务的精确度、召回率和圧core。TAGS-ACC 是POS标记的准确性。TOKEN-ACC是令牌细分的精确度。
对于同义词实体提取器的作用主要在于一些实体并不是只有一种说法，而实 体识别本文采用了在训练语料中自己标注的方式，而训练语料的数量完全不足以 支撑训练一个包含词向量相似度的模型（这也是采用spacy预训练模型的原因）， 我们使用一个同义词实体提取器来弥补一些近义词的识别（当然也是基于任务型 对话场景范围小，基本可列举的特点来安排）。
本模块也包含了模型的训练，使用Rasa自带的训练器对pq）eline中的实体 提取器和意图识别器进行训练，语料来源于自模拟的点餐机器人语料，包含的实 体和意图信息也是可枚举设定好的，如需要加入新的实体和意图信息，需要修改 配置文件和增加语料的形式将新的实体和意图加入NLU的处理（本文针对的是 垂直的任务型对话机器人领域，所以实体和意图一定是可枚举的，不是开放型的
31
问答型客服）。
本文的实体设置依托于点餐机器人的应用场景，主要的实体围绕点餐的菜品 展开，包含菜品的名称、菜品的属性名称、菜品的价格等信息，同时跟知识图谱 的信息对齐，保留一定的扩展性要求方便之后的扩展。具体的设计图表如下表 3-1所示。
表3-1实体设计表
实体名称.
实体类型
实体介绍
菜品名
字符串数组
用于表示具体菜品（因为单句 中可能不止一个菜品实体出 现）
菜品属性名
字符串
用于标识菜品的属性（包含烹 饪方式、价格、口味等特征）
价格
数字
表示菜品的价格信息
口味
字符串
表示菜品的口味特征，主要包 含甜、辣、咸等口味
菜品类型
字符串	’
用于标识菜品的种类，如主食 类，酒水类、炒菜类、干锅类 等
除了实体的识别设置之外，关于菜品的数量识别也是一个难点，因为点餐行 为是会带上数量词的，而中文输入的数量词需要转换为阿拉伯数字类型的数量词, 且和菜品实体进行对应，因为数量词有非常多种表达，不可能穷尽可能，这就需 要一个数量词提取的模块在进行句子语义理解的时候辅助实体提取，本文采用了 一个简单算法来实现这样的功能，基本的流程如图3-13中文数量值转换阿拉伯 数字算法流程图所示。
32



图3T3中文数量值转换阿拉伯数字算法流程图
首先在处理之前，需要设置一个个位的映射表｛零:0, — ：1,二:2,两:2,三： 3,四：4,五：5,六：6,七：7,八：8；九：9｝以及一个常见的高位映射基础值映射 ｛亿:100000000,万：10000,千：1000,百：100,十：10,个：1,碗：1,份：1,杯：1｝, 通过遍历句子中的字符将在两个表中找到的中文字符连起来得到一个连贯的中 文数量值表示，然后将该中文数量值从低位开始遍历，也就是从各位开始遍历， 使用个位映射表中的对应数值乘以高位基础值映射表中的数值就能得到该进位 的值，整体遍历得到整个中文数量值的阿拉伯数值表示，然后整体句子中所有的 中文数量值遍历得到了一个包含了整个句子所有数量值的数组。且先后顺序为句 子中的出现顺序。
关于意图的识别基于前文的模型选型讨论选择了更适合本文应用场景的 Sklearn意图识别器，该意图识别器充分利用了之前Spacy预训练词向量模型的 向量化生成器使用向量机算法SVN就能完成意图的识别工作，在构建复杂度上 也比较轻量级。
33

3.4.4对话管理模块设计
Rasa对话管理模块紧接着RasaNLU模块，负责处理的是对话上下文信息的 管理和最终回复的生成，本模块为生成文字回复的关键模块，其中Action服务 器负责的为需要用到上下文插槽信息和知识图谱结构信息的意图，而简单的意图, 如问好、再见等无需经过该服务器复杂处理，直接调用写好的模板结构输出即可。 这里主要的结构如图3-14所示。


图3-14 Rasa对话管理模块功能设计图
依托Rasa框架已有的基础能力，可以生成固定句式的回复，所以本文在实
现的时候将简单的闲聊语句使用固定的句式来回复，对于复杂的句式则需要依靠
34

Action服务器来进行更细致的处理，这里的一些基本设计分析如表3-2所示。
表3-2意IS
类型设计表
意图类型
意图回复类型
意图语料示例
意图描述
问好
简单回复
你好、你好啊
简单的开场问候语
再见
简单回复
再见、拜拜
简单的结束语
询问菜品属性
Action服务器处理回 复
米饭的价格是多少？
询问具体菜品的具体 属性
验证菜品属性
Action服务器处理回 复
干锅鸡是辣的嘛？
验证具体菜品的属性
点餐
Action服务器处理回 复
我要点一碗米饭
核心点餐功能
取消订单
Action服务器处理回 复
少要一碗米饭、不要 米饭了
取消某项菜品具体数
量或整体取消
结账
Action服务器处理回 复
老板，结下账
表明结账意图
菜品推荐
Action服务器处理回 复
你们这里都有什么辣 的菜啊
询问带属性的菜品信 息（也可不带属性）
默认回复
简单回复

意图识别失败时的兜 底回复
其中主要包含了闲聊部分、用餐部分和默认回复三个部分，闲聊部分就是上 表中的基本问好和结束等可以用固定回复来处理的简单情况，用餐部分的意图需 要用到Action服务器来处理，这个下文会详细介绍，最后就是关于意图识别失 败或置信率太低导致的默认回复，通过再次询问能让用户提供更详细信息，这里 也是简单的固定回复。
Action服务器是为了处理复杂的问句而必要的逻辑处理模块，依托于前文中 介绍的RasaNLU模块对于句意的理解、实体的提取和意图的识别，该服务器的 主要工作就是在已知意图和单句实体的情况下，管理上下文的插槽部分，对关键 的上下文信息进行存储和更新，并能在需要的时候提取出来，生成符合要求的回 复文本，其基本的逻辑处理包含了单句的信息和上下文信息整合、关键信息的存 储更新、回复的生成三个部分，其基本的流程图如下图3-15所示。
35



图3-15 Action服务器处理流程图
如图可以看出点餐机器人回复部分主要还是分为了三种情况，一种是关于单
个菜品的信息回复，这里包括了询问菜品的属性、验证菜品的属性等意图，生成
的回复模板为将菜品名、属性名以及属性具体数值留空的一个模板，只需要传递
进去这三项就能生成该回复。第二种回复模板为多个菜品回复模板，包括询问有
36
什么菜品，推荐菜品等意图，处理时需要列举出满足条件的所有菜品信息，所以 传入的参数应该为需要满足的条件（当然也可以不包含条件表示列举出所有的菜 品）。第三种回复模板为依据插槽中已有信息将多个菜品的某项属性一起展示， 本文实现的只有结账的意图使用该回复模板，将己点的菜品数量和菜品的价格以 及所有的总价进行输出，未来可能根据需要进行扩展使用，这里不需要再传入额 外信息，因为信息已经在插槽中保存完整。
作为Action服务器后备数据支撑的知识图谱构建也是设计的重要环节，这 里本文采用Rasa框架推荐的做法采用代码结合Json文件的方式构建一个小型的 知识图谱系统，首先基于本文点餐机器人的应用背景，需要对应设计出各项菜品 作为本文的实体，其中每种菜品的基本属性结构结构如下表3-3所示。
表3-3知识图谱实体属性表
知识图谱实体属性
实体数据类型
实体描述
唯一标识ID
数值类型
用于唯一标识菜品
口味
字符串类型
标识菜品的口味，如甜、咸、辣
菜品类型
字符串类型
标识菜品的烹饪方式，如主食、干锅
价格
数值类型
标识菜品的价格，用阿拉伯数字表示
菜品名
字符串类型
标识菜品的中文名称
可以看出这里的知识图谱实体设计跟Rasa NLU实体设计有很多重合的地方, 但是在RasaNLU模块中还有额外的如菜品属性的设计，这也是为了方便和插槽 相互配合，如果在插槽中存储有之前询问的菜品属性名称那么后续的对话出现了 询问其他菜品的问法时，如询问“那XX菜品呢？，沱样明显的属性询问意图时， 可以直接调用存储的菜品属性名称生成对应的回复，而在知识图谱的标识ID的 作用是为了作为除了名称外更便于存储和区分的属性。
除了 Json文件中的实体信息外，整个知识图谱还需要构建一些函数来支持 Rasa对话管理模块的调用和处理，同时和该模块形成高度解耦的结构方便以后 扩展到需要数据库上层的代码也可以不用改动，将必要的东西封装在知识图谱的 内部，这里主要需要考虑重点函数如下表3-4所示。
37
表3-4知识图谱基本函数表
函数描述
传入参数信息
输出参数信息
初始化函数，完成知识图谱 系统的初始化
初始的配置信息或配置文件地 址等必要的初始化信息
无
加载函数，载入具体的数据 信息
Json文件地址
无
设置显示属性函数，设置该 实体对外显示时使用的属性
实体名，属性名
无
设置唯一标识函数，设置该 实体的唯一标识属性
实体名，属性名
无
获取属性函数，得到该实体 的所有属性值
实体名
属性名列表
获取多个实体对象函数，获 得该实体类型满足条件的多 个具体对象
实体名，属性列表
实体对象列表
获取单个实体对象函数，根 据实体唯一标识获取具体的 单个实体对象
实体名，标识属性具体值
单个实体对象
上表展示的知识图谱基本函数可以看出与本文中使用的实体菜品其实是高 度解耦的，未来在添加额外的任务型对话场景系统时，也完全可以用到这样的知 识图谱，只是具体的Json文件有变化，同时，如果实体的对象数量或者属性非 常多，非常复杂，也完全可以脱离Json文件的构建方式在加载函数里面通过调 用数据库驱动的方式直接从数据库完成初始化加载，在获取信息和设置信息里面 也可以添加上对于数据库的操作。针对特别的系统需求还可以通过改变初始化函 数的方式做到更好的适配性和灵活度。
3.4.5语音生成模块设计
语音生成模块是最后合成语音输出的地方，其主要的技术点和模型已经在 上文详述了，除了基本的语音波形生成外，还涉及到了和后端中转层中转服务器 的交互，关于后端处理部分，本文的这部分的设计主要在于当语音合成服务器后 端接收到前端的文本信息后选择对应的模型并进行文本的预处理通过模型生成 语音的梅尔频谱再将梅尔频谱传递给声码器模型用于生成语音波形信号文件，存 储在服务器静态目录下后将文件的地址信息传给请求发送方，也就是后端中转层 的请求中转服务器。除此之外还涉及到语音克隆的编码器部分以及关于中文文本 信息转换为音素的处理，模块的整体结构如图3-16。
38



图3-16语音生咸模块结构图
本模块之所以会加入用户语音的额外编码器向量嵌入，是依据语音克隆论文
《Tians伦r Learning from Speaker Verification to Multispeaker Text-To-Speech
Synthesis》的思路，使用多人语音先训练一个音色编码器可以解决单独个人大量
语音语料难搜集且难扩展的问题，且多人语音的训练模型比单音色模型包含的信
息更全面，对迁移训练的支持更好，本文用一个预训练的多人对话的音色编码器
39 结构可以得到一个初步的包含了声音处理特征的语音生成模型，后续对特色语音 的训练只需要做迁移的训练就能达到克隆语音的效果，只需要搜集少量的语音信 息就能生成逼真度高的语音模型，同时本文没有使用Tacotron2文中使用的声码 器，而是单独自训练了 MelGAN和WaveFlow声码器模型目的是保证语音的质量 和即时生成速度，当然也对比了传统的信号处理算法，最后输出的波形文件地址 传递回后端请求处理模块，使得前端界面能引用静态资源链接的方式播放生成的 音频文件。
用户语音区分编码模块其实是一个类声纹识别的模块，主要完成的工作是将 声音波形转换为向量格式，其配合Tacotron2模型的编码器将编码信息嵌入组合 达到将音色信息融入的效果，使得Tacotron2模型能够训练多人语音数据，这样 就解决了单人语音信息不足声音特征覆盖不全面的问题。其基本的结构如图3-17 所示。


图3-17用户语音编码器模块神经网络结构图
该神经网络构建比较简单，主要先由一个ktm长短时神经元将波形信息进 行信息的存储功能，再有一个线性全连接层映射到需要的向量空间，由relu激活 函数完成向量的标准化激活，最后通过一个线性回归的相似矩阵similarity_matrix 完成回归分析，最后由多分类交叉矯损失函数cross entropy loss完成损失函数 的迭代更新，整体功能就是一个具备一定记忆性的多分类神经网络。
40
在前文中介绍了 Tacotron2模型，但是该模型其实处理的是字母型语言文本 到音素表示再到向量化输入最后参与训练得到梅尔频谱，但是中文文本需要将汉 字首先分词再转换为对应的拼音表达，且需要结合音调信息最后做为字母的输入 传入整个模型参与训练。这里关于中文的处理本文设计采用了 jieba分词器完成 分词工作，同时中文转为拼音，按照清华大学方案转为音素，分为辅音、元音、 音调。英文全部大写，转为字母读音。英文非全部大写，转为英文读音。标点映 射为音素。其基本的处理流程如图3-18所示。


图3-18中文文本转换音素流程图
如图中所示，中文文本首先会通过Jieba分词器进行中文的分词，本文釆用
的是默认的分词词库，然后会将每个词汇依据中文词汇与拼音的对应映射表转换
为拼音字母，再将拼音字母进行辅音元音等分割通过查询对应的映射表将拼音转
换为音素，最后查询音素在映射表中的下标索引将其转换为id值，将所有id值
41
整合在一起就构成了一个向量化的输入，该输入可以作为lacotron2模型的输入 进行同英文一样的训练。
同时，因为要既要训练Tacotron2语音合成模型又要训练声码器的神经网络 模型，需要考虑在生成梅尔频谱的时候采用相同的算法，这样才可以比较好地整 合在一起，在训练的时候对于可能出现的训练时长太长问题，也需要进行数据的 一些预处理，例如提前将梅尔频谱的向量和用户音色编码器输出的向量存储为文 件，在模型训练的时候只需要将该向量文件导入就可以在内存中直接处理。
3.5本章小结
本章开始部分结合背景介绍和相关技术进行了系统的需求分析，然后介绍系 统的总体的需求分析、模型的选型设计、以及各个系统模块的设计。其中需求分 析包括对于用户使用上的需求分析、界面的需求分析以及系统的需求分析，模型 选型部分介绍了 Rasa NLU P^eline选型、声码器模型的，之后介绍了数据预处 理部分的设计，最后介绍了各个系统模块的设计结构和设计方法，系统模块的设 计分成前端交互界面设计、后台中转请求处理模块的设计、RasaNLUPfeline构 建，对话管理模块设计、语音生成模块设计五个部分进行介绍。
42
第四章智能点餐客服系统的实现
本章结合第二章介绍的技术以及第三章的结构设计，结合智能点餐客服这个 垂直任务型对话领域进行具体的实现，其中包含了 RasaNLU模块的实现、对话 管理模块的实现、语音合成系统部分的实现、前端展示部分的实现以及后端处理 部分的实现。
4.1 RasaNLU模块的实现
该模块主要采用python语言依赖Rasa相关库开发，主要负责的工作是配置 文件的设置、实体和意图的分类设置、初步对话语料的模拟生成、pipeline流程 的搭建。整体架构的设计如前文中叙述，如第三章中pyline构建选型设计那样， 这里选用了最适宜的词向量模型Spacy模型、Sklearn意图分类器、CRF实体提 取器来构建。
4.1.1实体和意图设置
本文演示的为智能点餐客服机器人，所以实体的设置和意图的设置也围绕点 餐的场景展开，基于第三章中对于该部分的设计思路，本文在是线上设置的实体 包含类型如表4-1所示。
表4-1实体设置表
实体名称
简单说明
objecttype
标识具体的服务类型，本文只有菜品dishes 一个类型，后续可能扩展新的服务。
attribute
标识菜品的各种属性，如价格、烹饪方式、 味道特征、名称等，可扩展添加。
dishes
标识单句对话中识别的菜品的名称数组，因 为点餐可能一次点多个
dishtype
标识菜品的细分类型，如炒菜、酒水、干锅、 主食等
taste
标识菜品的口味，如辣、甜、酸、正常等口 味
price
标识菜品的价格，以具体数字显示
有了上述的实体类型，在具体的每句对话中都可以进行相应的实体提取，支 持后续的扩展。所有的上述实体也同时作为插槽存在，这样提取的实体可以直接 存储在插槽中且可以在后续逻辑中再改变到插槽中，这一部分在后面的对话管理 模块中会详细叙述。

43
除了实体外，本文使用的意图如下表4-2所示。
表4-2意图设置表
意图名称
简单说明
gree t
简单的问好意图，直接使用固定回复。
bye
离开再见意图，属于基本的闲聊回复不需要 调用Action服务器来进行逻辑处理。
abo ut
询问客服基本情况意图，属于基本的闲聊回 复不需要调用Action服务器来进行逻辑处 理。
need_help
召唤客服意图，统一回复为“请问有什么需 要嘛？"不需要调用Action服务器处理。
want_ordei
点餐前表达点餐意愿的意图，统一回复为 “请问您想吃什么？ ”不需要调用Action服 务器处理。
order_dishes
点餐意图，需要调用Action服务器处理，得 到具体的菜品和数量值。
check__order
结账意图，需要调用Action服务器处理，结 合上下文插槽得到共计点餐情况。包含点餐 的菜品和对应的数量。
get_info
获取具体服务的整体情况意图，主要与 object_type相关，需要调用Action服务器 处理。
verify_attribute
验证意图，本文中为验证菜品的某项属性值 是否和问句匹配。需要调用Action服务器处 理。
get_attribute_info
询问属性意图，本文中为询问某菜品的属性， 需要调用Action服务器处理。
ask_for_price
询问价格意图，和询问属性意图询问价格属 性相同，但不包含"价格"这个attribute 实体。需要调用Action服务器处理
cancel_order
取消点餐意图，包含取消的菜品和数量，也 可取消全部菜品，需要调用Action服务器处 理。
default
为无法识别的意图提供兜底，再次询问用户 情况，无需调用Action服务器处理。
上述意图能够比较完善地总结一个点餐流程的各种需求，除了应付基本的闲 聊意图，能够完成一个询问、点餐、取消、结账的完整过程，同时更细化地做到 能询问到某个菜品的某项属性，点餐和取消点餐精确到具体数量，并能对询问价 格做无具体实体的意图兜底，提供无法识别意图的兜底回复让对话更流畅。
4.1.2训练语料产生和配置
本文针对实现的为智能客服点餐机器人，所以训练语料也根据垂直领域进行

设置，其基本的格式如图4-1。


图4-1训练语料标注格式图
其中可以看到“酒水”标注为实体dish_type,用于实体提取器直接提前并 设置对应插槽，而“喝的”其实在句子中意思同“酒水”所以这里标注使用同义 词的标注方式，这里是基于前文叙述的使用了同义词的实体提取器来实现的，在 训练语料中通过人工标注的方式，不再额外做声明，Rasa框架的NLU模块就会 自动将同义词的实体提取归类到一起，在识别的时候同样能进行识别。
同时，在训练语料的格式上可以看出，同样的意图可以有非常多种的表达方 式，这就为之后的扩展和模型训练调优提供了比较好的基础，当然对于一些简单 的意图语句其实是没有实体存在的，如图4-2所示。


图4-2无实体标注训练语料格式图
这里的bye、about和defeult意图就是简单的意图分类语句，不需要实体的 提取就能完成识别，每种意图也有多种可能的问法语料，其回答其实也是简单的
45
文本回复，不需要用到Action服务器来处理。
除了意图的语料外，本文中Rasa NLU模块的训练语料还包括了场景story 语料，该语料即是对一个对话场景的归类，可以理解为一个完整的对话流程语料, 基本的格式如图4-3所示。


图4-3对话情景训练语料格式图
如图中所示，一个完整的对话场景是由意图和回复动作来共同构成的，比如 order a dish这个对话情景，首先是用户表达了一个获取菜品信息的意图，然后机 器人进行实体提取和意图识别后交给Action动作服务器处理，这就完成了一轮 的对话，接下来用户表达了一个点餐的意图，机器人按之前相同的步骤提取了实 体和识别了该意图后交给Action动作服务器处理，然后机器人再执行一个默认 的消息回复，这两轮的对话就构成了整个情景的对话。我们用很多的对话场景语 料就能让机器人学会在点餐客服这个领域可能出现的各种对话情况。
4.1.3模型训练和指标评估
值得说明的是，实现本文的主体功能，会针对每个意图都设置相应的问句语 料并进行标注，但是并不是对每个实体的具体值都进行标注（那样的话认为的标 注会耗费大量时间，也不利于扩展），Rasa NLU在进行训练时，是针对于实体 类型的训练，不是针对具体实体值的训练，即如果一句训练语料出现了“酒水” 这个具体的dish_type实体值，在训练时就等同于训练了所有dish_type的实体值 （包括“主食”和“干锅”等实体值相当于也有了这样的训练语料），这样就大大降 46
低了对于训练语料的数量要求，只需要针对每个实体类型模拟几条语料即可。同 时，关于对话场景语料的训练也是由许多的小对话场景可以自由组合而成的，这 样我们只需要将对话场景细分到最小，在训练时Rasa框架就能将这些对话场景 进行多次组合生成更多轮的对话场景，其基本的组合逻辑如图4-4所示。

意图语咪斗二	意图语料三	意图语料四

图4-4意图训练语料自动生成图
可以从图中看到一条意图语料就可以涵盖该实体所有值的训练，这样大大减 少了我们需要手动写入的语料数量而且有很好的扩展性。
和意图的语料自动生成一样，对于对话场景的语料其实也有相应的生成办法, 可以通过将多个场景组合的方式生成更多轮的对话，构建出更复杂的对话情景， 当然如果对话场景的组合非常多对于训练的开销也会非常大，所以这个需要根据 实际情况进行灵活地调整。
自动生成一样，对于对话场我们将pgeLine构建好以后对所有的其中的实体 提取器和意图识别器进行训练，其中两个部分的参数都使用Rasa框架的默认参 数，采用交叉验证的方法来评估NLU模型（这样可以比较好地评估模型的泛化 能力避免单个验证集的过拟合）将所有语料分为训练集和测试集，其中训练集占 80%余下的为测试集，得到的CRF实体提取器训练后测试结果如图4-5所示。
47


80
60 -
Entity Confusion matrix
MB hits
■■■ misses
s(D-dEes jo」<vqLunN
40 -
20 -
0
0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00
Confidence
图4-5实体提取器测试集效果图
图中可以看到，训练好的实体提取器在测试集上表现为高置信度的实体提取 正确占了绝大多数，而错误的案例基本属于低置信度导致的提取错误。关于意图 的识别器效果跟实体提取器类似，如图4-6所示。
48










































图4-6意图识别器测试集效果图
从图中可以看到意图的识别效果在错误的示例中与实体提取器有相同的规 律，主要是在低置信度下导致的识别错误，但是正确的识别分布没有集中在高置 信度下。
而具体的指标参数如表4-3所示。
表4-3 RasaNLU模型指标数据表
模型名称
数据集
Accuracy
Fl~score
Precision
Recall
CRF实体提取 器
训练集
0. 992
0. 982
1.000
0. 972
CRF实体提取 器
测试集
0. 969
0. 908
0. 955
0. 854
Ski earn 意图 分类器
训练集
1.000
1.000
1.000
1. 000
Sklearn 意图 分类器
测试集
0. 902
0. 876
0. 888
0. 851
上表中的Accuracy表示整体模型的精确度，即正确识别数量/样本总量,
49 Precison表示在模型的准确度，即正确预测数量/预测总量，这里的正确识别数量 表示在预测为该实体或意图的条件下正确预测的数量，而预测总量则是预测为该 实体或意图的总量，Fl-scores是Precision/Recall,而Recall召回率表示正确预测 数量/实际总量，这里的实际总量为真实为该实体或意图的总量，而正确预测数 量与Precision意义相同。从数据值可以看岀模型的准确率和召回率在测试集相 对训练集有一定劣化但是劣化的程度不大，整体模型的指标比较好，理论上达到 了预期，后续的实际效果展示也证明了这一点，在后续章节会再详述。
4.1.4 Rasa NLU后端业务服务
RasaNLU模块在部署上是单独的一个服务，这个在前文己经介绍了，这里 本文在实现上利用了 Rasa框架自带的服务启动函数，以服务器的方式开放后端 端口，并对后续的对话管理里模块中Action动作服务器进行对接，我们以5005 端口启动服务器，只有一个业务接口 focalhost5005/webhooks/rest/webhook地址 留出，提供给后端中转服务器将前端的文本信息传递调用，同时，RasaNLU的 服务器和Action服务器对接。基本的流程如图4-7所示。
50



图4-7 Rasa NLU后端服务图
如图中所示，整个后端服务非常简单，在接收到后端中转服务器消息后调用 已经训练好的NLU模型对文本中的实体进行了提取，并对意图进行识别，然后 将信息传递给Action动作服务器由该对话管理模块生成具体的服务再由Rasa NLU模块将信息回传给后端中转服务器。
4.2对话管理模块的实现
对话管理模块紧跟着RasaNLU模块，是处理具体对话逻辑和维持对话上下 文信息，实现多轮对话管理的关键模块，本模块使用python语言和Rasa库实现， 主要包含Action服务器的执行逻辑和对话策略的配置。
4.2.1 Action服务器实现
这里的Action服务器为处理对话的核心模块，负责管理、修改插槽和依据 RasaNLU模块提取出的实体和识别的意图做逻辑处理，本文实现的Action服务 51
器为智能点餐机器人相关逻辑处理，首先关于插槽的设置除了之前提到的实体都 有对应的插槽外，额外设置的插槽如表4-4所示。
表4-4补充插槽表
插槽名称
简单解释
ordered_dishes
存储整个对话已经点好的菜品信息，为键值 对结构，键为菜品名称，值为数量
last_attr
存储上次对话的菜品属性值，如果本次对话 不包含属性值则采用该属性值替代
补充插槽不在实体提取时候自动设置而是由Action服务器处理对话逻辑时, 在必要的地方设置来保证对话上下文的正确和实现多轮对话。
Action服务器作为一个单独的服务器模块接收对话的信息同时也调用了知 识图谱模块来完成对话上下文的逻辑处理，其主要也是按意图进行驱动，这里简 要列举其基本的执行逻辑和功能如下。
• verify attribute：验证属性信息（如口味，价格信息），调用知识图谱存 储结构读取对应实体的属性信息，然后生成回复返回。由于这里的属性信息可能 来源有多种情况，包括来源于本句话中的实体提取，包含了值的实体提取以及对 于历史存储的实体提取，基本的判断流程如图4-8所示。
52



图4-8询问菜品属性流程图
如图中所示，在识别到意图为跟菜品属性密切相关的verify_attribute>
get attribute info以及ask_ft)r_price意图时，都会走到这里的函数逻辑，首先会
用到dishes插槽中的值来表示询问属性的菜品名称，然后优先选择有值的属性通
过遍历知识图谱得到具体的属性名，如语句，辣不辣”中通过“辣”这个具体值推理
53
出需要询问的菜品属性为口味，其次如果语句中attribute插槽本身有值则直接使 用该值作为属性名，最后会依据插槽Jast_attr当做询问的属性名，这里是为了符 合上下文的询问，如先询问了某种菜品的属性，下一次询问时只带上了菜品名， 利用这个插槽配合意图就能理解用户的语义还是想询问菜品的属性。最后得到 了菜品名和属性名及属性的值，根据回复模板生成固定格式的回复并将插槽 last_attr设置为本次询问的属性名来满足下一轮对话再次询问，同时将attribute 插槽设置为空避免再次询问其他菜品这个属性时出现顺序和逻辑上的错误。
• check_order：执行结账，显示点餐信息和需要付款钱数，信息来源于 ordered_dishes插槽中的菜品名称和数量，再查询知识图谱中存储结构菜品单价， 进行计算。
• get_mfo：得到满足属性要求（如果有属性）的菜品列表，通过实体提取 的attribute实体值（可能为空）调用知识图谱对象去遍历匹配整个知识图谱存储 结构满足条件的菜品，生成回复。
• get_attribute_info:执行同verify_attribute也是先取得对话中属性信息，如 果本次对话没有attribute实体值则使用插槽中last_attr的属性作为问句的属性。
• ask_fi）r_price:作为没有明确带有“价格”实体值但语义识别意图为询问价 格，执行逻辑同verify_attribute<.
• order_dishes:点餐的意图识别后，需要再识别每样菜品的数量，这里为了 识别中文的数量词加入了一个小算法，能准确从中文中读取数量为数字，但是依 赖于位置关系，所以点餐数量词必须在菜品名称前，这样依据位置可以一一对应， 最后采用增加的方式添加到orderd_dishes插槽中，如果分两次点餐同样的菜品， 能够将数量进行相加。
• cancel_order:点餐过程中可能需要取消某样菜品，这个意图识别后采用 同order_dishes的办法将量词和菜品进行一一对应，具体的流程图如图4-9所示。
54

图4-9取消点餐逻辑图

4.2.2知识图谱构建
本文实现采用json配合rasa知识图谱接口格式实现了一个适用于智能客服 机器人的简单知识图谱结构，其基本的函数结构如前文第三章中所述，这里介绍 下各个函数具体的实现和功能。
•初始化加载：将json文件读取，由一个键值对结构进行存储在内存中（后 续可以根据需要扩展到数据库中），可以存储多种服务类型（本文只使用了点餐 机器人一种服务场景）。
•得到满足条件的所有对象值：根据传递进来的属性值（可能为空）然后 遍历整个对应服务的满足属性条件的所有实体对象，作为列表返回。
•得到服务对象的标识值：本文使用了 ID属性作为菜品这个服务对象的标 识值，如果扩展服务，可能有不同的标识值。
•得到服务对象的显示值：本文使用了名称name属性作为菜品这个服务 对象的显示值，用于返回显示，如果扩展新的服务类型可以使用其他的显示值。
•得到服务对象的所有属性值：本文使用了菜品这个服务对象，所以该函 数返回菜品的所有属性，作为列表返回。
•设置实体的显示属性：本文这个函数保留，可以修改用其他属性取代上 文默认的name属性。
•设置实体唯一标识：本文这个函数保留，可以修改用其他属性取代上文 默认的ID属性。
该知识图谱其实是做了一个抽象服务层功能，未来可以从各种数据库、远程
55 读取、文件读取等地方完成加载，可以支撑多个服务（不止是智能点餐机器人） 同时每个服务的标识字段和显示字段也可以单独设置，具有高度的抽象和扩展性。 初始化的json文件设置如下表4-5所示。
表4-5菜品实体存储表
ID
name
dish type
taste
price
0
宫保鸡丁
炒紊
甜
15
1
红烧鸡块
红烧
麻辣
22
2
米饭
主食
正常
1
3
小面
主食
麻辣
13
4
干锅兔
干锅
麻辣
48
5
干锅鸡
干锅
麻辣
38
6
干锅牛蛙
干锅
麻辣
56
7
红烧狮子头
红烧
咸
21
8
柠檬汁
酒水
酸
7
9
可乐
酒水
甜
3
10
燕京啤酒
酒水
正常
5
11
矿泉水
酒水
正常
2
上表展示的是目前设置的各个菜品的各项属性情况作为基础的底层数据支 撑，存储在json文件中，提供给知识图谱调用，再由Action动作服务器调用知 识图谱的函数进行访问，这里的数据可以很简单的进行扩展和修改基本实现了配 置驱动开发的目的。
4.2.3策略管理构建
这里对话的策略如第三章所介绍，是辅助对话执行和管理整个对话的部分， 本文的对话管理主要釆用了以下策略。
• MemoizationPolicy：用于标识在进行语义理解和意图识别时需要联系的 上文数量，本文采用默认值5,即在识别意图时会参考上文5条信息。
• TEDPoKcy：用于意图识别前置的词向量嵌入部分，会根据余弦相似度来 匹配回复Action和意图，辅助意图识别。其内部结构在前文中已经介绍，这里 采用了默认的参数就行构建。
• FallbackPolicy：回退策略，主要用于意图识别置信度低的回溯，生成默 认对话回复引导对话再次展开，本文结合之前RasaNLU模型的交叉训练结果设 置了置信度为0.4,即当识别的置信度低于该值会直接生成默认的回复。

4.3语音合成模块实现
4.3.1中文语音合成器实现
在迸行模型的训练之前，考虑到语音信号数据量较大且需要配合音色编码器 的使用，如果直接采用训练过程中读取音频文件做处理的办法会极大地增加训练 时长，本文在进行训练前先进行了数据的预处理操作，主要包含了训练文本的生 成、对正确结果的梅尔频谱进行向量化存储预处理和对于编码向量存储的预处理。 启动训练的步骤如下图4-10所示。

图4-10语音合成模型训练流程图
57
这里的中文语音合成器还是以Tacotron模型为基本选型，原官方模型采用为 英文，可以通过空格分词后将词汇对应为音素，但是中文文字显然无法直接进行 音素对应，且中文发声需要考虑音调的变化特征，本文实现先对中文分词，再进 行了拼音的转换，主要使用了 python的phkit库实现拼音的转换和最后到音素的 转换，使得中文能够和英文一样，进行音素的训练，最后产出为梅尔频谱，前文 第三章介绍了模型的详细结构和整个系统的设计结构，这里不再赘述，关键参数 值及含义如下表4-6所示。
表4-6 Tacotron模型主要参数表
参数名
简单解释
encconvnum」ayei*s
编码器的卷积层数，设置为3
encconvkernelsize
编码器各层卷积核大小，均设置为5
encc onvc hannels
编码器卷积层通道数，设置为512
en coder lstm units
编码器lstm神经元数量，设置为256
attention dim
注意力网络维度，设置为128
attentionfilters
注意力网络卷积层数，设置为32
attentionkernel
注意力网络卷积核大小，均设置为31
decoder layers
解码器lstm单元层数，设置为2
dec oder lstm units
解码器每层lstm单元数量，设置为1024
max iters
解码器最大迭代步数，设置为2000
上述参数值的默认值设置参考来自官方实现模型和其他相关中文实现模型， 经本地采用测试确实能达到工程目标。本文训练时租用了矩池云的服务器进行训 练,相关的配置参数为:每秒浮点运算次数为7.29 TFLOPS,显卡内存大小为8 GB, GPU带宽为44&06 GB/s,通道数为16, PCIE带宽为15.75 GB/s,主板型号为 PRIME Z390-P, CPU 型号为 Intel (R) Core (E) i7-8700 CPU @ 3.20GHz,可使 用内核数为6 cores,可使用内存为16 GB,硬盘为INTEL SSDSC2KW25,硬盘 带宽为301.81 MB/s=其中多人语音模型训练时长3天，周星驰迁移模型训练时 长为8小时，本人音频训练时长为8小时。
本文采用了 tensorflow框架来训练模型，梯度下降的方式为adam方法，采 用tensorboard来观察模型损失值的变化，如前文所叙述由于采集大量单人音频 困难，本文采用了语音克隆文章的思路，通过一个特殊的编码器结构加入，训练 一个多人语音的模型，然后基于该模型做特殊语音合成的迁移训练。用于迁移训 练的多语音模型损失函数变化如图4-11。
58

stats/after_lcss
:巧：Tacotfon.fBGSeizssais.- arer_：oss

■ I

-	1	j	，








3	2k	4v	&	2”	嵌	总	迢	承	2&<
图4-11基本多人语音模型损失函数图
该模型采用zhthchs30清华大学开源数据集训练，从图中不难看出从一开始 的快速下降后损失值趋于平稳，到了 20k的训练步数时整个损失值已经几乎不再 下降。
然后为实现特殊语音的合成，本文基于该多人语音模型，使用周星驰的语音 数据进行了迁移训练，损失函数值变动如图4-12o
stats/after
tac： Tacctrwvfnocei/stats.' 3t?er.ioss

图4-12周星驰语音数据训练损失函数图
在迁移训练的过程中可以发现损失函数值有波动的下降趋势，本文在训练的 同时每隔100步长都会生成测试语音和梅尔频谱预测，观察到22.8k步长后模型 实际情况有劣化，出现了测试集的过拟合情况，所以在最后选取了道22.8k步长 为止的模型作为周星驰特殊音色的语音合成模型。在步长为22.8k时对比预测的 梅尔频谱图和实际的梅尔频谱图区别如图4-13o
59
Target Mel-Spectrogram
0	25	50	75	100	125
-5	-4	-3	-2	-1















Tacotron, 2021-01-22 16:39, step=22800, loss=0.14778
图4-13周星驰语音数据预测梅尔频谱对比图
从图中不难看出，端到端迁移模型的梅尔频谱预测图像己经非常接近于真实 的梅尔频谱图像，同时损失值也达到了 0.14778的低点值。
最后是由录音采集的作者本人的音频数据训练的模型，如图4-14所示。

图4-14本文作者语音数据训练损失函数图
对比预测的梅尔频谱图和实际的梅尔频谱图区别如图4-15。
60


Tacotron, 2021-01-24 18:01, step=24900, loss=0.10986
图4-15本文作者语音数据预测梅尔频谱对比图
和周星驰训练的规律类似，使用本人语音进行语音合成器模型训练后，预测 的梅尔频谱图像也与目标图像趋近，损失函数值降到了 0.10986的低值停止训练。 4.3.2声码器模块实现
本文主要采用的声码器模型为MelGAN和WaveFbw,以及基本的信号处理 格林方法，相关模型或算法的结构已经在前文中提到，这里不再赘述，首先训练 集采用了清华大学zhthchs30数据集进行初步的训练，然后分别使用周星驰的语 音数据进行了迁移训练（还是由于采集单人大量音频数据实现难度非常大，不得 不采用迁移训练的方法），因为声码器训练输入为梅尔频谱值，为了跟合成器完 整适配，声码器的目标梅尔频谱生成方法采用和语音合成器相同的办法，两个模 型均采用了相同的训练数据，采样率均为22050,梅尔频谱的通道数量均为80, 其他定制化参数均参考官方论文实验设置参数，而训练服务器的硬件配置也跟之 前语音合成器的配置相同，其中MelGAN模型基本的训练情况如图4-16, WaveFbw模型训练情况如图4-17。
61
meLreconstruction
tag !oss/nwif_jeco;istrucncn



trainiagjoss

图4-17 WaveFfow训练损失值变化图
其中WaveFlow模型训练步数远远高于MelGAN模型才能达到比较好的效果, 训练时长也相对更长。WaveFlow模型由于采用的对数方法作为损失函数，所以 损失值可以为负值，依然是越小越好。
为了选择合适的声码器模型作为最后对接语音合成器的声码器,MelGAN模 型的训练和WaveFlow采用相同的训练数据，以损失值无明显变化且生成语音效 果较好为训练停止。在测试时了相同的测试文本比较三种声码器的各项性能。比 较结果如下表4-7所示。
表4-7声码器模型对比表
模型/算法
训练时长
生成语音时长(cpu)
生成语音时长(gpu)
生成语音质量
格林算法
无
0.403
0.403
好
MelGAN
3天
0.412
0.0345
较好
WaveFlow
7天
0385
0.0189
一般
综合上表所述，传统的语音合成格林算法是能够直接满足生成语音的基本需 求的，但是在高并发要求实时性强的场景中，生成时间相对处于劣势，而神经网 络模型的方法能够满足实时性的要求，即实时地语音对话环境，但是MelGAN
62 在训练单人语音后迁移到生成其他语音进行波形生成时效果明显不好， WaveFlow模型也有这个问题，其实时性相比属于最佳，但训练需要时长更久， 且在语音生成质量上相比于MelGAN和传统算法来说不够好，综合考虑本文在 系统构建上由于考虑到多种音色的切换以及训练的时间成本开销，在特色语音模 型上选用MelGAN模型构建的声码器，而在普通音色的选择上使用格林算法作 为基本的声码器。
4.3.3语音合成后端业务服务
为了将语音合成模块作为独立的模块部署，本文实现时也使用了 python语 言结合aioHttp库搭建了一个服务器端，用于接收文本请求来生成对应的语音文 件，并回传静态文件存储的url值，作为后端请求处理模块服务，不直接跟前端 关联。其只提供单个的服务接口 localhost:9009/voice给后端中转服务器调用，基 本的调用流程如下图4-18所示。


图4-18语音合成后端服务图
63

该图显示了语音合成模块的后端服务流程，与第三章的设计吻合，基于前文 的讨论这里会将文本信息和音色的选择作为参数传递用于区分使用的语音合成 器模型，而声码器模型也和前文所述一样，普通音色选用格林算法生成音频，而 特色语音的生成使用MelGAN声码器模型。
4.4前端展示模块实现
基于第三章的设计，前端部分具体使用react前端框架和ts语言编写完成， 主要实现依照设计完成，基本实现的组件树结构如图4-19。

图4-19前端整体组件树图
其中最外层组件为Message Window用来包含整个对话框需要的结构，同时 使用react hook中的useReducer和useContext构建了一个小型的数据管理结构， 所有对话的信息由该结构来管理，同时将其当前值以及改变值的dispatch方法作 为上下文context传递给子组件，避免多层的参数嵌套，同时各个子组件只需要 调用dispatch方法就能改变当前的对话值列表，然后显示组件MessageDialog直 接遍历该当前值就能将信息渲染到网页节点上，其包含了信息气泡组件 MessagePop以及下面细分的两种类型的气泡组件TextPop和AudioPop,然后 MessageSender组件主要存在于对话显示框下方，由对话输入框和工具栏组成， 其中输入框为一个TextArea类型的组件，而工具栏包括了三个主要用到的工具，
64
包含选择音色的工具，清空对话框按钮和语音输入组件，具体主要用到的数据结 构如下。
• Messageinfo：为基本的单条对话数据结构，主要包含以下参数。
■ type：主要有用户文本、用户语音、机器人文本、机器人语音四种枚举 值
■ info：具体的文本信息
■ audio：可含参数，如果是音频信息该参数为音频资源url
■ audioIcon：可选参数，值为音频信息显示的图标组件
■ icon：对话头像的图标组件
■ pos：气泡产生位置，左边还是右边
• MessageAction：作为disptch传入的参数，用于改变当前对话存储值，包含 以下参数
■ type:表示动作类型，包含加入一条文本信息、加入一条语音信息、加入 一个数组的信息、替换掉原有所有消息、改变音色选择人。
■ paytoad：具体的信息值，类型为Messageinfo或者Messageinfo数组
■ voicePerson:当前音色选择人
本文实现中主要用到的消息类型主要就由这两个结构以及上下文context （Messageinfo和MessageAction初始化）来完成，一些子组件可以改变通过传 递MessageActkm来改变整体存储的Messageinfo数组，而负责对话框渲染的组 件一旦感知到整体的Messa驴Info数组变化就会重新触发渲染，从而屏幕上显示 的对话就会得到更新。而采用这种上下文的实现具有低耦合高内聚整合的特点， 也便于以后的消息扩展。整体的数据流动如图4-20所示。
65



图4-20前端数据逻辑流转图
由图中可以看到数据的改变和数据的渲染是由不同的组件部分来负责的，相 互隔离，而整体的数据又由上文中提到的管理器来管理。首先由文本输入和语音 输入两种输入方式，语音输入在识别为文本信息后支持再次编辑，这里的数据改 变让ToolBar组件感知到，从而再改变全局的Messageinfo数组触发对话显示框 的组件MessageDialog的渲染再次生成多个MessagePop气泡显示框组件，并能 根据是否为文本消息显示不同的气泡格式。
其基本的页面实现效果如图4-21所示。
66


图4-21前端界面显示图
如图中所示，整体的界面样式和前文第三章的设计相同，包含了对话显示框、 文本输入框、工具栏等一系列组件构成，基本界面保持了简洁美观的需求，使用 不同的头像区分用户输入和机器人回复，并且针对不同的消息区分属于文本消息 还是语音消息，支持语音消息的播放和暂停。
下方工具栏三个按钮分别表示清空对话、选择输出音色和语音输入，其中语 音输入的使用如图4-22,输出音色的选择如图4-23。










图4-23输出音色选择
如上图所示，介绍了工具栏语音输入和音色选择工具的界面显示效果，在点 击时触发一个新的组件（其中语音输入为输入框组件而音色选择为单选框组件）, 达到前端切换音色和语音输入录入转换为文字的需求。
4.5后端中转请求处理模块实现
后端请求模块是接收前端请求的主要处理模块，其基本使用python语言和 aioHttp库来完成服务器部分的搭建，其中包含的请求如下表4-8所示。
表4-8报表模块的架构
请求名
请求url
请求方向
请求参数
请求说明
音色改变
/options
网页前端-后端
无参数
请求后端得 到可以使用 的音色输出 人列表
用户文本输 入
/text
网页前端-后端
Info字符串表示用 户输入
请求后端接 收前端的文 本输入
文本回复生 成
/webhooks/re st/webhook
后端-Rasa NLU模块
{
Sender:用户名 Message:文本值 }
后端将前端 的文本信息 传递给Rasa
NLU模块
语音回复生 成
/voice
后端-语音合成模块
info字符串表示回 复的文本信息
后端将Rasa 对话管理模 块生成的文 本回复传递 给语音生成 模块
68
由表格不难看出后端请求处理模块不只是负责作为一个服务器同时也会作 为一个客户端去请求Rasa模块和语音生成的模块，然后将生成的回复信息再返 回给前端让前端能够将文本信息和语音回复的静态链接url取得从而进行页面的 渲染。
在实现上采用了基本的服务器分层思想，分为控制层、业务处理层、持久层 （由于本文实现中未使用到后端数据库结构信息故该服务器只包含前两层），其 中控制层用于接收前端传来的请求信息，然后调用具体的服务层代码去执行相应 的业务逻辑，这里主要就是作为客户端去再次请求RasaNLU模块和语音合成服 务器模块。
4.6本章小结
本章主要应用了第二章介绍的各项技术来具体实现了第三章中各个模块并 完成了需求分析中的需求，其中介绍了各个模型的训练情况和结果，包含了 Rasa NLU模型的训练和最终性能指标的结果展示，语音合成器模型的训练和结果展 示以及声码器模型的训练和最后选型对比。同时实现了前端的设计介绍组件树的 结构，数据的流转以及展示最终呈现的效果。最后简单叙述了后端中转服务器的 交互请求列表和实现细节。
69
第五章实验结果展示和系统测试
在本章节中，对系统进行了功能与性能两个方面的测试。功能测试指的是对 各个功能模块的使用效果进行测试。性能测试是对各个功能模块在使用过程中的 响应时间、内存使用率进行测试。本次测试使用的电脑信息如下表5-1所示。
表5-1	测试计算机硬件信息
配置信息\计 算机
本地电脑
深度学习服务器
操作系统
WinlO家庭中文版
Ubuntu 16.04
cpu型号
Intel i5-8300H@2.3Ghz
Intel i7-8700@3.2Ghz
显卡型号
GTX 1050Ti-6GB
GTX 1050Ti-8GB
内存大小
24GB
16GB
硬盘大小
1TB
512GB
5.1功能测试
5.1.1界面呈现测试
界面呈现测试主要是测试界面在不同的情况下能否正常显示。本系统将界面 分为了导航栏、图片区域和数据侧边栏，将会对这几个部分进行测试。测试的目 标为以下几点。
(1) 在不同分辨率屏幕中界面显示不发生错位。
(2) 在窗口不同大小的情况下，界面显示不发生错位。
(3) 在不同操作系统中，界面字体显示不发生乱码。
经过多次测试，文本输入栏、工具栏和对话显示框均达到以上几点目标。并 且各项功能操作可正常显示不卡顿，与后端交互也没有出现异常情况。
5.1.2文本多轮对话功能测试
多轮对话功能是本项目的一个核心技术点也是核心难点，为更好地展示多轮 对话的功能测试，本文使用Rasa X作为可视化工具，其基本的技术已在第二章 进行了介绍，其作为Rasa整体框架对话驱动的交互式展示，能够使得机器人语 料的训练来源于真实的对话，且可以在对话中进行调试修改，非常方便地改动错 误，轻松地增加新的语料，这里用Rasa X来展示多轮对话系统的整体效果和识 别的实体意图等信息(不直接采用前端做演示是因为Rasa X的交互界面能将识 别的实体信息、插槽信息、意图信息都展示出来,能够更好地展示多轮多话效果)， 采用多组的测试用例来测试多轮对话的实际效果，首先测试意图的正确识别，然
70
后测试实体提取的正确性，最后测试插槽设置和消息回复的正确性，其中意图识 别的测试用例情况如下表5-2所示。
表5-2 意图识别的测试用例
功能描述
意图识别功能
用例目的
测试意图识别是否正确

前提条件
输入文本消息传送到RasaNLU模块后端服务

测试输入

测试期望输出
实际测试情况
文本信息“你们这里有什么菜品啊”
识别意图为get__info
达到预期效果
文本信息“你好”
识别意图为greet
达到预期效果
文本信息“再见”
识别意图为bye
达到预期效果
文本信息“我要点一碗小面和一碗 米饭”
识别意图为order_dishes
达到预期效果
文本信息“干锅鸡是什么口味的？ ”
识别意图为 get_attribute_info
达到预期效果
文本信息“宫保鸡丁是辣的吗？ ”
识别意图为verify attribute
达到预期效果
文本信息“少要一碗米饭”
识别意图为cancel_order
达到预期效果
其中简单回复的意图识别测试情况如下图5-1所示。
71

utter_greetx.C



US€f_f£3tMI izai<of»
uit&r_byeO.?9
亘见吧
actson^llstenl.O
图5-1简单回复测试意图识别
图中可以看到两个不需要调用Action服务器的简单回复测试用例能正确识 别意图，其中''你好'被识别为greet意图的置信度为0.68而“再见,械识别为意图 bye的置信度为0.72,其回复均为简单的固定回复。
需要调用Action动作服务器的复杂回复的意图识别效果如下图5-2所示。
72


s血干巔谿"sttribtjz^r ste' )Cz.44
sicitr	'tiste''*
廷航门i”干參席“拿
yser_ !es?ur?Z2ii<?n
scvon Query_kri<»wf€fSgs_bB5G1.0
干锅焰的口味是疥辣
sfGtfoh7ect^ivp^',r dishes slGt[">a5t._g ttr"/taste'r: siott^attFsbute^inu'G sts^d"	:'干魔建*
ssatr^aste^^*?' sc； ；w： M t«n0.9/
…一.
siotr*asteT^^n
sser.f&SiiK^s^.rn
图5-2复杂回复的意图识别
上图中可以看到当询问“干锅鸡是什么口味的？ ”时RasaNLU模块能正确识 别句子的意图为get_attribute_infb,而当询问“宫保鸡丁是辣的吗？ ”时，能以0.70 的置信度正确识别意图为verify attribute =
接下来进行实体提取的测试和验证，和意图识别一样，其测试用例的情况如 下表5-3所示，示例的展示效果如图5-3。
表5-3	实体提取和插槽设置的测试用例
功能描述
实体提取和插槽设置功能
用例目的
测试实体提取和插槽设置是否正确
前提条件
输入文本消息传送到RasaNLU模块后端服务
测试输入
测试期望输出
实际测试情况
文本信息“干锅鸡是辣的嘛？ ”
能正确提取实体“干锅鸡”和“麻 辣”，设置插槽taste为“麻辣”， 插槽 last attr 为"taste"
达到预期效果
文本信息“我要点一碗米饭一份宫 保鸡丁和两罐可乐”
正确提取实体“米饭”“宫保鸡 丁”“可乐”并设置插槽
ordered dishes 为{"米饭":1,"宫保 鸡 T"：l,"可乐"：1}
达到预期效果
73
干锅赠
丫空汗y_3ttrWut©r窃曲es":"干锅越丁牯沉e”:"疥礁H
stetf^tBstfe**:"麻辣”}
us^r^f^aturi^ation
actiQB_query_kno¥/ledge_base0.99
干锅斑的口味是麻换
s-atf^obj ect_t y g*： "6 i s hes**l
sjo^^atlribute^rntUil	.
Go建*?nem9h:"干謁建"}
s^otf^taste* tnuli)
-：「： -1
图5-3普通实体提取示例图
从图上可以看到，当询问“干锅鸡是辣的嘛？ ”时，能够将实体“干锅鸡”和“麻 辣％R别并将taste插槽设置为“麻辣，將last_attr插槽设置为，也ste”,这里其实有自 动的dishes插槽设置，但是在之后的处理中又被重新设置为空了，因为dishes 是绑定在同名实体上的插槽其特点是经常需要变动，本文实现Action服务器时 将其作为了单句的过渡插槽，实际点餐的信息由单独的插槽ordered_dishes来存 储。
下图5-4展示了数组形式的插槽设置和相同类别下实体的提取。


..- :- ?■ -
UotfPkhEdr术豉；善妥莖了丁可■乐" userjeatuiizatian


sk)t{9「血佗d_dis*b；r袜歳”:1；■莒垛蹲丁 ":常可乐-：2]j


uH€tr_default0.96


3ctianM.listen0.97
图5-4数组型实体提取示例图
从上图可以看到，当询问“我要点一碗米饭一份宫保鸡丁和一杯可乐”时, 机器人可以提取出其中三个菜品实体并将其设置在ordered_dishes插槽中，并且
74
包含了对应菜品的数量信息，这也为后续的结账或取消部分订单提供了上下文信 息。
接下来，结合上述的意图识别和实体提取插槽设置的功能，展示多轮对话上 下文信息的存储更新和利用，测试整体多轮对话的效果，测试用例如下表5-4所 z]\ O
表5-4	多轮对话的测试用例
功能描述
整体多轮对话功能
用例目的
测试多轮对话上下文信息设置和利用是否正确
前提条件
已经有上下文对话且存储有部分插槽信息
测试输入
测试期望输出
实际测试情况
本轮信息：“再来一份宫保鸡丁” 前置信息：插槽ordered dishes为{" 米饭"3}
正确提取实体“宫保鸡丁乙识别意 图为“order_dishes”并更新插槽 ordered dishes 为{"米饭”3,”宫保 鸡丁”:1}
达到预期效果
文本信息“少要两碗米饭”
前置信息：插槽ordered dishes为{" 米饭"3,"宫保鸡T"：l}
正确提取实体“米饭3识别意图为 "cancel_dishes"并更新插槽 ordered dishes 为:{”米饭”:1,”宫保 鸡丁VI},正确计算价格
达到预期效果
文本信息：“那干锅鸡呢？w 前置信息：插槽last_attr为”price"
正确提取实体“干锅鸡3识别意图 为ask_for_price,生成相关回复
意图识别未达到 预期，其他达到 预期
其中第一个测试用例的实际效果如下图5-5所示。
75


sp^- vUshes ：; M§?x37
us6r_featur?zation
action„query_i<nov/!edge_ba5el.O

sli，” *ordb&_<»s”* 軽-* 圾"：3."S9 码丁 ••: 1:
图5-5多轮对话测试用例一图
由图可以看出，一开始先发送消息“先点两碗米饭”后相关实体被正确提取及 点餐的意图也正确识别，插槽ordered_dishes被更新为｛"米饭":3｝生成的回复符合 预期，接下来输入“再来一份宫保鸡丁'‘的信息后，机器人能结合已知的插槽信息, 并将新的点餐信息添加进去。
测试用例二的效果如下图5-6所示。
76


少要两
csnceLordv；广辰s":"未饭"
来饭"卩
s\_ festud^gt i on
7- :-	「	'-.'
您巨苑的鬆单为1份米滾・1份言保鸡丁，共汁16 元
stot{"ordefed_dishes" ：f-7F?S' ：
^tter_defa«ItO. 9 :


s<tion_hstenO,99
图5-6多轮对话测试用例二图
上图的前置信息为前文对话信息的后续，及此时的插槽ordered_dishes为{" 米饭"3,"宫保鸡丁":1},当输入信息为“少要两份米饭”时，机器人正确提取了实 体和识别了意图且将插槽信息按照用户意图进行了更新，并生成了对应的回复, 计算了现有的点餐信息和价格，所有信息都和预期一样。
测试用例三的效果如下图5-7。
77


siotfprice'^uU]
ver i? y_attribute{ "dishes
sk>t{"dishes"4"-F4^r7§'*]|
user_f«aturization
3€tlon_Query_knowiedge_bass0.99
干锅鸡的价恪是38元
图5-7多轮对话测试用例二图
图中的前置信息为插槽last_attr设置为了”price”,这是由前置对话“宫保鸡丁 多少钱”这个输入完成的，接下来当输入“那干锅鸡呢？’‘这样比较符合我们日常 口语的交流表达时，口语看到机器人能正确提取出实体“干锅鸡”，但是在识别意 图时出现了错误，理论上应该识别为ask_for_price意图，但是识别的意图为 veriiy_attribute,这是因为其实这两个意图在前文中介绍了调用的是同一个函数， 为了适应更口语话的表达，在意图识别时做了区分，目前来说询问价格的 ask_for_price 意图和 verify attribute 意图都是 get_attribute_info 意图的特例，所 以在执行逻辑上基本一致，只是在提取attribute实体的时候有不同。
整体来说，不管是实体的提取还是意图的识别以及整体的多轮对话效果都符 合文本多轮对话的项目预期，能够达到比较好的效果。
5.1.3语音合成功能测试
第三章介绍了声码器的相关模型原理，第四章提到了两个声码器模型的实现 训练参数和训练损失值变化情况，对声码器模型进行了选型，本节需要对语音合 成整个模块进行功能上的测试，测试的目标为以下几点：
(1) 后端请求服务正常交互。
78
(2) 模型的切换正常。
(3) 语音合成效果较好，在生成语音质量和耗时上均达到好的效果。
经过多次测试，关于语音合成的前两个功能均达到了以上几点目标，但是第 三个功能上发现多人训练的语音模型在进行语音合成时因为训练文本没有与本 文项目高度结合导致部分音调发音不对，断句和语速也不够合理，只有特色语音 周星驰的生成效果最好，能达到吐字清晰语速自然的生成音频质量，由本人录制 的音频质量介于两者之间，在生成耗时上由于第四章己经比较了几种声码器模型 的相关性能特点所以本次测试各个模型均满足要求。
5.2性能测试
本系统主要针对后端Rasa NLU模块后端服务部分以及语音合成后端服务部 做性能测试，这两块都是利用深度学习模型构建的模块，也是主要耗时耗资源的 部分，本文对于性能更重要的要求是稳定性，需要保证系统运行中服务器消息的 成功交互。其中关于Rasa NLU模块后端服务的压力测试结果如下表5-5所示。
表5-5 Rasa NLU后端服务压力测试表
测试数据\测试机型
本地电脑
深度学习服务器
并发数
10
10
请求总数
100
100
总计耗时

每秒处理请求数量

返回消息大小
13433 bytes
13433 bytes
成功消息数量
100
100
失败消息数量
0
0
从表中不难看出，该系统服务对于配置相对较低的电脑效果不够理想，在耗 时上比较处于劣势，在稳定性方面两种电脑配置没有明显区别。
接下来对于语音合成模块进行后端服务的压力测试，使用语音周星驰合成模 型及由周星驰数据训练的MelGAN声码器模型作为整个模块的模型，同时均釆 用了单个即U的方式启动模型推理，测试结果如下表5-6所示。
表5-6语音合成后端服务压力测试表
测试数据\测试机型
本地电脑
深度学习服务器
并发数
10
10
请求总数
100
100
总计耗时

每秒处理请求数量

返回消息大小
30200 bytes
30200 bytes
成功消息数量
100
100
失败消息数量
0
0
79
从表中可以看出生成语音服务的耗时相对更长，且和电脑配置关联不大，由 于上述测试均采用gpu来进行模型推理，后续我又强制进行了 cpu的推理测试, 发现结果和卯U推理的差别不大，基于第四章声码器模型比较时更U推理明显快 于cpu,为找到性能的瓶颈再次进行了一轮测试使用，这次只使用深度学习服务 器，分别测试在网络连接、语音合成模型和文件存储生成三个方面控制变量的耗 时结果，测试结果如下表5-7所示。
表5-7语音合成后端服务性能瓶颈排查表

保留所有步骤
缺少文件存储
缺少语音合成模型
缺少网络连接
并发数
10
10
10
1
请求总数
100
100
100
1
总计耗时

每秒处理请求数
量


1
返回消息大小
30200 bytes
30200 bytes
30200 bytes
30200 bytes
成功消息数量
100
100
100
100
失败消息数量
0
0
0
0
由上表可以发现性能的瓶颈存在于语音合成器上，该合成器的实时性与声码 器的实时性不匹配拖延了整体的响应速度。后续需要对语音合成模型的及时生成 速度进一步优化。目前只能达到低并发的要求。不过从消息的成功率上看，本文 的最重要的稳定性要求得到了满足。
5.3本章小结
本章展示了最后的成果包含前端界面的最终效果以及利用Rasa X进行交互 式检验了多轮对话的效果，展示了实体提取、意图识别、插槽设置是如何协同工 作共同完成了多轮对话的，最后进行了性能的测试，得到了性能并发效果不够好 的结论，并发性能的瓶颈没有出现在声码器模型上而是存在语音合成模型部分。
80
第六章总结和展望
6.1论文总结
本文基于Rasa框架使用深度学习的相关知识针对任务型对话构建了一个可 交互的多轮对话特色语音客服系统，能够完成垂直领域的上下文对话信息存储 （本文中实践为智能点餐机器人）以及回复的特色语音生成且保持了生成语音的 高质量和实时性要求，具有一定的实际场景应用价值。本文的主要工作如下：
1）	通过网络查阅各种文章资料和阅读相关文献论文，在了解当前智能客服 机器人背景和发展趋势的基础上提出了研究方向和研究内容。
2）	研究学习 了 Python、React、Rasa、Pytorch、lensorflow> Aiohttp、lheotron、 MeKJAN、WaveFlow等语音框架或模型方法后，确定了技术方案。
3）	完成了需求的分析、流程的制定、整体系统的结构设计、各个模块的结 构设计，然后依照设计思路进行了具体的实现,在技术选型上了做了介绍和选择， 并对模型的相关训练参数、训练结果进行了图示和分析。
4）	最后展示了最终的效果，验证了实践的成果，也在声码器模型的选型上 做了比较给出了最终选型结果和理由。
6.2工作展望
目前本文实现的系统基于智能点餐机器人这一落地场景，完成了多轮对话和 特色语音的设计实现，在模型的训练、模型的选择、特色语音的训练也都跟这一 场景相关，未来可以探索更多的落地场景，迁移到更广泛的应用上。
本文中关于模型的训练选择基本依赖于后台的设置训练，缺乏友好的前端交 互来完成整个开发服务，特色的语音生成也无法通过前端录音的方式直接导入训 练再利用训练好的模型直接使用，在易用性上还有很多探索的空间。
未来本文使用的各个模块代码都会开源到github平台，结合当前无代码的设 计趋势，接下来会着力完成前端交互的升级和后端模块的组织优化，最终达到无 编程能力也可以透过前端界面训练部署一个多轮对话的特色语音客服机器人的 目标。让智能客服机器人得到更广泛的应用。
