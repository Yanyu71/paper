第一章绪论
1.1研究背景
5G及未来移动通信系统需要满足高移动性场景下的高速率通信要求，如高 铁通信、使用无人机的通信和汽车自动驾驶通信等。在高速移动场景下进行通信 时，无线信号经由建筑物车辆等障碍物反射后先后到达接收端。由于信号经由不 同路径到达接收端有各自的延迟与衰落，即多径效应，信道在频域表现为包络起 伏的曲线，产生频率选择性。同时收发端的相对运动使每条信号径有各自的多普 勒频偏，信道在时域产生选择性，称为时变信道。高速移动场景下的信道多为时 频双选择性信道。
当前在4G系统中主要使用的通信调制方式为正交频分复用(OFDM)oOFDM 为多载波调制，利用子载波间的正交性实现高频谱利用率。对于低速场景，不考 虑多普勒频偏影响时，信道被认为时不变，其多径影响主要是具有不同延时的信 号径间的干扰oOFDM使用循环前缀(CP)很好地解决了时不变频率选择性信道下 的通信问题。CP长度一般大于最大多径延时，可以消除符号间干扰同时保持子 载波正交性。但是在高速移动场景下，子载波正交性遭受破坏，并且最大多普勒 频偏与运动速度成正比，因此移动速度越大，OFDM性能越差。简而言之，传统 的OFDM不能很好满足此场景下的通信要求。
时不变频率选择性信道下，使用导频估计的信道对整个帧有效，然而时变信 道下，信道需要不断更新。相干时间大小为最大多普勒频偏的倒数，通常认为相 干时间的1/10以内信道变化缓慢，可以使用信道插值算法跟踪信道。因此在高 速场景下，一种保持低误比特率的方法为插入大量导频保持信道估计有效性，然 而CP与导频开销太大则会降低频谱利用率，增加成本。
为了解决高速移动场景下的通信问题，文献[1]中提出了 OTFS调制方案。 OTFS被证明相较传统调制方法更适合高速移动场景下的通信⑴[2][3][4]。OTFS在 延迟多普勒域进行信号的调制解调。时频双选择性信道可以在延迟多普勒域上使 用若干抽头表示，为延迟多普勒域上的稀疏信道。在时频双选择信道下，每条信 号径的时延大小和多普勒频偏大小在短时间(如几毫秒)内被视作大体不变，故在 延迟多普勒域进行的信道估计可以视作整个信号块的有效信道估计。延迟域与频 域为一傅里叶变换对，频域信号经过快速傅里叶变换的反变换(IFFT)可以变换为 延迟域信号；多普勒域与时域为一傅里叶变换对，时域信号经过傅里叶变换(FFT) 可以变换到多普勒域；在延迟多普勒域插入的信号通过逆辛傅里叶变换(ISFFT)
1 可以变换到时频域，其中ISFFT可由FFT和IFFT组合实现，时频域信号可以通 过辛傅里叶变换(SFFT)变换回延迟多普勒域。延迟多普勒域信号变换为时频信号 后，可以视作时域上若干个连续的多载波符号，此时可以使用已有的多载波调制 方式，如OFDM,进行信号的传输，可以很好兼容已有的信号传输系统。发送的 OTFS信号中，延迟多普勒域上调制的信号经过变换后会覆盖整个时频域，可以 视作经历了相同的时频衰落，同时也能产生分集增益。故，在时变信道下，OTFS 性能明显优于OFDM。
然而，OTFS在实际应用中尚存在一些挑战。在OTFS系统中，理想的收发 滤波器满足时频双正交性难以实现，因此实际情况下通常使用矩形滤波器代替。 此时，在高速移动场景中，OTFS信号亦会收到载波间干扰和符号间干扰。并且 由于在OTFS系统中，一个OTFS符号块相当于连续若干多载波符号，因此，当 接收信号表示为发送信号与信道矩阵的乘积时，信道矩阵的尺寸通常很大，使用 传统的线性检测方法进行干扰消除会具有很高的时间复杂度和空间复杂度【2］。使 用非线性方法进行检测时，关键的参数通常是根据仿真结果人为设定，这些参数 是否最优值得商榷。信道信息对信号检测至关重要，在OTFS信道估计部分，使 用冲激信号作为导频时，信道估计的方法通常是设定一阈值对接收到的导频信号 进行过滤，简单快捷，但是尚存在可改进空间。
近几年，机器学习飞速发展，在许多领域中发挥了重要作用。深度学习是机 器学习中发展最快的方法之一，在图像处理、自然语言处理和语言识别等领域取 得了巨大的成功。深度学习是由复杂连接构成的多层神经网络结构，多层结构比 少数神经网络层结构更有表现力。优化过程在以前是个难题，但是大数据发展带 来了丰富的神经网络训练样本，优化算法的进步为神经网络优化提供了充分的数 学根据，硬件资源的更新换代给神经网络模型的生成提供了足够的算力，深度学 习神经网络模型训练问题得到了很好的解决。深度学习分为两个阶段，即训练阶 段和应用阶段。在训练阶段，数据输入神经网络得到输出，计算实际输出与理想 结果之间的距离，通过反向传播算法优化神经网络权值，不断重复以上过程，最 后神经网络达到设定的收敛条件即得到最终的优化模型。应用阶段，直接使用实 际数据输入训练好的网络模型，便可得到期望输出，执行速度通常很快。在这种 情况下，深度学习相当于以线下训练时间为代价减少了线上执行任务的耗时。深 度学习在通信中的发展为其应用于OTFS信号解调提供了丰富的可借鉴案例。
1.2研究现状
1.2.1 OTFS相关研究进展
2
近几年,OTFS由于其在高速移动场景下的优越性能，受到越来越多的关注。
Hadani等人在文献［1］中率先提出了 OTFS的基本概念，论证了其较OFDM所能 取得的增益。随后，Raviteja等人在文献［2］中详细分析了理想波形下OTFS系统 的输入输出关系及应用于实际中使用矩形窗时产生干扰的数学表达，考虑了小数 多普勒频偏的情况，同时给出了简化后的整数多普勒频偏下的输入输出关系，然 后设计了 MP检测算法用于OTFS信号解调。该非线性迭代算法是OTFS最基本 的检测算法之一。为了完善整个OTFS收发系统，Raviteja等人在文献［5］中提出 了 OTFS导频插入方式，包括多用户、多基站和单发单收等多种情况，随后根据 接收端的导频信号设计了简单实用的基于阈值的信道估计方法。至此，OTFS收 发系统各部分都已有最原始的实现算法。之后的论文主要在OTFS原始系统上进 行改进。
文献［4］通过比较不同的收发滤波器，表明了矩形滤波器的实用性，同时根据 OTFS系统的实现过程提出了更为简单易懂的OTFS收发过程表示，便于OTFS 系统后来的分析与改进。
OTFS经常与OFDM结合，文献［6］分析了 OTFS与OFDM间的联系，认为 OTFS为具有CP和时间交织的块OFDM,进而分析了 OTFS相比OFDM上获得 的增益。文章还将OTFS的性能与其竞争者可变副载波带(VSB-OFDM)的OFDM 配置进行了比较，仿真结果表明了 OTFS更具有优越性。文献［7］研究了静态多径 信道上的OTFS,发现OTFS的系统结构等效于非对称正交频分复用(A-OFDM)。 OTFS-NOMA提出低速场景下使用OFDM,高速场景下使用OTFS,以提高资源 利用率，加快信息传输速率同。
近年来，针对OTFS的改进主要集中在降低信号检测复杂度和MIMO系统 中的信道估计上。文献⑶和文献［9］针对MP算法复杂度过高进行改进，通过对 发送信号进行预编码削弱了信道多普勒频偏的影响，同时改进传统MP算法的收 敛条件及更新规则，使用具有协方差预处理的方法改进近似消息传递(AMP)算法, 但是该预编码方案是基于信道中所有信号径多普勒频偏大小相等并且己知以及 不考虑多载波符号间干扰等假设，未必符合实际情况。
文献［10］研究OTFS中线性检测算法的改进。良好的线性检测结果可以作为 非线性迭代的初始化，实现降低迭代次数提高系统检测效率的效果。但是OTFS 中信道矩阵通常很大，矩阵的存储和求逆都需要较高的时间消耗和空间消耗。文 献［10］使用LU分解信道矩阵，提出了低复杂度线性最小均方误差(LMMSE)接收 器。
文献［11］研究了 OTFS用于MIM0系统时其信道估计和信号检测的方法，文 献［12］提出了 MIM0中OTFS信道估计的新方法，传统方法使用冲激信号作为导
3 频，在MIMO中需要消耗大量的符号区域，文献［12］针对该问题提出使用高斯随 机序列作为导频，所有导频占用同一二维空间，使用三维结构化正交匹配算法 (3D-S0MP)进行信道估计，成功保证了信道估计准确性，之后针对MIMO系统 下的信道估计的改进多是釆用类似思想。
1.2.2深度学习在信号解调中的应用现状
近年来，深度学习在通信系统中的信号检测与信道估计方面也取得了不错的 进展。文献［13］概述了基于深度学习的物理层通信的最新进展，指出了当前通信 系统中存在的问题，验证了深度学习在信号解调方面的巨大潜力。
文献［14］使用基于数据驱动的深度学习方法设计了 OFDM收发系统，使用端 到端的方式处理无线信道，隐式估计信道信息并直接恢复发送的符号。为了解决 信道失真问题，首先使用大量已有的信道模型生成充足的发送数据和接收数据， 接着利用数据进行离线训练得到对应的深度学习模型，然后直接用于恢复在线传 输的数据。从结果来看，该基于深度学习的方法可以解决信道失真问题，并且其 信号检测准确性与最小均方误差(MMSE)检测器相当。此外，在使用较少的训练 导频、省略CP以及存在非线性限幅噪声等情况下，基于深度学习的方法比传统 方法具有更强的鲁棒性。
文献［15］将深度学习应用于MIMO信号检测，最先通过解析已有的MIMO 非线性迭代算法提出基于模型的深度学习信号检测神经网络。该网络训练算法中 的关键参数，使用若干个相同的神经网络单元串联，每个神经网络单元模拟一次 非线性迭代过程，实现了使用神经网络模拟信号检测算法。结果表明基于模型的 深度学习神经网络兼具传统算法的可解释性及神经网络的泛化性，能够以较低的 复杂度实现相当可观的精度，同时对恶劣信道和错误指定的噪声方差具有鲁棒性, 显示出神经网络在某些方面比传统检测方法具有的优势。后续很多文献根据类似 的思路提出了多种基于模型的深度学习神经网络。
文献［16］在文献［15］的基础上，改进文献［15］所提出的信号检测神经网络，使 用稀疏连接代替全连接层，削减需要训练的参数，简化了损失函数，最终设计的 神经网络加快了训练速度同时提高了信号检测性能。文献［17冲通过展开正交近 似消息传递(OAMP)算法，设计了一个模型驱动的深度学习网络，用于MIMO信 号检测。通过深度学习技术优化OAMP算法中一些可训练参数，以提高检测性 能。由于网络的可训练变量的数目与网络的深度成正比，所以网络可以在很短的 时间内达到收敛。此外，该网络只需一次训练就可以处理时变信道。
文献［18］介绍了基于数据和基于模型的深度学习方法，并且比较了两种方法 在信号解调上的优缺点。结果显示在MIMO系统中发送信号和接收信号维度低
4 时使用基于数据的深度学习方法可以取得更好的性能，但是维度高时，基于模型 的深度学习方法更有优势。
文献［1刃提出使用DnCNN进行二维信道的去噪，文献［20］提出了一种用于 OFDM通信系统信道估计的深度学习算法，将快衰信道的时频响应看作二维图 像，利用导频位置的己知值来还原全部的信道响应。具体而言，先将导频处的信 道响应视为低分辨率图像，并使用超分辨率重构网络构建整个时频信道图像，使 用DnCNN优化信道估计。最终得到的信道估计优于LMMSE信道估计，接近 MMSE信道估计。
文献［21］针对高速移动环境下MIMO-OFDM系统的信道估计问题，提出了 基于深度学习的信道估计方法。使用卷积神经网络(CNN)实现二维信道的插值， 使用双向长短期记忆网络(BiLSTM)对信道进行预测，通过对神经网络进行离线 训练，有效地利用训练样本产生的信道状态信息来适应高移动性场景下快速时变 信道的特性。
基于深度学习的无线通信解调方法在信道信息不完备或者系统设计有缺陷 的情况下显示出强大的鲁棒性。文献［22］将深度学习方法用于没有CP情况下的 OFDM系统，传统方法难以解决此通信系统下的信号解调问题。信号解调由信道 估计部分和信号检测部分串联实现，神经网络可用于分别优化这两部分。信道估 计网络使用最小二乘(LS)算法初始化信道输入，使用LMMSE系数矩阵初始化 全连接网络需要优化的参数。因为此时的信道估计网络在训练时只需进行参数的 微调，所以这样的初始化方法可以提高网络训练速率和准确性。信号检测网络是 基于OAMP算法设计的，通过传统检测方法与神经网络结合，成功地提高了在 有缺陷情况下OFDM通信系统的性能。
文献［23］使用深度学习端到端的方法对信道信息不完备的情况与传统方法 进行对比，显示出深度学习方法可以在译码精度和译码复杂度下取得良好的折衷 并具有更强的鲁棒性。
文献［24］通过展开迭代算法和增加训练参数使所设计的网络能够适应不同 的信道环境，并且与基于数据的深度学习方法相比需训练参数数目依旧少得多， 可使用更小的数据集更快地训练模型。文章综合考虑了信道估计误差和信道统计 特性，并利用估计的有效载荷数据，提高了 MIMO接收机的性能。
1.3论文主要工作
本文通过对OTFS通信系统收发关系进行分析，提出一个简化的OTFS线性 均衡器，该均衡器在复杂度方面有很大改善，再通过分析高速移动通信场景下无
5 线信道特点，结合基于模型的深度学习方法设计出了适用于OTFS的深度学习信 号检测网络，以保证进行信号检测时能以低复杂度实现可靠的性能。
已有的基于阈值的信道估计方法得到的结果和实际信道信息存在较大误差。 由于信道为延迟多普勒域上的二维信道，可以视作二维图像，本文采用二维图像 去噪中常用的DnCNN网络给OTFS系统中的信道估计降噪，根据信道的特点简 化DnCNN网络，达到使用较小的层数实现信道估计去噪的目的，提高信道估计 精度。
本文主要贡献是提出基于模型的深度学习方法用于OTFS系统的信号检测, 简化DnCNN用于OTFS系统的信道估计。仿真结果表明提出的信号检测网络可 以取得性能与复杂度的良好均衡，信道估计网络可以以较少的卷积层数降低信道 估计的MSE,提高系统性能。
1.4论文结构
本文主要分为五个章节。第一章节简要介绍了论文的研究背景、研究现状及 主要工作，包括OTFS的应用和特点、深度学习在无线通信中的发展和应用、 OTFS信号解调的研究现状以及深度学习神经网络设计的研究现状。
第二章介绍需要了解的相关技术。我们详细剖析OTFS信号接收技术，包括 OTFS发送接收的过程及其相关的数学表达和推导。接着我们介绍相关的深度学 习原理和无线通信中的深度学习方法包括其应用、特点、优缺点等。此外，我们 概述已有的相关的信道估计方法和信号检测神经网络设计进而提出本论文实现 的OTFS解调系统的框架。
第三章实现基于深度学习的OTFS信号检测。我们首先大体介绍传统的 OTFS信号检测方法，包括线性均衡算法如迫零均衡(ZF)算法和LMMSE算法， 非线性检测算法如MP算法，然后提出简化的线性检测算法。为了便于将深度学 习引入OTFS系统中，我们介绍了传统的深度学习信号检测算法，包括基于数据 的深度学习方法和基于模型的深度学习方法，最终我们采用基于模型的深度学习 方法设计出适用于OTFS系统的深度学习信号检测网络。
第四章主要针对基于深度学习的OTFS信道估计问题。我们首先介绍两种导 频设计方法及需要比较的基于阈值的信道估计方法，然后参考已有的二维信道估 计神经网络，最后决定使用DnCNN神经网络用于OTFS信道估计，并根据OTFS 系统的信道特点调整神经网络，设计出适用于OTFS信道估计的去噪神经网络。 第五章是对全文的总结与展望。
第二章OTFS信号接收相关技术
本文拟使用深度学习方法对OTFS信号解调进行优化。OTFS适合高速移动 通信，是未来无线通信中有竞争力的一种调制方式。在本章中，我们拟介绍OTFS 的基本原理以及实现过程，对OTFS信号收发过程进行分析，从而为下文OTFS 接收器的设计提供理论基础。
深度学习作为机器学习的分支，己经应用于计算机视觉、自然语言处理、通 信系统等领域，且取得令人瞩目的成绩。在无线通信领域，使用深度学习方法设 计的信道估计网络和信号检测网络也显示出某些优于传统方法的特性。本章拟介 绍与OTFS接收器设计有关的无线通信中的深度学习方法，以便将深度学习方法 应用于OTFS信号的解调。最后，我们提出了基于深度学习的OTFS信号收发系 统框图。
2.1 OTFS收发系统
OTFS主要在延迟多普勒域处理数据。信息符号(如QAM等)首先被放置 于延迟多普勒域网格点上，经过ISFFT运算，变换为时频信号。此时的信息符号 可以物理上看作若干个连续多载波符号。接下来，使用海森堡变换(Heisenberg transfbrm)将多载波符号调制为一列时域信号。该信号被发送，经过无线信道，由 接收端接收。接收端使用维格纳变换(Wignertransfbrm)可以将信号恢复为时频信 号，然后时频信号经过SFFT变换得到接收的延迟多普勒域符号。OTFS系统框 图如图2-1。

图2-1 OTFS系统框图

在发送端构建延迟多普勒二维网格 A = {(/",也y),/ = 0,1,2,...,= 1,2,...,N_l},其大小为MxN,,其中延迟 维总点数为多普勒维总点数为N。Ar为延迟维网格间隔，为多普勒维 网格间隔。将信息符号放置于延迟多普勒网格点上，记为Ak,l],向量形式为- 使用ISFFT变换，将信息符号变换到时频域，如式(2-1)所示〔2〕： 其中加= 0,l,2,...,M-l, “ = 0,1,2,X[m,h\为时频域符号，向量形式记为 Xo不难发现ISFFT可以由FFT与IFFT组合实现。延迟域符号经过FFT变换 为频域符号，多普勒域符号经过IFFT变换为时域符号。故有⑷：

X =	(2-2)
其中%]皿=影exp(i冷q), p,q =	-1} , F”和F”为归一化的离散傅里叶
变换矩阵，(•尸表示矩阵的共辄转置。
此时，延迟多普勒二维网格上的信号转化为时频二维网格上的符号，时频网 格记为=	=	其中纣为频域网格
间隔，也为多载波符号中的子载波间隔，可在进行信息传输时通信系统根据需求 设定。T为时域网格间隔，与多载波符号持续时间有关。延迟多普勒网格与时频 网格满足式(2-3)所示关系[1】：
Ar =	, AP =
M^f NT
接下来，使用海森堡变换处理信号。如式(2-4)所示⑴：
N-1 ”一1	八	”
s(/)=£ £ 俎他”血(/ -
w=0 m=0
其中g“(f)是发送滤波器。公式(2-4)的矩阵表示形式为：
s = vec(S) = vec(GRX)
其中G严刃昭恣(0)血(77必),...盛(3/-1)77必)],S为发送的信号，表示为二 维矩阵，”ec(・)表示将矩阵按列展开为一列，s为最终发送的信号向量。当发送 滤波器为矩形窗时，G*=IM。此时，海森堡变换简化为IFFT,式(2-5)简化为：
s = vec(F^X) = Z ⑧FQvec(X)	(2-6)
其中0表示克罗内克积。使用矩形窗后，OTFS可与OFDM结合，作为OFDM 的预处理和后处理过程，可以很好地兼容现有的无线通信系统。
经过发送滤波器后，信号进入无线信道进行传播。考虑高速移动场景，信号 经过散射遮挡等从不同路径到达接收端，每条信号径有各自的时延和多普勒频偏。 在延迟多普勒域上，信道可以表示为：
P
力(&") =工如(7■-巧)5少一匕)	(2-7)
,=1
其中，P表示多径总数，巧为第，径的延时大小，匕为第，径的多普勒频偏大小, 人为其信道增益，§(•)为冲激函数。

在无线信道中，信号径的延迟大小和多普勒频偏大小不一定恰好分别为 和的整数倍，即信号径不在延迟多普勒网格的网格点上。但是，由于"爲 在子载波间隔不变的情况下M与■成反比，通过增加子载波数可以使•足够 小，达到提高时延分辨率的效果，而实际应用中，多载波符号的子载波数通常很 大，故而通常不考虑小数时延。由式(2-3)可得，多普勒域网格间隔与多载波 符号数N成反比，但是增加总符号数意味着传输的OTFS信号总持续时间增加， 不能保证依旧满足信道延迟多普勒特性大体不变的条件，因此不能忽略小数多普 勒信道的影响。幸运的是，小数多普勒频偏的影响可由若干条整数多普勒径拟合 ⑶列⑼，故而，为了便于分析，通常选择整数多普勒信道进行推导论证。因此, 有：
S=lQT,Vi=kv4v	(2-8)
其中厶为延迟维下标，忍为多普勒维下标。
发送信号经过延迟多普勒信道所得结果为信号与信道的卷积，信道噪声记为
(2-9)
(2-10)
(2-H)
(2-12)
其中，咄"可表示第i径的时延影响，该径信号经过延迟到达接收端相当于循环 左移了/个符号，0®可表示其多普勒频偏的影响，多普勒频偏使相位大小随符 号坐标线性增长。根据矩阵表达形式可以很容易分析出信道对发送的信息符号的 影响。经过无线信道后，接收信号与发送信号的关系可以表达为：
r = Hs+w	(2-13)
在接收端进行相应的逆变换可以得到接收的延迟多普勒信号。首先，使用维 格纳变换将接收信号变换回时频域，如式(2-14)所示：
W,/) = Ag* (_/,/)全 \ g；(厂一(2-14)
9

其中，接收滤波器g“(/)是发送滤波器纭⑴的匹配滤波器，为时频域的接 收信号，在时频域网格上为：
y［w,w］=y(/,/)|/=„7./=m¥	(2-15)
用矩阵表示有：
Y = FwGra (unvecir})	(2-16)
其 中 ， unvec(») 为 vec(・) 的 逆 运 算， G“=/ag［g“(0),gr(77M),...,gJ(M-l)77M)］。当收发滤波器使用矩形窗时， G/h，相当于对多载波符号进行了 FFT变换，此时有
(2-17)
经过维格纳变换后，时频信号再经过SFFT变换即回到了延迟多普勒域，如 式(2-18)所不：



式(2-18)可表示为:
(2-19)
式(2-4)(2-7)(2-9)(2-14)联合可得，在时频域上，OTFS输入输出关系为⑵：
N-l A/-1
Y[m9 n]=	”[加；+ w\m, ri\	(2-20)
nf=0 J»*=0
其中
h(r,可Ag” & ((加--v,(n~n')T- r)
丿2龙(u+wi'Af X( n-n' )T-T]


当使用矩形滤波器时，式(2-20)简化为［2］：
n M-1
Y[m,ri\=工	Hmn [m1, n']X[m',«(] + w '[w, M]
n'=n-\ w*=0
= Hrnn[m',n']X[m',n']+ £
+工 ％,” [M " -1]俎皿"一 1] + W 0,
»f=0
其中',£/-［,M'nlA，［m，,n］为子载波间干扰，是由多普勒频偏引起的。
M—\
工％为前一个符号对该符号的干扰，通常由多径时延引起，在 m*=O
OFDM中通过添加CP的方法消除符号间干扰。诃［加同为零均值加性高斯白噪
声。
10

使用矩形滤波器时，在时频域上OTFS输入输出关系用矩阵可表示为:
vec(Y)=也 0%)11血 ©朋)vec(X)+w'	(2-23)
理想情况下，发送滤波器和接收滤波器应当满足时频双正交性，文献［1］［2］ 给出了其定义，即
AgC/■，叽—4=诃+(叫.7 胡"］知虬《(%」/)(2-24)
其中，么⑴当xw(-a,a)时为1,其他情况为0。根据公式(2-24)可得，当且仅当 加=0," = 0时，Ag” g”(/,/)在虫(-仏,忌),/ e (-％i, vmax)处为1,其他情况为 0o
但是，实际中无法实现该滤波器。理想状态的收发滤波器通常用于分析确定 滤波器影响的下限。当使用理想滤波器时，OTFS时频域输入输出关系可以表示 为12】：
Y[m, n] - Hm n [m, ri\X\m, ”] + w'[m, n\
其中
%,”［心］=沪匕％5"5”2圖血石	(2-26)
由式(2-25)(2-26)可得，理想滤波器下，在时频域接收信号为发送信号矩阵与 信道矩阵的点乘。因此，理想状态下OTFS可以很容易进行信号检测，只需要少 量的存储空间消耗和运算时间消耗便可实现分集增益。对于实际情况下使用矩形 滤波器的情况，文献［2］进行了分析，给出的延迟多普勒域输入输出关系为：
(2-27)
其中
1
咗宀N — 1切(零)
e v J
N
为了更便于理解，结合公式(2-2)(2-6)(2-17)(2-19)(2-23),可以得到延迟多普 勒域上OTFS输入输出关系的矩阵形式：
vec(y)=(巧 ®IM)H(F[ ®Iw)vec(x) +w	(2-29)
式(2-27)常用于在延迟多普勒域直接进行信号的检测，OTFS符号的矩阵运 算表达式常用于各阶段处理分析，可以根据矩阵变换探求简化方式和改进算法⑶ 及剖析实际情况下OTFS原理，如与OFDM结合每个多载波符号前加CP的情 况⑹。
11
2.2无线通信中的深度学习方法
由于深度学习在学习复杂模型上具有优越性，加之硬件的发展极大提高了设 备运算速度，深度学习在计算机视觉、自然语言处理等诸多领域显示出了独特的 优势。近几年，越来越多学者将深度学习应用于通信系统中，取得了卓越的成果。
传统的物理层通信依赖于每个通信模块的数学表达，但是，在复杂的系统中 可能包含难以解析的未知效应，而深度学习强大的泛化能力为应对该挑战提供了 一种行之有效的方法。此外，传统通信系统由诸多处理模块组成，在通信系统设 计时通常在每个模块中进行局部的设计和优化，但是，局部最优并不能保证全局 最优，并且在不同的通信环境下，最佳的通信系统结构会有所不同。而深度学习 可以采用纯数据驱动的方法，利用系统产生的大量训练数据进行模型的训练和优 化，不需要依靠数学上可处理的模型，因此可以针对特定的使用场景进行优化， 为解决该缺陷提供一种新的可靠的方法。另一方面，过去的几十年里，许多通信 系统数学模型为通信的优化提供了理论基础，增强了系统的可解释性，而这些模 型依旧可以和深度学习相结合，设计出模型驱动的深度学习通信系统。实践表明， 基于模型的深度学习方法在保证鲁棒性的同时能更快地完成训练，达到不逊于传 统方法的效果。另外，在通信系统中使用神经网络具有一个不可忽略的好处，即 神经网络可以以低精度数据类型在并发架构上高度并行化，所以与现有的手动编 程算法相比，深度学习的模型可以更快地执行【⑶。
我们接下来介绍本论文设计神经网络需要了解的关于深度学习的一些基本 知识。在无线通信中使用到的深度学习神经网络主要涉及深度神经网络(DNN)和 卷积神经网络(CNN)。本节将分别介绍DNN和CNN的基本原理。
2.2.1 DNN基本原理
深度学习技术最初被称为感知机，其结构比较简单，除输入层和输出层外， 只有一层隐藏层，故而网络的数学表达也不复杂。当输入与期望输出的关系为较 为复杂时，单层感知机无法得到较理想的结果，因此最初的感知机只能处理简单 的函数运算。网络的函数表达能力与隐藏层的层数有关，DNN©〕采用增加隐藏层 的方式提高神经网络处理数据能力，因此，DNN也被称为多层感知机；复杂函 数关系可能具有多个输出，DNN通过增加输出层神经元个数的方式进行模拟； 神经网络的激活函数不仅影响网络的表达能力还在网络训练时发挥了重要作用， DNN可以使用多种激活函数，根据不同情况做出不同搭配a】。近年来，DNN获 得了越来越多的关注。
DNN模型如图2-2所示，主要由输入层、隐藏层和输出层组成，每一层都 包含了若干个神经单元。输入层只负责数据的输入，隐藏层和输出层的神经单元 12

会执行特定的运算。在基本的DNN中，各层之间为全连接结构。互连神经单元 的边代表一个可训练的权重值。通过训练调整权值，可以生成拟合特定输入输出 关系的神经网络模型。

图2-2深度神经网络结构
输入层的输入信号记为X®，将需要进行操作的数据传入输入层，通常输入 数据为一维向量。输出层的输出记为y°M，输出神经网络处理数据的结果；中间 部分为隐藏层，隐藏层可由不同的网络结构组成，与输入层输出层相连，完成输 入输出关系转化。第「层隐藏层输入记为x(T，为前一层网络的输出，第j层隐藏 层输出记为X®,有

其中为神经网络权重，可表示为二维矩阵，为偏置向量，和 b"T都是神经网络可训练的参数矩阵；£“(・)为神经网络激活函数。由于线性函 数经过组合依旧是线性函数只能表示线性关系，但是实际中的自变量因变量关系 很多情况下为非线性关系，为提高神经网络的关系表达能力，需要引入非线性函 数。激活函数即为非线性函数。激活函数的设置需考虑实际情况。如文献［24］中 输入的是LS信道估计，输出的是LMMSE信道估计，其为LS估计与特定矩阵 的乘积，即网络的输入输出为线性关系，故文献［24］中利用神经网络优化信道估 计时并未使用激活函数。
13

DNN 的激活函数通常有tanh(・)、sigmoid(•)、•和leaky_relu(y)等。 神经网络在正向传播时，从输入层通过隐藏层到输出层输出，反向计算时需要根 据导数对网络权重进行调整。下面介绍各激活函数相关信息Nd%
sigmoid(・)表达式为：
sigmoid (x) = —(2-31)
1 + e~x
该函数输出的取值范围是(0,1),常用于输出层，在二分问题中输出可表示概 率。其使用于信号检测网络时输出的结果可以视作发送比特为0和为1的可能 性，再经过判决可以直接得到原始比特。Sigmoid^的导函数为：
sigmoid©) =(]：一乂)2	(2-32)
该激活函数收敛较慢，求导运算与relu类函数相比，较为复杂，若是大量用 于隐藏层则网络优化难度较大，并且sigmoid函数容易产生梯度消失的问题，故 隐藏层通常不大量使用其作为激活函数。
tanh(・)表达式为
tanh(x) = =[	(2-33)
e+e
该函数输岀的取值范围是(-U)。tanh函数可以由sigmoid函数进行平移和 缩放操作获得，中心在(0,0)处，其他性质与sigmoid函数类似。其导函数表达式 为:
tanhf(x) = (cosh(x)) 2
尸刃吩)表达式为:



其导函数为:

relu函数常用作隐藏层激活函数，可以有效解决梯度消失问题，并且计算速 度非常快，因为只需要判断输入是否大于0就可直接获取输出。实际应用中，relu 函数为使用最广的激活函数之一。但是，当自变量小于0时，函数值为0,这会 导致在神经网络参数初始化较为极端的情况下或者学习速率设置过大时出现梯 度消失问题。
leaky_relu@)表达式为：
14
leaky _ relu(x) = max(x, EX)	(2-3 7)
其中&为一绝对值很小的数，可设置为可训练参数，也可为固定常量。其导函数 为：
, f 1, x>0
leaky _relu (x) = <	(2-38)
—	[s, x < 0
leaky_relu函数是为解决relu函数存在的问题而被设计,当自变量小于0时， 函数值随自变量改变，输出一个较小的值而非恒零值，可以有效避免梯度消失的 情况出现。
DNN为有监督学习，输入的训练样本有相应的标签即期望输出。进行训练 时，输入信号经过网络由输出层输出，输出值与期望输出之间存在差距时，会根 据差距进行反向传播优化可训练参数。前向传播从输入层开始经过隐藏层串联的 全连接线性运算和激活函数处理到输出层，其关系式如式(2-3刃所示：
y out = /DNN (X)
九心(…心 皆 +b®)...) + b(s) (2-39) 其中you,为DNN的最终输出，fDNN(*)为DNN网络输入到输出的函数关系，L为 网络总层数。
DNN模型的训练主要由两部分组成，分别是正向传播过程和反向传播过程。 网络训练前，DNN中的可训练变量会先进行初始化，变量初始值可以指定为特 殊值，如文献[24],也可以赋值为绝对值较小的随机值，如零均值高斯随机变量。 在正向传播过程中，数据依次通过输入层、隐藏层和输出层，与可训练变量一起 进行相应操作，得到输出结果。接着计算此时的输出结果与期望输出的差距，该 差距是使用损失函数度量的，当结果未达到要求时，进入反向传播过程。在反向 传播过程中，根据损失函数沿原来的连接通路逐层依据规则修改可训练参数的值, 以达到降低差距的目的。反向传播过程结束后，再次进入正向传播过程，直到满 足设定的停止条件才结束模型的训练〔26][29〕。
在DNN训练中，损失函数可以计算网络输出与期望输出之间的差距。损失 函数Loss可以表示为：
Loss = fIoa. (yoa,, y 嗣)	(2-40)
根据实际情况设计相应的损失函数。当网络处理的问题为分类问题时，在二 分类情况下常使用的损失函数为交叉爛损失函数，在多分类情况下，常使用对数 似然损失函数。平方误差损失函数多用于回归问题，当神经网络要解决的是预测 具体的数值时，网络的损失函数可取平方误差损失函数[26〕。假设DNN的输出结 果及真正期望的目标分别为和y,&“，则平方误差损失函数可以表示为：
15

Loss = -||you, -yideJ
当输出层激活函数为sigmoid函数时，若使用平方误差损失函数则在输出结 果靠近0和靠近1时，收敛较慢，而对数似然函数可以解决此问题。对数似然损 失函数是对预测概率的似然估计，衡量的是预测概率分布和真实概率分布之间的 差异性。其标准形式为
(2-42)
其中S为总样本数，C为总类别数，％表示第i个样本类别为几 內为第j个样本 类别为/的概率。当总类别数为2时，优化问题简化为二分问题，对数似然函数 简化为交叉爛损失函数，其公式为：
Loss = —-—^(j log p, +(1-力 log(l-口))
5 C
其中八(0,1),必为第i条样本预测为1的概率。
损失函数是一个非负实值函数。通常来说，损失函数越小，则模型拟合效果 越好，学习到的网络表达能力也就越好。神经网络的最终目标就是，通过不断调 整权重矩阵，使得模型的预测值与数据标签尽可能的一致，即找到损失函数的最 小值。而寻找一个凸函数的最小值，最简单的策略就是朝着该函数梯度的反方向 去寻找。DNN从输出层开始，逐层向前传递误差，向梯度方向的反方向调整权 值，使得损失函数不断减少，直到满足要求［29】。
DNN的优化算法主要思想为梯度下降。DNN可通过梯度下降法逐步迭代地 求解损失函数的最小值，以寻找模型中的最优的可训练参数值。首先确定设计的 DNN网络表达式即前向传播函数，视情况设计网络损失函数。设DNN中的模型 参数为u (包括可训练的加权系数矩阵和偏置向量)，损失函数记为Z(u),则梯度 下降公式为：

其中〃e/■表示第力er次迭代；〃表示学习速率，为梯度下降的步长。步长影响网 络参数更新大小，当步长较大时，网络参数每次的更新较大，可以更快地达到收 敛条件，但是容易产生函数在极小值附近来回震荡的问题，从而阻碍收敛；当步 长较小时，可以避免震荡问题，但是会增加达到收敛所需的迭代次数。梯度下降 算法依据损失函数采用的数据量的差异，可以分为批量梯度下降法、随机梯度下 降法和小批量梯度下降法。通常批量梯度下降法很消耗内存并且较慢达到收敛， 因为它是使用整个训练数据集进行优化计算，而训练数据集通常较大；随机梯度 下降法训练时随机地选取一个样本进行优化更新操作，故与批量梯度下降法相比, 内存消耗小收敛较快，但是会由于每次选取的样本自身的特殊性造成损失函数值 震荡；小批量梯度下降法为前两种方法的折衷，其每次训练选取的数据为整个数 据集中的小部分,在保证数据更具有代表性的同时解决了大数据训练收敛慢的弊 端，也是目前最常用的算法之一a】。
传统的梯度下降法设计固定的学习速率，难以快速准确地达到收敛，此外传 统的梯度下降法容易达到函数的局部最小值，为解决这些问题，已有很多梯度下 降法的改进方法被提出。深度学习中模型的更新涉及大量参数，其中会有部分参 数更新频繁,部分参数更新频率少。网络训练时，要达到较快较准确的训练效果， 希望偶尔更新的参数每次学习步长更大一些，减少所需迭代次数，而对于频繁更 新的参数每次学习步长小一些，以免被当前输入的样本特殊性影响。Adagrad。。］ 算法可以自适应调整学习速率，它设置了一个固定的全局学习速率，对于每个参 数，全局学习速率会联合其历史梯度共同生成当前迭代的学习步长，具体实现为 将全局学习速率与历史梯度平方的累积和的平方根的倒数相乘，所以之前更新大 的参数会获得较小的更新而之前更新小的参数可以获得较大的更新。对于学习稀 疏数据，Adagrad是一种有优势的优化算法。然而，Adagrad考虑了参数之前所 有的更新值，随着迭代次数的增加，历史梯度平方的累积和会越来越大，参数的 学习步长变得越来越小，难以实现快速准确地完成网络训练。
Adadelta［31］算法和RMSpropt32］算法是对Adagrad算法的改良。解决Adagrad 算法中历史梯度不断累积的问题的一个行之有效的方法是加大最接近当前迭代 的历史梯度的影响，减少或者忽略太过陈旧的梯度值对当前参数更新的作用。 Adadelta算法和RMSprop算法都采用了一种称为指数加权移动平均卩加习的方法, 设置一个小于1的正数作为衰减因子，将历史梯度平方的累积和转化为历史梯度 的衰减均值，离当前迭代越远的梯度值衰减越大，在非凸问题上能取得更好的效 果。经过该方法处理后，保证了 Adagrad算法优点的同时，不会出现后期参数更 新整体减小的情况。RMSprop算法仍需要手动设置初始学习速率，Adadelta算法 则根据参数变换量自动确定学习速率，不需要手动设置初始值。
Momentum［33］算法仿照动量的原理设计。Momentum算法存储了历史梯度， 因为当前梯度更新与历史梯度有关。当梯度方向一致时，学习速率会变大，可以 更快抵达极小值点；当梯度方向改变时，学习速率大小随之改变，可以有效减小 在极小值点附近的震荡。
Adam®】算法汲取了 RMSprop算法和Momentum算法的思想，结合两种算 法的长处对网络参数进行优化更新。Adam算法使用指数加权移动平均方法确定 更新幅度，利用之前的梯度方向和当前梯度方向确定更新方向。同时Adam算法 具有低内存消耗的优点，是目前神经网络常用的优化算法之一。
17
2.2.2 CNN基本原理
图2-3展示了 CNN的结构。CNN可以视作DNN的简化。CNN对DNN的 简化主要体现在三个方面，分别是局部连接、权值共享和池化。


图2-3卷积神经网络结构
局部连接与全连接相对。在DNN中，层与层之间为全连接，每个层与上一 层所有的神经元相连，由于DNN经常处理的是一维数据，全连接结构易于实现 并且容易使用矩阵乘法表示。在处理多维数据如二维图像时，如果将多维数据展 开为一维，也可以使用DNN处理，但是需要训练的网络参数会非常多。CNN使 用局部连接可以有效减少所需训练的参数，在CNN中，每层神经元仅与上一层 相近的神经元相连，因为通常来说特征图中相邻区域的相关性强，距离远的区域 相关性较弱，釆用局部连接亦可以保证具有足够的信息提取到需要的特征。此外， 随着网络层数的增加，感受野会随之扩大，采用局部连接也可以使用到更多的输 入信息。
权值共享也是CNN减少所需训练参数的一个重要手段。局部连接时，每层 神经元的输入为上一层相连接的神经元输出加权平均的函数，其中的可训练权值 被称为卷积核。每个卷积核都会滑动遍历上一层所有神经元，与之进行对应相乘 再求和的操作，该操作类似卷积，由此可以得到一个特征图。如果每个神经元与 上一层相连接的神经元之间的权值与偏置都不相同，则仍会产生大量待训练参数, 为简化网络加快训练，故而使用卷积核进行处理。神经网络训练时，类似于DNN, 但是调整的参数为卷积核的值。通过增加卷积核数可以增加生成的特征图，增加 网络特征提取的能力。
池化可以降低网络规模。局部连接和权值共享是在卷积层采用的，池化层在 卷积层之后，用于减少卷积层生成的特征图的尺寸。池化简单来说是对特征图进 行下采样。直接使用卷积层生成的特征图可能需要消耗更多的存储空间和更大的 计算量。对特征图进行池化时，会将特征图按一定规则划分为若干个互不重叠的 区域，池化层神经元与对应区域每个神经元相连生成一个数值，池化后的数据组 成新的特征图。在CNN中，对特征图进行池化可以获取抽象的表达，可以用于 应对输入数据可能出现的平移旋转等变化【均。池化常用的方法有最大池化和平
18 均池化。最大池化进行的操作是选取区域中的最大值，平均池化选取的是区域中 的平均值。最大池化操作简单快捷，并且对于数据特征图发生的变化有一定的鲁 棒性，虽然未使用区域的所有信息，但是通常能够取得更优的效果厲〕。
CNN通常使用多个卷积层和池化层对通过输入层后的数据进行处理，在输 出层输岀所需要的结果。卷积层的局部连接特点便于CNN利用输入数据的空间 相关性，权值共享使每张特征图对应一个卷积核，网络训练时只需调整卷积核中 的参数，因此减少了需训练参数数量，更容易优化网络；池化层中，池化操作具 有降低网络过拟合的风险和提高所训练模型的泛化能力的优点。CNN利用这两 种特殊结构能够减小网络规模提高网络训练效率［殉。
批标准化(Batch Normalization, BN)最先由文献［37］引入机器学习以加快网络 训练。当设计的神经网络具有很多隐藏层时，在网络训练时，各层参数的变化会 导致各层输出数据的分布发生变化。当输出数据分布渐渐向激活函数饱和区域 (如tanh函数靠近-1、+1的区域)偏移，训练会变得艰难，文献［37］称该现象为内 部协变量偏移，同时提出了有效的解决方法，即批标准化，用以归一化神经网络 层的输入。BN具体实现为先求每层待输入的数据的均值和方差，利用这两个参 数对输入数据进行缩放和平移，将输入数据的分布转化为零均值方差为1的分 布。通常经此处理后，神经网络对输入数据敏感度降低并且可以使用更高的学习 速率训练，以较少的迭代获得更优的模型［37］［38］。
CNN在使用卷积层处理之前，会对输入特征图的外围边缘进行零填充操作 卩9】。主要有两种填充方式，分别为“same”和“valid”。卷积核大小为1x1时，两 种填充方式相同。使用“same”模式进行填充时，卷积前后输入数据和特征图的 大小相同，因此需要在输入数据周围填充适当的“0”数据。“valid”不采取填充， 经过卷积操作后，特征图大小通常小于原输入数据。
在CNN中，卷积层可以提取输入数据的不同特征，浅层的神经网络可以提 取低级特征，随着网络层数的增加，神经网络提取复杂特征的能力增强。卷积核 本质就是一个很小的矩阵，矩阵规模通常取3x3、5x5等。卷积核通过设定的步 长在前一层数据上进行平移，每移动一次，卷积核对应位置与之相乘求和，再加 偏置经过激活函数，就可生成一个特征值。一个卷积核可以生成一张特征图，故 通常使用多个卷积核处理上一层数据，以提取多个特征增加网络表达能力。网络 优化时，只需要按特定规则调整卷积核参数，优化算法与DNN类似。卷积层后 若需要对特征图进行降维则通常接池化层，对特征进行选择，进一步减少参数数 量。在池化操作时，窗口内的数据共同生成一个值，由此特征图成倍缩小，极大 减少了需要处理的数据量，从而精简了网络，减少需训练参数［均。
2.2.3基于数据驱动的深度学习方法
19
与传统的模块化的通信系统结构相比，基于深度学习的通信系统设计神经网 络用于促进数据传输。基于数据驱动的深度学习方法通常是使用DNN作为执行 特定功能的神经网络，并用大量的带有标签的数据来训练网络优化模型的参数。 这样的DNN可以被视为“黑匣子”，并且在每个处理模块中DNN被单独地使用 以替换现有的算法。此外，当DNN合并通信系统中的所有处理模块时，它可以 用来优化整个发射机或整个接收机。这种结构称为端到端通信系统［⑷。
基于数据驱动的方法通常将整个通信系统视为端到端重建任务。具体来说， 发射机学习将源数据编码成编码符号(或发送信号)以在信道上传输，而接收机 学习从接收信号中恢复源数据，采用监督学习的方法对模型的权值进行优化，以 降低数据恢复精度的损失。因此，该通信系统就不再需要传统通信系统中的模块 结构。此外，端到端方法在为不同的信道提供通用的解决方案这方面有很大潜力
传统上，信道估计和信号检测在接收机上是两个独立的过程。在检测到发射 符号之前，首先通过导频来估计信道状态信息。然后利用估计的信道状态信息可 以在接收机处恢复发射符号。在使用基于数据驱动的深度学习方法优化通信系统 的实践中，文献［14］提出了一种联合信道估计和信号检测方法。在OFDM接收机 中嵌入一个五层全连通的DNN,通过将信道视为“黑匣子”来联合估计和检测信 道，训练DNN时通过输入与发送数据和导频相对应的接收信号来重建发送数据。 因此，DNN可以隐式地推断信道信息，不必进行显式地估计就可直接预测发送 数据。当没有足够的导频或CP且存在非线性失真时，使用DNN的信道估计和 检测方法优于使用MMSE的方法。
在通信系统中，基于数据驱动的深度学习方法在实际应用时尚面临一些挑战。 如第2.2.1节所述，DNN的权值通常是基于随机梯度下降法(SGD)【40】调整的，损 失函数的梯度从输出层反向传播到输入层。然而，当信道参数预先未知时，因为 用于更新发送器的梯度被未知信道阻塞，所以梯度不能通过未知信道反向传播， 这就阻碍了端到端网络的学习。可以通过预先假设信道传递函数来解决这个问题, 但是任何这样的假设都会使学习的模型产生偏差，重复假设的信道模型与实际信 道之间可能存在因差异导致的陷阱。其次，在实际的通信系统中，由于端到端信 道通常包含不同类型的随机效应，这些随机效应可能是未知的或无法解析地表示 的，例如信道噪声和时变效应，因此很难预先获得准确的信道传递函数ID］。
此外，通常训练一个完全连接的DNN除了需要大量的数据集外，还需要大 量的训练时间，尤其是在端到端通信系统中。然而，在无线通信系统中，计算资 源和标记数据往往是稀缺的。这些是应用基于数据驱动的深度学习方法时需要考 虑的问题。
20
2.2.4基于模型驱动的深度学习方法
基于模型驱动的深度学习方法通常是在原有的通信系统上使用深度学习优 化其中的模块，不会对原有的通信系统结构做出大的更改I?®。文献［41］将模型驱 动的深度学习方法解决特定任务的过程分为三个步骤：
1）	根据该任务所包含的任务目标、物理机制和先验知识等建立一个模型。 该模型不需要非常精确，只需对该任务的解决方案空间做出粗略广泛的定义。因 此，模型驱动的深度学习方法的建模过程与传统方法相比更加简单。
2）	根据建立好的模型设计求解算法。设计的算法需考虑约束条件、网络中 的未知参数和网络的大概的收敛速度等。
3）	将设计的算法展开为神经网络，使用神经网络训练未知参数，利用网络 深度模拟收敛所需的迭代次数，使用合适的优化算法对网络进行训练优化。
基于模型驱动的深度学习方法利用已知的物理机制和相关领域知识，如成熟 的信道模型和信息理论，可以减少需要学习的参数数量，提高训练效率［⑶。以 MIMO系统信号检测为例。基于Bayesian最优检测器的迭代算法在计算复杂度 适中的情况下表现出了优越的性能。然而，这些检测器往往对信道分布进行假设， 从而限制了其在复杂环境下的性能。通过引入机器学习的方法，可以根据特定数 据对模型参数进行优化，从而提高检测器的适应性。在文献［1刀中，将迭代过程 展开为信号流图，在有监督的学习方式下，只需要几个关键变量来调整图。该训 练框架与OAMP检测器相结合，每次迭代只设置两个变量作为可训练参数。由 于可训练参数的数目与迭代次数相当，因此与常规深度学习方法相比，它可以在 较短的时间内容易地训练，并且训练数据较少，同时提高了 OAMP检测器在瑞 利信道和相关MIMO信道中的性能。因此，这种方法可以扩展到大规模的MIMO 通信中，很有可能应用于时变信道。
与之相对应的数据驱动方法采用的是一般的系统结构，通常有很多未知参数 需要由一个庞大的数据集来训练。它们各有利弊，一般来说，基于数据驱动的方 法对先验知识依赖小，在不同的环境下，表现得更稳健，但是所需的样本的复杂 度很大;基于模型驱动的方法有先验知识，学习模型的样本复杂度可以大大降低， 但在实际场景中先验知识不准确时，模型可能会受到影响［⑴。
2.3基于深度学习的OTFS信号接收
深度学习神经网络可以看作函数运算，自变量是输入数据，输出数据是函数 结果，神经网络的训练则是拟合最优函数的过程。本论文拟将OTFS系统与深度 学习结合，用深度学习优化信道估计和进行信号检测。
在信道估计部分，优化后的信道是原先信道估计的函数，可以表示为：
21

fch anNet %)
其中hm为传统的信道估计方法得到的结果为优化后的结果。输入大量原始 信道估计，使用MSE衡量网络输岀与理想信道的差距并将其作为神经网络的代 价函数，深度学习神经网络将用梯度下降的方法通过改变参数值优化代价函数, 当神经网络达到收敛状态时，即可得到所需模型，模型表达为仏加函数。
进行信号检测时，用若干相同的神经网络单元串联进行信号检测，每个神经网络单元的 输入输出关系数学表达为：

其中x贈为经过第恥7■个神经网络单元时的信号检测结果，y为接收的信号。训练 该类神经网络通常有两种方法，一种是结合所有层的网络输出，使用每一级输出 的检测信号与真实信号的MSE的加权平均作为损失函数，共同训练整个信号检 测网络；另一种训练方法为每级神经网络单元单独训练收敛后固定参数再训练下 一级神经网络单元，每级训练的损失函数为网络输出与真实发送信号的MSEo 视情况采用合适的训练方法。本文拟用OTFS系统中简化的线性检测的值作为网 络的初始化，经过不断地训练收敛得到所需的模型，即式(2-46)中优化后的 爲的函数。由此，基于深度学习的信号解调框架大体完成。
基于深度学习的OTFS接收器设计为解决现有的OTFS研究中存在的问题 提供了一种新的解决方案，图2-4是本论文的系统模型。

图2-4系统框图
为充分发挥深度学习模型执行速度快功耗低的优势，我们考虑采用线下训练 深度学习模型，线上直接使用模型解调的方法实现基于深度学习的OTFS信号解
22
调。线下训练阶段，生成大量训练数据和足够的测试数据，输入训练数据进行神 经网络的训练，收敛后生成相应的神经网络模型，用测试数据验证网络模型的性 能，测试阶段作为线上解调的模拟。
2.4本章小结
本章首先介绍了 OTFS系统的收发过程，给出了各个过程的数学表达形式, 阐述了 OTFS系统的两种数学表达，可利用延迟多普勒域输入输出关系直接对信 号进行解调，也可以根据矩阵表达在其他模块进行优化。接着，我们详细介绍了 本论文设计基于深度学习的OTFS信号解调系统中需要使用到的深度学习知识, 包括DNN和CNN等，并对深度学习神经网络各部分进行数学推导和理论分析， 可以较为全面地了解深度学习内部原理，为设计神经网络储备基础知识。然后， 我们对无线通信中使用深度学习方法设计神经网络的两种主要方法做出了说明， 比较了基于数据驱动的深度学习方法和基于模型驱动的深度学习方法的优缺点。 最后，我们提出了所设计的基于深度学习的OTFS信号收发系统框架。
23
第三章基于深度学习的OTFS信号检测
3.1引言
在OTFS通信系统中，接收信号可以表示为发送信号与信道矩阵相乘叠加噪 声的形式，因而，OTFS的信号检测也可以使用常用的信号检测算法，包括线性 检测算法如ZF算法和LMMSE算法、非线性检测算法如MP算法。本章拟介绍 传统的OTFS信道均衡算法。此外，本文主要探究使用深度学习解决OTFS信号 解调问题，因此将简要介绍已有的相关的信号检测神经网络。最后，本章将描述 提出的深度学习神经网络，并进行对比分析。
3.2传统OTFS信号检测方法
3.2.1 ZF 算法
ZF算法⑺R2］为线性均衡算法的一种，简单快捷。根据第2.1节，可以将OTFS 系统中接收信号与发送信号的关系写为：
y = Hx + w	(3-1)
其中x和y都为延时多普勒域的信号，信道矩阵H可以根据第2.1节的分析确定， w为零均值加性高斯白噪声，记其方差为
若使用ZF算法，则均衡系数可以表达为：
(3-2)
均衡后的结果为：
x厉== x+H-1w	(3-3)
由式(3-3)可得，使用ZF算法时可以得到叠加了噪声的原始发送信号，不会 含有多径信道影响产生的符号间干扰和子载波间干扰，但是最终的检测结果忽略 了噪声的影响。当信道为深衰弱信道时，ZF算法会加大噪声的影响，从而使整 体性能变差［⑹。
3.2.2 LMMSE 算法
文献［7］在OTFS系统中使用LMMSE算法进行信号检测,LMMSE算法目的 是最小化信号检测结果与原始发送信号的均方误差，噪声方差为丈时，其均衡 系数表达式为：
24
陋阿=H气HF + £l尸	(3-4)
x观s严H"(H"H + bl)Ty	' (3-5)
LMMSE同时考虑了多径信道和信道噪声对检测结果的影响，是噪声与信号 的良好折衷，能够获得更好的均衡效果，但是需要知道信道的噪声方差等信息。
3.2.3简化的线性检测算法
ZF算法和LMMSE算法均存在矩阵求逆运算，会消耗大量运算资源。当滤 波器为理想滤波器时，只需要通过ISFFT和SFFT运算即可在时频域进行点乘和 点除，简化检测算法。使用矩形滤波器时，我们通过对OTFS系统各部分的数学 关系进行分析，提出了一种简化的线性检测算法。为了方便表达分析，不将无线 信道噪声写入到公式内。由式(2-27)和式(2-28)得，当不考虑符号间干扰时，OTFS 延迟多普勒域输入输岀关系可表示为：
p	y,..
y[k,	ejU\^ ^x[[k- kv]N,[i-]
其中P为多径总径数，勺为每条径的信道增益，M为子载波数，N是多载波符号 数。
为了方便快速检测信号和设计神经网络，对输入输出关系进行了近似表示。 Y[n,m] = Y^y[k,l]e “丿
/=°	,	、	(3-7)
心乞乞乂说” IM丿N”(N M )x[k',r]^ IN M丿
p=or=o 匸1
将延迟多普勒域信号通过ISFFT变换到时频域后，我们采取了近似处理的 方法将公式中的厂用厂的期望M/2代替，即
舟心的*2 ”2”(勞將	(3-8)
令斤#,e列晋修，此时，可以将时频域上接收信号表达为发送信号与信道矩 阵点乘的形式，如下。
Y{n,ni\« £恥列矿罚£*[宀咕右厂刃	宀°、
1=1	Q=%O	(3-9)
=H[n, m\X\n^ m\
其中恥"]=爭旳(妙伶一为]。此时，虽然引入了误差但是极大降低了运算复杂 度和所需的着储空间。式(3-9)可以结合式(3-3)和式(3-5)分别得出简化后的ZF均 衡系数和MMSE均衡系数，均衡后的结果如下：
25


(3-H)
其中(・)"表示共辄。时频域的检测结果经过SFFT变换即可得到延迟多普勒域的 信号。
3.2.4 MP 算法
MP算法由文献[2]提出,是进行OTFS信号检测常用的非线性检测算法之一。 在OTFS系统中，接收信号可以表示为
y = H,x +w
其中y、x和w都是MNx\维的复向量，分别代表延迟多普勒域接收信号、发送 信号和零均值加性高斯白噪声矩阵。w的方差为^2。x所有取值的集合为C,共 有0个值，例如发送的是QPSK符号，贝lJ2 = 4o比是MVxMV维复信道矩阵， 其中元素记为HXa,b}, a,b = {l,2,3,...,MN},根据式(2-27)(2-28)可以确定信道矩 阵的各个元素值。假设无线信道总共P条整数径，则无论使用的是矩形滤波器还
是理想滤波器巴中每行每列中只有p个非零值。因为H,是尺寸为MNxMN的矩 阵，每行每列有个值，而PwMN ,故瓦是稀疏矩阵。可以利用矩阵稀疏性 设计低复杂度检测算法[2〕。令9(a),a = 1,2,3,...,MN和畑b =	分别表
示索引集中第。行第b列具有非零元素的索弓I，有»(a)| = "@)| = P。在OTFS系 统中，发送信号和接收信号间的关系可以建模为稀疏连接因子图，其中有个 变量节点x和阿个观测节点y。每个观测节点y[a]与尸个变量节点 [x[6],fee5(a)}相连，每个变量节点x[刃与P个观测节点{y[a],a e 相连。使 用联合最大后验概率(MAP)检测规则估计发送信号，则有
x = arg max Pr(x | y, H)
对于每个元素有
x[6] = arg max Pr(x[^] = c - \ y, H) CjeC
=arg max 丄 Pr(y | 兀[b] = c ., H)
CjeC Q	3
-arg max n Pro⑷ k®] = Cj,H)
MP算法具体过程如下[2]。
消息从观测节点觅O]传到变量节点X0]:
26

y{d) = x[b]H[a, b\+ 工 x[d]H[a, d] + w[a]
de&(a\d^b
其均值可以计算为:
Q
xa = L工阴匕対砸间
dw9(Q\dHb j=\


其中"•)是一个指示符函数，如果参数中的表达式为true,则其值为
Oo
决策更新为：如果计" >严,
x［/)］ = arg max p(li}(cXc = =2,3,…,MN
Cj eC
仅当当前迭代比先前的迭代可以提供更好的估计时，才更新传输符号的决策。
MP算法设置了停止迭代条件。当满足以下任意条件时,MP算法停止：泸)=1； 沪)</)_£,其中r为第，次前的某次使於［为最大的迭代；达到设定的最大迭 代次数。第一个条件发生在所有符号都收敛的最佳情况下。如果当前迭代提供的 决策比先前迭代的决策更糟糕，则第二个条件对于停止算法很有用【44］。
3.3基于深度学习的信号检测算法
27

基于数据驱动和基于模型驱动的深度学习方法是目前用于信号检测的两种 主要网络设计方法。本小节将对两种方法具体实现进行介绍。
3.3.1基于数据驱动的深度学习信号检测算法
基于数据驱动的深度学习方法主要思想是将接收端视作黑盒子，输入端输入 需要解调的数据，由于神经网络需要学习输入信息中的特征从而得到输出解调信 息，故网络输入应包含足够的与期望输出相关联的信息。若神经网络输入只为接 收到的受到多径等信道影响的未知信息符号则神经网络想要输出解调信号相当 艰难。为了让神经网络更快完成模型训练，更容易找到输入输出间的函数关系， 通常来说，信号检测神经网络输入会包含接收到的信息符号和接收到的导频符号。 神经网络要表示复杂的输入输出关系需要较多层数，然而神经网络层数越多，需 要训练的参数随之增多，网络变得复杂，难以训练，收敛也会相当缓慢。已有的 基于数据的用于通信信号检测的神经网络层数为三到五层[EM)"]。
将接收到的信息符号与接收到的导频符号相连接作为神经网络的输入，神经 网络设计为DNN或者CNN,损失函数为期望输出与实际输出差距的函数，经过 学习后，神经网络可以实现信号的成功解调，而不需要额外的信道估计与信号检 测部分。下面我们介绍通常使用的基于数据驱动的信号检测网络，该网络通常用 于OFDM信号检测中，详细信息可见文献[14][18]o
V
J data
A pilot

图3-1基于数据的深度学习信号检测网络
如图3-1,基于数据驱动的深度学习信号检测网络中“深度学习神经网络” 通常为DNN,直接解调二维信号时，网络也可能为CNN,如二维信道估计网络。 其中辺为接收到的信息符号，y豳为接收到的导频符号，乂竝,为神经网络输出 的解调数据。
在OTFS系统中，可使用一整个OTFS块插入导频用于信道估计，导频块与 数据块为连续传输，可将导频符号置于第一个OTFS块中，其后接着若干OTFS 块用于传输所需信息，这些OTFS块在一定时间内可以视作经历相同信道，通过 适当控制导频块与数据块的长度以满足信道大体不变要求。接收端可以将二维的 OTFS数据块展开为一维信号。现有大部分深度学习信号检测网络都是处理一维 信号，此时，图3-1中的“深度学习神经网络”为DNN。该DNN以一个导频块
28
与一个数据块作为神经网络输入，解调后获得的原始数据为输出，从而恢复传输 的数据。
正如大部分深度学习神经网络，信号检测网络也包括离线训练阶段和在线应 用阶段。离线训练阶段致力于优化DNN参数，使用己有的信道模型处理随机符 号以生成大量可用于训练的仿真数据。DNN由于其训练参数通常较多，加之难 以使用数学模型解析其信号检测原理，故通常需要大量的训练数据，以确保模型 的鲁棒性和对数据的泛化能力。在线应用时只需要DNN输入符合网络需要的格 式，即可直接输出解调数据，方便快捷。
假设所设计的DNN有L层，则网络的输入输出关系为：
x如=阕6(戊艺(…閲c”(严)-))	(3-23)
y pitot _
其中［I：：］表示接收的信息符号和接收的导频符号连接为一列；办”"6”(・)表示一层 全连穆网络，最后一层激活函数使用sigmoid^ ,目的是使输出范围集中在(0,1), 若输出大于0.5则判别为比特1,输出小于或等于0.5则判别为比特0,由此可以 直接输出传输的比特信息完成解调。其余各层激活函数皆为疋/“(・)，使用该激活 函数不会削弱网络表达能力，可以减低网络训练难度，改善网络。办创6”(・)具体 实现见221节。神经网络的损失函数为网络输出与期望输出的MSE。
输入神经单元个数根据要解调的数据确定，输出神经单元个数则可以手动设 置。由于设计的单个DNN网络一次性解调出所有输入的信息符号很有挑战性， 所以通常使用若干个并联的DNN对数据进行解调，每个DNN只负责解调输入 数据中的一段，比如输入64符号每个DNN只解调其中8个符号，由8个DNN 并联组成完整的接收器。
由于现有的神经网络都是处理实数数据，并无对应的复数神经网络，因此不 能直接将复数接收信号传入网络中。一般将复数信号拆解为实部和虚部连为一列 的形式进行输入，解调后的数据也为实数数据，如式(3-24)所示：

其中Re(.)和Im(.)分别为取实部和取虚部操作，%为复数的接收信息数据，
为接收到的复数导频符号，袤竝，为解调后的复数数据。
文献［14］和文献［18］都使用包括输入层输出层在内的五层神经网络，隐藏层
设置为三层，各个隐藏层神经单元个数设置没有统一标准。通常而言，每层神经
单元数都不小于输出层，第一个隐藏层神经单元数最多，这样做可以将输入数据
映射到更高维度，接下来的隐藏层神经单元数会依次减小，以提取目标特征。在
文献［14］中输入层设置为256,输出层神经单元为16,三个隐藏层神经单元分别
29
为500、250、120；文献［18］中则比较了各层神经单元数量变化对网络产生的影
响，总体而言，神经单元越多网络拟合能力越强，但是随着神经单元的增多，对
BER的降低能力逐渐减弱。此外，当MIMO系统中天线数量增多时，比如4x4
时，基于数据的深度学习方法已经不如基于模型的方法。
在OTFS系统中，信号矩阵通常很大，如果使用一般的DNN则需要训练的 网络参数会过于庞大消耗大量存储空间，并且网络训练也会很耗时。此外，由于 网络的可解释性不强，神经网络各层神经单元数目的设置也是个难题。CNN可 能为解决以上难题提供一种方法，但是尚未有相关文章将其实现。鉴于以上问题, 暂不考虑在OTFS系统中设计基于数据驱动的信号检测网络。
3.3.2基于模型驱动的深度学习信号检测算法
在基于模型驱动的深度学习方法中，文献［15］最先使用已有的MIMO信号检 测的知识设计了 DetNet信号检测网络，之后有很多文章是按照其神经网络设计 思路设计出相似的神经网络用于解决不同的问题的，文献［16］设计的ScNet在 DetNet基础上进行改良简化最终实现了更好的检测性能。ScNet使用的稀疏连接 方式大大减少了神经网络所需训练的参数，使设计能够实际应用的OTFS信号检 测神经网络成为可能。本小节拟先介绍DetNet再介绍ScNet进行的相应改进。
DetNet〔®被提出用于Massive MIMO信号检测，其解析最大似然(ML)投影 梯度下降进行设计，DetNet依据的公式如式(3-25)所示：
A /匚 f a||y-Hx||2
x*+i = fnL ^k~Sk "-	"
l	铳 “J	35)
其中ZJ・)表示某种非线性函数关系，(・卩表示矩阵的转置，y为接收信号，乞 表示第£次迭代得到的信号检测结果，假设共进行Z次迭代，贝U<k<L,心为 每次的步长，在手动编程解调时步长多为手动设定更新规则，神经网络中可将步 长交由网络自动优化。从式(3-25)中可以看出，接收信号通常不直接出现，而是 以H'的形式参与运算，且有
Hry = HrHx+V^e	(3-26)
其中V”加可以视作零均值加性高斯白噪声，^{-1,+1}为独立等概二进制符号。 为了简化神经网络计算过程，在DetNet网络优化前计算好了 H、和H『H。Hry 作为每次迭代前的输入；HrH每次迭代前与上次输出的更新检测结果乞相乘之 后作为输入，即iTHi”；乞作为需要更新的信息也是网络完成迭代模拟所必须 的输入之一；此外，DetNet加入了一个变量输入，我们记为U*,表示第£个网络
30

中的该变量矩阵的输入状态，该变量初始化状态为全零向量。H、、HrHxx. xt 和U”组成了 DetNet的输入。DetNet类似于DNN,先将输入与更多的神经单元 进行全连接以解析输入向量内蕴含的隐藏关系，再将其通过类似输出层的网络层 以输出下一网络单元所需的输入。DetNet由若干具有相同内部结构的网络单元 串联而成，每个网络单元执行~次对信号信息的迭代更新。DetNet中每个网络单
元的具体结构如图3-2所示:

图3-2 DetNet网络单元问
图3-2中，“concatenate"为连接操作，W都表示权重，b表示偏置，网络会
对心和6更新。该网络单元的数学表达如下:



其中。(・)为非线性函数，此处取为『刃“(・)，$(・)也为非线性函数用于对信息符 号进行处理，具体表达式如式(3-28)所示：

DetNet将式(3-28)的f设置为可训练变量，$(・)可将变量全部转化为[7+1] 内的数据。在$(・)中，当x<-\t\时判决为-1,在时判决为+1,在-|r|<x<|/| 时输出x/\t\,类似于简化的软信息输出。通过调节/大小，可以控制判决范围， |/|过小输出容易震荡，过大容易导致收敛提前。实际设计时为了避免“o除”，会
31 在分母处添加绝对值很小的正数。神经网络最终输出的检测结果会使用s,g"(・) 函数进行判决。
文献［29］则通过对DetNet的分析，将网络简化如下：


图3-3 DetNet简化示意图
如图3-3所示，DetNet可以大体简化为三层网络，假设MIMO中接收信号 y的矩阵维度为刃xl,发送信号x维度为HX1,则信道矩阵H维度为mxn,输入 向量中H「y维度是“xl, iTHi*维度是”xl,乞维度是nxl, U”在DetNet中设 置为了 2“xl,即输入层维度为5nxU隐藏层神经单元个数设置为了 8“xl,隐藏 层激活函数为relu^),输出层中，输出殳出时激活函数为？(・)，输出U"时未设 置激活函数，输出层维度为3"X1。
DetNet的损失函数考虑了所有层的输出，并且采用了规范化，具体表达式如 式(3-29)所示［⑸：
Lg =	⑷占2斗	(3-29)
A F-XL5||
其中心$为输入信号的LS估计，有
=(HrH) Hry	(3-30)
DetNet每个网络单元输出都乘以了系数添加到最后损失函数中，越靠近最 终输出层的输出对检测结果的影响越大，因此系数更大。损失函数具体推导过程 见文献［15］。此外，如果需要知道各个单元的结果，可以提取每层的输出计算误 比特率，这样就可判断神经网络使用多少层时已经收敛。文献［15］中使用30个网 络单元完成DetNeto
ScNet为DetNet的改进版，在文献［16］中提出。ScNet致力于简化DetNet, 简化后的网络能更好地实现大规模MIMO的信号检测。其做出的主要改动在三 点，分别为简化网络输入、使用稀疏连接代替全连接、简化损失函数。
ScNet的结构可以简化如下：
32

k+l
图3-4 ScNet简化结构
如图3-4所示，ScNet删除了 U- 的作用是添加偏置以表征可能出现的 非线性因素，但是神经网络通过激活函数已经获得了非线性特性，所以U*能发 挥的作用有限。加之6作为网络的输入以及每一层网络单元的输出，增加了网 络开销，占用了大量的资源，如果删去则网络单元连边数立减为原来的一半。
ScNet的设计更契合ML投影梯度下降公式，公式(3-25)中 +	所包含的三个输入为一一对应关系，并不需要隐藏层映射
到高维以进一步挖掘特征，也不需要全连接层使每个输出都用所有输入为自变量。 在三个输入向量中，坐标相同的数据具有显著的函数关系，坐标不同的数之间单 从公式(3-25)上看，无明显联系，故而使用一一对应的稀疏连接代替全连接结构， 并且去除了隐藏层，大大减小了所需训练的参数。ScNet公式可以表达如下：

(
Hry



wo

+ b
(3-31)

k

丿

其中O表示哈达玛积。对图3-3的分析可知DetNet每个网络单元的连边数目为 5nx8n + 8wx3w = 64w2 ,经过减少输入和稀疏连接后，连边数目减小为3”。
DetNet的损失函数计算了理想输出与实际输出后加入了规范化函数项 収-红『，有[叫
||xf权一但吋叭『
=卜-(HrH) 1 (HrHx + V”Q『	(3-32)
=||(H「H)TV爲『
可以将规范化函数项视为未知噪声的函数。文献[29]以噪声项随机性高容易 加大误差、函数运算需要使用LS估计从而进行矩阵求逆操作复杂度高、MIMO 系统中不一定能保证矩阵满足可逆条件等理由删除了规范化函数项，ScNet损失 函数如式(3-33)所示：
(3-33)
损失函数简化后所需的计算量下降，并且检测性能能够得到略微的提升
[16][29]°
33
当将DetNet和ScNet应用于OTFS系统解调中时，DetNet每个网络单元连 边数变为64(W)2,而ScNet的连边数则为3MM,而在OTFS系统中M和N通 常较大，所以ScNet实用性更高，文献[16]中的结果表明ScNet在收敛性和误比 特率性能上都优于DetNet,故拟用ScNet作为对比方法。
3.4改进的信号检测神经网络
忽略噪声，根据式(2-25)(2-26),在理想滤波器下有
Y[m, n] = HWea/[w, M]X[m, n]	(3-34)
其中理想滤波器下的信道矩阵为：
H如[% «] = JJ h(r, v)严 Te-jKv+MFdv	(3-35)
由于理想滤波器不可实现，为了便于实际应用，采用矩形滤波器作为收发滤 波器。在第323节中，我们提出了简化的线性检测算法，式(3-9)的形式与式(3- 34)类似，可以使用式(3-9)近似表示时频域上发送信号与接收信号的关系，利用 该近似，可以通过在时频域里先进行点乘再转化为延迟多普勒信号来计算H：y 和H：H,x,如下:
unvec(^y) =	(H* OY)F^	(3-36)
⑷vec(H：H「x) = (H* OH0X)F；	(3-37)
其中直为式(3-9)中的近似信道矩阵。通过式(3-36)和式(3-37),可以快速计算出神 经网络所需的输入，并且计算所需的内存也大大减少。
文献[45]在ScNet上进行简化直接将Hry-HrHx作为网络的输入，这样处 理更契合ML投影梯度下降法的公式。然而在OTFS系统中的信道矩阵与MIMO 不同，MIMO的信道多径总数通常会随发送天线和接收天线数量的增加而增加， 但是OTFS系统中，一个OTFS块的大小对它所经历的信道的多径总数影响不 大。接下来我们在OTFS系统中分析H/y-H/H'X的特性。我们定义：
^ = fcountV (丫，直,Xd)
=unvec^y -	)	(3-38)
= Fw(H*OY-H，OHOXrf)F；
在我们设计的网络中，处理的数据为二维数据不需要将其展开为列向量。图 3-5显示的是信噪比20dB下，假设有4个符号判决错误时，V =
的绝对值的图像，其中X。表示对x进行了一定程度的判决。可以看到当错误判决 发生时，残差图像有4个大峰值，分别对应判决错误的位置，在大峰值外还有若
34

干较小峰值，是由信道的多径效应造成的。为了非线性迭代时，能够更有效接近 目标值，我们将对V进行处理。

图3-5残差图像
对丘进行一定程度判决可以使判决错误的符号的影响更突出，同时减少尚未 进行判决的符号可能带来的干扰，本文用的是QPSK调制，采用式(3-28)中的函 数进行判决。将需要处理的W实部和虚部分别通过该函数，可得到经过一定程度 判决的符号：
+丿％ 区)	(3-39)
其中，心和初分别为丘的实部和虚部，Q(・)为函数，取式(3-28)中/ = 0.05, 目的是对初和x；进行一定程度的判决同时保留部分软信息，方便训练。
我们设计神经网络的思路为使用V的绝对值寻找前次迭代结果可能存在错 误的点，再使用V对应位置的数值对可能错误的符号进行更新。设计的神经网络 拟对残差进行训练，求解大峰值出现的位置并纠正判决错误的符号。为了降低小 峰值的影响，将残差沿延迟维的均值和沿多普勒维的均值都加入训练
用V,和%分别代表V的实部和虚部，J 和如分别代表％的绝对值 和正负符号，V加和耳品”分别代表V,的绝对值和正负符号。［•］“,和［•］」，分别表 示沿第一维和第二维的均值，贝!J：
1 M
! ；	SO)
接下来将实部和虚部分别训练。将延迟维均值、多普勒维均值和残差的绝对 值一起训练，以减少小峰值带来的影响，如下：
加％ ”］ =	+ %,2 ［劇［Vs］,N ［加I
A	(3-41)
匕［刃,勿=V® ［肌,”］+ ^,1［»］［VAa6s］A/＞［«］ + 給2［刃］［V/』N ［加］
35


图3-6提出的网络
在图3-6所示网络中，fCouniy在式(3-38)给出定义，为了减少运算，通常存储 计算一次H 0Y和宜* 0宜然后存储以待进行fCoun!y时直接使用。神经网络输入 的初始化使用第3.2.3节提出的近似的LMMSE算法，输入的信息有接收信号、 初始化的检测信号和信道矩阵。由若干相同的神经网络单元串联，每个神经网络 模拟一次非线性迭代过程，输入的信号先进行简单的判决，然后与接收的信号共 同生成残差，训练参数，输出优化后的结果，更新检测出的信号，继续通过下一 个网络单元优化。损失函数釆用ScNet^l中的损失函数。网络模型训练好后，将 相应的数据输入模型即可得到需要的输出，经过硬判决后得到原始的发送比特信 .息、。
3.5性能评估
本节我们拟设计仿真实验，对提出的方法进行评估。提出的信号检测神经网 络先采用LMMSE对网络的输入进行初始化，再通过深度学习神经网络进行非 线性迭代模拟。因此，线性初始化的复杂度和性能也会影响信号检测总体耗时与 36
收敛。我们拟先对线性检测算法与简化的算法进行对比。由第321节和第322 节可知，直接使用ZF或者LMMSE运算，由于要进行矩阵求逆，复杂度很大, 都为O（（册/）,而简化的算法由FFT、IFFT和矩阵点乘组合而成，复杂度为 O（MN\ogMN）,但是简化算法引入了误差，我们拟使用仿真结果更直观了解简 化算法的耗时缩减与性能下降。
我们参考文献[1][2][4][5]等OTFS相关文章，采用载波频率为4GHz,子载 波间隔为15kHz的仿真设置，信道模型使用EVAH6]信道，信息符号使用的是 QPSK,移动台移动速度为240km/ho鉴于直接矩阵求逆运算量大，并且存储信 道矩阵的空间消耗较大，故选择较小的载波数量和多载波符号数以作比较，选择 载波总数为32,多载波符号数为16,仿真500个OTFS数据块。误比特率仿真 结果如图3-7所示。

0	2	4	6	8	10	12	14	16	18	20
SNR（dB）
图3-7线性检测对比
我们记录了使用matlab对以上各种情况进行仿真的耗时。使用不同的线性 均衡方法检测OTFS数据平均每个数据块需要的运行时间如表3-1：
表3-1线性检测耗时对比
均衡方法
ZF
LMMSE
简化ZF
简化LMMSE
耗时/s
0.341138
0.320626
0.002967
0.0029208
从图3-7中可以看出，简化后的ZF和LMMSE算法在性能上有所损失，在
误比特率为0.05处，简化后的ZF比原始的ZF差ldB左右；在误比特率为0.01

37

处，简化后的LMMSE比原始的LMMSE差2dB左右。但是，从表3-1上看，简 化后的线性检测方法耗时比原始方法的1/100还要少。此外，使用LMMSE的误 比特率明显好于ZFo
接着，我们使用简化的LMMSE均衡结果作为设计的信号检测神经网络的输 入初始化。我们拟使用最少的网络单位数完成OTFS的信号检测，故我们仿真了 在12dB下信号检测网络随相同网络单元个数递增的误比特率曲线，同时对比了 OTFS经典非线性检测算法MP算法随最大迭代次数增加的性能情况。
保持载波频率、子载波间隔和移动速度不变，信息符号依旧为QPSK, OTFS 块中子载波数设置为128,符号数设置为64,比较非线性迭代次数对误比特率的 影响。神经网络使用相同的网络单元串联，每个网络单元模拟一次迭代；MP算 法每次迭代的更新系数分别设置为0.60、0.65和0.70o分别对比MP算法、ScNet 和提出的深度学习神经网络（记为ProposedNet）。MP算法仿真500个OTFS块; 神经网络使用批量的大小为32,学习速率为0.001,优化算法为Adam,共训练 50000次。在信噪比为12dB下进行仿真，仿真结果如图3-8所示：

[0-4 	I	I	i	I	I
2	4	6	8	10	12	14
迭代次数
图3-8迭代次数与BER对比图
使用MP算法的情况下最大迭代次数小于6时，更新系数设定较大则性能较 好，但是随着最大迭代次数的增加，BER会产生震荡，可能的原因是MP算法停 止迭代的条件是人为选定的并非最优。根据图3-8结果，我们选择MP算法的更 新系数为0.65,在最大迭代次数为10时误比特率最小。设计的深度学习神经网
38
络和ScNet大概在8个或10个网络单元时已经收敛。为了便于比较，故设计神 经网络网络单元数为10, MP算法最大迭代次数设计为10次。
根据确定的仿真条件，我们测试所设计的信号检测神经网络的性能，仿真结 果如图3-9所示：

图3-9显示了不同检测方法随着信噪比增大BER的变化。此处，LMMSE为
理想滤波器下的OTFS性能，与传统LMMSE性能相当，但是可以直接使用点乘 点除的方法进行均衡复杂度低，实际情况下不可实现。MP算法可以达到理论最 佳，但是实际中需要手动设置迭代过程中的关键参数，参数设置的不完美会导致 检测性能的下降。信噪比为8dB及其以下时，ScNet与MP算法检测的误比特率 相当，提出的神经网络在信噪比lldB以下时为四种方法中误比特率最佳，表明 深度学习神经网络在低信噪比条件下比常规方法更能忍受噪声的影响。所提的神 经网络在信噪比较低时优于MP算法，可能的原因是设计的神经网络将残差的绝 对值信息加入训练,可以在一定程度是削弱噪声的影响。信噪比在lldB以上时， 传统的MP算法可以取得更低的误比特率，信号检测网络采用的简化计算方法有 利于设计网络降低计算复杂度，但是采用的近似会带来固有的误差，该误差会对 信号检测造成一定影响。但是，提出的深度学习神经网络与已有的ScNet以及线 性检测相比都可以提升性能，在误比特率为0.01处,提出的网络相比于LMMSE, 可以提升2.5dB左右，相比于ScNet可以提升0.9dB左右。
39
在3.3.2节中，我们分析了 DetNet和ScNet的网络连边数量，分别为64i?和 3“。由于在OTFS系统中发送信号和接收信号类似于二维展开为一维，因此，在 OTFS系统中，使用DetNet时，连边数量为64(A^V)2,而ScNet的连边数量为 3MN。提出的神经网络类似于ScNet,但主要训练的是残差，由式(3-40)和式(3- 41)得网络中与需训练参数进行运算的数据主要包括残差绝对值、沿延迟维的残 差绝对值均值和沿多普勒维的残差绝对值均值，其中在更新数据前残差绝对值前 的系数为1，因此需训练的参数主要集中在其他两个输入对应的权重矩阵。综合 考虑可得，提出的神经网络连边数量大约为M+N,总结如表3-2所示：
表3-2网络连边数比较
网络
DetNet
ScNet
ProposedNet
连边数目
64(MN)2
3MN
M+N
由表3-2与图3-9可得，设计的神经网络比已有的ScNet在复杂度、训练难 度和性能等方面更适合OTFS的解调。我们比较了 MP算法一次迭代的运行时间 与提出的神经网络单个网络单元的运行时间，结果如表3-3所示：
表3-3迭代耗时比较
平均每次迭代耗时/s
MP
ProposedNet
0.563
0.00313
从表3-3可以看出，MP算法虽然可以取得不错的解调效果，但是完成MP 检测耗时更长。使用神经网络进行一次迭代模拟耗时为原来的1/180左右，而MP 算法与设计的神经网络迭代次数相当，因此可知，设计的神经网络大大减少了信 号检测的运算量，能够取得性能与复杂度的良好折衷。
3.6本章小结
在本章中，我们首先介绍了传统的OTFS信号检测方法，包括线性检测方法 如ZF均衡和LMMSE均衡以及非线性检测方法MP算法，通过分析OTFS系统 输入输出关系，我们提出了一个简化版线性检测器，可以在性能损失可接受范围 内大幅降低信号检测复杂度并减少空间复杂度。MP算法是最经典的OTFS非线 性检测算法之一，能够使信号检测性能接近最优，但是计算复杂度较高，性能受 人为设定参数的制约。深度学习为提高信号检测性能、加快检测效率和增强鲁棒 性提供了一种行之有效的方法。我们介绍了现有的值得参考的由深度学习方法设 计的信号检测网络oDetNet通过剖析非线性迭代原理设计网络结构以解决MIM0 信号检测问题。但是由于DetNet具有连边数量多、需优化的权重数庞大、空间 复杂度较高等缺点，不适合具有较大信号矩阵的OTFS系统。ScNet是DetNet的
40 改进结构，通过减少输入向量的数量、改变节点间的连接结构和简化损失函数的 方式极大地减少了网络的空间复杂度和网络训练难度。ScNet适合大规模MIMO 的信号检测，也可用于OTFS系统中。我们通过分析OTFS系统中发送信号、接 收信号与信道矩阵间的关系，利用其残差的特点设计了一个适用于OTFS的信号 检测网络。通过与ScNe做对比，设计的网络需优化参数减少并且信号检测性能 更优，与MP算法相比，所设计的网络实现了性能与复杂度的良好折衷。
41

第四章基于深度学习的OTFS信道估计
4.1引言
在高速移动场景中OTFS相较传统的OFDM更有误码性能优势，为了成功 实现OTFS信号的解调，需要在接收端获取OTFS信号经历的信道信息。信道估 计一般借助导频进行，在发送端插入导频，接收端导频信号经过信道后，携带信 道冲激响应信息，再经由特定的信道估计算法，可以解析出导频处的信道信息, 利用导频处的信道信息可以推测出所需要的信息符号处的信道信息。
OTFS可以在时频域进行信道估计，但是通常来说时频域信道矩阵较大导致 实现复杂度较高。在文献［5］中OTFS信道估计问题得到详细的阐述，与OFDM 信道估计有所不同，OTFS导频信号主要在延迟多普勒域进行设计。在每个OTFS 帧中，在延迟多普勒网格点插入导频、保护间隔和数据符号，使用合理数量的保 护间隔以适当避免接收机处的导频和数据符号之间产生干扰。在本章中，我们拟 对OTFS信道估计进行研究，并设计基于深度学习的OTFS信道估计方案。
4.2 OTFS导频设计及信道估计
接收导频：•
图4-1 OTFS导频设计示意图
在发送端，导频信号设计为OTFS块的中间区域，保护间隔为全零数据，根 据最大多普勒频偏和最大时延设计保护间隔区域分布；在接收端可以收到经过了 多径时延和多普勒频偏影响的数据符号和导频符号。使用◎代表导频符号，定义
42
导频功率与噪声功率比值为SA笔=|XP|7CT2 ,发送信号中包含导频信号及其保护 间隔和信息符号。使用£表示数据符号。则在发送端延迟多普勒域的符号设计可 以表不为：
k = kp,l = lp kp-2kv<k<kp+2kv lp~lr<l<lp+lT
otherwise.
其中©和每分别表示导频符号在多普勒轴和延迟轴上的坐标，该位置为手动指 定，在单发单收(SISO)系统中，通常取kp=N/2和—=凶2,指定其为整个OTFS 块的中心，使其信道估计更有代表性。人和―分别为最大多普勒频移和最大时延, 设计的保护间隔需要降低导频对符号的影响同时避免数据符号进入接收端将截 取导频信息的区域。因此，共需有N”=(2.+l)(4怠+1)-1个保护间隔。保护间隔 内的符号取值为全零，导频符号值为一大绝对值的正数。在OFDM等调制中一 般不使用冲激序列作为导频，原因之一是冲激序列具有很大的峰均比，不利于硬 件实现。但是，在OTFS系统中，延迟多普勒域信号还需经过处理变换到时频域， 处理后，每个延迟多普勒域符号都会拓展到整个时频网格上，因此，大功率的符 号经过变换叠加后对发送的OTFS信号整体峰均比影响很小，文献[5]中做了相 关研究，当导频信号功率提升I2dB时峰均比只提升了 0.2dB左右。因此，在 SISO+OTFS系统中适合使用冲激序列并且这样的设计可以实现节省导频开销。 此外，信道估计在该类导频设计方案中可以很容易实现，并且在实际应用时，将 导频符号功率设置较大提高了 SNRp可以有效降低接收端导频区域的受到的噪声 对信道估计的影响。
当收发系统使用理想滤波器时，在延迟多普勒域上，接收信号相当于发送信 号与一个固定不变的二维信道矩阵做卷积运算，冲激序列导频信号与信道矩阵卷 积后，会在延迟多普勒域上形成二维的信道图像，保护间隔可以使二维信道信息 更加完整，由于信道噪声的存在，二维信道图像也会受到其干扰。此时，导频部 分在接收端的表达式为：
y\k,l} = b[k-kp,l-l^h\k-kp,l-l^xp+v\k,l}	(4-2)
其中k&[kp-kv,kp+kv],l^[lp,lp+lT], = 冈，门丁"語缶,Z>[AU]w{0,l}, 当b[k,l} = \时表示在坐标伙刀处有信号径，若b[k,l] = 0,则此处无信号径，此时 y\k,l} = v[k,lAo因此b[和]总和为信道多径总数，有：
丈	= P	(4-3)
k=-kv /=0
当使用矩形滤波器时，接收信号表达式则为⑸:
43


导频区域网格范围是ke[kp-kv,kp+kv], Zw£,/p+J]。Thre大/卜为人为设 定，一般与噪声功率有关，在文献[5]中，选取的恥畑为噪声功率开方的三倍，即 3b。使用阈值过滤后再将留下的信号径根据式(4-6)纠正每条径的频偏，即可得 估计的信道。
另一种导频设计方法为将导频序列设计为类似高斯随机序列的具有良好自 相关性的二维序列。发送端导频设计图案示意图如图4-2所示：

x
M.
X

X

X



X
X
X
X
X
X
X
X
X
X
X
M
X









X
X







X
X
x
X


•
•
•



X
X
X


•
•
•


X
X




•
•
•





X







X
篝









X
X

X
X
X
X
X
X
M
X
X
X

X

X

X


X
X

发送数据:;保护间隔：|	导频符号:•

图4-2另一种导频设计方式
44
此时，欲进行有效的信道估计需要使用特定的算法，如正交匹配追踪算法R7］ 和3D-SOMP112］算法，利用导频的自相关性确定信道多径值，增加了信道估计的 复杂度并且增加了导频开销，故在SISO+OTFS系统中通常不使用该导频设计方 案。在MIMO+OTFS系统中，为了导频之间不相互干扰，在使用冲激序列的导 频设计需要划出不重叠的区域分别插入导频，而图4-2所示方案将所有的导频都 叠加在一起，通过自相关性进行区分以估计信道，能有效降低导频开销。本文主 要考虑SISO+OTFS场景，故不对该方法进行详细介绍和对比。
4.3基于深度学习的OTFS倍道估计方法
目前尚未查阅到使用深度学习方法针对OTFS信道估计进行优化的文章。 OTFS信道可以在延迟多普勒域表示，可以将二维信道视作二维图像，已有的图 像处理神经网络可以对其进行处理。在使用深度学习方法进行二维信道估计的研 究中，文献［20］［48］都是在OFDM系统中进行时频信道估计，文献［48］设计SRNet 直接从低分辨率(LR)信道图像生成高分辨率(HR)信道图像作为最终的信道估计 结果，文献［20］在生成HR图像后，使用IR网络进行去噪提高信道估计精度。
但是，在OTFS系统中，时频信道矩阵尺寸很大且不具有稀疏性，若是在时 频域进行信道估计优化，可能会造成很高的时间复杂度和空间复杂度，影响系统 整体的解调性能。其次，在高速移动场景下OFDM导频处的信道信息与数据符 号处的信道信息通常存在较大差异，因此不适合直接使用导频处的信道信息对符 号进行均衡，但是OTFS导频处的信道被认为是整个OTFS块的所经历的信道， 故在OTFS系统中没必要通过SR网络生成整个OTFS块信道图像。
我们拟在OTFS系统中使用IR网络对延迟多普勒域的信道估计进行优化， 文献［20］具有较大参考价值。本章拟介绍文献［20］提出的基于深度学习的信道估 计网络，之后根据己有的信道估计网络结合OTFS信道特点设计适用于OTFS的 信道估计神经网络。
4.3.1基于深度学习的信道估计神经网络
文献［20］使用图像超分辨率(SR)网络和IR网络进行级联，共同完成二维 信道的估计优化。先将信道响应的时频网格建模为仅知道导频位置数值其他初始 化为零的二维图像，接着可以使用已有的用于图像处理的深度学习神经网络对信 道估计进行处理，具体而言，先使用SR网络完成信道图像插值，然后使用IR网 络给信道图像降噪。由原始导频处信道估计构成的信道图像是LR图像，导频处 信道信息和信息符号处信道信息共同构成的完整的二维时频信道图像被认为是
45
HR图像。首先，输入LR图像，使用SR网络进行处理，得到HR图像图像。之 后，利用IR网络去除噪声影响，得到最终的信道估计。
先使用导频信道信息构建LR图像。使用不需要信道统计信息的LS算法计 算导频处的信道。文献［20］提出的方案是使用于OFDM系统中，在OFDM系统 中，对于第上个时隙和第，个子载波，输入输出关系表示为：
X* = H.kXi* + Vik	(4-8)
其中，入，尤/和X#分别是接收信号、发送的符号和高斯白噪声。考虑大小为 N/ND的OFDM子帧，时隙索引力在［0,血-1］之间，并且子载波索引i的范围 是［0,N$-1］。H卡是ZC沁的亿幻元素。H代表所有子载波和时隙的信道时 频响应。为了在高速移动场景下估计信道，时域响应表示为 H = {h［l］,h［2］,...,h［^］},其中每个h伙］是第£个时隙的信道频率响应。
使用LS方法估计导频位置处的信道，如式(4-9)所示：
(4-9)
其中©包含已知的导频值，而儿是相应的观测值。构建信道时频二维网格，将 导频处的信道估计插入对应的时隙，将此时的二维信道图像视作LR图像。
使用SR网络重构HR信道图像。为获取信息符号处的信道，需要在时频域 进行二维插值，即利用LR信道图像重建覆盖整个时频域信号的HR图像。可采 用的超分辨率卷积神经网络(SRCNN)作为SR神经网络。

图4-3 SR网络效果示意图
如图4-3所示，SRCNNR0］首先使用插值方案来找到HR图像的近似值，然 后设计轻量的CNN重建图像，损失函数为输出信道图像与真实信道的MSE。SR 网络输出的图像含有噪声，使用IR神经网络进行降噪处理(如图4-4所示)，以获 得最终的信道时频估计。SR网络与IR网络级联，训练IR网络时冻结训练好的 SR网络参数。目前常用的图像降噪神经网络为DnCNN,采用DnCNN作为IR 网络。
46


图4-4 IR网络效果示意图
DnCNN的设计思想是认为噪声图像与原始图像低频部分大致相同，故去除 图像低频部分进行训练，具体表现为训练加噪图像与原始图像的残差，加噪图像 减去卷积神经网络的输出即可得最终的去噪图像，极大地减小了训练难度同时允 许设计更深的网络进行拟合。DnCNN损失函数依旧为输出信道图像与真实信道 的 MSE。
4.3.2适用于OTFS的信道估计神经网络
OTFS信道估计在延迟多普勒域进行，信道信息可以表示为分布于二维网格 的若干个离散复数值，叠加的噪声为高斯白噪声。OTFS难以使用文献［20］中的 SR网络生成整个OTFS块的时频信道信息，但是，OTFS信道图像可以使用IR 网络去除噪声，以提高信道估计准确性。拟使用DnCNN对二维的信道信息进行 去噪处理，以优化信道估计。
DnCNN最初由文献［49］提出，用于图像去噪，主要使用残差学习的思想，通 过学习噪声图像中存在的噪声，经过相减后，获取更清晰的原始图像，在图像去 噪领域取得了很大的成功。DnCNN主要创新点有两个，一是使用残差学习的思 路学习图像噪声，该处理方法使得DnCNN可以拓展到多个去噪领域；二是将残 差学习与BN相结合，共同提高去噪能力和网络的训练速度。
残差学习最开始提出用于解决随着网络层数增多网络性能不再提升甚至下 降的问题，同时也具有加快网络收敛的优点。残差网络显式学习一些堆叠层的残 差映射，可以比原始的映射方法更容易学习。当残差较小时网络训练简单，当残 差为零时，网络训练目标为恒等映射，非常容易优化收敛。而图像去噪领域中， 噪声图像和清晰图像的残差一般很小，所有残差学习很适合图像的去噪。DnCNN 采用的是残差学习的方法，但是原始的残差网络间隔几个网络层就会进行一次残 差运算，而DnCNN只在最后一层进行残差操作。在DnCNN中，网络最后一层 输出为噪声图像，原始图像减去该输出得到去噪图像。因此，网络的损失函数是 网络的输出与噪声图像的MSE。文献［49］进一步引入了 BN技术，发现其可以稳 定和增强DnCNN的训练性能。在一批图像进入卷积层时，先计算其均值和方差，
47 再进行归一化，然后将归一化后的数据输入卷积层；对于卷积层输出的数据，先 通过学习到的数据的均值和方差将输出恢复到其原先的分布，再通过激活函数。
残差学习和BN可以相互受益，并且它们的集成可以有效地加快训练速度并提高 去噪性能。DnCNN示意图如图4-5所示。


64	64	64
图4-5 DnCNN结构
在图4-5中，DnCNN得到的最后去噪图像为输入二维图像与输出噪声图像 的差值。在DnCNN中所有卷积核大小都设置为3x3 ,第一层使用64个卷积核 使用T“(・)作为激活函数，中间层由卷积层、BN和relu^激活函数构成，最后 一层卷积层用于重构图像。DnCNN不使用池化操作，所有填充方式都为“same”。 卷积核为3x3时，网络每个点的值都由上一层网络对应的大小为3x3区域的值生 成，第一层每个点带有原始图像3x3区域信息，第二层带有第一层3x3区域信息 即带有原始图像5x5区域信息，以此类推，若将网络深度记为比初，则感受野大 小为(2^+l)x(2JCjW+l)o由于网络使用的是零填充，感受野增大时，靠近边 界的点受越来越多零值的影响，但是结果表明DnCNN不会产生边界伪像［49】。中 间层的数量会影响感受野的大小，感受野大时可以有效利用更多底层图像信息， 故设计时需要兼顾性能与复杂度。最终，根据文献［49］的验证，当使用DnCNN去 除高斯噪声时，选择网络深度为17,去除复杂噪声时，深度选为20。
OTFS使用DnCNN优化信道估计时，因为神经网络目前只能直接处理实数， 故可信道的实部和虚部分离设计为两通道的图像，再经过DnCNN优化。在原始 的DnCNN中，网络深度直接取17时，对应的感受野大小为35x35 ,而OTFS中 的信道图像小于感受野时，随着网络深度的增加，网络输出的结果受到零填充的 影响也会增大，故而需要调整网络深度需要根据实际情况进行设计适用于OTFS 信道估计的神经网络。
4.4性能评估
本节拟对提出的适用于OTFS信道估计的深度学习神经网络进行性能评估。 我们采用的是SISO系统，主要对比简化后的DnCNN与传统的基于阈值的方法。 仿真参数设计类似第3.5节。载波4GHz,子载波间隔15kHz,子载波数128,多
48

载波符号数64,信道模型EVA,移动速度240km/h»我们首先仿真了 DnCNN层 数对估计信道与真实信道间的MSE的影响，学习速率为0.001,批次大小为32, 总优化次数为20000,当SNRp为25dB时，DnCNN网络深度与对应MSE的关系 图如图4-6所示：

DnCNN网络深度
图4-6 DnCNN网络深度影响
从图4-6中可以看出随着DnCNN层数增加MSE逐渐提高，但是都非常接 近，根据曲线的走势可以推断出，在DnCNN网络深度为3层时，就已经达到了 优化收敛，随着层数增加，网络逐渐出现过拟合。当网络深度为3层即达到优化 收敛的原因可能是二维信道图像的尺寸较小，故使用较小的感受野就可以获取足 够的信息以优化。因此，我们选择DnCNN网络深度为3,即感受野为7x7,以 进行接下来的仿真。我们使用简化后的DnCNN优化信道估计，并与传统的方法 进行比较。结果图如图4-7所示：
49


21	22	23	24	25	26	27	28	29	30	31
pilot SNR (dB)
图4-7信道估计方法性能
在图4-7中，"不处理”表示为不进行弱径清零的信道,“2*sigma”和“3*sigma” 表示设置的用于清除弱径的两个阈值。可以看出，使用基于阈值的方法优化信道 估计可以有效减少估计信道受到的噪声影响，当MSE为0.001时，阈值为” 3*sigmaM比“2*sigma”性能好大概0.5dB,简化后的DnCNN性能比阈值为” 3*sigma”好大概2dB,比不进行任何处理的信道估计好大概7.5dB。由此可见, DnCNN可以获得比基于阈值的信道估计方法更好的去噪性能。
在第三章中，我们使用的是理想信道估计，为了评估实际信道估计对信号检 测的影响，我们仿真了信噪比为12dB且57\对为29dB时，在实际信道估计下, 各个检测算法的收敛性能，如图4-8所示。
50



图4-8估计信道下迭代次数与BER对比图
图4-8是信噪比为12dB时，使用信道估计获取信道信息时，迭代次数与信 号检测方法所得的BER的曲线图。由图4-8可得，在估计的信道信息下提出的 信号检测网络略优于ScNeto提出的简化的DnCNN能使信号检测更加准确。在 迭代次数为10次时,信号检测网络大体达到收敛，故我们取最大迭代次数为10。
当进行信道估计时，根据式(4-2)可得输入的信道图像大小(2心+1)x(；+1), 基于阈值的信道估计方法需要比较(2心+1)x(4+1)次，而简化后的DnCNN只有 三层，时间复杂度为0((2^+l)x(/r + l))o由于2心+1<N且A+1《M,故系统 的总耗时中依旧是信号检测部分耗时占很大比例。我们将信道估计与信号检测结 合构成OTFS的接收器，系统总体的仿真结果如图4-9所示。
51
不同信道处理方法性能



4	5	6	7	8	9	10	11	12	13	14
SNR (dB)
图4-9 OTFS系统性能对比
在图4-9中，比较了阈值为“3*sigma”、DnCNN和理想信道(记为”ideal”) 下的误比特率性能。从中可以看出基于阈值的信号估计结合MP算法所得性能最 差，而使用神经网络进行信号检测则略优于此时的MP算法，这说明深度学习方 法相比传统方法在信道信息不完美的情况下更具有鲁棒性。使用DnCNN进行信 道优化系统总体的误比特率优于基于阈值的方法，在误比特率为0.001时，使用 深度学习方法的信道估计能让信号检测性能比传统方法大概好0.7dBo由此可得, 提出的适用于OTFS信道估计的简化版DnCNN与传统方法相比可以取得更好的 性能。
4.5本章小结
在本章中，我们介绍了 OTFS的导频设计方法，介绍了已有的用于信道估计 的深度学习方法，并将深度学习方法应用于OTFS信道估计中。在SISO+OTFS 系统中，通常使用冲激序列就可以在延迟多普勒域作为导频，使用足够的保护间 隔就可以轻易地在接受端获取信道信息。传统的基于阈值的信道估计方法方便快 捷，但是还存在改进的空间。深度学习在信道估计中也发挥着作用，鉴于OTFS 系统中信道为二维信道，参考已有的二维信道深度学习信道估计方法。SR与IR 串联估计信道的方法先将导频处信道恢复整个时频域信道，再使用去噪神经网络 优化信道估计。但是，在OTFS系统中，根据导频处的信道可以得到整个OTFS
52
块的信道信息，故不需要SR网络对信道进行处理，我们直接使用去噪网络优化 信道，并根据信道特点简化了 DnCNN网络深度使之更适合OTFS。仿真结果显 示，使用的信道估计网络性能更佳。
53
第五章总结与展望
5.1论文总结
本论文使用深度学习方法在OTFS系统中进行信道估计和信号检测。OTFS 在高速移动场景下比OFDM更具有优势，但是OTFS信号解调是个挑战。深度 学习的发展为OTFS高效解调的实现提供了一种新思路。在第一章中我们介绍了 论文的研究背景及研究现状，已有的OTFS相关研究和深度学习在通信系统中的 应用为本论文提供了充足的理论材料和研究思路。在第二章中，我们介绍了 OTFS 收发系统的基本原理，OTFS是在延迟多普勒域处理信号，能够利用时频分集提 高系统信息传输效率，但是也面临着多径效应引起的符号间干扰和子载波间干扰 的影响。接着我们介绍了深度学习的基本原理，介绍了基于数据驱动和基于模型 驱动的深度学习方法大体思路，为神经网络的设计提供理论依据。
在第三章中，我们介绍了 ZF和LMMSE这两种传统的线性检测算法，并提 出了一种简化的线性检测方法，简化的方法可以极大降低运算量和所需存储空间, 但是性能也有所损失。接着我们介绍了 OTFS中常用的检测算法，即MP算法， 但是MP算法复杂度依旧较高。在应用于信号检测的深度学习神经网络中,DetNet 使用基于模型驱动的方法成功实现MIMO信号检测，其改进方案ScNet能取得 较好的效果并且适用于输入信号维度较大的情况。我们分析了 DetNet原理，利 用ScNet的简化思路，结合OTFS信道特点设计了改进的OTFS信号检测网络， 仿真结果显示，设计的信号检测网络优于已有的ScNet,并且与MP算法相比， 取得了检测性能与复杂度的良好折衷。
在第四章中，我们对OTFS信道估计进行优化。首先我们介绍了 OTFS导频 的设计方式以及最基本的基于阈值的信道估计方法。接着我们介绍并借鉴了己有 的信道估计网络，设计了适用于OTFS系统的简化的去噪网络。仿真结果表明设 计的网络可以取得比基于阈值的信道估计方法更好的信道估计结果。
总而言之，本论文通过对已有研究结果的分析借鉴和改进，设计了基于深度 学习方法的OTFS信号解调网络，所设计的网络可以以低复杂度实现较好的解调 性能。
5.2未来工作展望
在信号检测部分，通过对残差图像的分析，适用较为简单的方法降低了较低 峰值处的残差符号对信号检测的影响，虽然快捷有效，但是还存在改进的空间。
54
可以通过借鉴图像处理的对残差图像进行处理，或者根据已有的算法设计改进的 信号检测网络。在信道估计部分，可以尝试改进其他网络比如自动编码器作为IR 网络对信道估计进行优化。在MIMO+OTFS系统中，可以根据已有的信道估计 算法设计神经网络，以使深度学习方法能更全面地优化OTFS通信系统。
55
対文献
LllHadani R, Rakib S, Tsatsanis M, et al. Orthogonal Time Frequency Space Modulation[A].	// 2017 IEEE Wireless Communications and
Networking Conference (WCNC)[C], San Francisco: IEEE, 2017: 1-6.
E2]Raviteja P, Phan K T, Hong Y, et al. Interference Cancellation and Iterative	Detection for Orthogonal Time Frequency Space
Modulation[J]. IEEE Transactions on Wireless Communications, 201&17(10): 6501-6515・
[3] Li L, Liang Y, Fan P, et al. Low Complexity Detection Algor it hms for OTFS under Rapidly Time-Varying Channel[A]. // 2019 IEEE 89th Vehicular Technology Conference (VTC2019-Spring)[C], Kuala Lumpur: IEEE, 2019: 1—5.
[4] Raviteja P, Hong Y, Viterbo E, et al. Practical Pulse-Shaping Waveforms for Reduced-Cyclic-Prefix OTFS[J]・ IEEE Transactions on Vehicular Technology, 2019, 68(1): 967-961・
[5] Raviteja P, Phan K T, Hong Y. Embedded Pilot-Aided Channel
Estimation	for OTFS	in Delay - Doppler Channels[J]・ IEEE
Transactions on Vehicular Technology, 2019, 68(5): 4906-4917.
[6] Rangamgari V, Tiwari S, Das S S, et a.1. OTFS: Interleaved OFDM with Block CP[A]. // 2020 National Conference on Communications (NCC)[C], Kharagpur: IEEE, 2020: 1-6.
[7] Raviteja P, Viterbo E, Hong Y・ OTFS Performance on Static Multipath Channels [J]・ IEEE Wireless Communications Letters, 2019, 8(3): 745一 748.
[8] Ding Z, Schober R, Fan P, et al. OTFS-NOMA: An Efficient Approach for Exploiting Heterogenous User Mobility Profiles[J]. IEEE Transactions on Communications, 2019, 67(11): 7950-7965・
[9] 李伶垢.抗多普勒频移正交时频空系统性能分析与优化[D].重庆：西南交 通大学，2019.
E10]Tiwari S, Das S S, Rangamgari V. Low complexity LMMSE Receiver for OTFS[J]. IEEE Communications Letters, 2019, 23(12): 2205-2209・
[11] Ramachandran M K, Chockalingam A. MIMO-OTFS in High-Doppler Fading Channels: Signal Detection and Channel Estimation[A]・ // GLOBECOM 2018 - 2018 IEEE Global Communications Conference[C], Abu Dhabi: IEEE, 2018: 206-212.
[12] Shen W, Dai L, An J, et al・ Channel Estimation for Orthogonal Time Frequency Space (OTFS) Massive MIMO[J]. IEEE Transactions on Signal Processing, 2019, 67 (16): 4204-4217・
56

[13] Qin Z, Ye H, Li G Y, et al. Deep Learning in Physical Layer Communications[J]・ IEEE Wireless Communications, 2019, 26(2): 9399.
[14] Ye H, Li G Y, Juang B F・ Power of deep learning for channel estimation and signal detection in OFDM sysIEEE Wireless Commun. Letters, 201& 7 (1) : 114-117.
[15] Samuel N, Diskin T, Wiesel A. Deep MIMO detection [J]. 2017 IEEE 18th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC), Sapporo, 2017, 18(1) : 1-5.
[16] Guili Gao, Chao Dong, Kai Niu. Sparsely Connected Neural Network
for Massive MIMO Detection [A].	// 2018 IEEE 4th International
Conference on Computer and Communications(ICCC)[C], Chengdu: IEEE, 2018: 397-402.
[17] He H, Wen C K, Jin S, et al. A Model-Driven Deep Learning Network for MIMO Detection[A]. // 2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)[C], Anaheim: IEEE, 2018: 584- 588.
[18] Wang X, Hua H, Xu Y・ Pilot—Assisted Channel Estimation and Signal Detection in Uplink Multi~User MIMO Systems with Deep Learning[J], IEEE Access, 2020, PP(99): 1-1.
[19] He H, Wen C K, Jin S, et al. Deep Learning-based Channel Estimation
Massive MIMO Systems[J], IEEE Wireless 2018, 7(5): 852-855.
V, Mirzaei A, et al. Deep Learning-Based IEEE Communications Letters, 2019, 23(4):
652~655.
[21] Liao Y, Hua Y, Cai Y・ Deep Learning Based Channel Estimation Algorithm for Fast Time-Varying MIMO-OFDM Systems[J]. IEEE Communications Letters, 2020, 24(3): 572-576.
[22] Zhang J, He H, Wen C K, et &1・ Deep Learning Based on Orthogonal Approximate Message Passing for CP-Free OFDM[A]・ // ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)[C], Brighton: IEEE, 2019: 8414-8418.
[23] Chen Q, Zhang S, Xu S, et al. Efficient MIMO Detection with Imperfect Channel Knowledge 一 A Deep Learning Approach[A]・ // 2019 IEEE Wireless Communications and Networking Conference (WCNC)[C],
Marrakesh: IEEE, 2019: 1-6.
[24] He H, Wen C, Jin S, et al. Model-Driven Deep Learning for MIMO Detection[J]・ IEEE Transactions on Signal Processing, 2020, 68: 1702-1715.
[25] LeCun Y, Bengio Y, Hinton G・ Deep learning [J]・ nature, 2015, 521 (7553): 436.
[26] 晏小琴.基于深度学习的大规模MIMO信号检测研究[D]・重庆：重庆邮电 大学，2020.
57
[27] 刘湘峰.基于深度学习的MIMO检测算法研究[D].西安：西安电子科技大 学，2019.
[28] 郑沛聪.基于深度学习的MIM0信号检测算法优化研究[D].哈尔滨：哈尔 滨工业大学，2019.
[29] 高贵利.基于机器学习的Massive MIM0检测技术研究[D].北京：北京邮 电大学，2019.
[30] Duchi J C, Hazan E, Singer Y. Adaptive Subgradient Methods Adaptive
Subgradient	Methods	for Online Learning and Stochastic
Optimization[J]. Journal of Machine Learning Research, 2011, 12: 2121-2159.
[31] Zeiler M D. ADADELTA: An adaptive learning rate method[J]. Computer ence, 2012.
[32] Geoffrey Hinton. CSC321 Neural Networks for Machine Learning - Lecture6. http://www. cs. toronto. edu/~tijmen/csc321/slides/lecture_ slides_lec6. pdf
[33] Qian N. On the momentum term in gradient descent learning algoritNeural Networks, 1999.
[34] Kingma D P, Ba J. Adam: A Method for Stochastic Optimization[J]. arXiv: Learning, 2014.
[35] 周飞燕，金林鹏，董军.卷积神经网络研究综述[J].计算机学报，2017, 40(06): 1229-1251.
[36] 李飞腾.卷积神经网络及其应用[D].大连：大连理工大学，2014.
[37] Ioffe S, Szegedy C. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift[J]. 2015.
[38] 陈嘉聪.基于卷积神经网络的人脸表情识别的研究与实现[D].北京：北方 工业大学，2020.
[39] 张智琦.基于卷积神经网络的车辆智能无线定位算法研究[D].北京：北京 交通大学，201&
[40] Li Xilin. Preconditioned stochastic gradient descent[J]. IEEE Transactions on Neural Networks and Learning Systems, 2018, 29(5): 1454-1466.
[41] Zongben X, Jian S. Model-driven deep-learning[J]. National Science Review, 2018(1) :1.
[42] Butler M R G, Collings I B. A Zero-Forcing Approximate LogLikelihood Receiver for MIMO Bit-Interleaved Coded Modulation[J]. IEEE Communications Letters, 2004, 8(2): 105-107.
[43] 梁恒浩.SC-FDE系统信道估计和均衡研究与实现[D].哈尔滨：哈尔滨工业 大学，201&
[44] 刘天俊.基于正交时频空(0TFS)系统的导频序列设计与信道估计[D].四 川：西南交通大学，2019.
[45] 张晓羽，贺光辉.基于深度学习的大规模MIM0检测算法研究[J].信息技术, 2020, 44(06): 10-14.
[46] Evolved Universal Terrestrial Radio Access (E-UTRA); Base Station (BS) Radio Transmission and Reception, Version 8. 6. 0, document 3GPP
58
TS 36. 104, Jul. 2009.
[47] Rasheed 0 K, Surabhi G D, Chockalingam A. Sparse Delay-Doppler Channel Estimation in Rapidly Time-Varying Channels for Multiuser OTFS on the Uplink [A]・ // 2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring) [C], Antwerp: IEEE, 2020: 1-5.
[48] 毛恒熙.基于深度学习的信道估计算法研究[D].安徽：中国科学技术大学, 2020.
[49] Zhang K, Zuo W, Chen Y, et al. Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising[J]・ IEEE Transactions on Image Processing, 2017, 26(7): 3142-3155.
59
