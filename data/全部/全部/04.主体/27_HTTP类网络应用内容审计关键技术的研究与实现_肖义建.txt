

第一章绪论
1.1研究背景与意义
以互联网为代表的信息产业的高速发展是21世纪初期的标志性特征。信息 技术产业在国民经济与社会发展中的关键性地位H渐凸显。信息产业不仅为国民 经济的发展提供了新的增长引擎，而且为国家的产业升级、转变经济增长方式展 现了新的视野⑴。与此同时，信息产业、信息技术的发展为人民大众的物质精神 生活水平提高立下了汗马功劳，人们的工作、学习方式也因此而得到了极大改善 [2]0根据《第36次中国互联网络发展状况统计报告》的统计数据，到2015年6 月为止，我国通过手机访问网络的网民占比已高达88.9%,环比增长了 3.1%, 保持了多年的增长态势I*。由此可见，手机已经成为了一个非常重要的网络访问 媒介。与此同时，通过电脑（包括台式电脑和笔记本电脑）进行网络访问的用户 量出现了较大程度的下滑。这反映了移动上网设备在网络用户日常生活中已经具 有较强的重要性。在移动智能网络连接设备方面，平板电脑的使用出现了较大幅 度的下降，引起这一现象的原因应该与智能手机性能的不断提升，以及网络用户 对便捷移动化网络访问需求正在变的日益旺盛有关。在智能家居方面，?具有代表 性的网络电视使用率并未有较大变化，可能是一些关系尚未理清，影响了网络电 视的推广。总体来讲，信息产业还是为政府、企业、教育机构等各种组织、机构 提供了极大的便利，助力了各个行业的发展。
在“互联网+”的大背景、大环境下，企业借助信息技术的发展获得了更大 的发展机遇，于此同时，却也面临着巨大的挑战。作为国民经济活动的重要参与 者的各类公司企业，在这场信息技术演进的浪潮中扮演了重要的角色。他们不仅 是这个重要变革中的推动者，更是其中的最大受益者〔4]。无论是日常的行政办公， 还是对外提供服务、推介产品。无不是借助信息网络的巨大力量，并日渐成为一 种依赖。
近年来，在互联网移动新技术的推动下，互联网应用发展整体呈现较强上升 态势。即时通讯类工具已几乎成为网络用户必不可少的重要应用，而且，还表现 出了高使用率基础上呈现高速发展的态势。同时，还由之前偏重人与人之间的联 系的特征，逐步向强化人与服务之间连接的方向发展。正是因为移动通讯类应用 的这种发展态势，不仅影响了传统网络通讯类应用，甚至于到了在很大程度上影 响到了传统电信运营上的境地。例如，电子邮件目前更加偏重于办公等正式沟通 环境下的应用。微博在社交功能方面虽然有不断尝试加强，然而其作为社交工具 的使用率却日益下降，目前更倾于向媒体功能的方向发展。
同时，在传统的投资消费领域，也因信息科技的发展，尤其是互联网移动化 的新趋势的影响之下，出现了新的特征和变化。移动类型的商业应用与服务快速 发展，虽然有许多不成熟之处，至少目前是互联网尤其是移动互联网市场的一个 有力的推动点；金融支付领域的变化更加成熟，竞争也更加激烈，标志现象是传 统互联网企业向传统金融领域的扩张，使得原本单一的网络支付手段从线上走到 了线下，支付方式也更加灵活。使用率得到了迅速增长。网络金融理财应用，特 别是余额类理财类应用从过去的一家独大，发展成为目前群雄并起的态势，为民 众财产性收入的增加提供了新的渠道。总之，人们日常生活与信息网络的结合愈 加紧密。尤其是020的不断发展，更是推动了这一现象的快速发展囱。
随着信息产品应用的日渐丰富、网络使用者的规模急剧扩张，带来的后果之 一是网络流量几乎呈几何式增长，这对各种类型的网络设备以及针对网络的管理 都提出了极高的要求。正是基于这样的现实，在网络环境中部署检测审计设备， 对网络中的应用内容，使用情况进行监控、审计［用成为一个愈加迫切的需求。
伴随着互联网的高速发展，网络的非授权使用，网络恶意攻击呈现日渐增多 的趋势。网络规模，速度的提高，使得处理网络异常变的愈加困难。网络应用内 容审计为优化网络内部资源分配，及时了解网络的实时状态，发现处理网络中的 异常情况，提供了高效且具有充分可靠性的解决方案。
1.2本文研究内容
本文以与HTTP相关的网络应用为主要研究对象。通过多角度、多层次的分 析研究，在充分研究、调查多种成熟的网络内容审计工具的基础之上，结合新兴 的大规模数据并行处理方式，根据所研究对象的特点对网络应用内容审计技术进 行改进、优化，实现对网络应用内容的多维度分析，以此为基础获取目标网络的 流量特征、应用的分布、用户行为等情况。
本文通过对网络IP报文头部字段特征的分析，利用IP报文中标识号 (Identification)在特定范围内的单调递增等特征，对使用NAT (Net Address Transfer)设备的计算机网络中的网络终端设备进行检测，据此实现了解网络终 端的组成状况的目的。为进行网络应用内容审计研究时，将审计结果与网络终端 的组成情况结合分析，提高分析结果的准确性。
在上述研究的基础之上,本文进一步研究了与HTTP具有紧密关系的HTML 文档的元素的提取技术。从基本的HTML标签标记定位,D0M等方式提取入手, 在充分分析HTML文档的结构的基础之上，对当前研究结果了进行广泛研究、 比较，同时，还对HTML文档中的信息元素进行了自动化提取的研究尝试。据 此，提出了对HTML文档内容审计信息进行提取的改进技术方案。
另外，HTTP作为应用层重要的且被广泛应用的信息传输协议，HTTP报文 中携带着大量的与网络应用内容有极大相关性的信息。本文对网络中存在的 HTTP报文进行捕获并处理。并通过大数据并行计算处理、聚类等技术。对HTTP 报文提取的信息数据进行分析。并通过分析结果推测网络用户的行为特征，达到 完善网络应用内容审计的目的。通过并行数据分析处理工具的使用，使得审计过 程能够快速、高效的实现。
1.3网络应用审计研究现状
本文的内容为在真实网络环境下，设计实现一种基于HTTP的网络应用内容 的审计技术，实现对网络状态的监控分析，并通过数据并行分析、计算手段对海 量的网络数据进行处理，据此实现对用户的网络使用行为特征进行聚类分析。最 终实现对网络的结构、配置进行优化，起到提高网络使用效率以及优化资源配置 的目的。
一、	国内研究现状
国内对网络中应用内容的审计，早期大多集中于使用网络流分析的方法，多 是通过对较底层的网络数据传输流的分析来获取结果，其中，得到广泛应用的是 防火墙或者比较基础的网络流量分析设备。全系统级别的监控分析设备技术较为 缺乏。在信息技术发展，信息网络的安全面临越来越大的挑战的新形势下，国家 于2014年成立了中央网络安全与信息化领导小组，并以极高的组织、领导规格 显示了国家对新时期、新形势下，信息网络安全的重视⑹。在政策、技术的积极 推动下，国内的网络安全日益得到重视，特别是在目前国内互联网产业迅速发展 的情况之下，人们的生活与网络的应用愈加密切。网络应用内容审计领域的理论 技术不断创新，新产品也不断涌现，如综合杀毒软件、防火墙设备、入侵检测设 备等的UTM设备的使用，就是为了提供应对新型复合型网络安全威胁的有效措 施。
二、	国外研究现状
国外，尤其是计算机网络的使用较早的国家，网络的管理也较为成熟，在网 络内容审计的研究技术也具有相当的领先地位。对于网络安全，网络应用内容的 监管与审计也早已提升到国家的层面。传统安全机构通过新的网络安全技术与设 备的引入，实现的对计算机网络中有害国家安全，公民利益的违法犯罪行为的有
效监视、审计。国外的网络安全技术公司也积极推进新的网络安全防护，网络内 容审计的新技术与新设备。尤其是针对目前高速发展的智能移动设备的领域，如 得到广泛应用的智能移动设备安卓（Android）操作系统，由于其发展生态开放 的特征，导致其成为了恶意软件攻击的重要对象，是网络中的需要得到重点保护 的节点但是由于国外安全厂商具有较长时间的网络安全防护领域的经验。在 短时间内快速反映并推出相应的解决方案。安卓系统的原始贡献公司，也积极的 通过新版本发布，新安全特性加入来解决这些安全问题。
1.4论文组织结构
本文共分为六章，具体以如下的组织结构进行行文：
第一章，文章的初始——绪论部分，介绍了当前互联网的发展状况。当前互 联网发展呈现的多样化，复杂化的特征。互联网的发展给大众的日常生活及企业 的发展提供了巨大的机遇的同时也带来了极高的风险。
第二章，网络应用内容审计的概念、作用，及其面临的挑战，以及，本文所 研究的网络内容审计所涉及的相关技术。
第三章，对包含NAT设备的网络中，终端的检测分类技术进行了研究分析， 使对网络的内容审计能够在一个对目标网络清晰了解的基础上进行，使得审计结 果更加深入、准确。
第四章，对网络中的典型重要应用，网络用户的Web浏览所涉及应用场景 的网络内容审计。对其中的关键环节，HTML文档的主要信息元素进行分析，通 过两个层次上的技术设计，对HTML文档中的元素进行提取，并将这些提取的 信息用于网络内容的审计。
第五章，对HTTP报文结构本身进行分析，对报文中能够反映网络用户行为 特征的内容进行提取，并结合数据并行分析计算、聚类等技术对得到的海量数据 进行分析，实现对相关网络应用内容进行审计的目的。
第六章，本文的总结，总结本文对开篇提出的网络应用内容审计相关问题的 解决情况，分析本文所提出的解决方案的优势。同时，总结其中的不足，并以此 为基础对未来研究工作中所需要解决及改进的方面进行规划和展望。
1. 5本章小结
本章在对目前互联网发展现状进行研究的基础上，揭示出网络应用内容审计 所面临的问题，以及这些问题的解决思路。并对本文的行文结构进行了介绍。
第二章网络应用内容审计概述
本论文主要的研究内容是与HTTP相关的网络应用的审计技术的研究与实 现，并根据审计结果来分析整个网络的状况，以及网络用户的行为特征。通过包 括NAT网络终端检测；HTML文档元素提取；以及使用Hadoop分布式数据计 算平台，通过聚类分析对网络情况、用户行为进行分析。
2.1网络应用内容审计的概念
网络应用内容审计就是综合多种软硬件技术，对所监控的目标网络中的所运 行的网络应用进行监测、管理。及时发现网络中存在的异常情况、违规操作等危 害网络安全稳定的事件，并进行有效的控制、处理。网络内容审计是保障网络安 全，及网络高可用性的重要途径。
2.1.1网络的安全及可用性
计算机网络安全具有多维度，广泛关联等特点，是系统性问题。主要分为实 体硬件的安全以及逻辑上的安全。实体安全是指计算机网络的相关系统组成设备、 设施有相应的防护措施，得到有效保护。逻辑安全则是指存在于网络中的信息完 整、可信以及可用等属性得到充分的保证。
计算机系统的信息安全包括个大的方面：
?合理的权限，网络中的用户都可以根据系统管理员所分配的相应权限获 取与其权限相对应的信息内容。
?信息完整，信息的完整性是指信息的真实性，无论是在信息的存储还是 传播过程之中，都得到了妥善的处理和防护，避免信息出现错误，遭到 破坏，保证信息的真实。
?信息的高可用，得到授权的用户都能通过合法手段、途径能够高效的获 取所需信息，保证网络中的信息能够及时的提供给授权用户。
?信息的可审查，在对信息进行合适的权限控制的基础上，同时能够提供 可追查机制，能够记录网络中的信息在传播、存储过程中的状态得到准 确、高效的记录。为网络中信息的传递及内容状态演变提供回溯机制。
保证网络的安全是之所以需要网络应用内容审计的原因。计算机网络是一个 极其多样且复杂的系统,这样的繁杂的系统结构就注定了计算机网络系统存在缺
陷的可能性。
由于计算机网络设备大多运算处理性能优越。网络通信中的差错控制，通信 过程中的加解密，编解码大多在上网终端设备中完成。这种网络的分布式方式结 构，使得计算机网络的使用方便性有了很大程度的提高。同时，却也带来了管理 的困难，给整个网络的安全风险控制带来了问题。网络终端同时也是一个复杂的 系统，从而同样存在着因结构设计等原因造成的软件或硬件的问题，导致自身作 为网络节点无法使用。更严重的情况是一成为网络中的缺陷点，被当作对网络 进行攻击的切入点，造成巨大危害。
网络的传输介质同样是可能出现安全问题的方面，在使用电磁介质进行通信 的网络中，如果未对线路或端口做屏蔽工作，网络中就会存在着发生电磁信号辐 射的问题，辐射的电磁信号一旦被恶意截取，破译，就出现信息泄漏的问题，对 网络的信息安全造成威胁。作为网络通信功能实现的网络的通信协议同样因为设 计缺陷，或者因为被错误的配置，造成资源浪费，影响计算机网络的信息传递效 率。严重的甚至成为非法入侵者攻击网络的突破口。
计算机网络需要达到的安全等级根据网络的用途，网络成本的预算，根据网 络管理者的设置，而达到不同的安全等级。
计算机信息系统最早的安全评估正式标准是《可信计算机系统评估标准》 (Trusted Computer System Evaluation Criteria ,TCSEC)同,是由美国国防部于 1985年公布的，该标准从安全策略、可计量性、安全保证以及技术文档四个方 面对计算机系统进行评估，根据不同的计算机系统对上述评估规则的服从情况共 将其分为包括四类七个级别的安全等级标准。
计算机网络包括计算机信息设备组成的网络服务节点以及进行数据传输的 通信系统。因此，计算机网络的安全评估体系比单独的计算机设备的安全评估要 更加复杂。美国国防部于1987年在《可信计算机系统评估标准》的基础上发布 了《可信计算机网络安全说明》図。每项标准都规定了相应的安全结构与设计， 安全结构中应对计算机系统的安全策略、协议以及目标进行说明。同时，为了对 计算机系统作为一个可信实体进行评估，在《可信计算机系统评估标准》的TCB
(Trusted Computing Base)基础上提出了 NTCB(Network Trusted Computing Base) 概念［期。NTCB对计算机网络进行安全评估时，仅考虑网络与安全相关的组成部 分，网络的通信稳定性以及网络设备的操作方式则被排除在外。需要进行安全评 估的计算机网络应具备明确的网络安全结构的设计，而且网络安全结构的设计内 容应该包括网络安全策略、安全目标以及安全协议等。网络安全策略则应包括自 主及强制访问控制，安全支持策略以及安全应用策略等卩°】。同时，网络安全设 计还应对网络提供的接口以及服务做出说明，以此，才可以使得网络作为一个实
体进行安全评估。
随着信息技术的发展以及应用需求的变化，信息安全的标准也在不断变化， 19世纪90年代后期《国际信息技术安全评估标准》(Information Technology Security Evaluation Criteria , ITSEC)被除美国外的许多国家所接受。后于1999年经协商达 成的《国际通用信息技术安全评估标准》取代了《可信计算机系统评估标准》以 及《国际信息技术安全评估标准》被大多数国家所接受。如同其他信息技术标准 一样，它也在不断的完善发展过程中。
国内的相关技术安全标准是最早于1999年发布的《计算机信息安全保护登 记划分准则》nu,为国内建立计算机系统安全标准、进行安全管理提供了重要的 依据。
2.1.2网络用户行为分析
网络用户行为在本文中特指网络用户在计算机网络中做出的特定行动。目前, 最大的计算机网络——互联网已经演化成为一种虚拟化的人类社会，所以网络用 户行为可以作为一种虚拟的社会行为进行分析。通过对当前用户网络使用中产生 的数据的分析，了解网络用户的行为轨迹，形成网络用户行为的历史记录，根据 分析形成的历史记录，通过合理的模型对网络用户的未来行为进行合理预测。
2.1.3网络用户识别
在进行网络应用审计的过程中，很重要的一个步骤就是针对特定用户的审计 方式，在网络用户行为分析中，包括对整个网络用户宏观的聚类分析，还包括针 对具体的个体针对性分析，从而对网络用户的行为，进行精细化跟踪记录。网络 用户的识别是通过包含用户身份信息的一组特定数据来表示的，广义上是一种虚 拟的数字身份信息，信息系统对用户的授权也是基于该系统所支持的数字身份的 进行的〔⑵。
计算机网络用户的虚拟数字信息可以分为六大类，分别是：
<1>静态密码，即常见的“账号+密码”的身份验证方式，在较长的一段时间 内是固化的，这种特点给使用带来了便利。但是，因为它的这一特点， 也造成了其安全性低的弊端。
<2>动态口令，根据特定的触发机制，通过特定算法生成难以推算出的不确 定组合。每个口令作为密码仅使用一次。有效的提升了认证的安全性。
<3>USBKEY搭载特定程序的硬件设备，同样是“一次一密”的认证方式。 它通过一种便携式USB设备存储用户的私钥或是个人的数字证书。并通 过自身的相应算法实现认证功能。
<4>智能卡，通过内置芯片存储合法用户相关的信息数据。用户进行身份验 证时，通过专门设备读取智能卡中的认证信息的方式来完成认证过程。
智能卡由专门设备制作，几乎无法被复制，所以增强了这种认证方式的 安全性，同时，又因为智能卡中存储的信息是静态的，身份信息被读取 后还是存在泄漏风险。
<5>数字证书，本质是一种有效力的电子数据文件，经由数字证书认证中心 (Certificate Authority, CA)签发。数字证书采用公钥方式实现用户个 人身份的认证。
<6〉生物识别，是一种通过生命体自身的某些生物独有的特征来区分生物个 体的计算机技术。是一种较新的科技方式，存在着指纹、掌纹、语音以 及血管纹理识别等多种多样的认证方式。
在进行网络应用内容审计的过程中，审计系统大多是作为第三方进行网络用 户数据的采集，网络用户的虚拟数字身份的安全强度与身份在网络数据中的提取 复杂程度成反比。在局域网的应用审计过程中，对于特定使用的网如公司网 络，及其他网络终端具有一定固定使用性质的网络，可以使用终端的网络地址如 IP地址、MAC地址等，来对网络用户进行标记，作为一种网络用户的虚拟身份， 用于网络用户的识别。
2. 2网络审计关键技术简介
计算机网络审计从计算机网络出现的初期就已具雏形〔"I。随着技术的发展, 计算机网络审计的概念已经扩展成为信息系统审计。专门的针对计算机网络内容 审计现在作为信息系统审计的主要组成部分存在。计算机网络内容审计通过网络 报文抓取，网络系统使用日志记录等方式获取网络运行、使用中的实时或历史状 态数据。通过数据即时分析或延后分析的方式，对网络的性能、用户行为、安全 等方面的状况进行了解，记录那些影响系统安全性、性能的操作以及对那些操作 负有责任的网络使用者。可以分为内容审计以及行为审计两个大类。从层次上划 分，可以分为系统审计、应用审计以及用户审计三个级别层次上的审计。
传统的网络应用审计多侧重于网络流量的实时审计，审计结果多采用关系型 数据库的方式进行存储。随着技术的发展、需求的提升，网络带宽从M (Mbps) 级向G (Gbps)级网络演进发展中，这种偏重实时分析的方式越来越不能满足实 际应用的需要。
针对目前网络的结构状况、应用状况。本文对以下的计算机网络审计的关键 技术进行了重点的研究实现：
?网络终端识别技术。当前网络内容审计技术要求的时效性，精确性越来越高。 高精确性的要求，意味着审计结果应精确到具体的每个网络的终端，将网络 行为实际确定到实际产生特定网络行为的终端，就可以将网络行为与具体的 网络用户进行关联，保证了网络审计的准确性。
? HTTP相关信息提取。HTTP是目前被广泛应用的应用层网络协议，HTTP的 最著名也是最广泛的应用就是WWW (WorldWideWeb),网络页面中包含了 丰富的信息。是网络用户的最主要的应用之一。也是进行网络应用审计的重 要项目，本文通过对HTML文档的深入研究分析，设计了两种网络页面元素 的提取方法。除了网络页面中的使用，HTTP还广泛应用于计算机软件以及 移动智能设备中应用的通信，这些信息中包含了软件的使用者信息，使用软 件所进行的操作等行为，这些都是对网络应用审计具有重要意义的信息。这 也是本文进行重点研究的方面。
?海量应用审计信息的分析技术。传统方式中，网络审计获得的信息数据大都 以关系型数据库的方式进行存储以及后续的信息处理，数据分析。但是随着 技术的发展，网络审计所面对的数据量也正以几何级数的方式增长，同时， 对网络审计要求的提高、对审计指标的细化，对数据的处理平台提出了更高 的要求。因此，分布式大数据处理平台Hadoop的引入就十分有帮助［风，也 是适应当前网络状况，且通过实际网络环境应用检验通过的高效、可靠的网 络内容审计技术。
应对当前网络状况的审计方式应该是多维度，多方式，系统化的方式。从实 时的网络流量的审计，到事后网络使用数据的审计，综合分析，达到效率与准确 性之间的平衡。
2. 3网络应用内容审计逻辑流程
综合上述分析，本文中提出的网络应用的审计思路不仅可用于网络的安全监 控，对于网络性能检测也具有较大意义，并根据监测数据优化也是具有重要的意 义。
本文中网络应用内容审计的整体设计思路如图2-1所示。本系统包括三个大 的模块，分别是：网络终端检测模块，该模块用于检测目标网络中的终端组成; 审计数据提取模块，本模块从HTML文档以及HTTP报文中提取用于网络应用 内容审计的网络数据；并行数据处理模块，这个模块用于将审计数据提取模块中 获取的数据进行并行处理以及聚类计算，用于分析网络中的流量特征，用户行为 等信息。



审计数据提取


审计数据预处理

图2-1应用内容审计逻辑流程图

2.4本章小结
本章对网络安全及可用性方面分析了进行网络应用内容审计的必要性及所 需的关键技术，并以此为基础对本文提出的审计技术进行了相应分析。

第三章NAT网络终端检测
网络结构的复杂化是当前网络的一个重要特征，因此进行网络审计一个重要 的辅助内容就是检测终端的类型、活跃状态信息，将这些信息与网络应用内容审 计的信息相结合，根据网络终端的活跃状态，将发生的网络使用行为进行对应， 增加审计的精确程度。
3.1网络设备地址问题概述
从十九世纪五十年代开始互联网从概念到雏形,直至现在的深入到人类社会 的各个角落，至今已历经了半个多世纪的历史，其间经历了巨大的变化。其中最 重要的变化之一是网络通信方式的不断变革发展，网络传输层协议也经历了从 NCP(Network Control Protocol)到TCP/IP的演进，最终将存在于世界各个角落各 式各样的具有不同结构、多种类型的计算机网络连接起来。因其简单的实现，高 效的数据传输等优秀的性能，TCP/IP协议族在互联网中逐渐赢得了当下的重要 地位，成为了互联网中的实际标准。如同信息技术的各个领域一样，TCP/IP的 一个重要的特质就是不断的优化、提升，用以应对新挑战，满足新的需求。.
TCP/IP协议族同样面临着相当多的问题，其中一个就是网络设备地址分配 不足。TCP/IP协议族中目前被广泛釆用的网际层协议是IPv4,该协议最早于19 世纪80年代初推行，釆用32位的二进制数字表示地址。因此，IPv4可用于的 互联网地址数为大致为232(43亿)。扣除特殊用途地址，如私有网络地址、本机 回环地址等，实际可用的网络地址仅为约37亿。在互联网的高速发展之下，IPv4 提供的地址数量愈发的捉襟见肘。
全球互联网IP地址由互联网号码分配机构(Internet Assigned Numbers Authority, IANA)管理。IANA将IP地址分配的交由五个大的区域互联网注册 机构(Regional Internet Registries, RIRs)负责，这五个大的区域互联网注册机 构负责将IP地址进行逐级分配。其中，亚太网络信息中心(Asia Pacific Network Information Centre, APNIC)负责亚洲太平洋区域的互联网注册机构，IANA已 于2011年2月3日将最后的未分配IP地址区段平均分配给了全球五个大的区域 互联网注册机构［项。
据 APNIC 的 2014 的年度报告，LACNIC (Latin America and Caribbean Network Infonnation Centre)的IPv4地址资源已不足a/9,即800万个左右。这也意味着，拉美及加勒比地区的IPv4地址几近耗尽。其他各区的情况也大致类 似。
对于情况目前来说,IPv4地址耗尽的最为彻底和有效的应对策略是使用IPv6, 即第六个版本的IP方案的解决方法。IPv6是网际协议的最新版本，它使用128 比特存储网络地址，从而扩展了 IP地址空间。同时，IPv6还简化了 IP报文的报 头格式，增加了新的选项，这些新的变化方便了 IP协议的使用及实现，使得操 作更加高效。但存在设备兼容性问题，设备更新成本等问题,今年虽有迅速发展， 但是仍未得到大面积应用，2014年，全球范围内IPv6的普及率仅为5%。
然而，因为兼容性、成本等问题的原因，目前获得广泛应用的方式是机构自 有网络内部使用私有地址方式组网，在网络的出口通过NAT设备与外部网络相 连，最终连接到互联网。这样就可以使用少量，甚至仅需要一个有效IP地址将 大量的网络设备连接到互联网上。通过NAT方式连接互联网的方式，虽然只能 暂时性的解决IPv4地址耗尽的问题，但是因其部署方便，成本低等特点，获得 了广泛的应用，成为解决IPv4地址即将枯竭问题的主要方案。
目前NAT共有四种实现方式，分别是：
完全圆锥型NAT,也被称为一对一 NAT,这种NAT的实现方式为，只要内 部网络中的一个地址-端口对与外网的地址-端口对完成映射，那么，之后的任意 外网主机都可以通过这一映射实现与内部网络终端的通信。
受限圆锥型NAT有时会被称作地址受限圆锥型NAT,受限圆锥型NAT的实 现方式是，内部网络中的一个地址-端口对与外网的地址-端口对完成映射后，外 网中的主机只要接受到过映射中的内网终端的数据包，就可以通过上述的地址- 端口映射实现与内网终端设备的通信。
端口受限圆锥型NAT同样是完成内部网络中的一个地址-端口对与外网的地 址-端口对完成映射后，通过上述的地址-端口映射实现与内网终端设备的通信。 外网中的主机不同之处在于，外网主机可以通过建立的地址-端口对映射进行通 信的前提是，外网主机必须使用内网终端曾发包到过的端口与内网终端进行通信。
对称NAT的实现方式是，内部网络终端与外网主机通信时，拥有不同地址- 端口对的网络数据包与目的地址-端口对的通信都会使用不同地址-端口对映射， 而且，只有曾经与内网中主机通信过的外部主机才可与同一网络中的终端进行通 信。
因技术成熟，方便易用，NAT技术获得了大范围的应用。除了可以作为使 用私有地址的网络终端与外网中的主机进行通信的方法之外，NAT技术还可以 通过将部分指向特定服务器的连接重定向到其他随机选定的服务器从而实现服 务器负载均衡，通过NAT实现的连接重定向也可以在特定主机出现故障的情况下，将流量负载转移到备份服务器，从而实现高可靠的服务。
NAT的广泛使用虽然带来了诸多的便利，为地址耗尽问题提供了良好的解 决方案，但在网络审计中却成为了一个障碍。正如NAT技术的另一个名称IP掩 蔽(IP masquerading)的字面意思表述的那样，NAT的存在使得NAT设备后的 网络的结构以及终端的组成变得难于获取。然而对网络结构，尤其是网络中终端 的组成情况的掌握是网络审计中的一个重要因素。
3. 2 NAT网络终端检测的可用信息
由于了解网络中的终端分布情况对了解网络结构，以及在网络的使用及管理 方面都具有重要的意义。在NAT网络终端检测领域有着大量的研究，提出了多 种有效、可行的检测方法，与此同时却也存在着不同程度的局限性。文献［16〕中 提出了使用IP报文的标识号(Identification)字段进行终端分析的方法，但是由 于只考虑了 IP报文的标识号字段，使用这一单一的判决信息，导致结果有较大 误差。文献［17］中，使用HTTP报文的Cookie信息对网络终端进行分析检测。但 是，由于并不是所有的网络通信报文中都携带Cookie信息，该终端检测算法同 样存在较大的局限性。
3.2.1 IP报文结构分析
IP协议是网络中最为重要的协议之一。IP协议无连接、不提供可靠，转而 将这些功能交由上层协议完成。IP协议支持多种协议。IP协议将需要传输的报 文添加IP协议头后封装为IP报文后，将报文在协议栈中向下传递，进一步封装 成相应的数据组成形式，最终实现数据在网络中的传递。在不同结构类型的网络 中传输时，IP报文会封装成相应的分组在数据链路层进行传输。在目前应用最 为广泛的局域网类型——以太网中，IP报文通过封装在以太网帧的方式，在数 据链路层中传输。
如图3-1, IP报文的头部包含了丰富的信息，用于数据在网络中的传输。IP 报文头部各部分的具体含义为：版本(4bit)报头长度(4btt)优先級tlB賜细(8bft) 总长度(16bit)
标识(16bit)	标志(3bft)分段偏移(13btt)
存活鄭(8brt)	协议〈8bit)	报头模绘和(16bit)
源IP地址＜32bit)
目的IP地址＜32bit)
迭项《0或32bit,若有的话)
数据《可変)
图3-1 IP报文结构
IP报文的头部包含了非常丰富的信息，其中本文中算法使用到的部分是：
版本一4比特，用以表明IP协议的版本，根据不同的版本，IP报文具有不 同的格式。	五
IP报头长度一4比特，该字段指示整个IP报头的长度，单位是32位。因为 IP头部中存在“任选项”与“填充”两个可变的字段，所以整个IP头部的长度 也是可变的。其中，IP报头的固定长度是20个字节。所以“任选项”与“填充” 的总长度最大是40个字节。
服务类型一8比特，服务类型定义了该IP报文被处理的方式。该字段可用 于配置IP报文的优先级，当IP报文被配置了较高的优先级的情况下？如果网络 发生拥塞，报文可以被优先转发。服务类型字段可以具体配置的类型，包括，吞 吐量、时延、可靠性、费用等。
总长度一16比特，本字段指定了整个IP报文的长度，也即是报头与有效载 荷的长度之和。报文总长的单位是字节。在以太网等多种类型的数据链路中，需 要对上层的报文分组进行数据填充以达到最小帧长度的要求。那么，通过总长度 字段就可以标记实际数据的大小。
标识号一16比特，这个字段是发送者在数据报中做的一个标记。同时，该 字段也被定义为一个递增的标志，即每发送一份报文，这个字段所对应的值也会 相应的加一。这样，当IP报文被分片之后，具有相同的标识号的分片就可以认 为是来自于相同的IP报文。从而可以被正确的重新组装。该字段在下文中的终 端检测算法中也会被重点使用。
标志一3比特，标志本IP报文是否分片，以及标志本条报文在正通信数据 流中的位置。
生存期一即TTL, 8比特，用于报文的存活时间的控制。在实际的协议实现 中，大多以经过的路由器的跳数表示，报文每经过一个路由器，则TTL会相应的减一，当TTL的值变为零后，则报文就会被丢弃。同时，返回错误信息。从 而避免了报文在网络中无限传递的现象，防止了网络资源的浪费。
协议一8比特,用于表示本条IP报文的载荷是对哪种具体上层协议的封装。 如应用最为广泛的传输层协议，TCP对应的是6, UDP对应的是17。
报头校验和一16比特，用于报头正确性的检查。通过对IP报文头部每16 比特经过运算之后，将获得的校验值设置于该字段中。接受方收到报文后进行相 同的位运算，即可对报文完成完整性检验。
源IP地址一32比特，IP报文发送方的IP地址。
目的IP地址一32比特，IP报文接收方的IP地址。
可选项一可变长度，用于定义如特殊路由、时间戳、错误报告等信息。
填充一可变长度，用以保证IP报头始终TCP/IP标准所定义的头部长度必须 是32比特的整数倍。
IP头部后面就是IP报文的实际载荷的数据。IP报文的理论最大长度为65535 字节，但是，在实际的网络环境中，报文出错后，依据网络传输的纠错机制，需 要重传整个报文，如果，报文的长度过大，进行报文重传时，将会造成极大的网 络资源浪费。因此，IP报文的最大值大都限制在1500字节之下，这也是本文中 算法所要用到的一个条件。
3.3终端检测IPID算法
根据IP报文中，标志号字段所表现出的特点规律，本文设计了一种用于检 测存在NAT设备网络中终端的检测算法，算法使用了开源的Libpcap库，部署 在实际网络环境中的由实验室自主开发的网络应用内容审计设备之上，抓取经过 设备的网络数据包。通过终端检测算法对目标网络中的终端数量进行检测和估计。
3.3.1 Libpcap 简介
Libpcap (Packet Capture Library),即数据包捕捉库，是一个著名的C语言 库。广泛的应用于多种环境下的网络开发，主要用于网络报文的捕捉、处理。 Libpcap可以高效的工作于大多数的类Unix系统平台下。通过对底层的抓包功能 进行封装,Libpcap为不同的操作系统提供了一致的用户级别的编程接口，因此， 使用Libpcap编写的应用程序，可以很方便的在不同的平台间移植。
Libpcap进行网络抓包时，有两种模式可以设置，分别是混杂模式与非混杂 模式，这两种模式之间具有很大的区别，在混杂模式中，Libpcap的嗅探器可以 接收到平台主机所在的整个传输线路上的网络通信，如果是非交换网络，则是整个网络的通信数据，而在非混杂模式状态下，情况就会变的比较简单，Libpcap 仅会嗅探那些与平台主机相关的网络通信数据。根据上述描述，可以发现，如果 网络审计设备不是处于网关的位置，而且，需要检测整个网络中的流量数据，则 需要将进行流量检测的网口设置为混杂模式。
3.3.2 IPID终端序列分析
如上文所述，IP报文的头部的标识号字段会用于IP报文分片后，判断报文 是否来自于同一个IP报文的分片。从而使得IP数据包的接受方可以正确将分片 组装成初始的IP报文。IPv4在RFC791中，报文头部的标识号字段中被实现为 一个简单的计数功能，在RFC6864中被定义为进一步强调在一个最大数据报生 命周期内(Maximum Datagram Lifetime, MDL)对于_个给定的源/目的地址/协 议组必须是唯一的。所以根据这两个定义，可以推断由同一个主机发出的相同IP 数据包，其IPID字段应该是一个连续变化的整数序列，所以将所有捕获的IP数 据包的标识号字段进行重组，将会获得多条的连续递增序列，根据上述的推断, 则可以认定，每条连续递增序列都代表着一部通过NAT设备连接网络的终端设 备。
算法最终目的是寻找代表一台终端设备的连续递增IPID序列，这就要求部 署的网络审计设备必须获取网络终端发出的全部的IP数据包，而在实际的网络 环境中，存在着大量的局域网内部的数据传输，许多的终端的应用会使用本机环 回地址实现某些功能。这些通信过程产生的IP数据包，对于部署在本地目标网 络与外网之间的审计设备来说都是不可见的。所以，进行检测获取的IP数据所 重构得到的序列将是不连续的，甚至会发生跳变，这将是对IPID序列进行重组 时,.所面临的问题。
同时，在实际的网络终端检测卖践过程中，一个更加复杂的问题是，许多的 网络终端操作系统并未使用单调递增的方式来实现IPID字段，另外，一些运行 在“小端序"硬件上的操作系统在发送IP数据包时，并为未将数据字节序转换 成为网络数据传输中使用的“大端序”，从而导致，即使这类系统用简单计数的 方式实现了 IPID字段，但是，在网络传输过程中IPID字段的值依旧是不可用的。
具体到操作系统上的表现就是，大多数Linux会针对每个应用的一次通信过 程，生成一个随机的初始值，随后的IP数据包中的IPID会依次递增，目前，普 及率最高的移动端操作系统Android以及IOS同样符合上述特征。


图3-2终端检测设备工作示意图

如图3-2是终端检测设备的工作示意图。进行网络终端的检测设备分为两个 功能模块：报文捕获，字段提取，轨迹分析。报文捕获，借助Libpcap库，可以 很方便的实现网络报文的捕获功能，将捕获的报文进行处理获取该报文的IPID, 通过IPID轨迹分析，获得终端信息并存储用于后续网络应用审计。
将获取的IPID在时间维度上的轨迹进行分析，并根据描述出的轨迹与网络 中存在的终端建立对应关系。在网络中终端进行通信时，存在内网通信与网内终 端与网外设备进行通信，由于审计设备的部署位置在网络的出口，所以，终端发 生的内网通信无法观测到，由于网络内部通信的存在，审计设备分析建立起的网 络终端IPID轨迹就存在中断的间隙；IP报文的标识号字段的取值位于0-65535 的有限整数区间，因此，当建立终端的IPID轨迹时，不同终端的轨迹就存在重 叠、交叉的情况；同时，IP报文的标识号字段的取值对上述取值区间的值是循 环复用的，标识号字段的值出现循环时，应该对终端的IPID轨迹检测程序进行 合理的设计，防止出现将一个终端检测误判为两个的错误。终端的IPID的轨迹 分析也是终端检测模块的核心部分，对上述情况的处理下文会进行详细的分析、 处理。
3.3.3 IPID轨迹分析
对网络IP报文中IPID的轨迹进行分析可以得到网络中终端的数量、分布等 信息，是网络终端检测的核心组成部分。同时，因为不同系统对IP有不同的实 现，IP报文的标识号字段在不同的实现中会有不同的定义。又因为网络中存在 多种多样的终端，网络又存在多种多样的拓扑，对IPID的轨迹分析带来了极大的挑战。



根据上述IPID字段特征的分析，并通过实际检测的经验，提出了如图3-3 的IPID轨迹分析算法。
1）抓取、处理IP数据包，得到IP报文的IPID字段值以及IP报文所负荷的 传输层数据报的源端口号等信息，并存储用于下一阶段的分析处理。根 据NAT的实现，存在〈地址，端口〉对的映射，端口映射记录端口与终端 连接间的关系，且一一对应0传输层协议所使用的端口号的取值区间为[0, 65535],所以当NAT设备进行地址转换的端口映射时，端口会被循环复用。 即NAT设备对一次通信进行的地址转换，通信结束后，用于映射的端口 就有可能被循环复用,意味着端口与终端IPID轨迹对应关系存在时效性, 过期之后会端口可能被复用。于是，端口与轨迹间的对应关系也就无效
19
了。同时，考虑检测系统的性能，存储一个100个节点的序列存储报文 的端口信息，用以后期的IPID轨迹的区分。
2）	将新获取的IPID值依次与已存储的IPID值序列的末尾的值进行比较，如 果差值不大于30 （该值为工程实现中多次实验得到的网络终端数量小于 100的以太网的经验值。会根据网络的出口带宽，网络中的终端数量、拓 扑结构等的变化，进行相应的调整），则将新的IPID值加到差值最小的 序列尾部。
3）	如果岀现与多个序列差值相等的情况，出现冲突的节点开始构建新的队 列，将后续值随机插入一个序列。随后的序列按照2）中的方法进行轨迹 的构建。
4）	当出现与任意存在的轨迹序列的末尾值的差值都大于30的IPID值时， 即认为出现了一个新的终端，建立一个新的序列进行后续IPID值的存储。
5）	对3）、4）中新构建的序列，在新建立的轨迹序列中査找端口号，并与原 始序列轨迹中的端口号进行比较，发现相同的序列后，就将新建序列合 并入有相同端口号的原始序列。
6）	IPID字段有16比特，所以IPID的最大值为216-1（65535）,无论IPID值 的递增方式是针对整个操作系统，还是针对应用程序，IPID的值都是循环 使用的，也就意味着，IPID的值是循环复用的，IPID值的序列在理想状 况下会呈现周期性。设定，网络环境为目前较为常见的传输速率为 100Mbps的以太网，在平均IP包大小为150字节的情况下，则每秒网络 最多可以向外网发送83333个IP数据包，但是，考虑到拥塞控制，实际 中终端的流量状况，以及网络的实际负载能力，并根据在实际网络环境中 测试得到IPID值的循环周期约为600秒，所以以600秒为统计周期对数 据进行统计检测网络终端数。
因为，每个网络终端的活动状态具有阶段性，为了防止活跃主机，网络活动 处于一段时间的静默之后，重新开始处于网络活跃状态之后被误判为新加入主机, 故而设置主机列表的刷新时间，即为建立的IPID序列与主机的对应表对应关系 的生存时间，根据上文中的终端统计周期，并根据时间的统计经验，定义两个终 端统计周期为一个检测列表的刷新周期。
3.3.4终端检测算法效果


图3-4 IPID终端检测验证结果

图3-4是根据本文提出的终端检测算法所描绘出来的IPID轨迹，检测的目 标网络是一个拥有15部网络设备的网络，从图中可以看出，共检测出13条轨迹， 经验证，当时网络中的有2台终端在检测时间段内未进行网络通信。可见，终端 检测程序准确的描述出了活动主机的实时网络通信状况。
观察图3-4可以发现，终端轨迹大都比较平滑，这主要因为检测啊络为一办 公网络，由于网络配置或者网络用户自身不太会有使用视频等大流量的网络应用 需求，同时，由于这类网络用户具有非常接近的行为方式，导致，最终检测到的 终端轨迹有聚集、相交的现象出现。从而形成了图3-4的IPID轨迹特征。
在网络终端通信的IPID轨迹的检测、分析过程中发现，实际网络中的用户 上网行为，并非一个线性的状态，部分网络终端的网络具有突发性的特征，这就 导致了部署网络监控模块无法获取足够的关联信息，不能把来自于同一终端的数 据归类到一起。部分终端因为与外网通信过少，导致了检测无法获取足够的数据 包，来判定该终端的存在。
通过检测建立的终端IPID轨迹中可以发现网络中的终端在各个时段中的活跃 情况：终端IPID轨迹的数量代表着存在网外通信的网络终端的数量，轨迹的斜 率代表终端网络通信的发送IP报文的速度，斜率越大，发送IP报文的速度也就 越快，反之则越慢，据此可以推断出终端的网外通信的繁忙程度，这些都是对网 络中终端的网络使用情况的富含价值的反映，对网络应用的审计具有重要的意义。 进行网络应用审计时，比照检测建立的终端IPID轨迹反映出来的信息，可以对 审计结果进行相互印证，增加审计结果准确性。

本文提出的终端检测算法对Windows系列的操作系统实现较好的检测效果， 如前所述，由于不同终端操作系统之间对IP报文的标识号(Identification)字段 的实现方式的不同，可能导致上述算法存在误差的可能。同时在实际检测过程中 发现，如过网络中存在Linux系列、Android或IOS等操作系统，检测结果会产 生较大的偏差。如果需要对网络中的终端进行准确标记，还需要借助其他的方式。 其中，检测网络通信中携带的Cookie的信息,TCP初始序号(ISN, Initial Sequence Number)检测等技术都是比较准确、有效的检测方法，在未来对网络终端的检 测研究中可以考虑增加其网络流量信息，对检测算法进行改进、优化，提高终端 检测算法的准确性，增加终端检测算法的适用范围。
3.4本章小结
本章在对IP报文及计算机网络流量特征充分分析研究的基础上，提出了一 种利用IP报文标识号字段对网络中的终端进行检测的算法，通过对网络中终端 的类型及构成的分析，达到对所要进行内容审计的目标网络的审计结构与网络组 成组合分析的目的。可以细化网络应用内容审计的结果。并且可以根据网络终端 的情况制定相匹配的审计方式。

第四章 Web页面内容提取技术
网页浏览作为网络中最为主要的应用之一，应该在网络应用内容中得到足够 的重视。而由于Web页面本身的特性，对这类应用进行审计时，需要对审计对 像进行规范化，结构化等的处理。
4.1 Web页面内容信息提取
网页浏览在日常生活中的地位越来越重要，据文献[18]网页数据传输（包括 一般页面浏览，电子邮件，即时通讯等）的流量，在2014年的总的互联网流量 数据中排名第二，虽然流量仅为排名第一的网络视频的流量四成多，但考虑到网 页的载体HTML文档在传递信息时所需的流量要远小于视频文件，可以想见， 网页浏览在网络应用中的重要地位。与此同时，Cisco预测，互联网中网络浏览 的数据流量在2014年-2019年间的复合增长率可达22%[18]0正是因为这样的重 要性，网页信息审计在整个网络审计中应该得到足够的重视。
然而，如前所述，用于网页信息展示的HTML,因其在创立及发展过程中的 历史原因，以及网页信息展示中的特点，由HTML构建的网页有大量的非结构 化，冗余的信息，这些内容对提升网络浏览的体验具有很大的帮助。但是，这些 内容却对网页中关键的信息提取造成了障碍。这些信息恰恰是进行网络内容审计 的关键元素。
对网页信息进行审计，首先要做的是对网页中的关键信息，或者主要内容进 行抽取，本文提出了定向提取，自动化提取两种HTML文档关键元素的提取方 式分别根据D0M（文档对象模型）的方式以及Web页面结构特征方式针对所分析 提取网页的结构，进行内容的提取。并对这两种方式进行了实现。同时，对具体 实现的效果、性能进行了分析。
4.1.1 HTML 简介
HTML （Hyper Text Markup Language）也即超文本标记语言，广泛的用于网 络页面的创建以及标记其他可以在网页浏览器中展示信息。最初由蒂姆?伯纳斯- 李于 1982 年创建，IETF （Internet Engineering Task Force）使用简化的 SGML （标 准通用标记语言）语法对初始的HTML进行了改进，后经多年发展最终成为国 际标准，现由W3C （万维网联盟）负责维护"I。
早期的HTML的语法定义非常宽松，时至今日，网页浏览器仍然接受非标 准化，语法不严格的HTML文档。这方便了 HTML最初的推广和使用，但这却 对HTML的标准化产生了阻碍。因此，W3C曾计划语法严格的XHTML （可扩 展超文本标记语言）来替代HTML成为网页信息标记的标准。然而，实际操作 中，XHTML成为了一个与HTML并行发展的标准。但是，随着2004年出现， 并于2014年成为W3C推荐标准HTML5的出现，被当作下一代的HTML标准， 成为了 HTML的发展方向。
4.2 HTML文档元素提取
Web页面即在网络浏览器中显示的HTML文档，具有多种多样的内容，部 分网络页面出于利益目的或是因为设计不良，包含了大量的与页面主题内容不相 干的干扰信息，如弹窗、动图、大量的连接等。即使设计良好，用户体验优秀的 页面，为了提供良好的交互体验，提高信息展示的有效性，增加了大量的修饰性 信息，将页面设计为具有复杂的结构。网络应用内容审计所关心的是网络页面中 所包含的主题信息，或者是这些主题信息的具体组成部分。这些需要用于审计的 关键信息往往被修饰性的信息所干扰。在部分劣质的网络页面中甚至被噪声信息 埋没，与网络页面主题关联性不大的信息元素，大大增加了网络应用内容审计过 程中对审计所关心的关键元素的提取难度。
网页信息提取，是信息提取技术的一个分支，传统的信息提取的偏重于通过 自然语言处理的方式通过对词汇、语法分析的方法从非结构化的文本中提取信息 [201o网页信息提取则通过模式挖掘、机器学习的方式，利用句法模式或结构布 局分析的方式对网络页面中的感兴趣的信息进行提取。目前，存在着大量的 HTML文档元素提取方面的技术。
网页信息提取包括干扰信息去除，特定信息元素提取。前者侧重于将页面中 广告、装饰美化元素等噪声信息滤除，保留网页中的主体内容。后者则更重视于 对网络页面中的特点部分信息的提取。如社交页面中的用户ID信息，网络购物 页面中的商品名、商品价格等信息。
基于噪声信息去除的网络页面信息提取，大量的应用于网页的标准化处理， 或者对网页进行信息无障碍处理。例如，适用于PC等具有较大显示设备，对 HTML文档具有较强处理能力的网络页面，为了将此类的页面迁移到显示屏幕较 小且不具备太多对HTML文档容错能力的设备时，如果对网页进行重新编写， 将会耗费大量的时间、精力。一种较为高效、可行的方式为，通过页面信息提取 系统，提取网页中的主题、正文内容、正文配图等主要信息。在提取网页主要信息同时，可以按照W3C标准对页面进行格式检查，使得网页在移动手持设备, 或其他类型的不具备较强处理能力的特殊电子设备中的信息展示。
面向特定元素的网页信息提取则更具有指向性，如进行网络应用内容审计是 需要了解网络用户访问过的页面的类型，网页中的主要信息。有时需要根据网页 的类型，提取网页中的关键元素。一种常见的应用场景是，当检测到用户访问的 是购物类页面时，对页面中的商品名称，及其相关的特征、价格信息进行提取。 通过上述获取的信息可以对网络用户的网络使用的行为轨迹、使用习惯等特征进 行统计描述，对网络中的用户进行行为画像。为网络的管理、优化提供参考信息。
由于网页多是用于信息的展示，因此，网页的设计者大多会利用“加粗”, “斜体'’等通过设置特殊的字体样式、格式，对网页中的主要、重要的信息进行 强化或突出显示，文献［21］就借助了这种网页的视觉特性，提岀了针对特定网页 结构特征通过对网页进行语义块划分，根据HTML标签设置过滤规则，提取网 页信息元素。在文献［22〕中作者提出了一种根据网页的视觉特征对深度网络进行 网络页面数据信息提取的技术，万维网中存在着大量的，根据客户端发送的请求, 网络页面服务器动态生成相应的页面反馈给客户端，作者将其定义为深度网络, 深度网络生成的页面即为深度网络页面，电子购物网站反馈给用户的商品检索页 面，新闻类网站根据不同地区用户访问，生成并反馈给用户的本地新闻页面，都 可以认为是深度网络页面。
网络应用内容审计中关心的内容为页面的主题内容，如访问页面所使用的认 证信息，购物页面中的产品名称，价格等这类可以反映网络使用者的活动轨迹， 行为特征的信息。
信息提取系统中一般会使用到一种重要组件包装器（wrapper）,包装器用于 在信息提取系统中提供一个用于在不同的信息源间，提供一致化的查询接口。具 体到网页信息提取领域，包装器一般会实现三个功能，这三个功能分别是向网页 服务器发送请求获取网页内容；提取网页中的关键元素；对提取的内容进行结构 化存储。其中，又以网络页面的元素提取功能最为关键，包装器有时也会被称为 提取器。
包装器根据一系列预先设定的提取规则，通过模式匹配的方式进行网络页面 的提取。对不同类型，不同复杂程度网络页面进行信息提取时，往往需要对包装 器进行结构、参数调整，使其符合新的提取要求，而通过将包装器设计成为使用 样本训练的方式来调整网络页面提取规则，可以大大提供网页信息提取系统的可 复用性能，降低维护开销。
本文在充分阅读、研究了前人成果的基础上，结合网络应用内容审计的特点， 在HTML文档元素的定向提取，以及HTML文档元素的自动化提取两个方向上进行研究与实现，为网络应用的内容审计提供一种新的途径与思路。
4.3 HTML文档元素定向提取
在进行网络应用内容审计时，需要对网络用户进行的网络页面浏览进行监督、 审计。例如，审计网络用户所访问过的网站类型，在每个网站上的停留时间，所 进行过的交互操作等用户的网络行为0进行上述审计就需要对用户访问过的网络 页面中的主题，页面正文或各分块中的主体内容等信息进行提取。
4.3.1元素提取方式性能比较
在网络信息元素的提取领域有着多种多样的开发语言，编程语言库等工具。 本文中应用并比较了 HTMLParser、Jsoup两款开源的网页解析、处理开发语言 库。
HTMLParser、Jsoup这两款开源开发语言库都是用JAVA编写,两者在HTML 文档的解析处理方面都有着广泛和长时间的应用，为了在这两者中选择一款合适 的开发库，对它们性能，易用性等方面进行了了测试。
使用HTMLParser与Jsoup编写的程序，分别对相同的三种类型（新闻、论 坛、网络购物）的网站进行数据抽取的运行时间方面的统计，运行时间分别是数 据抽取运行时间、将数据写入文件的时间。以及二者之和，总时间进行了统计。
网页信息元素提取方式性能测试中，选取在页面布局、包含信息类型方面具 有代表性的新闻、论坛以网络购物类的网站进行主要内容的提取。为了降低客观 因素对测试结果的影响，在这三类网站中随机选取不同的20个页面分别进行2 次数据抽取，提取网页中的主体内容并统计时间。同时，为保护用户隐私，结果 展示中隐去了网站用户的部分信息。

證页	诳闻国内 国际	社区论丘編判	中国侨网华文报扬	财経
顎9台滝灿法治	關,博客宝紂	侨界欢人物	1T
金M证与汽军	文化娱乐体冏	??	漩5演出	WiA
略 編 sa	na as生话	酔	me供d	手机饭

201 睥 11 月 18日 KMH
WWW.CHINANEWS.COM
毒页位査：85 -话词中? -*国际瞬	国际癩U：	脚#评	。卜姆 人凯修 S?W,z
2。11做月22日16:21来源：中国漩舸 好鬱与互动釦	r字体：t大)小】
中新网9月2汨电据英国蘇体22日报道，利比亚换政当局衰示，他们已占領卡扎 菲在撒哈拉沙?漠深处髏后据点之一，爰现了化学武繇，并在很大程度上控制了另一她 据点?
此外，外英国《金敲时报》周四(2诅)援引英国和利比亚官员的说法称，利比 亚“全国近渡委员会"似下简称“过渡委”)还在该国央行发现了卡扎莊“遗留"的 价值230亿美元的资产?
分析称，宣布即将组建新政府的利比亚"过渡委"目闱面临重云压力，它一方面 需要全面控制利比亚音地、复苏该国经济，并为效府机构筹资.
“过渡委"军方发言人法提?巴沙哈(Fathi Bashaagha)*示,执政当阙军已占领 的黎波里东南为70狡里处朱夫拉Guff a)和基I、哈(Sabha)的大部分地区，

图4-1新闻类页面及其提取结果



图4-2论坛类页面提取及其提取结果


图4-3购物类页面及其提取结果

分别HTMLParser与Jsoup对上述三种类型页面进行元素提取所用时间比较。
表4-1新闻类页面提取所用时间
时间（\\次
1	1	2
抽取	写文件	总时间	抽取	写文件	总时间
HTMLParser	2511	72	2583	1990	44	2034
Jsoup	2072	17	2089	2114	18	2132

表4-2论坛类页面提取所用时间
时间?\次	1	2
抽取	写文件	总时间	抽取	写文件	总时间
HTMLParser	1756	51	1807	1165	30	1195
Jsoup	1567	16	1583	1680	30	1710


表4-3网购类页面提取所用时间
时间\^欠	1	2
抽取	写文件	总时间	抽取	写文件	总时间
HTMLParser	5922	49	5971	5323	17	5340
Jsoup	6759	49	6808	6368	18	6386
注：测试设备的主要性能参数：
Processor: Intel(R) Atom(TM) CPU N270	@ 1.60GHz
Memory: MemTotal: 1029640 kB MemFree: 66756 kB

从上述的测试结果可以发现，基于HTMLParser与Jsoup编写的网页元素提 取程序执行的时间大致相当。也就是说明，这两个编程库的性能是相近的。
而在在实际工程实践中，发现HTMLParser在对HTML文档进行解析准确 度方面，具有一些比较大的缺陷：
?容错性差，如果HTML文档存在错误，如标签未关闭等，对这类文档进行解 析时将无法获得正确的结果。
?对网络页面中的元素间的层级关系处理能力不佳，需要手动对HTML文档模 型中的每个层级的元素进行手动编写相应代码进行分析。因为对层级关系的 过于依赖，导致即使对文档结构做出细微的修改，代码也需要做出修改，不 利于项目的后期维护。
?由于缺乏相应的方法，如果使用HTMLParser如果要对原始HTML文档进行 操作、修改将会存在着非常大的困难。
?同时，HTMLParser还存在着缺乏维护的问题，最新的版本也是2006年发布 的1.6版。难以满足新技术的使用与缺陷的修正。
然而，Jsoup可以完美的解决上述问题，在对HTML文档中的元素进行提取 时需要对元素进行检索，Jsoup使用了与其他的HTML解析工具不同的方式。

Jsoup支持使用类似jQuery中的CSS选择器的方式对网络页面中的元素进行选取。 从而，可以很方便的对HTML文档的元素进行检索。如果熟悉JavaScript,可以 非常容易的上手使用Jsoup,从而极大的降低了使用者的学习成本。
也正是因为Jsoup具有的上述众多的优势，在本文中选择它作为对HTML 文档中信息元素提取工具的开发语言库。
4.3.2网页中身份信息的提取
如果要对网络页面也就是HTML文档进行元素提取，就要先理解 DOM（Document Object Model,文档对象模型）。DOM 是用于 HTML、XHTML 以及XML文档中对象展示和交互的，跨平台且独立于具体编程语言的编程规范 [23]
0
<head>
<title>DOM Example</title> </head>
<body>
<hl>Example Body</hl>
<p>Hellc world1</p>
</body>
图4-4 HTML示例文档代码
图4-4的HTML代码段可以解析为以下的DOM结构:


图4-5 HTML示例文档DOM结构图
上图DOM结构图可以看到，除文档(document)节点外的每个节点都有自己 的父节点。例如，＜head＞节点和＜body＞节点的父节点是＜html＞ ,文本节点 “Hello world!w的父节点是＜p＞节点，DOM中共有12种类型的节点。大部 分元素节点都有子节点，＜head＞节点拥有一个子节点＜title＞。同时，＜title＞节 点也有一个子节点，文本节点“DOM Example”。当多个节点拥有一个共同的父 节点时，它们就是同级节点。图中，节点＜hl＞和＜p＞即同级节点，它们的共同 父节点是＜body＞o
在选择的编程库方面，Jsoup是一款使用Java语言编写的HTML文档解 析器，可直接解析某个URL地址、HTML文本内容。它提供了一套非常省力 的APL可通过DOM, CSS以及类似于jQuery的操作方法来取出和操作数据 [24]
O
Jsoup的主要功能如下：
1.从一个URL,文件或字符串中解析HTML；
2.使用DOM或CSS选择器来查找、取出数据；
3.对HTML文档的元素、属性、文本等进行操作。
另外，Jsoup还具有其他几点非常优秀的特性。首先，Jsoup编程语言库是基 于开源MIT协议发布的，因此可以将Jsoup应用于商业应用的项目，这即拓展了 Jsoup的适用领域，反过来也促进了 Jsoup的发展。Jsoup可以以本地文件的方 式加载HTML文档，同时，提供了一个使用URL获取网络页面的静态方法，但 是该方法仅对网站中的静态页面有效，对动态加载的页面无效。
其次，Jsoup提供静态的解析HTML的方法，该方法根据WHATWG HTML5 规范，能够最大程度上从原始的HTML文档中解析出结果，无论HTML文档的 语言是否完整。Jsoup可以处理包括未关闭的标签，隐式标签等不规范的情形。 另外，Jsoup还可以解HTML片断，例如，在论坛等可以接受用户使用HTML 发帖、提交评论的网站中，可以使用Jsoup对提交的HTML代码片段进行解析， 从而最大程度的解析出其中的内容。同时，Jsoup还利用白名单策略，过滤HTML 代码段中的恶意代码。另一方面，Jsoup还支持在解析HTML文档时对文档中的 元素进行修改、删除等操作，为元素提取过程中对HTML文档修改提供了方便。
Jsoup在解析、提取HTML文档中的元素时提供了两种方式，一种是传统的 DOM方式，Jsoup按照DOM对HTML文档进行解析，然后，采用遍历方式， 查找、提取需要的文档元素。第二种便是非常独特也是，最常用到的选择器的方 式，在这种方式下，Jsoup可以像CSS或jQuery那样以多种类型的方式选择和提 取文档元素，这是Jsoup与传统HTML解析库相比的独特之处，为HTML文档 信息元素提取提供了灵活，方便的方式。
<!-- saved from url=(0049)http://weibo.com/u/3832e32124/home?topnav?l&wvr=5 -->
? <head>-.</head>
▼ <body class="FRAf-1E_main 8_indexM>
<div styles," posit ion: absolute; top: -9999px; left: -9999px; "></div>
▼〈div class*,,WB_ainiblog" >
▼ <div class=,,WB_miniblog_fb" >
▼ <div id="plc top">
〈…简易唤奇导航拚页面用
▼〈div class="l、B_global_nav WB_global_nav_alpha - node-type="top_all">
▼ <div class="gn_header clearfix">
<!-- logo -->
?<div class="gn_logo', node-type="logo" data-logotype="logo" data-logourl= "http://weioo.com? topnav?l&mod=logo">_</div >
<!-- logo -->
<! ??捜索
?<div class=,'gn_search">-</div>
<!-搜索 ->
▼ <div class="gn_position">
▼ <div class?"gn_nav,,>
▼ <ul class=',gn_nav_lisf>
? <li>_</li>
▼ <a aot="pos55b9e0848171G" bpfilter=,'page_frame" href="/3832032124/profile?topnav=l&wvr?6 class="gn_name" suda-uatrack="key?topnav_tat>&value=profile',>
<em dass="W_ficon _fic_on_user S_ficon" >H</eno
<em class="S_txt 1"修龜—MH em>
</a>
</li>
</ul>
</div>
图4-6 包含身份信息的HTML代码段
对如图4-6这样，包含身份信息的网络进行分析时，就应首先对HTML文
档的D0M结构进行分析，从图中可以发现待提取的信息元素位于一个属性为”
32
gn_nav"的分块中，该分块在DOM结构中还从属于多个分块。由于每个分块的 属性都不相同，进行元素解析时，解析库会按照DOM结构逐级解析，所以，进 行元素选择时，只需要指定可以区分元素所在节点的层级就可以，再利用选择器 方式来对身份信息进行提取即可。因此，示例代码的身份信息提取选择器的设置 为 select ("div.gn_nav > ul.gn_nav_list > li:eq(3) > a > em.S_txtl" ) 0 这样可以极大 降低代码复杂度，其它的目标提取元素也可以按照类似的方式进行。
4.4 HTML文档元素自动化提取
上一小结中的使用的对网页信息元素的定向提取中，虽然可以完成需求，但 是存在问题，首先，网页信息元素的定向提取，过于依赖网页的结构，当网页出 现细微的修改，都会影响到信息元素的提取效果，有时甚至会导致针对修改前页 面的提取程序，对应修改后页面完全无法使用。导致，必须重新编写程序，这就 会导致大量精力、资源的浪费，使得提取程序难于维护。其次，网络页面的类型 多种多样，不仅不同网站间的网络页面有很大区别，甚至相同网站的网络页面都 会有着千差万别。因此可以适用于一种页面的提取程序，在另一个页面上就毫无 作用，而针对每种类型的页面都设计一个信息元素提取程序，将耗费大量的精力， 有时甚至是无法完成的任务。导致了信息元素提取程序的适用性不佳。
4.4.1 RoadRunner算法
为了解决上述问题，就要需要一种半自动化，甚至是全自动化的网页信息元 素提取工具。即不对目标页面的内容、结构等属性有任何的先验知识依赖。Valter Crescenzi, Giansalvatore Mecca在文献［25］中提出了一种较为高效、可靠的网页信 息元素的自动提取方法，研究的主要类型为数据密集型页面。这类页面多为网络 站点服务器根据客户端的请求，根据一定的规则动态生成的网络页面。因此页面 之间都有一定的规律及相似性因］。RoadRunner中定义了一种HTML文档的结构 比较算法，通过比较相同类型数据密集型页面，推断出这一类页面数据布局的规 律，进而根据推断出的规律生成包装器，包装器用于这些同类网页进行信息元素 的自动化提取。
4.4.2文档元素自动化提取实现
本文基于RoadRunner算法的原型编程库实现网络页面的自动化提取技术， 并根据所要提取的网络页面类型的特点进行了一定的改进。算法要求目标页面间具有相似的结构特征，但是如果需要数据提取的页面结构等特征出现变化时，仅 需要使用新的训练集进行训练产生新的包装器即可，对不同类型网络页面进行数 据提取时，也是同样的操作方式。以简单的数据集训练的方式代替数据提取程序 的重写从而极大降低了程序的维护成本，扩展了程序的适用范围
自动提取实现
图4-7展示了本文实现的自动化网络页面信息元素的提取步骤：
HTML文档的语法检查
由于，使用RoadRunner中的元素自动提取算法中需要HTML严格的符合 HTML的标准。所以进行网络页面元素提取的第一步是对原始HTML文档进行 语法检査，即语法错误修正。本文中使用NekoHTML编程工具库对原始HTML 文档进行语法检査，NekoHTML可以对HTML文档中常见的错误，如遗漏的标 签，缺失DOM父元素节点等。另外，NekoHTML将所有可选的关闭标签都进行 补齐，使其符合严格的XHTML标准。本文没有使用文献［25］中的jTidy,是因为 在实验中发现NekoHTML可以提供更好的语法检查，且NekoHTML有更加新的 维护，保证了 NekoHTML的性能的提升，以及提供了更多的新特征。方便HTML 文档的规范化。
生成包装器
将HTML文档标准化为XHTML后，就可以利用这些XHTML文档通过

RoadRunner算法生成用于数据提取的包装器。
信息元素提取
包装器生成后，就可以对任意同结构类型的目标HTML文档的数据进行提 取了。
HTML元素自动化提取结果分析
本文选取了某购物网站的搜索结构页面进行了 HTML元素自动化提取的测试。

amazon
j ' Hx. * 療然		■BQ BLACK FRIDAY deals week >
Shop by Department ?	　Vwur Aiiict-jtMi con<	Deal? (險 CxnJs	Help	　　　　　Hello.Smnin	l?v	Vow _	*\0?
Your Account - Prime ~ Lists ? rr Cart
- -- — ~ ；
(a) 页面一


1-16 of 102492 results for "java-
BLACK FRIDA/ deals week〉
M?Ka.Sjga?i Your Account -
Yow Lists <
Show results for
java P(Mra 贼 mnq
Campvtefs & Technutoffy Reftirence
Pfoyaiwren? Languages Bechwe" Guides toJ?*a
Pt&gramming
? see mwe
Kinoie Store >
Jara Computer Projfammiofl Computw Proflramiwna computsre & Technoioov
. See more
? See All 32 Departments
Refine by
international Shaping
SMp? China
Amazon Ptima
Shop The Programmer's Bookshelf
Java I C++1 Pytftcn J Sw?! j Ruby 1 Vfcuai Basic
ReUted Searehes: java jao^rafnniing. jjw龄顷出 玲then.
Java: A Banner's Guide. Sixth Edition Mays. 2014 tyH8(aetlSd)iii?
Pawrfsack
$23.83 WM GstSUy T?e?aay, Nw 24
More Euy：f>s Choices $15.32 uses & new (815??rs}
嗷僉敏喰金-R
in Beginners 3<tes to Java Pro*a：nm林
TratJe >n you?$ for ?n Ainazon C3-6 uo tc $8.83
FREE SHi^nn^ on ofCsts cwr S35
Soests： See 溯 21^31 ims
Payback
S3ZS5 9fAW <^>rln? fuesaay. X<w 24
More SuySno Chc-ses $25.57 us;t：d & iSSoSsrs}
Java: The Complete Reference, Ninth Edition Apt t.aou b￥Ham?rtScaSiB
?^喩癡囁喰r a
Tratfe in youts fsr an A/nazon Gifl 3怂 up to $<$.08
FREE pippins on otfSefs c?? $35
Bo?*s： See a* 2723, ttems
(b)页面二

Show for
Books〉
Python Pfc^rafiin-iny Computers & Technofcfly Rafetec<e
Prajraming languages Coniputer f^ogramming
? Sea more
Shop The Programmers Bookshelf 、密va j C++: Python i swift | Ruby | wt)ai Basic
Related Searches 伞沖、；av& pyrhoti 冲"mining
Kindle Store >
Fatten Computer Ptcgmming
Compirter Programming *S?emore
(Python
Learning Python. Sth Edition m 6.2013 &y Mark lute
P?t Supplies >
Aquanum Cteaners
? See AB 29 Depanments
Pap?rt?cfc
$18.25 tc tent
M5.G2 to bey
Oeiil by tuesday, Uw 24
Mors Bayiftt Ctioitss
539.9S ut?d4n?w 縱漓《s；
Trade in yours for an Amazon Gift Card up te S23.1? FREE Sfi：?ptt:^on oiden dver Si?
Books: Sea all 4.1&5 Ben>$
Fieftne by
intenwtiOMl snipping -Sf：p to China
Amazon Prime
?UTO?U>n
TMt aoxiNC trvrr WttHPVTMOW -?二 msg："
Papaitwts；
S24.65
G?；3&￥ TgwJ", Mo* 24
Mm：? Buying ChoSefts
S16251瞬<5 &	樹 ?S?n)
Automate Use Boring Stuff with Python: Practical Programming fix Total Begsnnecs way ?.2oi? Iff fi S?%t53rt
盘務飼"92
Ttade it; yuan fcr si- Amsxw Gi* Cam a# to <5.93
FREE Sfi：PP?>9 en	?ver SJ$
Boolcs: S?? ?H 4J55 fems

(c)页面三
图4-8自动化提取原始页面



图4-9自动化提取结果
图4-9即为根据RoadRunner算法对测试页面进行自动化提取获取的部分结 果数据集。结果中每一列代表一个还原出的原始数据的列，并用大写字母标记列 名。未表明列名的是一个子树结构。图中不显示的为元素页面中的图片地址，因 为未对地址解析，所以图片未显示。从结果可以看出，本文的提取方法较好的还 原了网络页面中的数据，并用树状结构表示数据之间的关系。生成的数据已经具 有很好的结构化，通过简单的处理就可以存入关系型数据库，或者大数据处理系 统的数据仓库内。
但是，因为网络页面的样式的多样自由化。虽然，HTML标准的不断规范与 严格，以及XML的出现，都对HTML的规范应用以及网络页面的规范化有着巨 大的促进。但是，无监督的自动化网页信息元素的提取仍然面对的极大的挑战, 如同，上文提到的基于RoadRunner算法的HTML元素自动提取，仍是有诸多的限制，算法的效果也是有很大的提升空间。然而，这却为页面元素的自动化提取 提供了很好的参考。结合网络页面用于信息展示目的的自身的特点，未来的研究 通过结合机器学习、人工智能等技术或许是一个较为光明的研究方向。
4.5本章小结
本章对网络中的一种重要应用，Web页面浏览进行了分析，通过Web页面 的组成，结构特点等入手，将页面中的关键元素选为进行内容审计的对象，并根 据研究现状对Web页面中的关键元素设计了定向提取，自动化提取两种提取方 式。在Web页面中提取的元素，对于网络应用的内容审计就有极高的价值。

第五章网络应用内容审计用户特征聚类分析
目前，网络应用审计领域审计数据获取手段日益丰富，可获取的审计数据几 乎呈几何级数增长。面对日益增长的数据规模，传统的数据分析方式已经不能满 足当下海量数据的分析需求。对新数据分析方式的应用的要求也变的日益迫切。 本章提出一种基于分布式大数据处理计算平台Hadoop的海量审计数据分析方法。 对通过上文中以及本章中提出的审计方法所获取的数据进行处理、分析，为网络 应用内容审计提供了一个新的思路和方向。
5.1HTTP报文信息审计
5.1.1HTTP 简介
HTTP是应用层、面向对象的最重要的协议之一。因其简洁、快速等优秀的 特性，被广泛的应用于分布式超文本信息系统。HTTP最早于1990年被提出， 在多年的使用与发展过程中，得到了不断的发展和完善。HTTP/2已于2015年5 月通过RFC 7540发布。
HTTP的特点可以概括如下：
＞使用客户端/服务器模式:通常通过使用HTTP的应用作为客户端向服务 器指定端口的发送请求。由于服务器的存在，因此可以提供较为稳定、 可靠的服务。
＞简单快速：使用HTTP通信时，仅需传送请求方法和资源路径。HTTP 中定义的方法规定了客户机与服务器的不同通信类型。正是因为这种简 单的协议实现思想，使得HTTP简单快速。
＞灵活：HTTP可以对任意类型的数据对象进行传输。传输的数据类型通 过Content-Type字段加以标记。这种灵活性使得HTTP的应用变得十分 广泛。
＞无状态：HTTP协议是无状态协议。所以HTTP对事务处理是没有记忆 能力的。以URL形式提交的客户端请求可能包含cookies等带状态的数 据，这些数据完全指定了所需的文档，而不需要其他之前请求的上下文 或内存地址，所以HTTP服务器对请求可以实现快速应答。
5.1.2HTTP报文结构
HTTP报文是面向文本的，报文中的每一个字段都是一些ASCII码串，各个 字段的长度是不确定的伽】。HTTP有两类报文：请求报文和响应报文。HTTP报 文由起始行、首部、和报文主体3个部分组成,首部与报文主体之间由空行分隔。 起始行位于报文的第一行，表示客户端请求的内容，或服务器做出了怎样的回应。
HTTP报文的首部字段位于起始行之后，每个首部字段都由字段名及其对应 的值组成，首部包含了 HTTP报文的状态或控制性信息。分为通用首部、请求首 部、响应首部、实体首部以及扩展首部五类，通用首部、实体首部在请求、响应 报文中都可以使用，扩展首部是指在规范中没有定义的首部"I。
报文主体，首部字段空一行后就是报文主体，是HTTP报文实际传输的数据, 可以是文本或二进制数据。
方法	　URL	坂本	　　回车待	换行符	请求行
首部	　　　　域值		　　回车苻	换行苻	　　请求头部
首部	　　　　场值		　　回车有	換行苻
回车存兼行存
报文买体（O）			请求数据
图5-1	HTTP请求报文结构

请求报文的起始行是请求行，请求行由方法字段、URL字段以龙HTTP版 本号三个字段组成。其中，HTTP共有八种不同的方法，HTTP通过不同的方法 对资源进行相应操作。HTTP应至少实现GET与HEAD这两个方法。
请求首部位于请求行的下面，请求首部与请求行中的HTTP方法配合工作, 共同决定了 HTTP报文通信所实现的功能。
HTTP的响应报文也分为三个部分，分别是状态行、响应首部和响应数据。
版本	状斓	蜒语 维苻	换行袴	状态行
岫	　　响应头部
曽部		岫
函节賴有有	　1収实体耕附响应｝收不蒯H）		　　响应实体
图5-2 HTTP响应报文结构
状态行包括协议版本、状态码和状态短语。HTTP提供了丰富的状态码，用 以表示数据报的响应状态，状态代码位于HTTP响应的第一彳-一状态行，位于 HTTP版本号之后，状态码由3位十进制数字组成，他们分别代表的含义为：
?最高位为“1”表示消息，说明请求已经被接受，等待后续处理。
?最高位为“2"表示成功响应，说明请求已经接受、并已经处理完成。
?最高位为“3”表示重定向，说明客户端的请求被重置，需要客户端根 据响应进一步操作才能完成请求。
?最高位为“4”表示请求错误，说明请求不符合语法规范或者服务器无 法处理该请求。
?最高位为“5”表示服务器错误，说明客户端的请求是合法的，但是服 务器在处理该请求时，在服务器端发生了错误。
每一个大项还有多种的详细状态的划分,分别由次高位以及最低位的不同数 字表示，如常见的“200 OK”、“404 Not Found"。描述状态的短语在RFC 2616 中有详细的描述，但这并非是强制性要求。Web或其他使用HTTP应用的开发者 可以自定义状态短语，对状态描述的显示进行本地化，或者用于满足其他个性化 需求。
响应首部同时包含了响应报文的一些附加信息，方便客户端对响应报文的处 理。并为接下来的请求提供参考信息。共包括信息性首部、协商首部、安全响应 首部等。
5.2 HTTP报文审计数据的提取
利用网络审计设备的网络报文捕获程序，对流经审计设备的TCP报文进行 抓取，并通过TCP重组技术获取一条完整的HTTP报文，根据审计需求提取报 文中的客户端信息以及服务端信息，并存取为日志。为下一步的报文审计做数据 来源准备。
5.2.1分布式数据处理平台
Hadoop是一个Apache基金会管理的开源数据处理框架系统。最初是由Doug Cutting于2005年基于Google的GFS和MapReduce的技术思想的开源实现。经 十多年的不断发展，尤其是随着Hadoop 2 （下文中如未特别指出，则本文中 Hadoop特指Hadoop 2）的出现，Hadoop已经由最初的分布式处理框架向开放性 的基础资源管理框架演进，随着功能的不断改进，Hadoop在开源数据处理领域 开始扮演了越来越重要的角色。
当前Hadoop中的核心部分：数据的存储系统HDFS以及计算框架较之于 Hadoop发展之初已经有了巨大的变化，基本实现了对Hadoop架构的重建。架构 中计算框架最重要的变化是，原始默认的MapReduce不再是唯一的计算框架， 截至目前Hadoop已经可以同时支持Spark,Storm,Hama等多种分布式计算模型。 这些计算模型都可以运行在Hadoop新的核心组成部分YARN（Yet Another Resource Negotiator）Jto当前的存储架构中的HDFS Federation通过釆用多个 NameNode,且各个NameNode之间相互独立，各自管理着自己的命名空间，每
个DataNode会向集群中的所有NameNode注册。通过这样的设计解决了最初
HDFS中存在的单点故障问题，同时还提高了 HDFS的高可用性和可扩展性。
Ambari
（部署、配置及管理工具）
图5-3 Hadoop生态系统
经过多年的发展，伴随着算法的改进、技术创新，以Hadoop为基础衍生出 多种多样的，结合分布式计算思想的新工具。这些新的工具与Hadoop共同组成 T—"成熟并且持续发展的Hadoop生态系统oHadoop生态系统中的不同工具通 过不同的组合，可以完成多种多样的任务和功能。
5.3网络应用内容聚类分析审计
在进行网络应用内容审计时，部分需求可以实时的完成，如本文进行的网络 终端分布情况检测，以及对网络终端实时流量检测，这都是需要实时完成的任务。 同时，有大量的网络审计需要对一个相对较长的时间段内的信息数据进行分析, 这往往就意味着需要对大量的数据进行分析。另一方面，在本文中提到的，无论是在HTML文档中提取的元素信息数据，还是对网络流量中的HTTP报文中釆 集到的用户网络信息内容数据都是可以达到TB(Terabyte)甚至是PB(Petabyte) 级别，在网络应用审计的过程中，需要通过对这些网络数据进行分析，来获取目 标网络的关键特征。当对如此巨大的数量级别数据分析时对数据分析工具以及分 析方法都提出了极高的要求，传统的数据分析工具在进行如此大数量级的数据分 析时，表现的越来越捉襟见肘。为了提高分析的准确性，提升分析的效率，分布 式大数据分析平台Hadoop的引入都是有必要和非常明智的。
5.3.1 HTTP报文数据的用户行为分析
网络流量中的HTTP报文广泛的应用于服务器与客户机之间进行数据传输 和信息交互。随着智能移动设备的迅速发展，因HTTP简单、快速的特点，智能 移动端的软件应用与服务器之间也广泛的使用HTTP作为数据传输，信息传递的 手段。因为智能移动设备与用户日常生活、工作有着更加紧密的联系。针对智能 移动设备产生的网络流量进行分析，更能反映网络用户的行为特征。

图5-4日志数据格式

使用网络审计设备对网络中的HTTP报文进行抓去、解析，并按照图5-4的 格式保存为日志记录，共有11个字段分别为：HTTP方法、审计设备编号、网 络终端MAC地址、网络终端IP地址、远端主机IP地址、远端主机端口号、报 文时间戳、主机地址、主机路径、Referer、Cookie。其中利用MAC来区分代表 各个用户。
对网络用户应用行为进行分析，就需要先将网络中报文特征进行提取。利用 MapReduce长于文本数据的优势进行提取，并存储为[终端操作系统类型、通讯 社交应用、购物应用]结构的记录。其中终端操作系统类型检测Windows、Android、 IOS三种类型的操作系统；通讯社交应用统计微信、QQ、微博三类；购物类应 用统计京东、淘宝这两类应用。对应某个终端系统记录中若检测不到则标记为“0 ”。 分别在原始报文中的主机地址、Referer以及Cookie中对上述字段进行匹配检测。
本文中对用户行为的分析使用了 k-modes聚类算法[281, k-modes是对经典的 聚类算法k-means的扩展。不同于k-means主要面向数值型数据处理，k-modes 长于对分类属性数据进行聚类分析。
假设两个可进行分类的对象A、B,这两个对象分别拥有n个可进行分类的 属性。则A、B可以表示为A=[ai,…，a」、B=[bi，…，bn]?那么可以用下式对A、B的相异度进行测量。
d(A,B)=￡*N(aj, bj)

如果将可分类对象中的每个属性出现的频率考虑进来，可以按照chi-square 距离【29】的定义方式将式(5-1)重新定义为
dx2(A,B)=Sj=i ma.m-6(ai- 0)	(5-3)
式(5-3)增大了对象中某个属性出现频率低的值对相异度的权重。充分利 用了低频属性信息量高的特点，提高相异度计算的准确性。
将一个可分类对象集合A中的所有元素与一个给定元素G (G是与集合中 元素同类型的可分类对象)的相异度最小，则G即为对象集合A的modeo
寻找G的方法，查找G中每个属性乡的所有可选值的组合，当满足/(gi)>/(Ci) 时(G为集合A中任意可能对象的与gi对应属性)，则G即为对象集合A的modeo 式(5-4)是函数f(x)的定义。
/应眄=勺	(5-4)
k-modes聚类定义式(5-5)为综合相异度。其中ygh是在文献［30］中定义的划 分矩阵丫朴中的一个元素。k-modes聚类的最终结果应实现式(5-5)的最小化。
E=Zg=i Sh=i yghd(Ag, Gh)	(5-5)
k-modes聚类算法步骤：
?从待处理数据中随机选择k个对象，将它们作为聚类的簇中心。
?利用上文中的相异度计算公式，遍历计算数据集中元素与簇中心间的差异度。
将元素与与其最小相异度的簇中心归为一个簇。
?利用上文中分类对象集合mode的查找方法，重新设置各个簇的中心。
?对2, 3步进行迭代，直至每个簇的中心都不再发生变化，整个计算结束。

图5-5 MapReduce实现k-modes聚类流程图

目前，大数据的聚类已经有许多研究。但是，由于聚类本身循环迭代的特征， 常规工具实现聚类算法很难达到很高的效率。本文利用Hadoop的MapReduce 计算框架分布式并行计算的特点，对上述算法进行实现，在map阶段读取用户 记录数据以及设置为DistributedCache簇中心文件，计算样本对象与簇中心间的 差度，并根据最小差异度分配到相应的簇。Reduce阶段用于重新设置簇中心， 并判断簇中心是否不再变化，或者综合相异度满足设定的阈值。当簇中心不再变 化，或者合相异度小于设定的阈值时，则输出聚类结果。否则进行下一轮迭代。利用MapReduce计算框架分布式并行计算的特点达到了较好的运算性能。将上 文中整理的数据聚为四类，得到了如下的聚类结果：
聚类结果的簇中心：
1) [Windows、QQ> 0] 2) [Windows> 微博、淘宝]
3) [Android、微信、淘宝] 4) [IOS、微信、京东]
表5-1聚类各个簇样本数
类别	1	2	3	4
数量	2573	1200	4122	1245

根据上述的聚类结果可以得出本文研究的目标网络中的终端特征如下，PC 以日常办公为主，生产工具的特性已经非常突出。网络用户的娱乐、购物行为正 大规模向移动端迁移。微信的使用量已经有很大的规模，淘宝与京东用户有一定 的分化。根据微博与淘宝之间较强的共存关系，可以推测微博对淘宝起到了较强 的流量导入效果。
5.4本章小结
本章对根据前-面章节中提取的网络应用审计相关的元素提取技术，结构检测 技术所获取的审计信息进行了分析。根据目前网络规模庞大，网络审计信息是一 个海量的量级的现实，提出了使用分布式数据处理框架，结合聚类技术对网络中 的审计信息进行分析，并据此得出与网络状况相关的用户行为特征，实现了对实 际的计算机网络在一个宏观层面上的审计分析。
第六章总结与展望
6.1全文工作总结
在信息技术不断革新，信息产业飞速发展的大背景下，人类社会的各个方面 的信息化程度不断深入，信息技术已存在于人类社会的各个方面，为民众的生活、 工作、学习带来了巨大的便利，极大的提高了民众的生活尤其是精神生活质量和 水平。作为信息化的重要方面的计算机信息网络，在其中扮演了重要的角色，发 挥了巨大的作用。正因计算机网络表现出来的这种重要性，以及与人们的日常生 活深度结合的程度，在充分享受计算机网络带来的自由与遍历的同时，如何对其 进行有效的管理和维护也成为了一个极其重要的课题。
本文重点研究、介绍了基于HTTP或与HTTP相关的网络应用及其内容产生 的网络流量特征的分析。同时根据所进行分析内容的特点，提出了和改进了相关 的处理、审计技术。较大程度的提高了网络审计的效率及审计结构的准确性。
本文主要完成的工作是：
一、	对国内外的网络审计系统及技术进行学习研究，确定本文所要进行研究、 改进的网络审计方面技术的方向。根据当前网络的特点，研究、选择了对网络审 计最有价值之一的网络应用类型——与HTTP相关的网络应用o其中一个具体的 方面是网络用户所进行Web页面浏览活动的审计。通过对Web页面中的关键信 息元素的提取，来描绘网络用户的浏览活动特征，实现对网络终端Web浏览活 动的审计。本部分的关键技术是对Web页面也即HTML文档的信息元素的提取。 本文基于开源HTML解析编程库，结合DOM, HTML文档的结构分析等技术， 根据网络审计的需求特点，进行优化改进。同时，根据当前成熟技术，尝试实现 HTML文档信息元素的自动化提取工作，并取得了一定成效。另一方面，HTTP 还广泛的应用于网络终端间的信息传递。因此，HTTP报文中包含了丰富可以反 映用户网络行为特征的信息，这些信息对网络应用内容审计有着极其重要的意义。 本文中通过对HTTP报文的特征进行的分析，有选择的将HTTP报文中最能反映 用户行为特征的信息提取。同时，将提取的信息数据存储用作网络流量状况、网 络用户行为分析、网络审计的重要数据来源。
二、	针对所面对计算机网络的特点，并根据在本文中提出的获取的网络审计 数据的特点，以及所要进行分析的需求。本文选择使用著名的大数据分析平台 Hadoop对采集到的网络审计数据进行并行处理分析。通过选取HTTP报文中提取的网络用户特征信息的分析，研究并实现了基于k-modes聚类的网络用行为特 征分析方法。由于网络用户的HTTP报文特征数据具有多个维度，且数据量巨大, 因此本文采用了对分类数据类型具有良好性能的k-modes聚类算法。针对HTTP 报文数据量大的特点，使用MapReduce计算框架实现k-modes算法进行实现， 并对实验数据集进行处理测试。根据聚类出的结构，分析出网络用户行为所表现 出来的聚集特性，可以了解网络用户的行为趋势，通过大数据聚类分析方法，对 网络流量在一个宏观的维度上进行分析，为网络应用内容审计提供了一个新的方 法和思路。
6. 2未来研究展望
在对网络应用内容的审计技术的研究中获取一定成果的同时，作者也清楚的 意识到自己在网络审计尤其是网络应用内容审计方面仍存在这很大的不足，还有 多个需要改进的方面：
首先，在网络终端的检测技术方面，检测结果还略显粗糙，使用的方法较为 单一，应综合更多的网络终端流量特征及其他相关信息，实现网络终端更详细的 检测。
其次，HTML文档的信息元素提取，需要人为干预的工作还是偏多，虽然在 一定程度上实现了信息元素提取的自动化，但是，该自动化提取技术的性能及适 应范围与期望之间仍有较大距离。将来的研究中，应注重对机器学习、人工智能 等复合技术的使用，实现较好的信息元素自动化提取。
第三，在对HTTP报文数据的用户行为相关分析中，虽然借助了较能反映用 户行为特征的聚类分析方法。但是所进行分析的维度仍偏不足，对用户信息进行 更多维度的分析，是未来的一个重要工作。
网络内容审计是维护网络健康、有效运行，为人们生活、工作提供稳定、高 效、安全服务的重要措施。在未来的研究工作中，结合上述提出的工作方向。在 网络审计的研究中进行有效的改进和积极的提升。
参考文献
[1]陈清泰.新兴产业驱动经济发展方式转变卩].前线,2010 (7): 49-52.
[2]闵栋，崔媛媛.我国面向移动互联网的终端产业发展浅析[J].移动通信,2009 (19): 17-20.
[3]新华网.中国互联网络信息中心[J].第35次中国互联网络发展状况统计报 告,2015:01-15.
[4]王华莹，罗嗣红.中国互联网产业的现状与发展趋势[J].科技进步与对策， 2000, 05 期(05):105-106.
[5]席文军.网络内容审计系统关键技术研究[J].科技资讯,2009, 17期
(17):170-170.
[6]曹如中，曾瑜，郭华.基于网络信息安全的国家竞争情报体系构建研究卩]. 情报杂志,2014,第8期(8): 13-18.
[7]Enck W, Ongtang M, McDaniel P. Understanding android security [J]. IEEE security & privacy, 2009 (1): 50-57.
[8]Latham D C. Department of Defense Trusted Computer System Evaluation Criteria[J]. Department of Defense, 1985, 951(5):pags. 69-72.
[9]Mark W. Principled Assuredly Trustworthy Composable Architectures[J].
[10]Garfinkel T, Pfaff B, Chow J, et al. Terra: A virtual machine-based platform for trusted computing[C]//ACM SIGOPS Operating Systems Review. ACM, 2003, 37(5): 193-206.
[11]1999 GB.计算机信息系统安全保护等级划分准则[S][D]., 1999.
[12]裘俊.流媒体资源数字版权管理系统的研究与设计[D].华中科技大学,2007.
[13]White T. Hadoop: The definitive guide[M]. H OReilly Media, Inc.H, 2012.
[14]JianYAN. Hadoop平台下的并行Web日志挖掘算法[J],计算机工程， 2013, 39(6): 43-46.
[15]Czyz J, Allman M, Zhang J, et al. Measuring ipv6 adoption[C]//Proceedings of the 2014 ACM conference on SIGCOMM. ACM, 2014: 87-98.
[16]Bellovin S M? A technique for counting NATted hosts[C]//Proceedings of the 2nd ACM SIGCOMM Workshop on Internet measurment. ACM, 2002: 267-272.
[17]Xue BAI, Bu-ren Q, Hua-qing L. A Scheme for Counting NATted Hosts[J].Computer Security, 2009, 4: 46-48.
[18]Cisco I. Cisco visual networking index: Forecast and methodology, 2011-2016[J], CISCO White paper, 2012:2011-2016.
[19]Graham I S. The HTML sourcebook[M], John Wiley & Sons, Inc., 1995.
[20]Gottron T. Evaluating content extraction on HTML documents[C]//Proceedings of the 2nd International Conference on Internet Technologies and Applications. 2007: 123-132.
[21 ] Gupta S. Context-based content extraction of html documents [J]. Doctor of Philosophy, Columbia University, 2005.
[22]Liu W, Meng X, Meng W. Vide: A vision-based approach for deep web data extraction]J]. Knowledge and Data Engineering, IEEE Transactions on, 2010, 22(3): 447-460.
[23]Jensen S H, Madsen M, M 0 Iler A. Modeling the HTML DOM and browser API in static analysis of JavaScript web applications[C]//Proceedings of the 19th ACM SIGSOFT symposium and the 13th European conference on Foundations of software engineering. ACM, 2011: 59-69.
[24]Hedley J. jsoup: Java html parser[J]. 2010.
[25]Crescenzi V, Mecca G. Automatic information extraction from large websites [J]. Journal of the ACM (JACM), 2004, 51(5): 731-779.
[26]Bemers-Lee T, Fielding R, Fry sty k H. Hypertext transfer protocol-HTTP/1.0[R]. 1996.
[27]Kristol D M, Montulli L. HTTP state management mechanism [J]. 2000.
[28]Huang Z. A Fast Clustering Algorithm to Cluster Very Large Categorical DataSets in Data Mining[C]//DMKD. 1997: 0-.
[29]Greenacre M J. Theory and applications of correspondence analysis[M]. 1984.
[30]Hand D J. Discrimination and classification]J]. Wiley Series in Probability and Mathematical Statistics, Chichester: Wiley, 1981, 1981, 1.
