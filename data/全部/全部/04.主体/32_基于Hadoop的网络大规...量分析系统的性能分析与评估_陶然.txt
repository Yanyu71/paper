
第一章绪论
1.1研究背景
近年来，随着网络的普及，移动互联网、云计算以及逐渐兴起的物联网都在 迅猛地发展，当今社会的数据规模呈指数型增长趋势，数据类型多种多样，包括 文本、语音、视频等［1］。根据IDC的研究报告:整个地球数据量在2009年是0.8ZB, 到2020年，会上升至35ZB,这十年将增长44倍，年均增长率达到了 40%左右 ［2】。由于数据规模的庞大，传统的数据分析与处理工具已经不足以满足当前的数 据分析需求，如何管理和使用这些数据，逐渐成为了一个新的领域。因此，“大 数据”的概念应运而生，大数据时代己然来临⑶。
大数据时代的来临给我们带来了巨大的机遇，处理与分析海量数据，发现并 提取数据的深度价值，为各行业提供高附加值的应用和服务［句。但与此同时，大 数据也给我们带来了巨大的挑战。面对爆炸式增长且结构日益复杂的数据，传统 的数据处理技术巳经不能实现有效的将数据进行存储并快速的处理和响应高并 发的数据［5】。自2003年以来，Google公司相继发表了三篇论文，向全世界分别 介绍了三个技术概念：分布式文件系统GFSm〕、分布式的编程模型MapReduce^ 以及分布式的结构化数据存储系统Bigtable^,并以事实证明了该框架在处理海 量网页数据方面具有强大的优越性。ApacheHadoop"］正是对Google提出的这一 优越框架的开源实现。Hadoop是一个开源的分布式计算平台，它的核心技术主 要包括分布式文件系统HDFS、分布式计算框架MapReduce及YARN。在大数据 领域，Hadoop可以在由普通PC组成的集群上获得良好的运行效果，因此大大的 节省了企业IT设备成本。Hadoop凭借其低成本、高性能、高可靠性的优势，得 到了全球大量有大数据处理需求的用户的支持。
1.2研究意义
如今，Hadoop得到了国内外企业和研究者的广泛应用，成为大数据处理的 基本工具。尽管Hadoop技术正在不断地完善和优化，但是在实际的运行过程中， 仍然会遇到各种各样的问题。人为操作问题，如误操作数据块丢失、参数配置不 合理等；集群服务器的硬件技术瓶颈，如内存不足、磁盘读写速率、网络传输速 率受限等。这些问题均会影响集群的正常运行，使集群处在一种不佳的性能状态 中。
基于Hadoop的网络大规模流量分析系统依托于Hadoop集群的框架和工作 机制，用于存储海量网络流量数据，并运行用户的离线分析应用程序，对网络流 量数据进行基础的统计分析。与Hadoop集群的性能状态类似，分析系统的性能 状态亦受到多种因素的影响。对于普通用户来说，各种影响因素信息的集中获取 并对其进行理解分析是超出其能力范围的，普通用户所在意的仅是在分析系统中 应用程序的正常运行和输出结果。如果分析系统处于一种不佳性能状态时，用户 并不知情，仍然提交并运行作业，只会使分析系统的负载进一步增大，性能进一 步恶化，从而影响分析系统所有作业的正常运行，给日常的工作或学习带来不便。
此时，对分析系统的性能状态进行分析与评估显得异常重要。对于分析系统 管理者而言，通过对分析系统性能状态的持续观察与分析，可以从中找到影响集 群正常运行的关键问题所在，通过数据建模分析，了解各因素对分析系统性能状 态的影响因子大小，有利于集群的维护和完善；对于分析系统用者而言，通过分 析系统的评估结果，直观地获得当前分析系统的性能状态，了解分析系统是否适 合运行应用程序，从而决定应用程序的提交时间，与其在分析系统性能不佳的时 候运行应用程序，使分析系统性能继续恶化，且导致应用程序运行时间过长或无 法正常运行，不如错开分析系统性能状态不佳的时期，保证作业的正常运行，并 减少分析系统的负载，使分析系统得以长时间处在一个性能较佳的状态，提升分 析系统的工作效率。因此，本文提出一种基于Hadoop的网络大规模流量分析系 统的性能状态分析与评估方案。通过该方案，可以对分析系统的性能状态进行评 估，通过该评估结果，指导分析系统用户的使用行为，同时，为分析系统的性能 优化工作提出优化建议。
1.3论文结构
本文共分七章，各章节的主要内容如下：
第一章，绪论。介绍本次课题的研究背景和研究意义。本章首先介绍了大数 据的基本知识，以及Hadoop的产生与发展。然后提出了基于Hadoop的网络大 规模流量分析系统的性能状态的评估需求，指明本课题的实际意义。
第二章，Hadoop集群性能状态研究。本章首先简要介绍了 Hadoop的相关基 本知识。然后分析了影响Hadoop集群性能状态的影响因素,主要包括硬件设备、 软件选择、参数配置。最后，介绍了国内外对Hadoop集群性能状态的研究现状， 即性能优化和性能评估。
第三章，性能分析与评估方案设计。本章基于分析系统实际情况，并结合功 能需求，提出了一套性能状态分析与评估方案，简要介绍方案的各个部分，并搭 建方案的实践环境。
第四章，评估标准与性能数据。本章首先介绍了方案中分析系统性能状态的 评估标准。然后介绍了方案中选取的性能数据指标，并基于Flume设计并实现性 能数据采集系统。
第五章，数据建模分析。本章首先介绍了两种建模方式：线性的多元线性回 归和非线性的BP神经网络的基本内容。然后通过二者分别对评估标准和性能数 据进行建模分析，并验证模型的可靠性。
第六章，评估验证与性能优化。本章主要介绍了通过验证可靠的模型，分别 对分析系统的性能状态进行评估验证,并根据建模分析结果，进行性能优化工作。
第七章，总结与展望。本章主要对论文内容进行了总结，并对方案的具体实 践步骤提出了更进一步的优化与展望。
第二章Hadoop集群性能状态研究
2.1Hadoop简介
Hadoop是一个分布式系统的基础架构，由Apache软件基金会开发。该项目 是Doug Cutting等人借鉴Google公司提出的GFS与MapReduce的思想，实现 的一个开源版本的分布式数据存储与处理框架。用户可以在不了解分布式系统底 层细节的情况下，进行分布式程序的开发，并且充分利用分布式集群的威力和优 势完成高速计算和数据存储。
当前最新的版本为Hadoop2,其针对Hadoop 1的不足和弱点进行一定功能 上的改进，本论文所研究内容针对Hadoop2°Hadoop2主要包含两大组件：HDFS 和Yam,分别用于解决大数据的存储和计算问题。
2.1.1HDFS
HDFS ( Hadoop Distributed File System),是 Hadoop 的最底层组件，用于存 储Hadoop集群中所有存储节点的文件。对于Hadoop的普通用户而言，HDFS 较常见的传统分级文件系统而言，在使用过程中区别不大，因为HDFS提供了标 准的文件操作接口，这与传统的Unix文件接口类似。HDFS系统由一系列的功 能节点组成，釆用主从(Master/Slave)结构模型，在Hadoop2版本，一个HDFS 集群是由若干个Namenode和若干个DataNode组成的。HDFS内部的所有通信 均基于标准的TCP/IP协议。HDFS的架构㈣如图2-1所示：
NameNode

图2-1 HDFS基本架构图
Namenode作为主服务器，其主要任务为管理文件系统的命名空间以及客户 端对文件的访问操作，通常运行在HDFS实例中的单独一个节点上。当外部客户 机发送请求以要求创建文件时，NameNode会以块标识和该块的第一个副本的 DataNode的IP地址作为响应。同时NameNode还会通知其他将要接收该块的副 本的DataNodeo Namenode仅仅是所有HDFS中元数据的管理者，用户的所有数 据均不会经过Namenodeo NameNode在管理整个HDFS文件系统时，主要借助 于两个文件：“Fslmage”文件用于存储所有关于文件系统名称空间的信息； “EditLog”用于存储所有事务的记录文件。这两个文件均存储于NameNode所 在服务器的本地文件系统中。相对于Hadoopl的单NameNode机制，Hadoop2通 过多个NameNode的机制改进，已解决Namenode的单点故障问题。
DataNode作为从服务器，主要负责存储数据和检索数据块。除了响应来自 HDFS客户机的读写请求之外，它们还响应来自NameNode的创建、复制和删除 数据块的命令。每个DataNode负责维护该节点上所存储的所有数据块信息，并 且通过定期的心跳报文向NameNode报告本地的数据块信息。存储在HDFS中 的文件被分成若干数据块，然后将这些数据块复制到多个DataNode。数据块的 大小（默认值为64MB）和数据块的备份数（默认值为3份）在创建文件时由用 户根据自己的具体需求进行设定。
2.1.2 Yarn
Hadoop2的YamUi］是对Hadoopl的MapReduce组件的改进版本％ Yam是一 个分布式的资源管理系统，用以提高分布式的集群环境下的资源利用策，这些资 源包括内存、10、网络、磁盘等。Yam相对于MapReduce,仍可认为釆用了 Master/Slave结构，总体上采用了双层调度架构。Yam的架构如图2-2所示。
Yam主要由以下四个部分组成：
ResourceManager：负责资源管理的主服务，整个系统只有一个，负责资源管 理、调度和监控，它支持可插拔的资源调度器，自带了 FIFO、Fair Scheduler和 Capacity Scheduler 三种调度器；
NodeManager：负责单个节点的资源管理和监控，它定期将资源的使用情况 汇报 ResourceManager,并接收来自 ApplicationMaster 的命令以启动 Container （YARN中对资源的抽象，后续介绍）、回收Container等；
ApplicationMaster:负责管理单个应用程序，它向ResourceManager申请资 源，并使用这些资源启动内部的任务，同时负责任务的运行监控和容错等；
Container：对节点资源的抽象，它封装了某个节点上的CPU、内存等资源， ApplicationMaste只有获得一个Container后才能启动任务，另外，

ApplicationMaster本身也是运行在一个Container之中。




MapReduce Status	?
Job Submission 	-*
Node Status  	 	 *
Resource Request	?-
图2-2 Yam基本架构图
2.2 Hadoop性能状态影响因素
Hadoop作为一个分布式集群，主要用于大数据的存储和计算。Hadoop集群 的搭架工作和普通应用，参考官网和网上的诸多教程，一般用户均能顺利完成, 从而在Hadoop集群上存储数据并对数据进行计算。但仅实现简单的可用性功能, 并不能体现Hadoop集群的优势。在基本可用性的基础上，应尽可能提高Hadoop 集群的性能，让存储速度更快、计算时间更短，提高用户的使用体验，使得集群 能提供更高质量的服务。
Hadoop集群性能的影响因素主要有四个方面：硬件设备、软件选择、Hadoop 参数配置和其他。
2.2.1硬件设备
在分布式集群出现之前，所有的数据均存放在单个服务器中，该服务器一般 为高性能服务器，以保证数据的完整存储和流畅计算。但是随着计算机技术、互 联网和移动互联网等技术的蓬勃发展，社交网络、电商交易、互联网金融、生物 健康等等这些各行各业的社会活动正在源源不断的产生大量的结构复杂的数据 资源。数据的爆炸性增长速度远远大于服务器等硬件设备的更新速度，即使最先 进的服务器也无法负荷如此巨大的数据存储，而且这些服务器的成本并不是一般 用户或者公司可以负担的。面对传统数据存储的瓶颈，分布式集群应运而生。
分布式集群系统允许各用户把普通的商用硬件系统组成机群，并且可以根据 具体需求随时在该机群中增加或缩减新的硬件，保证系统的伸缩性和可用性，以 此使用户能够在价格较为低廉的中低端平台上即可享用过去只有高端系统才能 具备的高可伸缩性和高可用性。不但提高了系统的使用性能，同时也大大降低了 成本,从而实现了以更多计算机达到更快速度的目标。分布式集群通过一定规则 连接若干普通服务器，实现传统单点高性能服务器的功能，极大地节省成本；并 且具备单点服务器所不具有的高扩展性、良好的并行性和可靠性。Hadoop集群 便是分布式集群中的翘楚，应用于各大行业，给广大普通用户提供便捷优质的服 务。
虽然分布式集群，如Hadoop集群，通过多个普通服务器实现传统的单个精 英服务器的功能，大大降低服务器的硬件要求。但是，这里的普通服务器即使再 普通，也仅是相对于传统的精英服务器而言的，这些普通服务器的硬件设备配置 仍然会影响Hadoop集群的工作性能。
首先，提高集群的所有服务器的配置是最直接的提高集群性能的方法。虽然 分布式集群提供多个普通服务器的组织方式，以降低每台服务器的配置要求，如 Google的数据中心，便是使用廉价的Linux PC机组成集群，亦能提供覆盖全球 的优质服务。但是无论哪种组织方式，服务器的配置肯定越高越好，如果能将多 个普通服务器升级，提高服务器配置，甚至升级成多个高性能服务器的组织方式， 在保留传统的高性能服务器优点的同时，又能提供分布式集群的新优势，二者完 美结合，服务质量必然更上一层楼。这种硬件设备的升级，其服务器的成本控制 和业务需求需要权衡再三。
其次，根据不同服务器的角色选择不同配置的服务器，以使其角色任务更好 地完成。NameNode节点存储了文件系统中所有的元数据，哪一个文件由那个数 据块组成，这些数据块分布在哪些DataNode中，有多少可用的数据块，这些数 据块在哪些主机上，如果没有NameNode, HDFS上的数据将变得完全不可用。 由于NameNode需要保证多台服务器，甚至成百上千台服务器的快速文件访问， 故所有这些信息都会驻留在内存中，保证访问速度。所以在NameNode中内存的 消耗量更大，对内存的要求更高。故选择NameNode节点服务器时需优先考虑良 好的内存配置。DataNode节点是Hadoop集群中主要的工作节点，它承担两种角 色：一是存储数据，二是执行Yam子任务。一般而言，对于存储数据的机器需 要进行数据备份来保证数据的安全性，如使用RAID,但是由于Hadoop在软件 上己经实现数据备份，即2丄1节中介绍的数据块备份数，故DataNode无需使用 RAID,可以节省更多服务器的硬盘资源。除了存储数据，DataNode还需执行Yam 子任务，由于各种任务类型并不一致，有CPU密集型、内存密集型等，此处的
服务器配置侧重点难以确定，且Hadoop有计算层面的冗余，一般无需特殊考虑， 但也要保证一定的处理性能。故DataNode在保证磁盘存储的良好性能之外，仍 需要平衡服务器的计算处理能力。
再者，其他硬件配置和部署策略也对集群的性能有着一定影响。Hadoop集 群的通信方式基于标准的TCP/IP协议，故网络是一个和CPU、磁盘、内存同等 重要的部件。HDFS和NameNode需要依赖网络通信，执行子任务NodeManager 和任务调度ResourceManager需要亦需要网络通信。故根据集群的规模，确定网 络带宽是一项重要任务。同时，集群的部署策略也同样重要。如相同角色的节点 选择相同型号的服务器，减少服务器配置不同可能带来的冲突和性能下降；集群 节点的拓扑结构，如DataNode尽量靠近，尽量部署在同一个机架上，若在不同 机架尽量接入同一个交换机等，均有利于提升数据存储和并行执行子任务的性能。
2.2.2软件选择
除了硬件设备之外，软件的选择同样会影响Hadoop集群的性能。
首先，Hadoop的版本选择。Hadoop有很多版本，作为一个开源项目，同时 很多公司也有自己的发行版。最普通的方式为选择Apache官方提供的版本(如 果根据业务需求发现其他公司提供的版本更能契合实际要求，亦可自行选择。)， Apache提供的Hadoop版本至目前分为Hadoop 1和Hadoop2,主要区别为 MapReduce (MRvl)和Yam (MRv2)框架。这两个框架的进程启动和概念都是 不一样的，而且Yam作为最新版本，业界普遍认为稳定性和成熟度不如 MapReduceo另外，当前最流行的非Apache的Hadoop发行版是Cloudera公司 的Hadoop版本，即CDH。当前CDH的版本为CDH5,具有Apache2.0和1.0的 特点，包括NameNode HA和Federation,同时支持MRvl和MRv2,这是当前 Apache版本不具备的。CDH的另一个特点是其集成了不同的Hadoop生态系统 项目，如HBase、Hive等，这些组件使得Hadoop使用起来更加友好，简化了组 件安装步骤，大大缩短了开发周期。还有其他的不同Hadoop版本，根据自己的 实际需求进行选择最适合的Hadoop版本，从而提升Hadoop集群的性能。
其次，操作系统和Java版本的选择。Hadoop内核和生态系统中的部分的组 件是Java写的，因为Java代码本身是跨平台的，所以理论上可以运行在各种操 作系统上。但Hadoop编写的时候，基本以Linux为设计目标系统，因此其中借 鉴大量的Linux架构思想和设计思路，使得Hadoop和其组件的很多代码如： start/stop脚本及权限模型都依赖于Linux的环境。故建议Hadoop集群运行在 Linux系统而不是Windows系统上，更容易操作和运用。Hadoop集群运行要求 Java的最低版本为Java6,使用更新版本的Java可以更好地利用其新特性，如
Java6ul4之后的版本，具有压缩普通对象指针的功能。
2.2.3 Hadoop参数配置
Hadoop参数对于一个集群的工作效率有及其重要的影响，良好的参数配置可 以提高集群作业的运行效率和集群的吞吐率。用户可以根据实际集群的硬件设备 和生产需求，自行设定这些参数，使得集群调整至最优状态。Hadoop有几个重 要的参数配置文件，分别简要如下。
core-site.xml, Hadoop的核心属性文件，用于定义系统级别的参数，其主要 参数如表2-1所示。
表2-1 core-site.xml基本参数表
参数名称	默认值	参数说明
fs.defaultname	file:/// （本地文件系 统）	设置Namenode的 hostname 及 port,默认 为本地文件系统，如果 使用集群模式则配置为 hdfs://hostname:900
hadoop.tmp.dir	Ztmp/hadoop- ${user.name}	Hadoop的临时目录，其 它目录会基于此路径
io.file.buflfer.size	4096 (bytes)	读写文件时使用的缓存 大小，这个大小应该是 内存Page的倍数
ipc.client.connection.maxi
dietime	10000（毫秒）	设定Hadoop client连接 時最大的闲置
fis.trash.interval	0	以分钟为单位的垃圾回 收时间，垃圾站中数据 超过此时间，会被删除
hdfs-site.xmL用于定义HDFS相关的参数，其主要参数如表2-2所示。


表2-2 hdfs-site.xml基本参数表
参数名称	默认值	参数说明
dfs.blocksize	67108864 (bytes)	每个数据块的大小
dfe.replication	3	数据块的副本数
dfs.heartbeat.interval	3 （秒）	DataNode的心跳间隔
dfs.namenode.handleECOunt	10	NameNode的服务线 程数，用于处理RPC 请求
dfs.datanode.handler,count	3	DataNode的服务线程 数，仅用于接收请 求，处理业务命令
dfe.datanode.max.xcievers	256	DataNode可同时处理 的最大文件数量
yarn-site.xml,用于定义Yam相关的参数，其主要参数如表2-3所示，其中


RM 为 ResourceManager, NM 为 NodeManager。
表2?3 yarn-site.xml基本参数表
参数名称	默认值	参数说明
y am.resourcemanager. schedu ler. class	org.apache.hadoop.y am.server.resourcem anager. scheduler, cap acity. Capacity Sched uler	作业调度器实现类，目 前可用的有FIFO、 Capacity Schedule 不口 Fair Scheduler o
yam.resourcemanager.resourc
e-tracker.client.thread-count	50	RM处理来自NM的
RPC请求的进程数目
yam.scheduler.minimum- allocation-mb/ yarn.scheduler.maximum- allocation-mb	1024/8192	单个container可申请的
最小/最大内存资源量
yam.scheduler.minimum- al location-vcores/ yam.scheduler.maximum- allocation-vcores	1/32	单个container可申请的 最小/最大虚拟CPU个数
yarn.nodemanager,resource.m emory-mb	8192	NM总的可用物理内存容 量
（续上表）
参数名称	默认值	参数说明
yam.nodemanager.resource.cpu-
vcores	8	NM总的可用虚拟CPU 个数
yam.nodemanager.log.retain-
seconds	10800 (秒)	NM上日志存放最长时间
除此之外，还有mapred-site.xml、https-site.xml等配置文件，分别用于配置 不同方面的参数，用户均可以灵活设置。

2.2.4其他影响因素
除了以上三类主要影响因素之外，还有其他的影响因素。比如对集群增加监 控功能，可以在发生异常或者大的事故之前，就找到潜在的危险，提前解决问题 或能更快速地定位问题原因。再比如，在Hadoop集群中运行计算作业程序时, 如果程序的内部算法不良，如循环嵌套层次过多、不及时释放内存等二即使服务 器性能再好，也会一定程度上影响集群的使用性能。	*
2.3 Hadoop集群性能状态研究现状
通过前两小节的内容，我们了解Hadoop的基本概念和框架，以及影响 Hadoop集群性能的各种因素。在Hadoop广泛被全球用户使用的同时，广大用户 对Hadoop集群的性能进行了各方面的研究，希望能够发现影响Hadoop集群性 能的关键因素，评估Hadoop集群的性能，一定程度上提高Hadoop集群的性能， 提高使用体验和效率。
2.3.1性能优化
Hadoop集群的性能优化在全球范围内被广泛研究，由2.2小节可知，影响 Hadoop集群性能的因素包括多方面，不能同一而论，故各研究者选取的优化角 度也各不一样。
通过参数调优提高集群性能，这是大多数研究者的优化方向。在2.2.3小节 介绍了 Hadoop集群的部分重要参数，但是Hadoop集群的参数远不止这些，初 略估计有200个以上，这些参数还有分类，分别作用于集群不同的方面。面对如 此多的参数，大多数研究者都是针对自身集群的实际需求来研究若干重要参数， 以提高集群的使用效率和性能。

微软公司针对Hadoopl的MapReduce作业推出Hadoop作业优化方案〔⑵。 该方案不仅详细分析每个参数的对MapReduce作业的影响效果，并且提供一套 用于优化MapReduce作业的研究方法，以供其他集群使用者能够根据自身集群 的实际情况来进行参数调优。首先，将MapReduce作业的瓶颈分为CPU计算、 内存、带宽和磁盘I/O四种，其研究方法为：1、通过作业日志或者在作业中自 行添加的资源标记，发现该作业的资源瓶颈；2、针对该资源瓶颈，调整相应参 数；3、测试同一作业的运行时间是否缩短，确定优化效果。其中针对部分常见 的瓶颈类型，己提供相应参数调整的解决方案，其余更多的瓶颈问题，用户可按 照其研究方法针对性地硏究测试，进行相应参数调优，从而实现优化MapReduce 作业的目标。与此类似，来自DH Technologies公司的Dominique Heger,针对 Hadoop的基准MapReduce作业	TeraSort排序作业，提出了一套实现Hadoop
集群性能的优化方案［⑶。通过迭代测试方法，确定各参数分别对TeraSort排序作 业产生哪方面影响，如何调整该参数以达到最优效果。虽然该方案仅针对TeraSort 排序作业，但是用户可以借鉴其分析方法，确定参数调优的方案，提高Hadoop 集群性能。
来自美国范德堡大学的Dili Wu和Aniruddha Gokhale提出一种基于Hadoop 作业性能分析的自动参数调优方案Ml。该方案提出一个分析架构PPABS (Profiling and Performance Analysis-based System ),该架构可以根据输入作业来 自动调整Hadoop参数，使得集群能处于运行该作业的最优状态。该框架分为两 个阶段：分析阶段和识别阶段。分析阶段，通过改进k-means++聚类算法和模拟 退火算法，生成各种作业类型的范例，针对每一种作业类型范例，确定该种作业 类型范例的最优参数。识别阶段，以少量数据为输入运行作业，通过该方法快速 确定该作业的逻辑流程，并通过分析阶段积累的作业类型，将该作业分至某作业 类型中，然后再针对该作业类型自动调整Hadoop参数。通过该方案，可对多种 作业进行参数调优，不会像上一段中的调优方式仅适用于某一类作业，增大了适 用范围，提升了用户使用体验。
除此之外，还有很多研究者从不同角度研究Hadoop参数对集群性能的影响， 只是多数研究者的研究范围相对都较小，针对性比较强。Hadoop的参数数量较 多，而且针对不同应用场景，某些参数还需要配合使用，各参数之间的相互关系 也不尽而知，需要更多的研究者进行研究和分享，故参数调优的道路任重而道远。
除了参数调优之外，仍有其他的方式来优化集群，如可以提升硬件设备、调 整集群拓扑结构、对Hadoop版本进行优化等，这些方面的优化相对而言较为固 定且缓慢，并不在大多数人的研究范围之内。

2.3.2性能评估
相对于性能优化，性能评估的研究相对较少，主要是因为影响Hadoop集群 性能的因素较多，集群的应用场景各不相同，无法制定一个相对统一的评估标准。 研究者多以某个或若干个指标为考核标准对集群性能进行评估。
参考文献SI中，作者利用Hadoop集群的MapReduce编程实现大数据倒排 索引，以索引构建耗时为评估标准，以不同的网络带宽、数据量规模和集群节点 数作为实验条件，对Hadoop集群性能进行评估。实验结果表明，网络通信的带 宽对Hadoop集群的性能状态有一定影响，高速集群链路更有利于发挥集群的大 数据处理性能；Hadoop集群具有良好的大数据处理能力，并且数据量越大，集 群节点数目越多，大数据处理的能力越能得到充分体现。
Intel公司提出一个名叫“HiBench”的基准测试套件“句用于评估Hadoop集 群状态。“HiBench”是一个切实全面的Hadoop基准测试套件，其中包含10种 Hadoop作业程序，既包含微基准作业程序，如Hadoop提供的示例程序WordCount、 TeraSort作业程序等，也包含现实应用程序，如网页搜索、机器学习作业程序等。 这些基准测试程序经过扩展、配置和定制，可测试得到不同作业类型时集群的各 方面的性能状态，通过某些指标，如作业运行时间、作业吞吐量、HDFS带宽、 系统资源利用率、数据接入模式等，对Hadoop集群进行评估。该基准测试套件 可以在任意Hadoop集群中运行，从各作业运行的情况，结合釆集得到前述的指 标，可以综合判断该集群的性能状况，哪些方面需要提升，对于哪种类型的作业 运行性能较佳等。
2.4本章小结
本章主要介绍了本次论文所需的背景知识。首先介绍Hadoop的基本概念和 框架，此处介绍的为Hadoop2,其主要组件为HDFS和Yam,分别负责Hadoop 集群的数据存储和计算。接着介绍影响Hadoop集群性能的各种因素，主要包括 硬件设备、软件选择、参数设置和其他因素，从而得知影响Hadoop集群性能的 因素多种多样，需要从不同角度考虑。最后介绍Hadoop集群性能研究的现状， 主要分为性能优化和性能评估，其中性能优化主要针对繁多的Hadoop参数进行 参数调优，性能评估的研究并不是很多，了解Intel公司提出的一组基准测试套 件。

第三章性能分析评估方案设计
通过第二章可知，Hadoop集群性能的影响因素众多，对于Hadoop集群性能 的研究集中在性能优化和性能评估两个方面。借鉴全球各研究者的研究方向，参 考其研究成果，现针对基于Hadoop的网络大规模流量分析系统设计一套性能分 析评估方案。
3.1功能需求
首先，简要介绍基于Hadoop的网络大规模流量分析系统。该分析系统部署 在Hadoop集群之上，依赖Hadoop集群的HDFS和Yam组件。该分析系统将合 作单位釆集得到的海量网络流量数据存放至HDFS,进而通过Yam框架运行计 算分析程序，对网络流量数据进行离线分析，如基础统计、数据挖掘等，得到相 应网络流量数据的研究分析结果。
分析系统框架如图3-1所示，釆取经典的Hadoop集群部署方案：1个主节 点、1个备份节点兼客户机和9个子节点。除了 HDFS (NameNode、DataNode) 和 Yam (ResourceManager、NodeManager, Application)相关的进程之外，还运 行其他与数据分析相关的组件进程，如数据存储相关的HBase (HMater. HRegionServer)相关进程。其中一台备份节点作为用户进入服务器，所有用户均 通过该服务器连接分析系统，并提交运行各自的应用程序。
Name Node
Resource Manager
HMaster
Job History Server





图3-1分析系统集群框架图
3.1.1需求定义
结合现有Hadoop集群性能的研究成果，并根据分析系统的实际状况，对该 分析系统的性能分析评估方案需求总结如下。
方案设计需与分析系统的实际应用场景相贴合。该分析系统的主要工作 是对海量网络流量数据进行离线分析，其分析方向主要为基础统计、趋势分析、 数据挖掘等基本的数据分析应用，且均以离线的方式进行，暂不涉及网页搜索等 在线作业应用程序。故设计方案时，一定要紧密结合该分析系统的实际应用场景, 如果方案的研究方向发生偏差，以此得到的分析评估结果并不能充分体现该分析 系统的性能状况，甚至产生误导指示，在性能分析和优化时会导致不良效果，使 得分析系统的性能难以得到切实的优化提高，甚至不升反降，使集群陷入一个更 糟糕的状态中。
方案需要有较好的普适性。在要求贴合该分析系统的实际应用场景的同 时，需要顾及方案的普适性，能够应用于更多的基于Hadoop集群的其他系统中。 尽管该方案是针对网络大规模流量分析系统而设计的，但是并不意味畫该方案仅 能适用于该系统，而无法应用于其他类似系统。在设计的过程中需要余虑到该方 案的通用性，评估方法不要局限于当前分析系统，从具体的评估分析步骤中可以 抽象出一套普适性强的方案，确保其他类似系统也能借鉴该方案对不同的系统进 行分析评估。
方案需较好地定位分析系统性能的瓶颈，利于系统的性能优化。该方案 除了通过一定的方法标准评估系统的性能，得到评估结果之外，还需要提供系统 性能瓶颈的相关信息。不一定需要提供切实详细的系统优化方案，但至少需要提 供系统优化的方向，有助于更加快速准确地定位系统的性能瓶颈，使得系统优化 工作的目的性更强、效率更高。
3.1.2需求与设计分析
分析系统的主要功能是离线分析，且其应用程序主要集中在基础的数据 分析方面。故可借鉴英特尔公司的“HiBench”基准测试套件的评估方式，以切 合分析系统应用场景——基础数据分析的示例应用程序的运行结果来对分析系 统进行状态分析评估。而且该示例应用程序需要具有普适性，在其他类似的系统 中亦能运行使用。
需要对分析系统的优化工作提出指导性优化方向。由第二章内容可知， 影响集群性能的因素种类颇多，当前大多数研究方向为参数调优，而Hadoop参 数的个数繁多，各参数之间的相关性并不明确，且对应不同的集群，由于其硬件配置、软件选择、拓扑关系等不同，很难统一确定参数调优的方案。需要用户根 据自身的集群特性，参考己有的参数调优研究成果，进行后续调优测试，才能确 定各参数如何调整才能使集群处于最优状态。故在此不对系统的优化工作提出切 实的优化方案，仅在对系统进行分析评估的同时，发现系统的可优化方向，为优 化工作提供一定指导性建议。
方案的各个具体步骤可以抽象总结成一套普适性的研究方法。借鉴微软 公司的“Hadoop作业优化方案”，该方案除了具体地分析各参数对MapReduce作 业的影响效果之外，还对其分析步骤进行抽象总结，输出一套用于优化 MapReduce作业的研究方法，以供其他用户在不同的集群中根据其实际情况进行 参数调优。故在设计方案时，各步骤需要具体化、适应化，可根据分析系统的实 际特征进行分析评估工作；但是不能局限化、限制化，导致分析评估工作无法在 其他类似的集群或者系统中应用。
充分利用分析系统的已有管理经验。该分析系统己经投入使用一段时间， 期间已经出现各种问题或者异常，在解决这些问题和异常的同时，发现对于该系 统性能状况的影响因素，逐渐积累丰富的系统管理经验。需要充分利用己有的管 理经验，对方案设计提供一定的指导建议。
3.2方案设计
通过本章前述的性能评估方案的功能需求定义和分析，借鉴第二章中各研究 者对Hadoop集群性能的研究，并结合己有积累的分析系统管理经验，设计基于 Hadoop的网络大规模流量分析系统的性能分析评估方案如下。为了提高方案的 普适性，此处陈述方案的抽象步骤，具体详细的实现方法由后续章节介绍，这些 抽象步骤可适用于不同的集群或者系统，其中各抽象步骤的具体实现方法需要根
据实际情况确定。


基于Flume的性能数据采集 系统，采集共8类、42项性 能数据	/
图3-2评估方案整体架构图
评估方案的整体架构如图3-2所示，总共分为4大部分，现将一一介绍各个 部分的主要内容。
确定分析系统（集群）性能状态的评估标准
根据分析系统（集群）的实际应用场景确定其性能状态的判断评估标准。由 于分析系统的主要功能是对数据进行基础统计分析，故选取Hadoop自带的三个 基准应用程序：Pi、WordCount和TeraSort的运行时间作为其性能状态的判断评 估标准。
采集积累分析系统（集群）的相关性能数据
结合分析系统（集群）的管理经验和各研充者对于集群性能相关的研究成果，确 定对于分析系统（集群）重要的性能数据。该过程需要对相应系统（集群）进行 长期的积累研究，需要多次迭代分析才能更准确地确定重要的性能数据。对于该 分析系统，暂时选取42个性能数据，主要包括服务器性能数据和Hadoop性能 数据。
关联性能数据和评估标准，对二者进行建模分析
采集积累一定数量的分析系统（集群）的性能数据之后，选取合适的建模方 法，分析确定影响分析系统（集群）的重要影响数据，作为性能优化的方向指导； 并以历史数据确定性能数据和评估标准的相关性，建立预测模型，最终可以通过 该模型预测评估标准，即标准应用程序的运行时间，作为性能评估的标准。此处 通过线性和分线性两种分析方式来分别对性能数据和评估标准进行建模分析，对 比不同分析方法的优劣性。	-
根据分析结果进行性能优化和评估
在第三步中，通过建模分析得到的分析系统（集群）的重要影响薮据，作为 性能优化的指导方向，借鉴己有的各研究者的研究成果，针对相应的性能数据进 行优化，可以通过升级硬件、参数调优等多种方式实现。根据历史数据建立的预 测模型的预测结果，作为性能评估的标准，对分析系统（集群）进行性能评估， 该评估结果可以作为分析系统（集群）普通使用者的使用参考，便于使用者选择 分析系统（集群）的最佳使用时间，提升使用体验，提高分析系统（集群）的工 作效率。
3.3方案实践环境
3.3.1搭建实践集群
为了避免干扰实际分析系统的正常稳定工作，我们将会在一个模拟分析系统 的Hadoop集群中完成方案的测试实践工作，验证该方案的正确性和可行性后再进行方案的实际应用。
本次实践搭建的Hadoop集群，选用Hadoop 2.5.0版本，总共有4个节点， 其中1个主节点、3个子节点。主节点上运行NameNode进程、ResourceManager 进程，子节点上均运行DataNode进程、NodeManager进程、ApplicationMaster进 程。所有节点通过100Mbps网卡连接在同一个交换机上。4个节点的硬件配置均 相同，单节点的配置信息如表3-1所示，实践集群架构如图3-3所示。
表3-1服务器配置信息
服务器型号	Lenovo 启天 M4360
处理器型号	Pentium(R) Dual-Core CPU E5800 @3.20GHz
内核数	1
单个内核超线程数	2
内存容量	4G
硬盘	500G
网络带宽	100Mbps
操作系统	CentOS 6.5 x64

Name Node
Resource Manager
Job History Server
图3-3实践集群架构图
3.3.2标准运行时间
确定选取Pi、WordCount和TeraSort三个标准应用程序，需要给这三个标准
应用程序分别确定一个标准运行时间。标准运行时间是在无任何操作的集群性能最优情况下，标准应用程序的运行时间，则该时间表明集群性能的最优值。通过 不同条件下的三个标准应用程序的运行时间分别与这三个标准运行时间相比较， 进而对分析系统的性能状态进行评估。
根据实验，对于本次实践环境，在运行时间为1小时的范围内，三个标准应 用程序的运行时间与输入均成正比关系，在此选取三个标准应用程序运行时间均 为20余分钟，三个标准应用程序对应的标准运行时间如表3-2所示。
表3-2标准应用程序的标准运行时间表
标准应用程序	标准运行时间（ms）	输入
Pi	1239437	150
WordCount	1227643	10GB
TeraSort	1246384	10GB

3.4本章小结
本章主要介绍了基于Hadoop的网络大规模流量分析系统的性能分析评估方 案的设计思路。首先对方案的需求进行分析，其需求主要分为三点：贿合实际应 用场景、具有良好的普适性、提供性能优化指导方向。接着，根据这些需求定义， 借鉴全球各研究者已有的研究成果，并结合分析系统的管理经验，确定一套分析 系统的性能分析评估方案。该方案可抽象成四个部分：确定切实的评估标准、釆 集自定义性能数据、建模分析提供信息、性能优化和评估。这四个部分可根据不 同系统（集群）的实际情况，确定具体的内容，完成分析评估工作。最后介绍方 案的实践环境，搭建一个模拟分析系统的Hadoop集群，完成测试实践工作。

第四章评估标准与性能数据
通过第三章的分析，确定一套基于Hadoop的网络大规模流量分析系统的性 能分析评估方案。本章将详细介绍该方案中评估标准与性能数据两部分内容。
4.1分析系统性能状态的评估标准
分析系统性能状态的评估标准需要贴合分析系统的实际应用场景，由3.1节 可知分析系统主要用于运行基础的数据分析应用程序。本论文选择的评估标准为 Hadoop自带的三个示例应用程序，Pi、WordCount和TeraSort的标准运行时间。
借鉴英特尔公司的“HiBench”基准测试套件的评估方法，选取多个标准的 应用程序作为评估标准，则其最优选择为Hadoop自带的示例应用程序作为评估 标准。因为Hadoop自带的示例应用程序具有良好的普适性，无论在哪个集群哪 个系统中都能正常的运行。而且这些示例应用程序由Hadoop开发人员编写，必 定是对Hadoop的工作原理充分了解的基础上开发编写的，其程序质量比自行编 写的测试程序更有保证，更能测试体现Hadoop集群（分析系统）的性能。Hadoop 自带的示例应用程序有多个，与分析系统的基础数据分析相关的应用程序最典型 的就是WordCount和TeraSort,这两个程序也被包含在“HiBench”基准测试套 件中。
根据广大研究者对于Hadoop应用程序的研究，Hadoop应用程序大体上分 为四类：CPU密集型、磁盘I/O密集型、内存I/O密集型和网络密集型网。根据 Hadoop的工作机制，当应用程序锁占用的内存过大时，会造成内存溢出现象， Hadoop会自动停止应用程序的正常运行，故运行应用程序时，本质上是不存在 内存瓶颈的，故暂不考虑内存I/O密集型应用程序。此外，鉴于本次后续测试实 践集群环境相对简单，工作节点不多，且连接在同一个交换机上，网络资源对于 应用程序来说亦不存在瓶颈问题，而且占用大量网络带宽的应用程序本身就不是 一个良好质量的Hadoop应用程序，故暂不考虑网络密集型作业。对于内存和网 络的分析将会在后续性能数据采集的时候考虑进去。
Pi应用程序是典型的CPU密集型应用程序，TeraSort应用程序是典型的磁 盘I/O密集型应用程序，WordCount应用程序则兼有CPU密集型和磁盘I/O密集 型两类特点，这三个应用程序分别体现了三种Hadoop应用程序类型。此外， WordCount和TeraSort应用程序自身带有数据统计分析的应用功能，贴近分析系 统的实际应用场景，可以更好地体现分析系统的性能状态。
故选取这三个应用程序作为分析系统的评估应用程序，后文将称这三个应用程序为标准应用程序。标准应用程序的运行效率，即分析系统的性能状态，体现 在该应用程序的运行时间上，运行时间越短，表明分析系统性能状态越好，运行 时间越长，表明分析系统性能状态越差。
综上所述，确定Pi、WordCount和TeraSort标准应用程序的运行时间即为分 析系统性能状态的评估标准。
4.2采集积累分析系统的相关性能数据
结合分析系统的管理经验和各研究者对于集群性能状态相关的研究成果，确 定对于分析系统重要的性能数据，在分析系统正常运行标准应用程序的过程中， 对这些性能数据进行釆集，以供后续建模分析这些性能数据和标准应用程序运行 时间之间的关系。
本论文选取了 8类共42项性能数据，通过基于Flume的性能数据釆集系统 进行釆集。
4.2.1性能数据指标
针对分析系统的实际应用场景，借鉴各研究者对于Hadoop集群性能的研究, 结合分析系统己有的管理经验，确定选取8类共42项性能数据为研究对象，分 析研究这些指标与标准应用程序的运行时间时间的关系。性能数据详情如表4-1 所示。
表4-1采集性能数据指标汇总表


（续上表）
打开文件 数	　　　打开文件数最大值	服务器负载
（自定义）	　　服务器负载最大值
打开文件数最小值		　　服务器负载最小值
打开文件数平均值		　　服务器负载平均值
打开文件数标准差		　　服务器负载标准差
Hadoop性能数据
HDFS	　　HDFS上传速率最大值	标准应用程 序	标准应用程序运行时
间
HDFS上传速率最小值
HDFS上传速率平均值
HDFS上传速率标准差
HDFS下载速率最大值
HDFS下载速率最小值
HDFS下载速率平均值
HDFS下载速率标准差
HDFS使用率
由上表可知，性能数据总共分为两大部分：服务器性能数据和Hadoop性能 数据。其中服务器性能数据分6类，Hadoop性能数据分2类。总共8类性能数 据，从类别来看，均为基础的性能数据，是大部分研究者的热门研究内容。但是 继续细分每种类别的性能数据时，却与大多数研究者有所不同，以下将对本方案 的细分性能数据进行解释说明。
在本方案的研究过程中，运行标准应用程序时，会覆盖所有的子节点。 ResourceManager会把应用程序的子任务分发到每一个子节点，保证每一个子节 点均处于工作状态，充分利用分析系统的所有可调度资源，这样更能体现整个分 析系统的性能状态。
绝大多数研究者在研究Hadoop集群性能状态的时候，对于CPU、内存等服 务器性能数据的处理均釆用的是平均值，体现的是所有工作子节点的平均性能状 态。在基础的数学统计学中可知，平均值只能反应样本的一个平均情况，这种考 量维度相对单一，需要更多的统计数据，如最值、方差等，才能更加全面、更加 准确地体现样本的数据特性。同理，采用平均值来考量集群的性能状态这种方式 相对而言较为笼统，仅能从单一维度进行分析。故本方案在研究整体性的同时, 考虑到差异性研究，在研究性能数据平均值的基础上，增加了另外三个维度：最 大值、最小值、标准差。
服务器性能数据的最后一项——服务器负载指标是自定义的一项性能数据， 用于描述一台服务器负载超过集群服务器平均负载的程度，而非通用意义上的服务器负载。前五类服务器性能数据，CPU、内存、硬盘、网络、打开文件数，均 可认为性能数据值和服务器负载存在单调递增关系，即性能数据值越大，一定程 度上表明服务器工作负载越大。对于每一台服务器的每一类服务器性能数据，通 过公式（1）、公式（2）计算其自定义负载。

Load, = ￡虬
77 = 1
对于前五类服务器性能数据，由公式（4-1）,由性能数据值月和该性能数据 平均值Pavs，计算该性能数据的负载值4；由公式（4-2）,将五类性能数据的负 载值叠加，得到该服务器的自定义负载值Load.
4.2.2 Flume简介

由图4-1可知，Flume的一个基本事件由Source、Channel和Source三部分 组成。
Source：负责一个外部数据源，用于接收外部传进的各种类型的数据，可以 根据不同的数据类型来制定不同的接收模式，如直接从文件中提取或者监听端口 获取数据。本系统Source的数据源为从釆集脚本获取的性能数据，或者下一级 Sink传输的数据；
Channel：当Source获取到数据之后，会将数据按顺序存放至Channel中， Channel釆用的是被动存储方式，数据会一直存放在Channel中，直到被Sink取 走；
Sink：将数据从Channel中拉取出来，存放至外部数据仓库，数据存放的数据仓库有多种类型，如将数据放至HDFS中。本系统Sink的数据会存放至数据 库中，或者传给上一级Source中。
4.2.3基于Flume的性能数据采集系统



图4-2采集系统架构
采集系统选用的版本为Apache Flume-1.5.0版本，所选用的Source、Channel、 Sink类型介绍如下。
Source 类型：Exec Source > Avro Source o
Exec Source为命令执行源，通过执行命令调用脚本，并持续获取该命令（即 执行脚本）返回的标准输出数据，脚本的输出数据即为釆集的性能数据，脚本执 行间隔由各指标的釆集粒度决定；Avro Source通过监听Avro端口，接收上一级 的Avro Sink的输出，本级Avro Source需和上一级Avro Sink匹配。
Channel 类型：JBDC Channel.
相对于其他Channel, JDBC Channel可以支持最高程度的数据流的还原恢复, 有利于增强数据釆集的安全性。
Sink 类型：Avro Sink. JDBC Sink.
Avro Sink用于输出本级数据到下一级的Avro Source；由于默认的Sink类型并不支持将数据存入数据库，故自行定义JDBC Sink用于数据库的存储。
现对该采集系统进行详细介绍：
每个子节点的部署情况均相同，子节点中部署若干釆集脚本，这些釆集 脚本均用Python语言编写，用于釆集一项或者多项性能数据，执行脚本命令的 输出即为所釆集性能数据，其输出内容均为：时间戳、IP地址、具体的性能数据。
子节点的Flume Agent由多个Source-Channel-Sink基本事件组成，每个 基本事件的类型均相同，即为：Exec Source> JDBC Channel和Avro Sink。其中 Exec Source获取执行脚本命令的输出，即釆集得到的性能数据，并将性能数据 存放至JDBC Channel中；JDBC Channel具有数据恢复能力，可以保证釆集性能 数据的完整性和安全性；Avro Sink从JDBC Channel中获取性能数据，将数据传 输至主节点对应的Avro Sourceo每一个基本事件对应一个釆集脚本，获取其釆 集的性能数据。
不同子节点的相同性能数据，将会通过各自的AvroSink传输至主节点的 同一个Avro Source中，从而实现相同性能数据的汇聚工作。
主节点的Flume Agent同样由多个Source-Channel-Sink基本事件组成， 每个基本事件的类型均相同：Avro Source. JDBC Channel和JDBC Sinko其中 Avro Source分别接收汇聚所有子节点的同类性能数据，并存放至JDBC Channel； JDBC Channel同子节点，用于保证数据的完整性和安全性；JDBC Sink从JDBC Channel中获取获取性能数据，将各项性能数据均存放至数据库中相应的库表中， 每一类性能数据对应一张数据库表。
总体结构：主节点按照类型汇聚所有子节点的各类性能数据，然后将不 同类型的性能数据分别存放至对应的数据库表中，完成性能数据的采集工作。
4.2.4性能数据采集积累
部署基于Flume的性能数据釆集系统，并确定需要釆集的性能数据指标之 后，正式开始性能数据的采集积累工作。
所有性能数据的釆集粒度均为5秒。在整个性能数据釆集过程中，三个标准 应用程序会一直定时运行。期间，我们会人为执行某些操作，改变各子节点的性 能状态。如从某子节点上传大量数据至HDFS,增加HDFS的工作负载；在某子 节点运行非Hadoop应用程序的程序，占用一定CPU、内存等资源；在两个子节 点之间互相传输文件，占用一定网络资源等。通过这些操作，改变各子节点性能 状态，模拟分析系统正常运行时的工作状态。在此需要注意的是，在标准应用程 序开始之前所进行的操作，在标准应用程序开始至结束之前都不能改变，要保证 标准应用程序在整个运行期间，该操作始终保持其所占用的性能资源。因为后续对标准应用程序运行时间的预测，仅能根据应用程序运行之前的分析系统性能状 态为判断依据，如果在标准应用程序运行期间，停止某操作或者开始某操作，这 些改变引起的性能状态改变属于不可预知因素，对最终标准应用程序运行时间的 预测会产生不确定影响，进而影响最终评估结果的准确性。
由于本次测试实践环境所有节点的硬件配置均相同，且主节点相对于子节点 而言，其计算工作较为轻松，故主节点的性能瓶颈并不会有子节点那么突出。另 外，所有的应用程序的具体执行均在子节点进行，主节点仅负责调度工作，机器 负载压力并不大。故主节点的性能状况相对而言并没有子节点那么重要。此外， 本次选取的性能指标除了单纯的性能数据之外，还会有对性能数据的统计指标数 据，这只能针对相同工作负载的子节点而言，无法包括主节点在内。故本次测试 重点考察子节点的性能状况与标准应用程序的关系，暂不考虑主节点的性能状况, 则主节点的性能数据并没有进行采集。如果对主节点的性能研究产生需求，后续 可添加相应采集性能数据，完成进一步研究。
本次实践总共运行三个标准应用程序各25次，釆集积累2万余条历史性能 数据。完成性能数据的采集积累工作之后，需要对性能数据和标准应用程序的运 行时间进行建模分析。
4.3本章小节
本章主要介绍了分析评估方案的评估标准的选取和性能数据的釆集两部分 内容。首先，根据分析系统的实际应用场景，借鉴已有的Hadoop集群研究经验， 确定选取Pi、WordCount和TeraSort三个标准应用程序的运行时间作为分析系统 性能状态的评估标准。然后，根据已经积累的分析系统管理经验，确定本次实践 的釆集性能数据共计42项，并介绍基于Flume实现的性能数据采集系统的整体 架构和工作原理。

第五章数据建模分析
本文选取基于多元线性回归的线性建模和基于BP神经网络的非线性建模两 种建模分析方式，分别对性能数据和评估标准进行建模分析，对比两种建模分析 方式获得结果的差异，比较两种建模分析方法各自的优缺点。
5.1多元线性回归模型
在统计学中，线性回归是利用称为线性回归方程的最小二乘函数对一个或多 个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称 为回归系数的模型参数的线性组合。当仅有一个自变量时，该线性回归称为简单 回归，当自变量大于一个时，该线性回归成为多元回归〔I%。在线性回归分析中， 数据使用线性预测函数来进行建模，并且未知的模型参数也是通过数据来进行估 计的。线性回归是回归分析中第一种经过严格研究并且在实际应用中广泛使用的 类型，是广大研究者进行回归分析的首要选择。而且在实际分析场景中，自变量 通常多于一个，所以多元线性回归分析的使用场景远远多于简单回归分析。
5.1.1多元线性回归模型的一般形式
设y为因变量，X], x2, x3,…，Xn为自变量，并且自变量与因变量之间为线 性关系时，则多元线性回归模型为:y = b0 + m + b2x2 + b3x3 +…+ bnxn + e。 其中，bo为常数项，知Z>2,	bn为回归系数，S为X2，x3,…，X"固定时，X]
每增加一个单位对y的效应，即迫对y的偏回归系数，缶，…，如同理；e是去除n 个自变量对y影响后的随机误差（残差）[20]o
设得到n组观测数据（⑶如，…小，匕），z = l,2,则多元线性回归模型 可以表示为：
尹1 = 4 + 肱 + b2x12 + …+ bpX、p + e】
儿=4 + 4与1 + b2X22 + …+ bpX?p +
，	...	式（5-1）
yn = 4 + 牝 + m + …+ bpXnp + en
矩阵形式为：y = Xb + e o
其中：

5.1.2回归参数的最小二乘估计
多元线性回归模型的参数估计，是在要求误差平方和为最小的前提下，用最 小二乘法求解参数。以下简要介绍最小二乘法求解参数的计算过程。
由y = Xb + e,得e = y-Xb，即用Xb表示尸的误差向量。；为了使
y = b0 +	+ b2x2 + b3x3 + ??? 4- bnxn + e拟合效果更好，需使得误差e的平
方和最小，则有：
求偏导数有:
些=匙二迎?2(y — Xb)
=2XT(y - Xb)
=2(XTy - XTXb)
令2(XTy _xTXb) = 0 ,艮卩XTy —XTXb=。，则可解得常数项如和偏回归系 数b\,膈b$…如，即:
式(5-4)
至此，整个多元线性回归方程求解完成。
5.1.3模型检验
多元线性回归模型在得到参数的最小二乘法的估计值之后，需要进一步进行 若干检验与评价，从而决定该模型是否可以应用。
拟合程度的测定
多元线性回归中的多重可决系数R2,它代表在因变量的总变化中，由回归方 程所解释的变化，即回归平方和所占的比重，若中越大，则表明回归方程对样本 的各数据点拟合程度越强，所有的自变量与因变量关系越密切。
估计标准误差
估计标准误差，即为因变量y的实际值和回归方程求得的估计值少之间的 标准误差，若估计标准误差越小，则表明回归方程的拟合程度越强。
回归方程的显著性检验
回归方程的显著性检验，即检验整个回归方程的显著性，亦可认为评价所有 的自变量与因变量之间的线性关系是否密切，通常采用F检验。
回归系数的显著性检验
在一元线性回归中，回归系数显著性检验（t检验），与回归方程的显著性检 验（F检验），是等价的，但是在多元线性回归中，这个等价不成立。t检验用于 分别检验回归模型中的各个回归系数是否具有显著性，从而使模型中仅保留那些 对因变量有着显著影响的因素。
多重共线性判断
多重共线性即为在多元线性回归方程中，自变量之间存在较强的线性关系， 如果这种关系超过因变量与自变量的线性关系，则回归模型的稳定性会受到破坏, 导致回归系数估计不准确。其实多元回归模型中，多重共线性的现象是难以避免 的，仅需多重共线性不太严重即可。
DW检验
如果多元线性回归模型根据动态数据建立，则其误差项e是一个时间序列， 如果误差序列各项之间相互独立，则误差序列各项之间不相关；若误差序列之间 存在密切的相关关系，则建立的回归模型就不能用于表述自变量和因变量之间的 真实变动关系。D.W检验就是误差序列的自相关检验。
5.1.4多元线性回归模型的应用
基于以上知识，我们可以将多元线性回归模型应用于本论文所提方案中。
首先，基于多元线性回归的基础知识，以多项过滤后的性能数据（具体的过 滤方法后续介绍）作为自变量，这些性能数据对应时间段里标准应用程序的运行 时间作为因变量，以最小二乘法作为参数估计方法，通过历史数据进行训练，对 性能数据和标准应用程序运行时间进行线性建模分析，从而得到一个多元线性回 归模型。然后，验证该模型的预测误差，在验证该模型误差在允许范围内之后， 对于新增的一组性能数据，可以代入该多元线性回归模型，从而预测相应的标准 应用程序的运行时间，通过比较预测的标准应用程序的运行时间与其标准运行时 间，对分析系统的性能状态进行评估。此外，通过多元线性回归模型可以分析得 知哪些性能数据对标准应用程序运行时间有影响，哪些性能数据则无影响，并且 能评估出有影响的各个性能数据的影响程度大小。以此为基础，可以对分析系统的性能优化提供指导性建议，从而针对性优化之后提升分析系统的性能。
多元线性回归模型的具体建模分析过程将会在5.4节中详细介绍。
5.2 BP神经网络模型
反向传播神经网络(Back Propagation Neural Network)，简称BP神经网络, 是一种监督学习算法，常被用来训练多层感知机。这是一种按误差逆传播算法训 练的多层前馈网络，是目前应用最广泛的神经网络模型之一。BP神经网络可以 学习和存贮大量“输入-输出”的模式映射关系，而不需要提前揭示描述这种映射 关系的数学方程Pi〕。
5.2.1 BP神经网络结构
BP神经网络是一种基于误差方向传播的多层前馈网络,其釆用Widrow-Hoff 学习算法和非线性可微转移函数。BP神经网络具有三层或三层以上的结构，分 别是输入层(inputlayer),一层或多层隐含层(hiddenlayer),输出层(outputlayer), 各层之间的神经元为全连接，层内各神经元无连接。一个典型的三层BP神经网 络的拓扑结构如图5-1所示。
图5-1中，输入向量为X =(X1，X2，"?,X“)T,输出向量为丫 = 31，为,“?,乂?)， 输入层节点数为们隐含层节点数为/,输出层节点数为仇；输入层与隐含层的 连接权值为％ ,隐含层与输出层的连接权值为？波，其中/ =	,顶=1,…J ,
上=1,…，m
5.2.2 BP算法
BP神经网络是基于BP算法实现的，该算法的基本思想：学习过程由信号 的正向传播与误差的反向传播1匆两个过程组成。现详细介绍该算法的训练过程:
步骤1：神经网络初始化。根据系统输入、输出向量(XY)来确定网络输入 层节点数n隐含层节点数/,输出层节点数m；初始化输入层与隐含层的连接 权值钓、隐含层到输出层的连接权值②心、隐含层神经元阈值印、输出层神经元 阈值与、误差允许范围￡,均为很小的随机非零值；确定学习速率"、隐含层激 励函数/(.)、输出层激励函数g(.)。
正向传播过程：
步骤2：计算隐含层第丿个神经元输出
Hj = /■(￡ a)ijxi +ay), j = 1,2,…，丿
s	式(5-5)
步骤3：计算输出层第A个神经元输出入。
1
儿=gQXc + 为)，A = 1，2，?“，0	、/…、
y=i	式(5-6)
由于g(?)一般选用线性函数，则式(5-6)可简化为：
1
A = Z Hj(0jk + bk > k = 12 …
妇	式(5-7)
步骤4：定义误差函数。若孔为实际系统的输出，必为网络训练输出，贝!I： 以=% - 人，k = 1,2,式(5-8)
则误差准则函数定义为：
1 a	iff
功=5 ￡(4 - yj = E ￡ e* , k = 1,2, , m
f	式(5-9)
步骤5：判别误差。若
0 - ￡	式(5-10)
则学习结束，否则进入以下的反向传播过程。
误差反向传播过程：
步骤6：输出层权值、阈值变化量的计算。误差反向传播算法的原理就是 沿着误差准则函数负梯度的方向修正权值、阈值参数。
M =-卩禦=
8bk	式(5-11)
31
△% = 一“貝丄=仰邑	式（5-12）
& =（4 -久）我）=勺	式（5_i3）
其中，g'（，）为输出层激励函数的导数，由于g?）为线性函数，则g'（，） 二 l。 步骤7：隐含层权值、阈值变化量的计算。
■ = _卩尧=-舟dk - yk） ■
耕
="'（?）%?￡（4 - yg
k=\
△a丿=笋=_ ygk
。。丿	k=l
其中，r（.）为隐含层激励函数的导数。 步骤8：权值、阈值修正。将修正后的权、阈值保存起来， 迭代时的值。输出层权、阈值参数修正：
% =纵 +
4 = 4 + A4 隐含层权、阈值参数修正：
/ -①寸+ A的
a. - a- + 啊
5.2.3 BP神经网络设计原则
进行BP神经网络设计的时候，需要主要考虑以下5种设计原则。
网络层数
理论己经证明，具有偏差和至少一个S型隐层加上一个线性输岀层的网络, 能够逼近任何有理函数，增加层数能够进一步降低误差、提高精度，但与此同时 会导致网络复杂化。不能用仅具有非线性激活函数的单层网络来解决问题，因为 能用单层网络解决的问题，用自适应线性网络也必定能够解决，然而对于只能用 非线性函数来解决的问题，单层精度又不够高，只能通过增加层数才可以达到期 望的结果。
隐含层神经元的个数
提高网络训练精度，可通过使用一个隐含层，并增加其神经元个数，在结构 实现上，这比增加网络层数的方法简单。一般而言，我们用精度和训练网络的时 间来恒量一个神经网络设计的好坏。当神经元个数太少时，网络并不能很好地学习，导致训练迭代的次数比较多，训练精度不高；当神经元数太多时，网络的功 能越强大，精确度更高，训练迭代的次数也大，可能会出现过拟合现象。隐含层 神经元个数的选取原则为：在能解决问题的前提下，加上一两个神经元，从而加 快误差下降速度。
初始权值的选取
一般初始权值是取值在(-1,1)之间的随机数。
学习速率
学习速率一般选取为(0.01, 0.8)之间的值，学习速率较大，会导致系统不 稳定，学习速率较小，会导致收敛太慢，需要较长的训练时间。对于较为复杂的 网络，在误差曲面的不同位置可能需要不同的学习速率，可以釆用变化的自适应 学习速率，使得网络在不同的阶段可设置大小不同的学习速率。
期望误差的选取
期望误差值应当通过对比训练后，确定一个比较合适的值，这个值由所需要 的隐含层节点个数确定。一般而言，可同时对不同的期望误差值的两个网络进行 训练，最后综合各因素，确定选择其中一个网络。
5.2.4 BP神经网络的应用
基于以上知识，我们可以将BP神经网络模型应用于本论文所提方案中。
首先，通过BP神经网络的基础知识，设计一个典型的三层前馈BP神经网 络，该网络以多项过滤后的性能数据作为输入层，这些性能数据对应时间段里标 准应用程序的运行时间作为输出层，对性能数据和标准应用程序运行时间进行非 线性建模分析。以釆集的历史数据为训练数据，对该BP神经网络进行训练，当 该网络训练完成，如模型的预测误差达到允许误差范围之内后，验证该模型可用。 此时，对于新增的一组性能数据，可以通过完成训练的BP神经网络，预测相应 的标准应用程序运行时间，通过比较预测的标准应用程序的运行时间与其标准运 行时间，对分析系统的性能状态进行评估。由于BP神经网络无法评估每一个输 入对输出的影响，故无法对分析系统性能优化工作提出指导性建议。
BP神经网络模型的具体建模分析过程将会在5.5节中详细介绍。
5.3建模分析准备工作
为避免内容重复，现以WordCount标准应用程序为例，解释说明建模分析过 程，另外两个标准应用程序的建模分析过程类似，仅展示最终建模分析结果。
5.3.1数据归一化预处理
对于采集积累的性能数据，由于各种类别的性能数据因其单位不同，其值相 差巨大，为了方便后续的建模分析，减少这种不同单位的数值差异化带来的影响, 需要对这些性能数据进行归一化预处理，把所有性能数据均转化成(0, 1)之间 的小数。对于以百分比形式存在的性能数据，如利用率、使用率等，则无需进一 步处理，直接转化成相应的小数即可。对于其他性能数据，均通过以下公式进行 转换：	_ X,
Xi-nor =	 丄
端X	式(5-20)
其中x,为未归一化的值，Xg,为该项性能数据的最大值，为归一化的值。 通过该公式，保证所有性能数据均转化成(0, 1)之间的小数，保持数据形式一 致性，有利于提高后续建模分析的准确性。
5.3.2相关分析
由于除了标准应用程序运行时间外的性能数据总共有41项之多，如此多的 性能数据在进行后续建模分析之前，需要过滤部分相关性不大的性能数据。减少 无关或者弱相关性能数据，在建模训练过程中，一来可以相应地减少训练时间， 二来可以排除不必要因素的干扰，优化训练数据的成分，提高建模的质量。
本次实践选用Pearson相关系数作为相关分析的方法，从41项性能数据中 选择8个与评估标准相关性最强的性能数据。8个性能数据的Pearson相关系数 见表5-1。
表5-1性能数据Pearson相关系数表
自变量	评估标准
CPU性能数据	CPU利用率平均值	　　Pearson相关性
显著性	0.846
0.001
CPU利用率标准差	Pearson相关性 显著性	0.543
0.005
内存性能数据	内存利用率平均值	Pearson相关性 显著性	0.806
0.003
磁盘性能数据	磁盘I/O最大值	　Pearson相关性
显著性	0.832
0.002
磁盘I/O平均值	　Pearson相关性
显著性	0.904
0.000
磁盘I/O标准差	　Pearson相关性
显著性	0.787
0.002

（续上表）
自变量	评估标准
服务器负载性
能数据	服务器负载最小值	Pearson相关性 显著性	　　　　0.696
0.004
HDFS性能数据	HDFS上传速率最大值Pearson相关性
显著性	　　　　0.732
0.004
由表5-1可知，对于WordCount标准应用程序，8个性能数据的Pearson相 关系数均大于0.5,表明这些性能数据均与评估标准存在中高度相关性；并且显 著性系数均小于等于0.05,表明这些性能数据均满足显著性检验。其中，如同各 研究者对WordCount标准程序的研究结果，与评估标准相关性最大的是CPU性 能数据和磁盘I/O指标性能数据。
5.4多元线性回归建模分析
本次实践通过SPSS软件完成多元线性回归的线性建模分析过程［23］。
首先，明确本次多元线性回归分析的自变量和因变量，以WordCbunt标准应 用程序为例。
自变量：8个一组的WordCount标准应用程序运行前三分钟内的归一化性能 数据，共25组；
因变量：1个WordCount标准应用程序运行时间，共25个。
5.4.1建模分析结果
基于多元线性回归的线性建模分析主要结果如下所述。
表5-2模型摘要表
模型	R	R2	调整后R2	标准估计的误差	德宾-沃森
1	0.856	0.733	0.721	0.2435	1.783
表5-2是本次多元线性回归分析的回归模型统计量。其中R是相关系数；R2 是相关系数的平方，又称为判定系数，用于判定线性回归的拟合程度，说明自变 量解释因变量变化的程度；调整后R2与R2类似。R2值越大，表明拟合程度越好， 一般判定系数大于0.7表明拟合程度较高。此处R2为0.733,说明本次多元线性 回归分析的拟合程度较好。标准估计误差较小，表明实际值与估计值之间的相对 偏离程度不大。德宾-沃森系数，即5丄3节中的D.W检验，该值越接近2,表明 自变量之间存在序列相关的概率越小，伪回归的概率越大。此处德宾-沃森系数 为1.783,接近于2,表明本次实践很大程度上自变量之间不存在序列相关，本次回归分析不是伪回归。
表 5-3 ANOVA 表
模型	平方和	自由度	均方	F	显著性
1回归	0.823	5	0.284	86.931	0.003
残差	0.106	19	0.083
总计	0.929	24
表5-3是本次多元线性回归分析的方差分析表。回归平方和为0.823,残差 平方和为0.106,总平方和为0.929,表明本次回归模型解释了总平方和的大部分 内容。F统计量的值为86.931,该值较大表明自变量和因变量之间的线性关系较 显著。最后一个显著性水平值，该值表示假设“所有自变量对因变量均不能产生 显著影响”成立的概率，显著性水平值为0.003, 一般认为小于0.05即可证明上 述假设不成立，则表明至少有一个自变量对因变量产生显著影响。综合而言，可 以认为本次分析所建立的回归方程有效。
表5-4回归系数表
模型	未标准化系数	标准化系 数	t	显著性	共线性统计
B	标准误差	Beta			容忍度	VIF
1 （常量）	-0.741	　　0.442		1.676	0.013
X1	　0.513	0.258	0.135	1.988	0.000	0.682	1.465
X2	　0.217	　　0.223	0.346	0.973	0.005	0.469	2.132
X3	　0.504	　　0.284	0.149	1.775	0.002	0.513	1.947
X4	　0.418	　　0.441	0.257	0.948	0.004	4.032	0.248
x5	　0.637	0.462	0.498	1.376	0.000	0.405	2.467
X6	　0.126	0.184	0.371	0.685	0.002	0.317	3.152
x7	　0.573	0.245	0.249	2.339	0.001	0.794	1.259
x8	　0.241	0.197	0.141	1.223	0.173	0.546	1.832
表5-4是本次多元线性回归分析的回归系数表。首先，观察显著性水平值, 其中自变量X8的显著性水平值大于0.05,表明其不会对因变量产生显著影响， 故将该自变量排除。其次，观察共线性统计中的VIF,即方差膨胀因子，该值用 于描述自变量之间是否存在共线性，若两个或者两个以上的自变量存在共线性， 则它们反映的内容是相似的，会对矩阵运算产生影响。一般判断VIF值大于5, 表示自变量存在共线性。表中所有自变量VIF均小于5,故自变量之间不存在共 线性。因此，本次回归分析得到的回归方程为：
ywc = -0.741 +0.513 玉 +0.217x2 +0.504x3 +0.418x4 +0.637x5 +0.126x6 +0.573x7
式(5-21) 其中，当为WordCount标准应用程序运行时间，X、为CPU利用率平均值， %2为CPU利用率标准差，*3为内存利用率平均值，&为磁盘I/O最大值，*5为磁 盘I/O平均值，％为磁盘I/O标准差，为服务器负载最小值。
同理可得另外两个标准应用程序的建模分析得到的多元线性回归方程分别 为：
yPi = —0.543 + 0.418玉 4-0.603x2 +0.582沔 +0.327x4 +0.513x5 + 0.276x6 4-0.319x7 式(5-22) 其中，5.为Pi标准应用程序的运行时间，X]为CPU利用率平均值，X2为 CPU利用率标准差，巧为CPU利用率最小值，&为内存利用率最大值，*5为内 存利用率平均值，祁为磁盘I/O平均值，X7为服务器负载平均值。
y-rs = -0. 613 + 0. 321X] + 0. 419at2 + 0. 512為 + 0. 623勾 + 583xs + 0. 374% + 0. 276否 +365* 式(5-23) 其中，办为TeraSort标准应用程序的运行时间，CPU利用率平均值， 工2为内存利用率标准差，*3为内存利用率平均值，&为内存利用率最小值，工5为 磁盘I/O平均值，乂6为磁盘I/O最大值，工7为服务器负载最小值，益为HDFS上 传速率平均值。
5.4.2模型预测检验
本次实践在建模分析之后，在8种不同操作导致的8种不同性能环境下，分 别运行8组三个标准应用程序，通过这8组性能数据，对建模分析得到的回归方 程的预测准确度进行检验。三个回归方程的预测验证结果如图5-2所示。
2500000
1000000
500000


图5-2三个回归方程预测检验图
Pi、WordCount、TeraSort三个多元线性回归方程的预测误差分别为7.15%、 7.97%、7.43%,均在10%以内，表明三个回归方程的预测结果可靠。
综上所述，本次多元线性回归建模分析所得回归方程具有较高的可靠可用性。 基本上可以通过该方程反映自变量和因变量之间的线性关系，并且验证在误差允 许范围内，可以通过该回归方程以任意的新自变量预测相应因变量的值。另外， 从回归方程的回归系数可知，各重要性能指标对标准应用程序运行时间的不同影 响程度，这将在后续的分析系统性能优化部分可以起到指导性作用。
5.5 BP神经网络建模分析
本次实践通过Matlab软件完成BP神经网络的非线性建模分析过程心〕。
首先，明确本次BP神经网络分析的输入层和输岀层，以WordCount标准应 用程序为例。
输入层：8个一组的WordCount标准应用程序运行前三分钟内的归一化性能 数据，共25组；
输出层：1个WordCount标准应用程序运行时间，共25个。

5.5.1 BP神经网络设计
本次实践建立一个简单的可训练前馈网络，其中建立该网络对象的代码如下:
%建立BP神经网络
%input为输入数据矩阵（8*25）, output为输出数据矩阵（1*25）
%三层网络结构，8个输入层神经元，12个隐层神经元，1个输出层神经元
%隐层传递函数为'tansig，线性传递函数
%输出层传递函数为河reliif正切S型传递函数
%学习训练函数为'traindm，动量BP算法函数
net = newff（input, output, 12, {ttansig,/purelin,}, ttrainlm,）;
%设置训练参数
%最大收敛次数为2000
net.trainParam.epochs = 2000
%训练目标最小误差为0.01
net.trainParam.goal=0.01
%学习速率为0.05
net.trainParam.lr=0.05
%开始训练
net = train(net, input, output);
5.5.2模型预测检验
与多元线性回归建模分析相同，在相同的8组预测检验中，得到的预测验证 结果如图5-3所
Pi神经网络预测检验图
2500000
1000000 500000
WordCount神经网络预测检絕图
2500000
2000000
1500000
1000000
500000
0
TeraSort神经网络预測检验图



图5-3三个回归方程预测检验图
Pi、WordCount、TeraSort三个BP神经网络的预测误差分别为5.33%、5.14%、 5.78%,均在6%以内，表明三个BP神经网络的预测结果可靠。
综上所述，本次训练所得BP神经网络具有较高的可用可靠性。基本上可以 通过该BP神经网络反映输入层和输岀层的非线性关系，并且验证在误差允许范 围内，可以通过该BP神经网络以任意的新输入数据预测相应输出数据的值。由 于BP神经网络属于非线性分析方法，输入数据和输出数据中经过三层网络进行 权重计算，故无法确定每项输入数据单独对输出数据的影响程度。
5.6两种建模方式对比总结
通过以上两种建模方法的分析结果，可得出以下结论。
两种建模方法所得模型，均能在误差允许范围内比较好地通过三个标准 应用程序运行开始之间三分钟内的性能数据分别预测相应标准应用程序的运行 时间。
非线性的BP神经网络建模分析的预测准确度更高。说明选取的8个性 能数据中存在一定非线性关系，通过非线性建模分析比线性建模分析更能体现性能数据和评估标准之间的关系。
线性的多元线性回归建模分析可以提供分析系统优化的方向。通过多元 线性回归方程的回归系数，可以初步判定哪些性能数据对评估标准影响较大，通 过该信息可以为分析系统优化工作提供指导性方向。
5.7本章小结
本章主要介绍了多元线性回归和BP神经网络两种建模模型，以及二者的建 模分析结果。首先，介绍多元线性回归，了解多元线性回归的一般形式、回归参 数的最小二乘估计，以及该模型的六项检验标准。接着，介绍BP神经网络，了 解BP神经网络的拓扑结构、BP算法，以及BP神经网络的五项设计原则。然后， 以WordCount应用程序为例介绍建模分析过程，在完成数据归一化预处理和相 关性分析之后，选取相关性较大的性能数据和评估标准进行建模分析。经验证, 两个模型的预测结果误差分别在10%和6%之内，证明两个模型具有良好地可靠 可用性。


第六章 评估验证与性能优化
利用验证可靠可用的两个模型，对分析系统的性能状态进行分析评估，以评 估结果指导用户的使用行为，并进行性能优化。
6.1分数评定规则
通过模型得到的预测时间长短表明分析系统性能状态的方式不够直观，现制 定一个分数评定规则，将预测时间转换成百分制的分数。
以3.3.2中确定的三个标准应用程序的标准运行时间为100分基准，以4倍 标准运行时间为0分基准，可将预测时间线性转换成相应的分数。由三个标准应 用程序的预测时间得到三个分数，再取三个分数的平均数，以此作为性能状态的 评定分数。
6.2性能评估效果
性能评估的最主要功能是对分析系统中的实际应用程序进行使用指导，提高 实际应用程序的工作效率，减少其运行时间。本次选用一个典型的实际应用程序 ——统计各个时段的用户数量。
6.2.1单个实际应用程序的指导效果
首先，分析评估分数和单个实际应用程序运行时间的关系。本次实践运行实 际应用程序8次，通过多元线性回归方程和BP神经网络分别进行预测评估，评 估分数和实际应用程序运行时间的关系如图6-1所示。
评估分数与单个实际应用程序运行时间关系图
22C0
2000
1800 —1600
1400
1200
1000
SOO
600
400
200
0

由图6-1可知，不管是多元线性回归还是BP神经网络，其预测的评估分数 和实际应用程序的运行时间基本上存在线性相关，评估分数越高，实际运行时间 越短，评估分数越低，实际运行时间越长。同时，在60分左右存在一个不太明 显的拐点，在60分以上的分数段中，曲线斜率较小；在60分以下的分数段中， 曲线斜率略微增大。表明相比于性能状态良好的情况下，当分析系统性能状态糟 糕到一定程度后，分析系统性能状态下降一点，对应用程序的实际运行时间产生 的影响会相对增大。
同时BP神经网络的红色折线比多元回归分析的蓝色折线更趋近于一条直线, 说明通过BP神经网络预测的评估分数与实际应用程序的运行时间线性相关性更 强。该现象与建模分析阶段的预测时间，BP神经网络的误差比多元线性回归误 差更小的状况相一致。
综上，可以通过这两个模型对用户运行单个实际应用程序提供指导性建议， 即当只有当前用户运行单个实际应用程序时，评估分数越高，分析系统的性能状 态越好，越适宜运行实际应用程序。当评估分数在60分以下时，不建议运行实 际应用程序，否则该应用程序的运行时间会较长。
6.2.2多个实际应用程序的指导效果
在实际应用场景中，分析系统中有多用户同时运行实际应用程序，希望预测 评估分数能够指导用户运行实际应用程序的行为，使得多个实际应用程序运行总 时间变少。
本次实践先后运行两次实际应用程序，第二次启动运行实际应用程序在第一 次应用程序运行结束之前，保证两个实际应用程序有一时间段是同时运行的。第 一次运行实际应用程序时的场景和前述分析场景相同，无需再讨论，现分析第二 次实际应用程序运行之前的评估分数和两个实际应用程序运行总时间的关系。总 共运行6组，结果如图6-2所示。
评估分数与多个实际应用程序运行时间关系图
――多元线性回归一LB啪经冋络

图6-2多个实际应用程序分析图
由图6-2可知，多元线性回归和BP神经网络所预测的评估分数和实际应用 程序运行总时间的关系趋势大致相同。仅从单调性来说，评估分数和实际运行总 时间的变化趋势是一致的，评估分数越高,实际运行总时间越短，评估分数越低， 实际运行总时间越长。同时，由图中曲线可以明显看到，在评估分数在65分附 近存在一个拐点。在65分以上的分数段中，曲线斜率较小；在65分以下的分数 段中，曲线斜率明显增大。表明相比于性能状态良好的情况下，当分析系统性能 状态糟糕到一定程度后，分析系统性能状态下降一点，对应用程序的实际运行总 时间产生的影响是成倍增长的。相对于单个实际应用程序的曲线图，两个实际应 用程序的曲线图拐点更加明显，斜率增加比例更大，且其对比关系不止两倍，表 明在两个实际应用程序的状况下，分析系统的性能状态对实际应用程序总时间的 影响是及其严重的。
由此可以对多用户同时运行多个实际应用程序提供指导性建议，以本次实践 为例，即已有一个实际应用程序在运行时，当评估分数在65分以下时，建议不 再运行新的应用程序，避免分析系统性能状态愈发下降，导致所有实际应用程序 运行总时间过长；当评估分数在65分以上时，可以运行新的应用程序，且评估 分数越高，所有实际应用程序运行总时间越短。
6.2.3性能评估总结
综上所述，本次实践通过两种建模分析方式得到的模型，在分析系统的实际 应用环境中，以预测三个标准应用程序的运行时间为基础，能够可靠地评估出分 析系统的性能状态，并且可以根据性能状态的评估结果，对分析系统的用户提供 指导性建议。
总体而言，本次实践所得的评估结果其实在分析系统的日常使用中均有所体 现。如性能状态越差，应用程序运行时间越长；同时运行应用程序数量越多，应 用程序运行时间越长。但是这些经验总结之前均为定性认知，在通过本方案的实 践验证之后，可以将定性认知转变为定量认知。定量认知可以提供更直观的性能 状态判断，有助于指导用户的应用程序使用行为，使得分析系统的性能状态保持 在良好的状态中。
6.3性能优化建议
由于BP神经网络是非线性模型，性能数据的内部关系无法以线性关系确定, 从而不能考察单个或者若干个性能指标对应用程序运行时间的影响关系。故只能 基于多元线性回归的线性建模，获得分析系统的性能优化的相关信息。
6.3.1确定性能优化方向
由多元线性回归模型建模所得的回归方程的回归系数反映了各个自变量对 因变量的影响程度，故可以此确定分析系统性能优化的方向。
由5.4.1小节得到的三个标准应用程序的多元线性回归方程如下：
= -0.741 + 0.513玉 +0.217x2 + 0.504x3 +0.418x4 +0.637x5 + 0.126x6 + 0.573jc7 式(6-1) 其中，厶为WordCount标准应用程序运行时间，X】为CPU利用率平均值， 工2为CPU利用率标准差，*3为内存利用率平均值，*4为磁盘VO最大值，*5为磁 盘I/O平均值，％为磁盘I/。标准差，=7为服务器负载最小值。
yPi = —0.543 + 0.418玉 + 0.603x2 + 0.582x3 4-0.327x4 + 0.513x5 4- 0.276x6 + 0.319x7 式(6-2) 其中，小为Pi标准应用程序的运行时间，Xi为CPU利用率平均值，X2为 CPU利用率标准差，为CPU利用率最小值，X4为内存利用率最大值，为内 存利用率平均值，％为磁盘I/O平均值，*7为服务器负载平均值。匕
"=-0. 613 + 0. 321X］ + 0. 419又2 + 0. 512也 + 0. 623羽 + 0. 583瓦 +。? 374* +。. 276而 + 0. 365羽
式(6-3) 其中，咽为TeraSort标准应用程序的运行时间，CPU利用率平均值， *2为内存利用率标准差，工3为内存利用率平均值，工4为内存利用率最小值，*5为 磁盘I/O平均值，为磁盘I/O最大值，与为服务器负载最小值，祁为HDFS上 传速率平均值。	'
首先，在众多的性能数据优化项中，可以缩小优化范围为以上7个或8个重 要性能数据，大大减少寻找优化点的工作量。其次，可以根据回归系数的大小来 确定重点优化的性能数据，使得优化工作有重点有顺序。
本次实践选取每个多元线性回归方程的最大回归系数对应的性能数据，进行 针对性优化工作，验证建模结果是否可以提供优化方向。
6.3.2性能优化结果
由2.2节可知分析系统的性能状态影响因素众多，均可针对进行性能优化。 由于本次实践环境的局限性，升级硬件设备等优化策略暂时无法实现，现对参数 调优的优化策略进行分析，检验建模分析得到的优化建议方向的准确性。针对三 个回归方程中最大回归系数的自变量，分别进行参数调优［25］。
三个多元线性回归方程中最大回归系数分别为：Pi, CPU利用率平均值； WordCount,磁盘I/O平均值；TeraSort,内存利用率最小值。针对三个性能指标进行参数调优，参数调优前后均在无任何操作的集群性能最优情况下运行标准应 用程序各5组。
Pi应用程序的回归方程最大回归因数对应的自变量为CPU利用率平均值， 将参数（＜ mapred.tasktracker.map.tasks.maximumM 和 "mapred.tasktracker.reduce. tasks.maximum”由2增大至4,调优前后的运行时间对比如图6-3所示，参数 调优后程序的运行时间平均减少4.5%。、
Pi性能调优对比图
14CDDDD 1200 涵
1。海00
80000D
600QDD
400000
2000Q0
图6-3 Pi性能调优对比图
WordCount应用程序的回归方程最大回归因数对应的自变量为磁盘I/O平均 值，将参数“mapred.compress.map.Output”由fhlse调至true,调优前后的运行时 间对比图如6-4所示，参数调优后程序的运行时间平均减少3.7%o
WordCount性能调优对比图


图6-4 WordCount性能调优对比图
TeraSort应用程序的回归方程最大回归因数对应的自变量为内存利用率最小 值，将参数"io.sort.mb”由100MB增大至200MB,调优前后的运行时间对比图 如6-5所示，参数调优后程序的运行时间平均减少4.2%O
TeraSort性能调优对比图
调优前図调优后

图6-5 TeraSort性能调优对比图
参数调优后，在相同的运行环境下，三个标准应用程序的运行时间分别减少 4.5%、3.7%、4.2%。表明由多元线性回归方程的回归系数所提供的分析系统性能 优化建议方向基本是准确的，通过该建议进行参数调整之后，可以减少应用程序 的运行时间。
6.4本章小结
本章主要介绍了方案的验证过程和结果。首先，介绍了分数评定规则。接着， 通过两个己验证的模型对分析系统进行性能状态评估，分析评估结果和实际应用 程序的运行时间之间的关系。结果证明模型的预测结果可以较好的反映分析系统 的性能状态，并且可以根据评估结果为分析系统的用户提供使用建议，提高分析 系统的使用效率。然后，可以根据多元线性回归建模分析过程中确定的回归因子, 对分析系统的性能优化提供优化方向，使分析系统的优化工作更具目的性。最终, 验证基于Hadoop的网络大规模流量分析系统的性能分析评估方案可以对分析系 统的性能状态进行良好的评估，并为分析系统的性能优化工作提供优化建议。

第七章总结与展望
7.1总结
随着大数据时代的到来，Hadoop受到了越来越多研究者和企业的青睐，成 为大数据存储与分析的首选工具。基于Hadoop的大规模网络流量分析系统借助 Hadoop的成熟架构与工具,对海量网络流量数据进行离线分析与处理。与Hadoop 集群类似，分析系统的性能状态受到多种因素的影响，且性能状态的好坏会直接 决定应用程序的工作效率。故需要对分析系统的性能状态进行准确有效的评估。
借鉴国内外各研究者的研究成果，结合分析系统的实际情况，我们设计并实 现了一套分析系统性能状态的分析与评估方案。
首先，选取三个标准应用程序的运行时间作为分析系统的评估标准。其次， 结合分析系统的管理经验，选取42项性能数据，且在平均值的基础上，增加最 小值、最大值和标准差三个分析维度。然后，应用线性的多元线性回归和非线性 的BP神经网络两种建模方式，对评估标准和性能数据的历史数据进行建模分析。 建模完成后，通过当前的性能数据对评估标准，即标准应用程序的运行时间进行 预测，两个模型的预测误差在允许范围内，且BP神经网络的预测误差比多元线 性回归的预测误差较小。表明评估标准与性能数据之间的关系更趋近于非线性， 同时，验证两个模型均可靠可用。最后，以模型的预测值为分析系统的性能评估 基准，经过实际应用程序的检验，证明该方案的评估结果能够准确地反映分析系 统的性能状态。在单个和多个应用程序的情况下，均能对分析系统的用户的使用 行为进行指导。此外，基于回归方程的回归系数可以有更强针对性地对集群的性 能状态进行优化，减少实用程序的运行时间。
综上所述，本文设计的基于Hadoop的网络大规模流量分析系统的性能分析 与评估系统可以良好地完成分析与评估工作，具有切实的可行性。
7.2展望
根据实际场景，可以针对性地修改或优化方案的具体实现步骤。本文选取三 个标准应用程序进行研究，有一定的局限性，可以考虑更多类型的应用程序，如 机器学习、网页搜索等。选取不同的性能数据，或者增加性能数据的分析维度， 对管理者关心的性能数据进行针对性分析。此外，建模分析模型可以根据不同的 分析重点进行更换，或者进行算法优化，进一步地减少预测误差。我们希望以后 能够不断地完善该方案，使之能够更准确地评估分析系统的性能状态。

参考文献
[1]王元卓，靳小龙，程学旗.网络大数据：现状与展望[J].计算机学报，2013, 36(6): 125-138.
[2]Wu X, Zhu X, Wu G Q, et al. Data mining with big data[J]. Knowledge and Data Engineering, 2014, 26(1): 97-107.
[3]McAfee A, Bryiyolfsson E. Big data: the management revolution[J], Harvard business review, 2012(90): 60-6? 68, 128.
[4]刘军.Hadoop大数据处理[M].北京：人民邮电出版社,2013.
[5]王珊，王会举，覃雄派 架构大数据：挑战，现状与展望叨?计算机学报,2011, 34(10):1741-1752
[6]Ghemawat Sanjay, Howard Gobio氐 Shun-Tak Leung. The Google file system[C].ACM SIGOPS operating systems review. ACM, 2003, 37(5): 29-43.
[7]Dean Jeffrey, Saiyay Ghemawat. MapReduce: simplified data processing on large clusters [J]. Communications of the ACM. 2008, 51(1): 107-113
[8]Chang Fay, Dean Jeffrey, Ghemawat Sanjay et al? Bigtable: A distributed storage system fbr structured data [J]. ACM Transactions on Computer Systems (TOCS). 2008, 26(2): 4.
[9]Hadoop Dociunentation [EB/OL]. http://Hadoop.Apache.Org/.
[10]HDFS Architecture Guide [EB/OL].
http://hadoop.apache.Org/docs/rl.0.4/hdfs_design.html.
[11]董西成. Hadoop技术内幕：深入解析YARN架构设计与实现原理[M].北京: 机械工业岀版社,2013.
[12]Microsoft IT SES Enterprise Data Architect Team. Hadoop Job Optimization (Microsoft IT white paper) [R]. 2014.
[13]Heger, D. Hadoop performance tuning-a pragmatic & iterative approach[J]. CMGJoumal 4 (2013), 97-113.
[14]Dili Wu, Aniruddha Gokhale. A self-tuning system based on application Profiling and Performance Analysis for optimizing Hadoop MapReduce cluster configuration[J]. High Performance Computing (HiPC), 2013. 89-98.
[15]谖超，强保华，石龙.基于Hadoop MapReduce的大规模数据索引构建与集群 性能分析[J].桂林电子科技大学学报.2012, 32(4): 308-312.
[16]Shengsheng Huang, Jie Huang, Jinquan Dai, et al. The HiBench benchmark suite: Characterization of the MapReduce-based data analysis [J]. Data Engineering Workshops (ICDEW), 2010:41-51.
[17]Jinsong Yin, Yuanyuan Qiao. Performance Modeling and Optimization of MapReduce Programs [J]. CCIS, 2014: 180-186.
[18]Flume Documentation [EB/OL]. http://flume.apache.org/.
[19]何晓群.现代统计分析方法与应用(第二版)[M],北京：中国人民大学出版 社,2007.
[20]李新海.多元线性回归方程及其应用[J].白城师范高等专科学校学报,2002, 16(2):38-41.
[21]韩立群.人工神经网络教程[M].北京：北京邮电大学岀版社,2006.
[22]D.E.Rumelhart, G.E.Hinton, R.J.Williams. Learning representation by back- propagation errors [J]. Nature, 1986, (323): 533-536.
[23]冯力.回归分析方法原理及SPSS实际操作[M].北京：中国金融出版社,2004.
[24]王小川.MATLAB神经网络43个案例分析[M].北京：北京航空航天大学岀 版社,2013.
[25]Swathi Prabhu, Anisha P Rodrigues, Guru Prasad M S, et al. Performance Enhancement of Hadoop MapReduce Framework fbr Analyzing BigData[J]. Electrical, Computer and Communication Technologies (ICECCT), 2015:1-8.

