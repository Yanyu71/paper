第一章绪论
1.1研究背景及意义
移动互联网时代，人们不再满足于单一的文字信息交流。得益于移动通信技 术的日臻成熟，通信速率的不断提高，语音、图片、视频等多种媒体传输技术取 得了长足的发展，极大地丰富了人们的工作与生活。语音信号作为一种最原始的 交流通信方式，在人与人之间的交往中扮演着极为重要的角色。然而，不论在现 实生活还是网络媒体中，语音信号总是容易受到各种各样不同类型的噪声干扰, 对语音信号的质量以及可懂度均造成不同程度的损伤，极大地影响了交流的有效 性。例如在咖啡店、餐厅等现实场景通过移动网络拨打电话，如果现场的环境嘈 杂，充斥着大量背景噪声，将会严重影响到与对方的正常通话，或者在车载语音 识别系统中，如果行驶途中或者车内伴有噪音，将使得语音识别的准确率下降， 轻则影响人机交互的体验，重则导致设备无法工作，妨碍驾驶员的正常驾驶。因 此，需要设计一种算法对采集到的真实场景中的语音信号进行处理，滤除其中的 噪声干扰，并保证不会损害到原始的人声信号。
语音增强技术可以解决上述存在的问题。作为语音信号处理领域的一个重要 分支，该技术旨在设计一种高效的处理算法，在保证语音的质量和可理解性的前 提下，滤除带噪语音中存在的各种噪声，还原出纯净的人声信号，使人与人之间 的交流、人与机器之间的交互变得更加轻松、易懂、有效率。语音增强研究领域 经过几十年的发展，大致可以分成两种算法分支，一种是传统的信号处理方法， 比如经典的谱减法根据语音和噪声的功率谱的不同来设计滤波器，用带噪语音的 功率谱减去估计得到的噪声的功率谱，得到增强语音功率谱，再经过傅里叶反变 换后得到最终的增强语音。传统算法大都需要预先对信号和噪声的概率分布以及 互相关特性做出假设，一旦真实场景不再满足条件，算法性能就会严重下降，此 外，对于平稳噪声，算法可以获得良好的增强性能，但是对非平稳的噪声，却难 以将其从纯净语音中滤除。另一类算法分支是新兴起的基于海量大数据的深度学 习增强算法，该类算法不需要假设信号的先验知识，克服了传统算法固有的缺陷， 在低信噪比、非平稳噪声条件下，获得了比传统语音增强算法更加优异的抑噪性 能。
语音增强算法在许多领域都扮演着重要角色，比如在传统的话音业务中，将 麦克风采集到的嘈杂语音通过声码器进行压缩编码之前，可以先使用语音增强算 法进行数据预处理，提高待传输信号的信噪比，使得后端的语音编码更加有效， 提高整个系统的性能；在车载语音识别系统中，车内的噪声环境会严重影响识别 的精度，所以在进行识别之前，可以将噪声抑制算法用作系统前端的预处理器， 以准确识别出人的声音指令。此外，语音增强技术在移动通信、智能家居、电话 会议、人工耳蜗助听设备、网络通讯和在线直播等领域都有着十分广泛的应用。
1.2国内外研究现状
语音增强技术是语音分离领域的主要分支，是说话人分离技术的一种特殊情 况。语音增强技术从上世纪六十年代发展至今，已经有六十多年的研究历史，其 中的研究成果从不同的角度来看有许多不同的分类方法。根据语音增强技术所使 用的麦克风数量的不同，可以分为单麦克风（通道）和多麦克风（通道）语音增 强。单麦克风增强技术可以利用语音信号的时域和频域信息，而多麦克风增强技 术还可以实现对空域信息的利用，通过空间分集技术将增强语音从带噪语音中分 离出来，最常使用的是波束成形（Beamfbrming）算法⑴⑵。一般而言，单通道语 音增强问题更具有挑战性⑶⑷。根据语音增强技术是否依赖目标增强语音，可以 分为无监督语音增强和有监督语音增强，根据语音增强技术所采用的基本原理的 不同，可以分为基于数字信号处理的传统语音增强算法和基于机器学习的新兴语 音增强算法。
传统的语音增强技术可以追溯到1978年由Lim等学者提出的Weiner滤波 算法［习，该算法在加性平稳噪声条件下基于最小均方准则设计去噪滤波器，输入 带噪语音信号，输出去噪后的增强语音信号A】。然而，该算法恢复的语音信号会 不可避免地残留一些高斯白噪声，并且在非平稳噪声的条件下无法工作。谱减法 是语音增强领域的另一种经典算法⑺。该算法的思想简单直观，假设背景噪声为 加性干扰且目标语音和噪声信号相互独立，用带噪语音谱减去噪声谱得到目标语 音的频谱，再结合带噪语音的相位信息通过逆傅里叶变换恢复最终干净语音冈。 然而，该算法会因为对噪声的估计不足，出现残余噪声，这种噪声不同于Weiner 滤波中高斯白噪声，其随机频率、幅度以及听觉效果与音乐信号相近，也被叫做 音乐噪声。此后有许多学者对谱减法进行了改进，Paliwal等人于2010年在调制 域上进行了单通道谱减法［9】的探索和研究。上述算法在既定的假设域内可以取得 去噪效果，在真实场景中一旦前提假设不再满足，增强性能将会出现下降。此外 还有基于统计学上最小均方误差（MMSE）的语音增强方法〔I。】，比如基于人耳的 非线性听觉感知特性设计的MMSE对数幅度谱估计器（MMSE log spectral amplitude estimator）〔⑴。然而，基于MMSE准则的方法计算成本偏高，而且受 噪声分布的先验知识影响较大【12〕，在复杂场景下去噪性能会大幅度下降。2001年, Cohen等学者提出了一种适用于非平稳噪声环境的优化修正对数谱振幅估计器
2
(optimally modified log-spectral amplitude estimator, OMLSA)语音增强算法卩习， 2003年作者又提出了一种改进的最小控制递推平均算法(the minimum control recursive average algorithm, IMCRA ) [14],可以用来预测和跟踪噪声信号。据本文 所知，结合了 IMCRA的OMLSA已经获得了传统语音增强算法的最佳性能。
语音增强作为信号处理技术的重要分支，已广泛应用于即时通讯软件IE、电 话会议系统和语音识别系统〔均。基于大数据驱动的机器学习语音增强算法近年 来异军突起，几乎不需要对语音信号和噪声信号做任何假设，克服了传统语音增 强算法的固有缺陷，取得了更优异的去噪水平和泛化能力。一般而言，可以将基 于机器学习的语音增强算法大致归为四类。第一类是基于隐马尔科夫模型 (Hidden Markov Model, HMM)的语音增强算法呵，通过数据训练的方式分别 得到语音和噪声信号的隐马尔科夫模型，然后在分离阶段通过最大化后验概率来 恢复目标语音。2010年，Cooke等人在Ephraim研究成果的基础上又通过训练得 到了各声源信号之间的交互模型，并用于语音分离与识别任务，取得了满意的效 果〔⑻。此外，Veisi等学者在2013年将基于隐马尔科夫模型的语音增强算法扩展 到梅尔域I"】。第二类是基于非负矩阵分解(Non-negative Matrix Factorization, NMF) 的语音增强算法[2°】，该算法假定语音和噪声的幅度谱都可以用各自的一种非负 矩阵来表示，然后通过训练的方法得到上述非负矩阵，并在测试阶段对带噪语音 进行去噪处理，恢复目标语音信号。然而，上述方法没有考虑语音和噪声之间的 相互关系，在实际应用中具有局限性。作为非负矩阵算法的改进和发展，Vu等 人在2016年将非负矩阵和深度神经网络(deep neural networks, DNN)相结合来 实现语音增强和自动语音识别任务，在客观语音质量上取得了显著的改进OH。第 三类是基于浅层神经网络的语音增强算法，1994年Xie等学者将带噪语音的对 数功率谱特征输入到人工神经网络中进行训练，输出增强后的对数功率谱a〕。该 类算法受限于当时计算机运算能力的不足，不能在训练数据量和网络规模上实现 突破，因此并未获得良好的性能，没能撼动传统语音增强算法当时的主流地位， 之后对于神经网络的相关研究便基本陷入了停滞。直到2006年出现了转折点， Hinton等学者提出的受限玻尔兹曼机(Restricted Boltzmann Machine RBM)逐层 训练策略[23〕为构建深层的神经网络指明了研究方向。后来随着计算机运算能力 的日益强大，在语音领域掀起了一股基于深度学习的研究热潮，各种用于语音信 号处理的深度学习模型不断出现，也不断刷新着模型的性能上限，由此出现了第 四类基于深度学习的语音增强算法。
2014年，徐勇等学者设计出基于深度神经网络的语音增强模型【24〕，将带噪 语音的对数功率谱作为网络的输入，采用全局方差均衡和噪声感知训练技术提升 网络的泛化能力，通过输入多帧对数功率谱来预测中间一帧的对数功率谱，然后
3
结合带噪语音的相位恢复增强后的语音波形，在100多种噪声条件下验证了模型 的去噪性能。在之后的研究[⑹中又提出了多目标学习DNN模型，基于对数功率 谱，梅尔倒谱系数和理想二值掩蔽来训练DNN模型，实验证明相比于原来的单 一特征训练，模型将具有更好的去噪性能和泛化能力。然而，DNN其实并不擅 长处理语音增强等时间序列建模的问题，其自身结构决定了增强性能的上限无法 突破，因此在语音领域出现了对循环神经网络(recurrent neural networks, RNN) 的研究，特别是RNN的一种常用架构 长短时记忆网络(long short-term memory, LSTM)O 2016年，Kolboek等学者提出了一种基于深度循环神经网络 (DRNN)的语音增强算法，用于噪声鲁棒的说话人验证，在噪声环境下使用基于 DRNN的LSTM语音增强前端进行测试以】。2017年，Sun等学者提出了一种基 于LSTM-RNN的多目标深度学习语音增强算法，在不可见噪声条件下进行的实 验表明，所提出的框架能够持续显著地提高语音质量和清晰度两种客观指标[27〕。 然而，基于RNN的语音增强模型训练时间过长，参数量过大，更容易出现梯度 消失的问题，不符合模型轻量化和实时化的发展趋势。近年来，生成对抗网络
(generative adversarial networks, GAN)在图像生成领域获得巨大成功，一些学 者开始将GAN应用到语音增强领域上来。GAN由生成器和鉴别器两部分组成， 生成器用于产生与训练数据有相同分布的数据，鉴别器用来判断生成器产生的数 据是否达到真实分布，双方在博弈之中逐渐达到纳什均衡，此时生成器的输出就 是真实数据。2017年，Pascual等人提出了基于生成对抗网络的语音增强算法 SEGAN【28],通过生成对抗训练来学习带噪语音到纯净语音的非线性映射。2019 年，叶帅帅等人提出了一种端到端的基于Wasserstein生成对抗网络(SEWGAN) 的语音增强方法〔29],其生成器和鉴别器分别为全卷积神经网络(fully convolutional neural networks, FCN )和深度神经网络，并基于 Wasserstein 距离利 用多种噪声类型和信噪比对SEWGAN进行训练，在真实场景中具有一定的泛化 能力。然而基于博弈思想的语音增强模型容易发生训练崩溃的问题，且模型的语 音增强能力与其他深度学习网络相比也不具备明显的优越性。
卷积神经网络(convolutional neural networks, CNN)中的计算可以并彳亍进 行，其独特的局部感知和权重共享特性能够有效地捕捉语音信号的局部细节，引 起了研究人员的广泛关注。2017年，Park等学者用卷积层代替了卷积神经网络 中的全连接层，提出了一种基于幅度谱语音增强的冗余卷积编解码网络 (redundant convolutional encoder-decoder network. RCED) [30h 通过输入多帧对 数功率谱预测最后一帧对数功率谱的方式实现从带噪语音到干净语音的非线性 映射，最后结合带噪语音相位，通过逆傅里叶变换得到目标语音波形。然而，作 者并未进行泛化性能的测试。2018年，Ashutosh等学者提出了一种新的时域监
4
督学习语音增强框架⑶],使用频域的损失函数来训练时域的卷积神经网络，适用 于需要频谱映射或时频掩蔽的语音处理任务。2019年，Gautam等学者提出了一 种基于多目标学习卷积神经网络的语音增强技术，能够在智能手机上实时运行 [朝，该方法将带噪语音信号的对数功率谱和梅尔频谱作为主要特征和辅助特征, 使用基于映射的卷积神经网络从带噪语音频谱中去除噪声。此外Fu等人提出了 一种基于端到端的全卷积网络语音增强框架mi,把短时客观可懂度[34](short-time objective intelligibility, STOI)作为模型的损失函数，将整段语音作为网络的输入, 无需考虑复杂的预处理和后处理过程，克服了基于频谱映射的方法忽略了相位的 情况。然而，由于卷积运算本身具有局部性，上述基于CNN的方法很难捕捉到 语音信号的全局上下文，限制了模型进一步提升语音增强的性能。此外还有关于 结合多种神经网络的研究，最典型的例子是卷积循环神经网络(convolutional- recurrent neural networks, CRNN) [35][36] o
注意机制是捕获远程上下文信息的重要发展，在机器翻译a】、图像分类和目 标检测Sim]等问题中得到了广泛的应用，可以在许多场景下作为RNN的代替。 据本文所知，注意力机制在语音领域的应用还较少，目前的方法主要是通过门控 机制或加法操作来重新校准原有特征。2019年，Hao等人将传统的注意力机制与 LSTM相结合，生成带噪语音谱的掩蔽值(mask)【呦；2020年，Lan等人在冗余 卷积编解码网络(RCED)中引入了挤压-激励机制(squeezing-and-excitation mechanism),帮助模型聚焦有用信息，抑制无用的信息刚；Dou等人将自注意力 机制与RDL[42] (residual-dense lattice)网络结合起来用于单通道时域语音增强问。 上述基于注意力机制的语音增强方法均提升了原有架构的增强性能，获得了较好 去噪能力。
1.3研究目标及研究内容
本文的研究目标是在充分分析语音信号声学特征、噪声信号统计特性的基础 上，通过注意力机制来提升全卷积神经网络学习输入信号全局语境的能力，帮助 卷积网络捕获有用特征，抑制冗余特征。在只增加少量网络参数的前提下提升原 有卷积模型的语音增强性能，能够在低信噪比和非平稳噪声条件下消除带噪语音 中的噪声干扰，还原出纯净的人声信号，在短时客观可懂度(STOI)和语音质量 感知评价(perceptual evaluation of speech quality, PESQ)删等指标上取得优异表 现。语音增强技术的研究领域可以分为单通道语音增强和多通道语音增强两个方 向，其中单通道语音增强由于缺少丰富的空间信息使得对纯净语音信号的恢复更 加困难。基于此，本文将主要研究加性噪声条件下的单通道语音增强问题。
本文的主要研究内容如下：
5
首先阐述了卷积神经网络的基本原理。对卷积运算，感受域，卷积核，通道 数，池化操作进行了介绍分析，并由此引出一个经典卷积网络的示例。接着介绍 了近期计算机视觉中流行的注意力机制，对硬注意力，软注意力，全局注意力， 局部注意力以及自我注意力原理进行了研究分析。
其次，在卷积网络和注意力机制的基础上，对基于UNet架构的全卷积神经 网络进行了详细的阐述，本文也将UNet作为骨干网络。受谷歌大脑团队启发, 本文仔细研究了一种新的二维相对自注意机制，这种机制在自注意力基础上将输 入数据维度扩展至二维，并加入了相对位置编码方案，在图像识别和目标检测中 已经被证明是十分有效的。在此基础上，本文提出了一种注意力强化全卷积神经 网络AAUNet,将二维相对自注意机制应用到全卷积网络中，具体做法是将卷积 运算与注意力机制产生的输出在通道方向拼接起来生成新的特征图，通过调整注 意力通道所占的比例，可以在卷积关注局部细节和自注意力获取全局语境之间找 到最优组合。在实验中本文采用Huber Loss作为模型的损失函数，结合了 L1和 L2损失函数的优点，对噪声具有较好的鲁棒性，可以使网络模型更快地收敛。
最后，针对AAUNet在实验中存在的问题——当自注意力机制的通道数占 比为100%,即全注意力机制时语音增强的性能出现下降，本文又提出了一种基 于独立自注意机制的语音增强模型SAUNet,相比于二维相对自注意机制，独立 自注意机制可以自由设置运算区域的大小，并通过多值矩阵提升基于距离的感知 能力，只需要增加少量的网络参数，就可以在语音质量、可懂度和未知噪声抑制 等方面获得显著的性能提升。为了验证模型的有效性，本文选取了语音质量感知 评价(PESQ),短时客观可懂度(STOI),信号失真(SIG)的复合测度，噪声失 真(BAK)的复合测度以及整体语音质量(OVL)的复合测度这5种指标用作评 估方式，评估模型性能。
1.4论文章节安排
论文一共分为五个章节：
第一章为绪论，首先介绍了论文的研究背景和研究意义，然后详细阐述了语 音增强技术在国内外的研究现状和发展历史，着重分析研究了具有代表性的、与 本文工作相关联的学术成果，对其中存在的问题进行了说明，最后阐明了本文的 主要研究目标和研究成果。
第二章为卷积网络与注意力机制概述。首先分析介绍了卷积神经网络的基本 原理，包括卷积运算，感受域，卷积核，通道数以及池化等相关操作，并给岀了 一个经典的卷积网络示例。然后给出注意力机制的介绍，对硬注意力机制，软注 意力机制，全局注意力，局部注意力以及自我注意力机制的基本原理进行了分析。
6
第三章提出一种用于单通道语音增强的注意力强化全卷积神经网络 AAUNeto首先详细介绍了一种基于UNet架构的全卷积神经网络模型，其次仔 细分析研究了一种新的二维相对自注意机制，然后将二者结合，提岀了一种基于 AAUNet的语音增强算法。最后通过7组消融实验和对比实验，选择了 5种评估 指标，地验证了所提出网络模型的语音增强性能。
第四章为了用注意力机制完全代替卷积运算，提出了一种基于独立自注意机 制的语音增强算法SAUNet。首先在本章中详细分析研究了 一种独立自注意机制， 在此基础上提出了 SAUNet语音增强算法，并通过最后的6组消融实验和对比实 验证明，本章所提出的语音增强模型超越了所有的对比方法，只需要增加少量的 网络参数就可以获得模型性能的显著提升。
第五章为总结与展望。首先对本文的工作做了最后的总结，最后针对论文中 存在的不足和需要改进之处给出了下一步的研究方向。


第二章卷积网络与注意力机制概述
本章将对卷积神经网络及其基本运算，注意力机制及其基本原理进行分析介 绍。首先对卷积神经网络的核心思想“卷积运算”及其相关概念进行阐述，然后 给出了一个经典的卷积网络LeNet-5示例。在下一小节，对5种注意力机制的设 计理念进行了分析。
2.1卷积神经网络
2.1.1卷积运算
图2-1表示的是卷积运算的示意图。其中左边图片表示输入当前网络层的二 维特征图,尺寸大小为” “，这里"=6 ；中间图片表示卷积核，尺寸大小为/*/, 这里/ = 3,需要指明的是卷积核的维度始终和局部感受域的维度保持一致，不 论输入是二维特征图还是三维特征图。右边图片表示输出的特征图，尺寸大小为
,这里血=4。卷积算子的本质是将局部感受域中的数据与卷积核中的数据 进行逐元素相乘再逐一相加。卷积步长指的是局部感受域从左到右、从上到下每 次移动的距离，也可以理解为卷积核对整个输入特征图进行运算时每次移动的步 长，这里步长s = l。填充(padding)操作的含义是在做卷积运算前，对输入特征 图的边缘四周补两圈“0”，尺寸大小变为(” + 2)*(“ + 2),有利于更好地学习特征 图的边缘特征，这里不进行填充，即P = 0。卷积通道分为输入通道和输出通道， 输入通道表示特征图的第三个维度，输出特征图的通道数由卷积核的数量决定。

图2-1卷积运算示意图
综上，卷积的输出特征图维度可以表示为加="+ 2「+ 1 ,其中卜」表示 向下取整。此外，反卷积运算本质上也是一种卷积运算，对特征图先进行补零填 充等操作之后再进行卷积运算。卷积运算通过共享可学习权重的卷积核和平移等 效的能力来提取输入信号的高级特征表示，一个卷积核提取一种特征，卷积的通 道数越多，在理论上可以从不同的维度对输入信号进行学习和建模。
9

本小节给出一个经典的LeNet-5卷积网络〔妁示例，如图2-2所示。图中LeNet- 5网络用于手写数字识别，网络的输入是手写数字图片，这里是灰度图，维度为 32*32*1,输出是识别的结果数字。整个网络的结构较为简单，但已经包含了卷 积网络中的所有元素。

图2-2 LeNet-5网络示例图
图中每个卷积块下方的数字(28*28*6, 14*14*6, 10*10*16, 5*5*16)表示 当前特征图的维度大小，/表示滤波器大小，$表示卷积步长，最后两层为全连 接层，“FC”表示展平(flatten)操作，下方数字(120, 84)代表全连接层中神 经元的个数。池化运算(在LeNet-5网络中为最大池化)的含义是对输入的特征 图进行下采样，在/ = 2的方形领域内取4个数据中的最大值，其余3个数据 丢弃，整个过程使得特征图得宽度和高度减半，但保持通道数不变，是一种有损 的操作。
2.2注意力机制
注意力机制相当于人类对某件事物的注意能力，也因此而得名。注意力机制 最开始主要用于提升基于循环神经网络(RNN)的编解码模型的学习能力，聚焦 重要信息，忽略无用信息，已经广泛应用于机器翻译和语音识别等领域。注意力 机制十分流行，目前衍生了许多变种，下面本文将对主要的5种注意力机制做基 本介绍。
2.2.1传统注意力机制
硬注意力机制和软注意力机制由Kelvin在2015年提出，用于图像描述 (ImageCaption)任务跑。下面给出软注意力机制的实现方式，具体如图2-3所 Zj\ O
给定编码端的输入序列X =[尤,^2,…，无”],给定从解码端学习得到的查询 向量0 ,图中矩形块代表一维向量，将所有输入序列分别与查询向量进行点积 运算，得到每个输入序列的注意力得分，表示一种关注程度，然后通过归一化指 数函数对所有注意力得分进行归一化，得到注意力权值向量A = [at,a2，-,an], 图中的方形块代表概率值，然后与对应的输入序列做加权平均处理，得到最终的 上下文输出序列y。
10

从上述的描述中可以看到，软注意力机制可以对每个输入序列赋予不同的权 重，帮助模型抽取出关键且重要的信息，模仿了生物神经元的关注能力，有利于 模型的学习。硬注意力的思想和软注意力类似，只不过软注意力是对所有输入序 列加权平均，而硬注意力是直接选择注意力得分最高的那个序列作为输出，值得 注意的是，硬注意力是不可微分的，不能直接用于训练。
此外，还有两种传统的注意力机制，分别为全局注意力机制和局部注意力机 制，由Luong等人I"于2015年在Kelvin的研究成果上提出，用于神经元机器翻 译领域。全局注意力机制的含义是对编码端所有的输入序列做注意力，整体思想 和软注意里十分类似，只不过在注意力权值向量和查询向量的实现方式上有所差 别。为了减少计算开销，局部注意力机制不对整个输入序列做注意力，它会预测 一个位置向量，只对属于位置向量内的序列做注意力，相当于是硬注意力和软注 意力的结合体，但它是可微的，同时还能减少计算开销，不足的地方是可能无法 准确地预测位置向量，导致模型的性能下降。
2.2.2自注意力机制
自注意力机制由Google机器翻译团队在2017年提出【37],作者指出基于RNN 的编解码模型不能并行计算，训练时间太长，因此提出了一种新型网络模型一一 Transformer,该网络模型同样是编解码架构，只不过用一种自注意力机制替代了 其中的RNNo自注意力机制与上述传统的注意力机制不同，传统的注意力机制 是在编码端和解码端之间做注意力，查询向量从解码端获得，而自注意力机则发 生在编码端输入序列内部或者解码端的输出序列中，具体流程如下图所示：
11


图2-4自注意力机制图
图2-4给出了输入序列尤 对其他输入序列做内部自注意力的示意图。从图 中可以看到，与传统注意力机制不同，给定输入信息^珂兀耳…兀］,通过 可学习映射得到各个输入序列的查询向量Q ,键向量K和值向量7 ,先是输 入序列尤对其他输入序列做内部自注意力，将Q与各个输入序列的键向量做 点积，得到禺对其他序列的“关注程度”，后续的过程与传统注意力一致，最后 的输出是尤的上下文序列X ,接着其余的输入序列依次执行上述过程。
2.3本章小结
本章简要分析了卷积神经网络的概念，卷积运算的基本原理，具体包括局部 感受域，卷积核（滤波器），卷积算子，卷积步长，卷积通道，填充以及池化等 相关操作，然后给出了一个经典的LeNet-5网络示例，阐明了卷积神经网络通过 局部感受域的权值共享机制对输入特征图进行学习的能力。接着对5种常用的注 意力机制的基本原理进行了介绍分析，包括硬注意力机制，软注意力机制，全局 注意力，局部注意力以及自我注意力机制，阐明了注意力机制对生物神经元注意 能力的模仿，具备学习输入序列的上下文信息的能力。
12
第三章注意力强化全卷积网络语音増强算法
3.1引盲
在语音增强技术的研究领域，基于卷积神经网络的语音增强算法模型己经吸 引了大批研究人员的关注，并取得了相当不错的成绩。相比于传统的语音增强算 法，卷积神经网络能更好地恢复增强语音的质量，同时提升增强语音的可理解度 等性能指标,而且相比于其他神经网络算法模型，在增强性能相差不多的前提下, 还能大幅度减少网络的参数量，符合神经网络轻量化发展的趋势，有助于基于深 度学习算法的语音增强技术的落地实用以及在智能家居、即时通信、电话会议、 语音识别系统、嵌入式人工耳蜗等领域的大规模商业部署。
在过去的几十年，计算机的运算能力还未像今天这样达到如此惊人的地步， 基于信号统计特性设计的传统语音增强算法一度占据了主流地位，人们在对语音 信号和噪声信号的统计特性做出一定程度的假设的前提下设计相应的去噪算法， 比如减谱法的基本原理假设语音和噪声是加性关系且相互独立，维纳滤波法的基 本原理假设语音和噪声信号都是短时平稳的随机过程等，这些传统的增强算法在 各自的假设域内都有着不错的去噪表现，而一旦处理环境变得恶劣或者假设条件 不再满足，比如在OdB以下信噪比或者非平稳噪声条件下，算法性能会急剧恶 化无法使用。诚然，传统算法与生俱来的设计缺陷大大限制了算法进一步的研究 和发展。在2017年，Park等人首次将卷积神经网络应用于语音增强技术领域， 提出了_种名为冗余度卷积编解码网络(redundant convolutional encoder-decoder network, RCED)的语音增强算法模型，在整个卷积运算过程中特征图的大小保 持不变，可在参数量减少12倍的情况下获得与DNN和RNN相近的去噪能力。 此后，许多基于卷积网络的改进的语音增强算法相继出现，有的聚焦于进一步提 升卷积模型的算法性能，有的聚焦于进一步减少模型的训练参数量，也有将卷积 网络同其他算法相结合的研究。本文则将研究的重点放在提高卷积网络学习长距 离上下文信息、获取输入信号全局语境的能力，在增加少量训练参数的前提下提 升原有卷积模型的语音增强性能。
3.2注意力强化全卷积神经网络
本小节将详细介绍一种用于单通道语音增强的注意力机制强化全卷积神经 网络算法，并通过仿真实验来测试和验证所提出算法的增强性能以及泛化能力等 指标。
13
3.2.1全卷积神经网络
全卷积神经网络是从卷积神经网络发展而来，最早由Park等人应用于语音 增强领域。全卷积神经网络在卷积网络的基础上去除了最大池化层、平均池化层 等池化操作以及相应的上采样层，上述池化运算会不经学习地直接削减（取局部 最大值或者平均值）卷积特征图的大小，是一种信息有损的操作。因此，全卷积 神经网络能保留更多的特征信息，对语音信号而言可以更好地恢复未被噪声污染 的干净语音。此外。全卷积神经网络同时摒弃了卷积神经网络在最后一层使用的 全连接层，改用单通道的卷积层代替，一方面可以不破坏特征图中像素点之间的 相对位置，有利于在回归问题中发挥更好的预测能力。体现在语音增强问题上， 全连接层会使得原时频结构中有二维关系的时频单元分散在一维长向量的不同 位置，相对位置的改变会增大模型对语音信号进行学习建模的难度。另一方面, 通过卷积操作可以方便地还原最开始输入模型中的特征图的尺寸大小，保留了原 始输入数据中的结构信息。


图3-1基于UNet架构的全卷积神经网络模型
图3-1是一种基于UNet架构的全卷积神经网络模型。UNetS］是一种特殊的 全卷积神经网络，最早应用于医学图像分割领域，因其整体的编解码网络设计类 似于英文字母“U”，因此得名UNeto Grzywalski等人将UNet网络与长短时记忆 网络LSTM结合，提出一种新的卷积循环网络用于语音增强a】。在本文提出的 网络模型中，本文将这种基于UNet架构的全卷积神经网络作为骨干网络，在此 之上研究如何提高卷积层捕获全局上下文语境的能力。在图3-1中采用的UNet 架构可以分为编码端和解码端两个部分，一共包含14个卷积层，在图3-1中用 “Conv”表示。其中编码端包含7个卷积层，解码端有与之对称的7个反卷积 层。在编码端，卷积操作的通道数以2的幕次方数逐层增加，每一个通道代表一 种特征表示，这样可以从多个维度学习输入语音对数功率谱的时频特征，同时， 卷积操作会逐层压缩特征图尺寸，提取输入语音的高级特征表示，并抑制带噪语
14
音中的噪声干扰；在解码端，对学习到的语音高级特征表示进行相反的反卷积操 作，逐层减少通道数，重构特征图尺寸，最终恢复增强后的语音对数功率谱。
除了卷积运算外，本文在除输入和输出层之外的所有层进行批量标准化
(BatchNonnalization)运算【倒，在图3-1中用"BN"表示，在网络的最后一层 使用线性激活函数(即不增加任何非线性激活函数)，在其它层使用常规的ReLU 激活函数，在图3-1中用“ReLU”表示。其中，批量标准化算法由Google团队 于2015年提出，它通常在卷积层和激活函数层之间使用，基本原理是将卷积层 的输出归一化为标准的正态分布，使得网络的输入输出值更加稳健，避免了训练 过程中梯度消失或者爆炸的问题，有利于网络的迅速收敛，加速整个网络的训练 过程。ReLU激活函数是为了给网络模型引入非线性因素，理论上可以使神经网 络表示为任意的非线性函数，这也是神经网络可以学习更为复杂的函数映射的基 础，ReLU激活函数的公式见式(3-1),图像表示见图3-2。图3-1中UNet的通 道数在编码端逐渐增加或者保持不变，在解码端进行对称的相反操作，为了在输 入特征图的频率方向上更多地学习上下文信息，在频率方向进行步长为2的卷积 操作，在时间方向上取步长为1同时进行置零填充，在编码端逐层将特征图的频 率维度减半，在编码端的最后一层减至一维，获得输入带噪语音的高频特征表示， 在解码端中再逐层地恢复原始的输入尺寸，整个过程不改变特征图的时间长度。
(3-1)
图3-2 RELU激活函数图像
此外，UNet编码端在逐层提取输入语音的高级特征表示的同时会不可避免 地损失掉一些细节信息，而这些细节信息很难在解码端通过反向卷积恢复，会对 最后的输出增强语音造成损害，而且随着网络层数的加深，模型会变得难以训练, 出现梯度弥散的问题，机器学习领域通常采用跳跃连接(skipconnection)机制汎1 来解决上述问题。跳跃连接一般分为两种，一种是特征图融合相加的方式，将编 码端的提取的语音信号对数功率谱特征和对应解码端的谱特征进行逐时频点相
15 加，此种方式要求编解码端的对数功率谱特征的尺寸和通道数完全一致，另一种 是特征图拼接方式，将编码端的对数功率谱特征和对应解码端的谱特征沿着通道 方向进行拼接，此种方式允许编解码端的对数功率谱特征的通道数可以不同。在 图3-1中，本文采用第二种跳跃连接机制，将编码端的特征图传递到对应解码端， 在通道方向上进行拼接。跳跃连接既有利于模型训练，又有助于恢复目标语音的 细节信息。在下一节的实验仿真中，本文也对两种跳跃连接方式进行了比较，验 证了特征图拼接方式的跳跃连接机制在语音增强领域更具有效性。
3.2.2二维相对自注意机制
上小节对基于UNet架构的全卷积神经网络模型做了详细的介绍和阐述。卷 积神经网络在语音增强领域也已经取得了不错的成绩。然而，卷积算子有一个明 显的特点，它通过有限的感受域来实现局部性运算，一次只处理特征图的一个局 部邻域，即所谓的局部感知能力，这种特性决定了卷积算子很难捕捉到特征图长 距离的上下文信息，从而丢失了感知全局语境的能力，这将不利于更好地恢复目 标语音。此外可以直观地感受到，在卷积网络中每一个通道表征着一种特征类型， 随着通道数的增加，网络中将会产生许多冗余的信息，逐层传递之后将无益于模 型的学习，如果可以通过某种手段帮助卷积网络强调有用的特征维度，抑制冗余 的特征维度，这在理论上可以使得基于卷积网络的语音增强系统性能仍有进一步 提升的空间。
在第二章中，本文已经对一种自注意力机制做了简单介绍，自注意力机制作 为捕获长距离上下文信息的重要进展而出现，已经广泛应用于机器翻译，答案选 择，图像标注等序列建模任务。卷积运算和自注意力机制本质上都是提取和学习 输入特征图信息的一种方式，只不过二者提取和学习数据的模式和侧重点不同， 卷积运算的局部感知能力以及权值共享特性决定了其更擅长学习局部信息。而自 注意力机制背后的核心思想是在输入特征图内部，对不同的隐藏单元(hidden units)赋予不同的权重，比如重要的单元被赋予“1”权重，冗余的单元被赋予 “0”权重，最后计算所有隐藏单元的加权平均值，以此来建模全局不同单元之 间的上下文依赖关系，帮助模型聚焦重要信息。由此可见，相较于卷积运算，自 注意力关注的是特征图内部自身的全局相互关系，因此也得名自(我)注意力机 制。本文研究的重点即是利用自注意力机制去强化全卷积神经网络，提高卷积运 算学习长距离上下文信息、获取输入信号全局语境的能力，由此期望进一步提升 整个语音增强系统的性能。
本小节将一种新的二维相对自注意机制应用于语音增强，它通过将自注意力 机制扩展到二维来加强自注意机制的表征能力，同时保证了卷积运算过程中的平 移等效性。此外，这种新的注意力机制采用了相对位置编码方案，通过在权重矩
16

阵中独立地添加相对高度和相对宽度信息来实现二维的相对位置编码，解决了自 注意力机制中排列等变性的问题。具体的实现方式是在运算过程中将学习局部信 息的卷积特征图连接到能够建模长程相关性的自注意特征图上，生成额外的特征 映射，而不是通过融合相加或者门控制来重新校准原始的卷积特征。二维相对自 注意机制将卷积运算与自注意力运算两者产生的输出特征图在通道维度上拼接 起来，这一特性允许本文灵活地调整注意力通道在整个特征图通道中所占的比例, 理论上可以在卷积关注局部细节和自注意力获取全局语境之间找到最优的组合。 最后，多头的二位相对自注意力机制还可以使模型同时关注空间维度和特征维度 (每个头部对应一个特征子空间)。



图3-3单头二维相对自注意强化卷积模块
如图3-3所示，本文给出了单头的二维相对自注意强化卷积模块的实现流程 图。多头注意力在下文中会给出其公式实现，因为多头的实现流程图较为复杂， 但是通过公式可以比较简洁地表示出来。在图3-3中，给定前一层的特征图输出 维度(T,F,C),其中T代表时间方向，F代表频率方向，C代表通道方向。本文 将前一层的输出(也即当前层的输入)进行展平操作，得到初始的二维张量 XwlfFxc ,通过三种不同的特征映射得到一个单注意力头的查询向量Q, (queries),键向量(keys)以及值向量匕(values),具体实现公式如下： 姑吧	(3-2)
Kh=XWK
(3-4)
其中，三个公式中的下标％表示第方个注意力头，和略wIRg” 是参数可学习的线性变换，用于将输入的特征图重新映射到三种不同的特征空间, dqlk和必分别代表每个注意力头的查询向量/键向量以及值向量的深度。对每 一个单头注意力，二维相对自注意机制的输出为：

其中，S/max(zJ仝严⑵)是一种归一化指数函数，常用在多分类问题上, 工 gexp(zj
代表不同类别的输出在所有可能的输出中所占概率的大小，它首先将输入向量映 射到指数空间，保证概率值非负，然后对所有可能的取值Z,- (z = l,2,3...C)进行归 一化，映射到0-1概率空间。这里本文通过SMmax(・)函数得到注意力机制的权 重矩阵，表示对不同隐藏单元的关注程度，最终得到单头二维相对自注意机制的 输出Ah。相比于一般的自注意力机制，本文在权重矩阵中嵌入了相对高度厅'和 相对宽度/^信息，这是一种相对位置编码方案，可以解决注意力机制中存在的 排列等变性的问题，下面本文进行具体阐述。
在自注意力机制中，如果没有加入明确的位置信息，自注意力是排列等变的， 即对输入序列的顺序并不敏感，因为自注意力机制本质上是对输入序列之间分配 权重，模拟当前序列对其他序列的关注程度，因此排列等变性是算法本身所决定 的，而本文认为这种对顺序的不敏感性对语音信号的增强和恢复是没有帮助的。 由此本文在自注意力机制中引入了相对编码方案，在权重矩阵中独立地嵌入相对 .高度和相对宽度信息。因为嵌入的位置信息是相对的而不是绝对的，所以这种编 码方案在解决自注意力机制排列等变性问题的同时也确保了卷积运算中平移等 效的性质。
在公式3-5中，P^l,P^^xTF分别是时间维度和频率维度上的二维相对 位置矩阵，对任意两个时频单元，它们之间的相对时间位置 和相对频率位置P%j)满足下述公式：
P%j) = q 用Q	(3-6)
形亿力=4心角)'	(3-7)
这里幺e表示第个时频单元的查询向量，也就是0矩阵的第「行向量， S陂％是沿时间维度的相对位置/-丿；的可学习嵌入，同样，礁/欣叫“是 沿频率维度的相对位置if~ jf的可学习嵌入。因此，对时间维度而言一共有 2*7-1个相对位置嵌入需要学习，对频率维度一共有2*F-1个相对位置嵌入需 要学习，这些相对位置嵌入在当前层的所有注意力头之间是共享的。举例说明， 如果本文只看时间维度，并且假设时间维度为3,那么一共有2*3-1 = 5个相对 位置嵌入需要学习：朮z；z•-2), r2(i,i-V),	, rA(i,i + V), rs(i,i + 2), i 表示
第i个时间点，斤(门-2)表示第i个时间点和第12个时间点之间的可学习嵌入， 其他的以此类推。相对位置矩阵展开如下：
18

罗(1,1) 加1,2)罗(1,3) 族) 価) 泅
P；性P『(2,1)耳"(2,2)罗(2,3)=色区)弘区)弘区) (3-8)
护3,1)膚(3,2)罗(3,3) %(彳)血) M
然后，将每个注意力头的输出A e Rr^沿着最后一个维度拼接起来，得到二维 相对自注意机制的输出：
A(X) = Concatenate^ Ai,...,Ah,...,AN]W0	(3-9)
这里N代表注意力头的数量，%€卅恥陋是线性可学习矩阵，用于将拼接起来 的注意力头的输出做一个线性拟合，最后，将&(力的维度变为(T,F,Ndv)a值得 注意的是，不加位置信息的自注意力机制的最大内存消耗为0((7^)2“)，如果保 存所有时频点的可学习嵌入，那么加上位置信息后会额外产生。((加Yd/)的内 存消耗，一般而言dq/k > N o为此，可以将cheng等人提出的高效记忆相对掩蔽 注意算法刖应用于二维相对自注意机制，可以将位置信息的内存消耗降至 0(%)。
最后，本文将标准卷积的输出Conv(X)和二维相对自注意机制的输出班X) 沿通道方向拼接起来，得到注意力强化卷积的最终输出：
O(X) = Concatenate[Conv(X)9 A(X)]
这里标准卷积的输出维度为⑺F,C-Ndv)。
3.2.3基于AAUNet的语音增强算法
encoder	decoder
图3-4注意力强化全卷积神经网络(AAUNet)
本文将图3-1中基于UNet架构的全卷积神经网络作为骨干网络，在此之上 嵌入二维相对自注意机制,在图3-4用"AA Block " (Attention Augmented Block) 表示。考虑到内存占用问题，本文只在编码端的最后三层和解码端的前两层进行 注意力强化卷积操作，本文将带噪语音的对数幅度功率谱作为网络的输入，输出 是增强净化后的对数幅度功率谱，然后将带噪语音的相位信息与增强的对数谱特
19 征相结合，重构出新的语音。卷积层的运算过程大致可分为三个步骤。首先，输 入语音(前一层的输出)由当前层中所有二维滤波器进行频率缩放卷积，然后对 输出通道维度进行批量标准化，最后利用激活函数对卷积特征进行非线性变换得 到当前层输出。二维相对自注意机制将卷积特征图与自注意力产生的多头输出沿 通道方向拼接起来生成新的特征图送入下一层网络，而不是通过融合相加或者门 控机制来重新校准原始特征。这一特性允许本文灵活地调整注意力通道所占的比 例，在卷积关注局部细节和自注意力获取全局语境之间找到最优组合。
此外，本文还将Huber LossQ］用作损失函数，其对噪声具有更好的鲁棒性。 神经网络在解决回归问题中，一般采用传统的MSE准则或者MAE准则作为网 络的损失函数，通过反向传播算法更新网络参数。然而这两种准则都有自己的不 足之处，MSE准则受噪声点影响较大，对误差较为敏感，MAE准则的梯度不可 变，且在y~f(x) = 0处不可导，这都不利于模型的收敛和学习。Huber Loss则将 二者结合起来，通过调整超参数在理论上可以融合二者的优点同时消除二者的不 足，具体公式如下：
扣\y-f{x^<8
厶(y-/(x)) = *	.	(3-11)
3\y-f^~82 \y-f{x^>8
其中，3是一个超参数，5的大小决定了 Huber Loss对MSE和MAE的侧重 性，当卩-选择MSE准则，当\y-f(x)\>3,选择MAE准则。
3.3实验结果与分析
在深度学习领域中，海量的训练数据、精心设计和处理的数据工程对网络模 型性能的提升起着十分重要的作用，本文将详细讲述整个实验数据集的选择及预 处理过程、语音增强性能的评估指标，并在此基础上对所有的消融实验、对比试 验进行阐述和分析，验证所提出模型的增强性能。
3.3.1数据预娅及实验配置
在本论文中，本文选用TIMIT语料库作为语音数据集。TIMIT语料库是目 前语音识别、语音分离与增强领域常用的英文数据集，它取样于630位来自美国 八个不同自治州的说话人，大部分为成年男性，每人说同样的10句话，共6300 条句子，规定其中462人说的话用作训练集，剩下的作为测试集，所有语音的采 样频率为16kHz,长度不一。在本实验中，本文随机打乱TIMIT语料库，并取其 中的4620句话用作语音训练集，又随机选择了另外200条不在训练集中的句子 作为语音测试集。为了保证训练效果的同时减少训练的数据量，本文将所有的原
20 始语音统一切割成2秒，并将其下采样到8kHz,这样便减小了一半的数据量。 与此同时，为了最大限度克服静默段对训练结果的影响，本文使用语音活动检测 （VAD）算法去除了所有语音的开始和结束部分的静默帧。本文选用NOISEX- 92噪声库来模拟现实场景中真实存在的噪声环境oNOISEX-92噪声库是1990年 由欧洲相关语音研究所采集自现实生活中的15种不同种类的噪声，所有噪声的 采样频率统一为19.98kHz,时长为235秒。所以为了与语音数据集匹配，本文需 要对其进行重新处理，包括音频切割，重采样等操作。本文从中选择了 4种不同 类型的噪声作为训练噪声，分别为白噪声（white）、工厂噪声1 （fkctoryl）、坦克 内部噪声（ml09）以及F16座舱噪声（fl6）。此外，为了验证模型的泛化能力， 本文选择了另外2种失配的噪声类型作为测试噪声，分别是粉红噪声（pink）和 工厂噪声2 （factory2）0下面本文将具体阐述训练集和测试集的构造过程。
对于训练集，本文将选取的TIMIT语料库中的4620句话，在-2.5dB、OdB、 2.5dB、7.5dB和12.5dB这五种信噪比条件下，与NOISEX-92噪声库中的4种背 景噪声（white、factory 1> ml09和fl6）混合，合成具有4种噪声类型和5种信 噪比水平的训练集，即4620X4X5=92400条带噪语音。此外，本文又随机选取 训练集数据中的20%作为验证集，以防止网络训练时发生过拟合现象。在测试集 中，本文加入了不匹配的噪声和不匹配的信噪比来衡量模型的泛化性能，把选取 的两种失配的噪音类型（pink和短ctory2）在一种匹配的信噪比水平（OdB）和三 种不匹配的信噪比水平（-5dB、5dB和10dB）上对另外200条纯净语音进行一 对一随机破坏，合成200条带噪语音测试集。最后，本文将使用短时傅里叶算法 对所有语音进行时域到时频域的变换，得到可输入网络的数据。本文用长度为 32ms （256点）的汉明窗，16ms （128点）的重叠移动，即50%的overlap对语 音波形进行分帧加窗，随后进行256点的短时傅里叶变换，得到语音信号的复数 频谱特征，提出其中的幅度谱特征，并取其对称的一半（129点）特征数据，再 平方取对数后得到语音信号的对数功率谱，就得到了本文输入到网络模型中的特 征数据。
网络模型的输入和输出都是124点时间帧，129维频率点的二维对数功率谱 特征。模型主要由14个卷积层组成，卷积核的大小为3X3,卷积步长的大小为 1X2,每个卷积层的通道数依次为 8-16-32-64-128-128-256-256-128-128- 64-32- 16-1,每一层的时间维度通过补零填充操作保持不变。在编码端的最后三层和在 解码端的前两层上执行注意力强化卷积操作。注意力头的数量为2,注意力通道 数占当前层所有通道数的比例是25%,即JV</C = 0.25,并取dg/k=dv,注意力 机制内的卷积核的大小为3X3,卷积步长的大小是1X1。在训练阶段，本文使 用Adam优化器进行模型的训练，并将初始学习率设置为0.005, 0严0.9,
21
02 = 0.999 , £ = l.Oe-8 o根据经验，本文将Huber Loss的超参数设置为8。epoch 的数量设置为15, mini-batch的大小设置为10。当验证集的损失超过2个epochs 之后不再下降时，本文使用学习率衰减策略将学习速率减少一半，最小至l.Oe"。 需要指出的是，上述网络模型参数设置以及训练策略在下一小节的实验中通用， 当涉及到控制变量实验时，如需微调上述参量，在实验开始部分会给出说明。
本文采用最佳修正对数功率谱估计器(OMLSA)结合最小控制迭代平均 (IMCRA)算法、UNet全卷积神经网络与本文提出的AAUNet进行性能比较。 此外，为了验证二维相对自注意机制在卷积网络中的通用性，本文将其融合到其 他的卷积网络(CED)中进行实验。CED网络也是一种编解码网络，主要有三点 不同：第一，通道数量不同，每层的通道数量依次为16-32-64-128-256-512-126- 128-64-32-16-1；第二，跳跃连接为融合相加而不是特征拼接；第三，损失函数采 用MSE准则，其他条件与本文提出的模型相同。
3.3.2语音增强性能评估指标
评估语音增强性能的标准可以分为两大类，一类是主观测听打分(mean opmion score, MOS),随机选取听众，对增强语音进行听力打分，取平均值后得 到算法的增强性能。这种评价方法主观性过强，没有统一的标准，不方便不同算 法模型的相互比较。另一类是客观评价方法。这种评价方法涉及的指标有很多， 为了进行多角度比较，这里本文选取了两种单一型评价指标和三种复合型评价指 标作为本文的评估指标。下面对五种指标做简单介绍。
客观语音质量评估(Perceptual evaluation of speech quality, PESQ)是语音增 强领域最重要的评估指标，在它内部通过设计众多复杂的算法对输入语音的整体 质量进行评价，得分范围为-0.57.5分，分数越高代表语音的质量越好。值得一 提的是，虽然PESQ是一种客观评价方法，但是它输出的得分和MOS的打分较 为一致。
短时客观可懂度(Short-Time Objective Intelligibility, STOI)旨在衡量增强语 音的可理解性。例如当发送方通过即时通信软件向接收方发送一段语音信号，在 传输过程中出现大量丢包现象，当接收方收到语音后，尽管接收到的语音质量较 高，但由于缺少了许多单字，语音的可懂度会随之下降。STOI便是衡量这个方 面的一个指标，评分范围为0〜1分，分数越高代表语音的可懂度越好。值得一提 的是，STOI在低信噪比时测评的结果更有意义。
信号失真(SIG)的复合测度，噪声失真(BAK)的复合测度，以及整体语音质量 (OVL)的复合测度，三种评估指标［呵是综合了 PESQ、分段信噪比(segSNR)、加 权斜率谱距离(weighted-slope spectral distance, WSS)以及对数似然比(log- likelihoodratio,LLR)的复合测度。分别代表语音信号的恢复质量，背景噪声的去
22
除程度以及增强语音的整体质量，三者的分数范围均为1〜5分，分数越高代表结 果越好。
3.3.3仿真实验结果分析
在3.2节中已经详细阐述了注意力强化全卷积神经网络的基本原理以及实现 方法，本小节将通过消融实验、对比试验来检验所提出语音增强网络模型的整体 性能和泛化能力。本小节中得到的所有结果均为各自在测试集上得到的平均值, 与训练集的数据结果无关。下面本文将进行具体的实验结果分析。

保证算法的收敛性是其他所有仿真实验的基础，在此基础上讨论算法的性能 才有意义，因此本实验将对所提出的AAUNet语音增强算法的收敛性进行测试。 结果如下图所示：


迭代欢數
图3-5 AAUNet语音增强算法收敛图
上图表示的是AAUNet语音增强算法的收敛性曲线。横坐标代表训练的轮 数epochs,这里一共训练了 40轮。纵坐标代表损失函数(HuberLoss)的值。可 以看到，在开始的几个训练轮数下网络收敛较快，在整体上随着训练轮数的增加, 网络的损失值逐渐下降，最终达到收敛状态。虽然在第17个epoch之前，损失 值呈震荡状态，并在第15个epoch ±呈现出较大误差，但在整体趋势上整个网 络的训练仍是收敛的。由此可见，本文提出的注意力强化全卷积神经网络 AAUNet的收敛性是有所保证的。

本组消融实验将探究AAUNet在是否嵌入相对位置信息的条件下，注意力 通道数在整个通道所占比例对网络模型整体性能的影响。信噪比水平为-5dB,这 里选择PESQ和STOI作为评估指标，AAUNet分为有位置信息(position)和无

位置信息(no-position)两种模型，每种模型的注意力通道数所占比例又包含5 种可能(0, 25%, 50%, 75%, 100%),其中“0”表示不进行注意力强化卷积操 作，是常规的UNet网络，100%表示全注意力通道，即没有卷积通道。综上，本 组实验一共测试了 10种AAUNet网络模型，具体结果如下图所示：

;1 .G !J)也逍数

图3-6 PESQ与注意力通道比例的关系
图3-6表示PESQ与注意力通道所占比例的关系。纵轴表示PESQ分值，得 分范围为-0.5〜4.5分，横轴表示通道比例系数。图中共有两组曲线，分别表示有 相对位置信息嵌入(position)和没有相对位置信息嵌入(no-position)的情况。 从图中本文可以观察到，对于有位置信息嵌入的情况，当注意力通道数比例为25% 时，也就是注意力通道数与卷积通道数的比例为1： 3时，PESQ分数达到最大 值，当注意力通道比例继续增加时，PESQ分数逐渐减小，表示网络模型的性能 呈下降趋势，说明注意力通道数并不是占比越高越好。对于没有位置信息嵌入的 情况，PESQ分数随着注意力通道数比例的提高而提高，在75%占比的情况下达 到最大值，全注意力模型仍旧没有达到最好的性能。但二者相较于原始的UNet, 模型的性能已经有了较为明显的提升。纵向比较，没有位置信息嵌入的模型在注 意力通道占比75%的情况下取得了最优的性能，这表明输入特征图中隐藏神经 元之间的位置信息对语音增强性能的提升并不是不可或缺的，此外也可以发现， 二维相对自注意机制只有和卷积操作结合时才能发挥更好的性能，全注意力模型 并不是最优解。
图3-7表示STOI与注意力通道所占比例的关系。纵轴表示STOI分值，得 分范围为0〜1分，横轴表示通道比例系数。从图中本文可以观察到，对于有位置 信息嵌入的情况，当注意力通道数比例为25%时，STOI分数得到最大值，当注 意力通道比例继续增加时，STOI分数逐渐减小。对于没有位置信息嵌入的情况，
24

STOI分数在75%占比的情况下得到最大值，但二者相较于原始的UNet,随着通 道数比例的增加，在整体上呈现下降趋势，这表明即使在position with25%和noposition with 75% 情况下，模型的STOI分数得到提高，但二维相对自注意机制对 语音增强性能的影响并不总是正向的，在全注意力情况下STOI分数甚至有了明 显的下降。也由此可见，语音信号的质量和可懂度之间并不是正向的关系，语音 质量的提高并不意味着可懂度的提高，在设计系统性能时应作出权衡。

注邈力適道数
图3-7 STOI与注意力通道比例的关系

本组消融实验将探究AAUNet在是否嵌入相对位置信息的条件下，注意力 头的数量对网络模型整体性能的影响。信噪比水平为5dB,这里选择SIG和BAK 作为评估指标，AAUNet分为有位置信息(position)和无位置信息(no-position) 两种模型，每种模型的注意力头数有4种可能(1, 2, 4, 8)„综上，本组实验 一共测试了 8种AAUNet网络模型，具体结果如下图所示。
图3-8表示SIG与注意力头数量的关系。纵轴表示SIG分值，得分范围为 1~5分，横轴表示注意力头的数量。图中共有两组曲线，本文可以从中观察到， 对于有位置信息嵌入(position)的情况，随着注意力头数量的增加，SIG分数逐 渐提高，在注意力头数量为8个头时达到最大值，表明二者是呈正相关的，带有 位置信息的注意力头数量对目标语音的质量有积极的作用。值得注意的是，8个 头相比于4个头的情况，SIG分数只有是有略微的提高，但却要付出较高的计算 成本，相比之下，4个头的注意力机制或许是更好的选择。对于没有位置信息嵌 入的情况(no-position),除了注意力头数为2时SIG分数出现了下降，其他情况 可与嵌入位置信息的得分相差无几，再一次表明在语音增强领域上，注意力机制 会带来性能的提升，但是否嵌入隐藏神经元之间的位置信息是不重要的。纵向上
25
来看，两条曲线都在注意力头为4的情况下取得了较好的SIG分数，本文将其设 置为模型的最佳参数。

注意力头数
图3-8 SIG与注意力头数量的关系

图3-9表示BAK与注意力头数量的关系。纵轴表示BAK分值，得分范围为 1〜5分，横轴表示注意力头的数量。两组曲线从整体来看，除了注意力头为2的 情况，没有位置信息嵌入的模型要全面好于有位置信息嵌入的模型，在每个注意 力头（1, 4, 8）的条件下都获得了更高的BAK分数，这表明对噪声的抑制能力 更加出色。两条曲线都在注意力头为8时达到了 BAK的最佳值，但同样，相比 于注意力头为4时未有较大的提升，表明注意力头为4仍是模型兼顾性能和计算 参量的最优解。

注意力头数
图3-9 BAK与注意力头数量的关系

26
表3-1 OVL与注意力头数量的关系

position
no-position

表3-1表示整体语音质量OVL在四种信噪比(-5dB, OdB, 5dB和10dB)条 件下与注意力头数量(1,2, 4, 8)之间的关系，又分为有相对位置信息(position) 和没有相对位置信息(no-position)两种情况。从整体上来看，no-position的整体 语音质量得分仍普遍好于position的得分情况，同样，在注意力头为8时双方都 取得了各自的平均最优值，然而相对于注意力头为4的情况，得分到的提升并不 明显，但在四种信噪比条件下，注意力头为4和8的得分要明显好于1和2的情 况。综上，本组实验得出的结论为：带有4个注意力头的不嵌入相对位置信息的 注意力强化卷积网络模型，在兼顾计算参量的情况下可以获得语音增强性能的最 优值。

(a)	跳跃连接


图3-10两种拼接型特征图的跳跃连接方式
(a)注意力强化特征图跳跃连接；(b)原始卷积特征图与注意力强化特征图分别跳跃连接 本组消融实验将探究AAUNet在是否嵌入相对位置信息的条件下，特征图 的跳跃连接方式对AAUNet语音增强性能的影响。信噪比水平为OdB,这里选择 PESQ, STOI, SIG和BAK作为评估指标，AAUNet本身采用了特征图拼接的方 法，在此基础下又有两种特征图的跳跃连接方式，一种是只对注意力强化的特征 图进行跳跃连接(aat skip-pos, aat skip-np),另一种是将原始卷积特征图和注意 力强化特征图分别进行跳跃连接操作(Conv-att skip-pos, Conv-att skip-np ),具体 如图3-10所示，各自又分为有位置信息和没有位置信息两种情况，所以本组实 验一共测试了 4种AAUNet网络模型，具体结果如图3-11所示。

图3-11 4种跳跃连接模式在4类指标上的平均得分
图3-11表示4种特征图的跳跃连接模式在4类指标上的平均得分。横轴表 示4类评估指标，纵轴表示4类指标的得分范围，"aatskip-pos”表示带位置信息 的注意力强化特征图跳跃连接方式，“aat skip-np”则表示不嵌入相对位置信息。 “Conv-att skip-pos”表示带位置信息的原始卷积与注意力强化特征图分别跳跃 连接的拼接方式，“Conv-attskip-np”则表示不嵌入相对位置信息。对于注意力图 跳跃的拼接方式，带位置信息的模型在四种指标上的得分普遍高于不带位置信息 的模型，而对于原始卷积与注意力强化特征图分别跳跃连接的拼接方式来说刚好 相反。从整体上来看，四种模型的PESQ、STOI、SIG、BAK得分相比于带噪语 音(noisy)的得分均有明显的提高，而Conv-att skip-np模型不论在语音质量、 清晰度以及噪声抑制能力上均取得了最高的分数，表明不嵌入位置信息的原始卷 积与注意力强化特征图分别跳跃连接的拼接方式可以取得较优的语音增强性能。 在 STOI 指标上，Conv-att skip-np 的得分为 0.8328, Conv-att skip-pos 的得分为 0.8228,四种模型的得分相差无几，这表明它们对带噪语音语音可懂度(0.7201) 的提高能力是近乎相同的。

本组对比实验将探究AAUNet分别使用三种损失函数用作训练的条件下， 检验模型的收敛性以及对语音增强性能的影响。本组实验在信噪比水平为-5dB 条件下进行，选择PESQ、STOI、SIG作为评估指标，本组实验一共测试了 3种 AAUNet网络模型，它们之间仅在训练时的损失函数不同，其他所有参数均保持 一致。3种模型的收敛性如图3-12所示，对语音增强性能的影响如图3-13所示。
图3-12表示三种损失函数(MSE, MAE, Huber Loss)的收敛曲线图。纵轴 表示损失值大小，横轴代表训练的轮数。从图中本文可以观察到，单从收敛性上 看,结合了 MSE和MAE优点的Huber Loss具有更快的收敛速度，相比于MSE,
28

Huber Loss对异常点（epoch=15）的鲁棒性更强，同时又克服了 MAE在零点不 可导的缺点。综上，三者的收敛性在模型的训练中均有保证，但H uber Loss的收 敛性更好，且对异常值不会过于敏感，在训练过程中的表现优于前者。

图3-13 3种损失函数在3类指标上的平均得分
图3-13表示在-5dB信噪比水平下，上述3种损失函数训练的模型在3类指 标（PESQ,STOI,SIG）上的平均得分，从测试的角度对3种损失函数进行评价。 纵轴代表评估分数，横轴代表3种评价指标，同时附上了三种损失函数的平均得 分数据表。从整体来看，3种损失函数训练的模型，相对于带噪语音（noisy）而 言，在STOI得分，PESQ得分以及SIG得分上均有明显的提升，表明它们具备 恢复带噪语音质量，提升语音可懂度的能力。仅比较三种损失函数，从分值上来 看，Huber Loss在PESQ和STOI指标上取得了略高的分数，MSE在SIG指标上
29 取得了略高的分数，Huber Loss次之。但其实对于人耳来说，是无法在恢复的目 标语音中分辨出三者的区别的。最后需要指出的是，由于Huber Loss的超参数是 基于次优的经验值设置的，有一定主观误差性，如果采用网格搜索法找到最优的 超参数，本文相信Huber Loss在收敛性和去噪能力上仍会有进一步提升的空间。 333.6增强语音波形及其语谱图分析对比
本组实验给出了经过AAUNet网络模型增强后的一条语音时域波形图，以 便更加直观地观察语音增强后的效果，同时给出了对应的对数功率谱，并与UNet 进行纵向对比，以探究经过注意力机制强化后的卷积网络相比于原模型有哪些方 面的改善。


图3-14AAUnet增强后的语音时域波形图
图3-14展示了测试集中的两条条语音，在OdB信噪比水平下被噪声破坏的 带噪语音的恢复情况。图中共有六条语音时域波形，最左侧两条波形为被噪声破 坏的带噪语音，中间两条是取自TIMIT语料库中的原始干净语音，最右侧是经 过AAUnet去噪后的两条增强语音。所有语音已经提前切割成2秒，下采样到 8kHz,通过VAD算法去除了开始和结束的静默帧。从图中可以十分直观的看到， 和带噪语音相比，增强语音在语音活动单元已经得到了很好的恢复，成功抑制了 大部分的背景噪声，不过在静默段仍有微弱的噪声残留，但己经不会影响整体的 语音听觉质量。
图3-15展示了一条在OdB低信噪比水平下被“工厂2”噪声破坏后的测试 语音的4种对数功率谱。（a）图表示该条测试语音的带噪对数功率谱，（b）图表示 该条测试语音的纯净对数功率谱，（c）图表示该条测试语音经UNet网络去噪后的
30
增强对数功率谱,(d)图表示该条测试语音经AAUNet去噪后的增强对数功率谱。 对数功率谱的横轴代表时间，纵轴代表频率，从图中可以看到，相比于带噪功率 谱，两种语音增强网络均较好地恢复了目标对数谱。相比于UNet, AAUNet在 细节方面更好地还原了测试语音的特征谱，特别是在图中被矩形框标出的部分。

图3-15 一条测试语音的4种对数功率谱对比

在本组实验中，本文将对不同的语音增强算法的整体性能进行对比与分析, 一共选取了 5种语音增强算法，包括OMLSA-IMCRA, UNet, AAUNet, CED和 AACEDo其中OMLSA-IMCRA是传统单通道语音增强的最佳算法，在下述实验 中将用简称OMLSA表示。选择另一种全卷积编解码网络CED的目的是为了验 证二维相对自注意机制对卷积网络增强效果的通用性。本组实验一共在2种不可 见噪声和4种信噪比(-5dB, OdB, 5dB, 10dB)条件下进行，覆盖了从极低信 噪比到高信噪比的常见范围，其中除了 OdB外其他三种均属于不可见信噪比。网 络的参数配置详见3.3.1节，5种算法的具体对比分析如下表所示。
表3-2表示含噪语音及3种不同增强算法(OMLSA, UNet, AAUNet)在4 种信噪比水平下SIG, BAK和OVL的平均得分。本组实验旨在进行模型的横向 对比和纵向对比，验证所提出模型AAUNet的语音增强性能。从表格中本文可以 看到，在所有信噪比水平下，AAUnet在三个指标上的得分都超过了 OMLSA和 Unet,而且远远超过了 OMLSA传统算法。只看纵向实验，在语音失真SIG方 面，AAUnet比带噪语音和经Unet增强后的语音分数分别高出30.0%和4.7%, 在抑制背景噪声BAK方面，AAUnet的分数则分别提高了约43.1%和4.6%,对
31 于最后整体处理后的语音质量OVL,AAUnet得分则比带噪语音得分高出33.6%, 比UNet得分高出4.4%o实验结果表明，基于注意力强化卷积的语音增强算法 AAUNet对未知信噪比和背景噪声具有更好的泛化能力，可以更好地平衡噪声抑 制和语音失真，具有较好的语音处理质量。本文提出的网络模型只需要增加少量 的训练参数就可以获得去噪能力的提升，取得了比所有对比算法更好的性能。
表3-2含噪语音及不同增强算法在4种信噪比下的SIG, BAK和OVL得分

SIG
BAK
OVL

noisy
OMLSA
Unet
AAUnet
noisy
OMLSA
Unet
AAUnet
noisy
OMLSA
Unet
AAUnet
-5


表3-3含噪语音及不同增强算法在4种信噪比下的PESQ和STOI得分
标
PESQ
STOI

noisy
OMLSA
CED
AACED
Unet
AAUnet
noisy
OMLSA
CED
AACED
Unet
AAUnet
-5

表3-3表示含噪语音及5种不同的语音增强方法在4种信噪比下的PESQ和 STOI平均得分。从表中可以看出，在可见信噪比（OdB）和不可见信噪比（-5dB、 5dB、10dB）的情况下，本文提出的算法模型AAUnet对平稳噪声和非平稳噪声 的抑制能力超过了所有其他方法。AAUnet的平均PESQ和STOI评分与带噪语 音相比分别提高了 28.3%和11.1%,与0MLSA相比分别提高了 18.0%和18.6%, 与Unet相比分别提高了 4.0%和1.6%。另外，通过比较CED网络和AACED网 络（AACED是CED经过注意力强化后的网络模型）的两项评估指标的得分，可 以证明注意力强化卷积模块（AABlock）可以作为一种插件集成到其他卷积网络 中，从而提高模型的整体性能。本文还注意到，与CED相比，UNet的PESQ得 分更高，而STOI得分稍低，而当两者都通过注意力强化后，AAUNet的STOI得 分已经完全超过了 AACED,这表明本文提出的网络模型在语音可懂度方面有着 更好的表现。
3.4本章小结
本章的研究重点是提高卷积网络学习长距离上下文信息，获取输入信号全局 语境的能力，以弥补卷积运算只关注局部特征的不足，旨在增加少量训练参数的 前提下提升原有卷积模型的语音增强性能。本章首先给出了一种基于UNet架构 的全卷积神经网络语音增强模型，然后又详细研究了一种新的二维相对自注意机 制的原理，其在图像识别与目标检测领域已经被证明是十分有效的。最后本章提 岀了一种用于单通道语音增强的注意力强化全卷积神经网络，将这种新的二维相
32
对自注意机制应用到全卷积神经网络中，通过灵活调整注意通道的比例，可以在 卷积关注局部细节和自注意力获取全局语境之间找到最优的组合。此外，在提出 的网络模型中，本文采用Huber Loss作为损失函数，它结合了 L1和L2损失的 优点，对噪声有较好的鲁棒性。随后本章详细介绍了与实验有关的数据预处理工 作与网络参数设置，共进行了 7组消融实验和对比试验，实验结果表明，本章提 出的模型性能优于所有的比较算法，能够更好地平衡噪声抑制和语音失真。本章 还将二维相对自注意机制应用到其他语音增强卷积网络中，并提高了网络去噪的 能力，表明这种注意力机制可以作为一种插件应用于基于卷积运算的语音领域， 具有良好的通用性。
33

34


第四章基于独立自注意机制的语音增强算法
4.1引言
卷积神经网络吸引了许多研究人员的关注，已经在语音信号处理领域中取得 了许多不错的成绩，在诸如语音识别，语音分离与增强等技术上都涌现出了许多 基于深度学习卷积神经网络的信号处理算法。然而，由于卷积运算具有权重共享 和局部感知的固有特性，在一个较大的感受域内放缩特性较差，导致其难以学习 到特征图内长距离的上下文依赖关系。为了解决卷积运算存在的问题，研究人员 最开始侧重于重新设计卷积算子，寄希望于从卷积网络本身寻求突破，例如膨胀 卷积(又名扩张卷积，空洞卷积)。在计算机视觉领域，已经有研究人员开始将 具备全局相关性建模能力的注意力机制应用于传统的卷积神经网络中，比如通道 挤压激发(Squeeze-and-Excite)机制，空间感知非局部模块(Non-local Block) 等，这些方法都是将注意力机制用作一种校正手段与卷积网络结合，通过重新校 准原始卷积特征图来帮助网络提升捕获长距离交互作用的能力。在语音增强技术 领域，将注意力机制与卷积网络相结合的做法尚数少数。Hao等学者在2019年 提出了一种结合非局部模块的卷积神经网络，将计算机视觉任务中兴起的这种注 意力机制应用到语音增强领域中来。Lan等学者在2020年提出了一种结合通道 挤压激发机制的卷积神经网络用于语音增强，可以帮助模型学习重要特征，抑制 无用特征。上述方法在其各自的论文中表示，实验结果显示将注意力机制与卷积 网络相结合的做法不仅提高了神经网络的计算效率，而且在客观语音清晰度和语 音质量指标方面都优于其他对比方法，这给本文的研究指明了方向。
不同于上述论文中的做法，本文在第三章提出了一种用于单通道语音增强的 注意力强化全卷积神经网络AAUNet,将一种新的二维相对自注意机制嵌入到基 于UNet架构的全卷积神经网络中，将卷积运算与自注意力运算两者产生的输出 在通道维度上拼接起来，这一特性可以灵活地调整注意力通道在整个特征图通道 中所占的比例，理论上可以在卷积关注局部细节和自注意力获取全局语境之间找 到最优的组合，强化卷积运算获取全局语境的能力。然而，本文在实验中发现， 将这种注意力机制的通道数占比设为100%时，也就是全注意力模式，语音增强 的效果呈现下降趋势，因此将这种注意力机制与卷积结合使用是一种理想的选择。 在本章中，本文将尝试在语音增强领域用完全注意力机制来替代卷积运算，力争 用最少的参数实现最优的性能。
4.2独立自注意机制融合卷积网络
35
本小节将详细介绍一种基于独立自注意机制的语音增强算法，并通过一系列 的消融实验得到最佳的网络模型，通过对比实验来验证所提出算法的语音增强性 能以及泛化能力。这里需要说明的是，本章目前的工作仅将这种注意力机制用作 语音增强模型的独立一层，与模型中的卷积网络融合，而不是完全替代整个卷积 网络。在这独立的一层中完全替代卷积层，也就是在此层中是全注意机制而没有 卷积算子的参与，这样一方面可以在原有工作基础上快速开发新的语音增强模型, 另一方面也便于对比试验的进行。在未来的工作中，可以继续探索完全抛弃卷积 的基于纯粹注意力架构的语音增强模型。
4.2.1独立自注意机制
在介绍独立自注意机制之前，本文先对一般卷积运算的特点进行简要介绍， 并由此引出独立自注意机制。
局部邻域


图4-1卷积运茸图
图4-1表示卷积运算的示意图。最左侧方形网格代表输入特征图，中间方形 网格代表一个卷积核(又名滤波器)，与输入特征图的局部邻域大小保持一致。 输入特征图的局部领域与卷积核通过逐像素点乘再求和得到输出特征图上的一 点输出，如图中最右侧方格所示。推广到一般情况，给定输入XGRAXWXC；,其中力 代表输入特征图高度，w代表宽度，ci代表输入通道数。特征图的任意一个局部 邻域用Ng表示，其中V代表局部邻域的中心点列的坐标，k代表局部邻域 的大小。一个卷积核所代表的可学习权重矩阵为FFeR™,若有多个卷积核同 时对局部邻域做卷积则有,其中co代表卷积核数量，也即输出通 道数。则此局部邻域的输出为：
(4-1) 其中，加，"代表局部邻域中像素点乙”的坐标，聲”为该像素点对应的卷 积核中的权重值，将所有点积求和后得到一个输出像素点之后再根据
36
卷积运算的权重共享和平移等效的性质，逐邻域地将输入特征图通过卷积运算映 射为输出特征图。
受谷歌大脑团队的研究启发，本文将一种独立自注意机制应用于语音增强， 可以用来代替卷积算子。与图4-1中的卷积操作类似，这种独立自注意机制的本 质是对输入特征图的任意给定的局部邻域做自注意力运算，得到该局部邻域的一 点输出，然后对输入特征图的所有像素点依次进行上述运算，得到最终的输出特 征图。为了让独立自注意机制具备位置感知能力，解决排列不变性的问题，在此 引入了第三章中介绍的相对位置编码方案。此外，为了弥补与卷积运算之间的差 距，让善于捕捉高层次全局信息的注意力机制能最大限度兼顾低层次边缘局部细 节，本文在值矩阵中注入了基于绝对位置信息的距离感知特征。这里需要说明的 是，上文中提到的位置感知和距离感知能力是基于不同的方法实现的，位置感知 能力是通过将查询向量和二维相对位置编码做矩阵乘法实现，解决的是注意力机 制排列不变性的问题；距离感知能力是通过结合绝对位置信息的多值矩阵来实现, 目的是利于全注意力机制更好地捕捉特征图的低层次特征和边缘细节。后续的仿 真实验表明，基于独立自注意机制的语音增强模型具备更少的网络参数和更优的 去噪性能，下面将进行详细介绍。

图4-2单头局部独立自注意机制
图4-2给出了单头局部独立自注意机制的实现示意图。最左边代表输入特征 图，与卷积类似，这里提取一个以为中心的局部邻域，后续的计算流程 都是在这个局部邻域上展开的。通过注意力核，一种可学习的线性变换(learned transform),得到亏的查询向量和局部邻域上各像素点的键矩阵和值矩阵，如图 中虚线所示，再通过将权重矩阵(查询向量和键矩阵做矩阵乘法并通过softmax 归一化)和值矩阵进行逐像素做点积后求和，得到列的输岀儿，即输出特征图的 一个像素，如图中实线所示。计算单头局部独立自注意机制的公式如下：
q产 “Q%	(4-2)
37
kmn ^kXmn	(4-3)
% = Wvxmn	(4-4)
儿=(4-5) 其中％ xmn丘口表式局部邻域m,neNK (，J)的中心像素和邻域像素，k代表方形 的局部邻域的大小，局部独立自注意机制要做的就是计算出此中心像素与局部邻 域内所有邻域像素之间的依赖关系。WQ,WK,WVGW°^是可学习的线性变换，分 别叫做查询注意力核，键注意力核以及值注意力核，用于将局部邻域中的像素映 射为查询向量9严踏，键向量km„eW°以及值向量％ 衆化$劝max””(・)表示 对一个局部邻域刃，"w N许，力内所有的像素点进行理A max归一化后，像素点 入”相对于中心像素列的权重大小。最后通过与值向量vmneRC0做矩阵乘法后求 和，得到局部邻域的输出对输入特征图的其他局部邻域依次做相同运 算，得到最后的输出特征图。
将公式4-5与公式4-1比较可以发现独立自注意机制和卷积运算的相似性。 卷积运算通过将感受域内的所有像素点与卷积核对应权重做点积再求和后得到 输出，而注意力机制通过计算中心像素与邻域像素之间的依赖性(权重)大小， 并与局部邻域内所有像素映射得到的值向量做点积再求和后得到最终输出。在第 三章中曾提到还可以将注意力机制扩展到多头，每个头部对应一个特征子空间， 学习输入数据的不同特征表示。基于N个头的独立自注意机制只需将中心像素 列分为N组，得到x； eRc//,v ,将三个可学习线性变换分为N组，得到
,然后分别做上述单头注意力运算，最后将每个注意力头的输 Q K V
出j, e欣皿拼接起来得到多头注意力的输出儿e踏o
下面本文将在独立自注意机制中嵌入相对位置信息。在第三章中的二维相对 自注意机制小节中，本文使用了相对位置编码方案，通过在权重矩阵中添加相对 高度和相对宽度信息来实现二维的相对位置编码，解决了自注意力机制中排列等 变性的问题。尽管在随后的仿真实验中发现具有位置信息的注意力机制并未取得 最优的语音增强性能，本文分析这可能与输入对数功率谱图过大，且相对于语音 时域波形而言己经不再是序列化信号，注意力对其进行全局位置的建模反而会产 生很多无用的冗余信息进而影响模型性能，但在局部独立自注意机制中或许是有 效的，因此本文在本节中仍将其作为一个可选项，通过后续的消融实验来验证本 文的想法。相对位置编码方案在第三章中已经给出了详细的阐述，这里只给出局 部相对位置编码的公式，不再具体展开讨论。局部相对位置编码的具体公式如下：
y.j =工”,,”出(,；/)$" max”,” (力―+力汕 +尬—)％	(4-6)
38 公式中字符的具体含义与实现方式在第三章已经给出介绍。相比于公式4-5,公 式4-6在计算陷相对于中心像素点勺的权重时，同时嵌入了相对高度和相对宽 度信息，所以两个像素点之间的权重是由像素内容和像素之间的相对位置共同决 定的，通过注入相对位置信息，注意力机制也具备了类似于卷积的平移等效性， 进一步模拟了卷积的能力。
为了弥补与卷积运算之间的差距，在尽可能少地增加参数的前提条件下，让 善于捕捉高层次全局信息的注意力机制能最大限度兼顾低层次边缘细节，本文在 独立自注意机制中加入了基于绝对位置信息的距离感知的能力。对于卷积运算， 卷积核中的可学习权重参数是基于像素距离的，这种特性对卷积在学习局部边缘 特征方面起着关键作用。在网络的初始几层，输入的信号对网络而言具有更多低 层次的特征，进入网络的编码端后被逐层提取抽象的高层次特征，在这个过程中， 初始几层的卷积运算将具备低层次边缘学习的能力，而这对于基于内容交互的自 注意机制而言是较为困难的。
为了解决上述问题，本文修改了值向量的获得方式，在值向量中注入了像素 的绝对位置信息，用多个值注意力核的加性组合来替代传统的值注意力核，每个 值注意力核都有各自的权重，此权重是局部邻域内的像素的绝对位置的函数，且 所有权重的加和为1。值向量由如下公式得到：
%=(工屛(九"，2席片”	(4-7)
与公式4-4相比，值注意力核豹变为了多值注意力核晞的加性组合，其中每个 值注意力核呼都是一种可学习的线性变换，各自的权重系数P(m,n,A)是像素的 绝对位置(加异)和多值数;I的函数，多值数是一个超参数，和注意力头数类似， 需要人为设定。权重系数P(弘"，刃由如下公式得到：
p(m, n, A) = soft maxx ((rm + rn )r rj	(4-8)
其中，“乙€时分别表示像素％的可学习的行位置嵌入向量和列位置嵌入向量, 也是一种可学习的嵌入向量，用于辅助和融合行列位置嵌入。50/?max/.) 表示将归一化函数$Mmax(・)应用于像素忌”的所有位置嵌入表示后，第A个位 置嵌入的权重。
此外，卷积运算的参数量随着感受域的增大而迅速增加，而独立自注意机制 的参数量主要与输入特征图和输出特征图的通道数cj和CO有关。Ramachandran 等人［39〕指出，当ci = co = 128时，k = 3的卷积层和k = \9的独立全注意层拥有 相同的参数量和计算代价。然而本文在模型训练中发现对于相同的输入，尽管独 立自注意机制有着更少的训练参数，但计算代价却并不小，而产生这种现象的原 因是在计算机的硬件加速器上缺少了用于优化计算的内核。
39

4.2.2基于SAUNet的语音増强算法
在本小节中，本文提出了一种基于独立自注意机制的单通道语音增强网络 SAUNet,将独立自注意机制嵌入到基于UNet架构的全卷积神经网络中。在上小 节中已经提到，本章目前的工作仅将这种注意力机制用作语音增强模型的独立一 层，与模型中的卷积网络融合，而不是完全替代整个卷积网络，在这独立的一层 中是全注意机制而没有卷积算子的参与，在未来的工作中，可以继续探索完全抛 弃卷积的基于纯粹注意力架构的语音增强模型。本文提出的模型架构如图4-3所 Zj\ O
LN	LN	LN SA Layer	LN	SA l .ayer LN	LN
ELI' EU	ELU	ELI	ELI; ELV
*	编康	>	解码瑤	"
图4-3基于独立自注意机制的语音增强网络SAUNet
与第三章相同，本文将图3-1中基于UNet架构的全卷积神经网络作为骨干 网络，在此之上加入独立自注意机制用作网络的一层，在图4-3用“SA Layer” (Stand Alone Layer)表示。为了方便进行对照试验，同AAUNet保持一致，本 文在编码端的最后三层和解码端的前两层加入独立自注意机制，整个网络将带噪 语音的对数幅度功率谱作为网络的输入，输出的是增强净化后的对数幅度功率谱, 然后将带噪语音的相位信息与增强的对数谱特征相结合，重构出新的干净语音。 本文在模型的最后一层使用线性激活函数，在其他层使用非线性的ELU (exponential linear unit)激活函数。相比于ReLU激活函数，ELU输出的均值在 0附近，更具鲁棒性。二者在x>0时都是比例系数为1的正比例函数，而在虫0 时，ELU函数变为指数形式，在输入为负值的情况下依然有信息输出，Q是可调 节的超参数。ELU激活函数的公式见式(4-9),图像表示见图4-4o

此夕卜，在SAUNet中，本文使用了层标准化函数(LayerNormalization) [54], 在图4-3中用“LN”表示。LN和BN都是一种对输入样本数据做标准化的方法， LN是对同一个输入样本的所有特征做标准化，即在不同通道方向做标准化，而 BN是对所有输入样本的同一特征做标准化，即沿着同一个通道做标准化。LN更
40
多的是用在循环神经网络中，在训练过程中不受批处理大小的影响，而且训练出 的模型更加稳定，本文尝试将其与卷积网络结合用于语音增强技术领域。

图4-4 ELU激活函数图

4.3实验结果与分析
本小节将对提出的语音增强模型进行仿真实验，通过进行消融实验得到最优 的网络模型，并通过对比实验来检验所提出模型的增强性能。本小节先简要介绍 实验数据集的选择及处理过程、网络参数的设置，最后对实验结果进行详细的阐 述分析。
4.3.1实验配置
本章选用TIMIT语料库和NOISEX-92噪声库作为实验数据集，从TIMIT语 料库中随机选择4200条句子作为训练集，再另选100条句子作为测试集。为了 防止网络过拟合，本文在训练集中随机取20%作为验证集。同第三章实验设置， 本文从NOISEX-92噪声库中选择白噪声（white）、工厂噪声1 （factory】）、坦克 内部噪声（ml09）以及F16座舱噪声（fl6）这4种不同类型的噪声作为训练噪 声，另选粉红噪声（pink）和工厂噪声2 （factory2）作为测试噪声。上述所有句 子剪切为2秒，下采样到8kHz,使用VAD算法去除句子开始和结束的静默帧。 在训练集中，训练语音和训练噪声在-2.5dB、OdB、2.5dB、7.5dB和12.5dB这5 种信噪比条件下进行随机混合；在测试集中，测试语音和测试噪声在-5dB、0dB、 5dB、10dB这四种信噪比条件下进行随机混合。最后，对所有句子进行短时傅里 叶变换，具体处理流程和实验参数与第三章相同，得到语音的对数功率谱特征作 为网络模型的输入，输出是去噪后的对数功率谱，再结合带噪语音的相位，通过 傅里叶逆变换得到增强后的语音句子。
41
网络模型主要由14个卷积层和3个独立全注意层组成。其中，卷积核的大 小为3X3,卷积步长的大小为1 X2,每个卷积层的通道数依次为8-16-32-64-128- 128-256-256-128-128-64-32-16-1,每一层的时间维度通过补零填充操作保持不变, 上述卷积层的参数设置在所有实验中是一致的。独立全注意层的输入和输出维度 保持相同，在此先将参数设为注意力头的数量为2,局部区域大小为5x5,加入 相对位置编码，多值数2 = 4,后续将根据实验需要进行调整。训练阶段所使用的 优化器、设置的初始学习率及其衰减策略、损失函数、epoch的数量和mini-batch 的大小与第三章中相同。
4.3.2仿真实验结果分析
在4.2节中已经详细阐述了基于独立自注意机制的语音增强算法的基本原理, 本小节将通过消融实验、对比试验来检验所提出语音增强网络模型的整体性能和 泛化能力，实验中得到的所有结果均在测试集上进行，与训练集的数据无关。下 面本文将进行具体的实验结果分析。

本小节先对提出的SAUNet语音增强算法的收敛性进行测试，在保证算法收 敛的前提下进行后续的其他实验，测试的结果如下图所示：


图4-5 SAUNet语音增强算法收敛图
上图表示的是SAUNet语音增强算法的收敛性曲线。横坐标代表训练的轮数 epochs,这里一共训练了 20轮。纵坐标代表损失函数(Huber Loss)的值。如图 所示，在前4个训练轮数下模型以较快的速度收敛，在整体上随着训练轮数的增 加，Huber Loss逐渐下降，在前10个epoch下网络损失值呈现震荡下降状态， 且在第9个epoch时Huber Loss产生了一次较大的震荡，表明在此训练轮数下 模型没有学到最优的函数映射，但在整体趋势上整个网络的训练仍是收敛的。由
42 此可见，本文提出的基于独立自注意机制的语音增强算法SAUNet的收敛性是有 所保证的。

本组消融实验将探究SAUNet在4种测试的信噪比水平(-5dB、OdB、5dB、 10dB)下，具有不同注意力头的网络模型的PESQ得分以及在-5dB信噪比水平 下的BAK, BAK, OVL得分。本实验一共选择了 4种注意力头，每种注意力头 代表一个训练完备的SAUNet网络，这里Oh代表没有融入独立自注意机制的骨 干网络UNet。综上，本组实验一共测试了 4种SAUNet网络模型，除了注意力 头参数不同外，独立自注意机制的局部区域大小均为5X5,加入相对位置编码， 不对值矩阵进行距离感知操作，实验结果如下图所示。


图4-6不同注意力头在不同信噪比下的PESQ得分
图4-6表示具有不同注意力头的网络模型在不同信噪比下的PESQ得分。纵 轴表示PESQ分值，得分范围为-0.5-4.5分，横轴表示注意力头的数量(Oh, lh, 2h, 4h, 8h)o图中共有4条曲线，每条曲线代表一种信噪比水平。从中本文可 以观察到，在同一个信噪比下，加入独立自注意机制的网络(lh, 2h, 4h, 8h) 的PESQ得分要明显高于骨干网络UNet,只有1个注意力头的SAUNet性能并 未达到最优，随着注意力头的增加，PESQ分数得到提升，但有2、4、8个注意 力头的SAUNet网络得分未有显著差别，具有4个注意头的模型得分略高；对比 不同的信噪比曲线，四条曲线的变化趋势是一致的，这表明SAUNet对不同的信 噪比水平具有较强的泛化能力和很好的鲁棒性。
图4-7表示具有不同注意力头的网络模型在-5dB信噪比下的SIG、BAK和 OVL得分。纵轴表示分值，得分范围为1〜5分，横轴表示三种评估指标。先只 看单一指标，SIG代表语音的失真程度，注意力头为2时的模型得分略高，表明 失真程度最小；BAK代表噪声的去除程度，注意力头为2时的模型得分略高，

表明去噪程度最好；OVL代表整体语音的恢复质量，注意力头为2时的模型得 分略高，表明整体语音的增强水平最好。以上表明SAUNet在注意力头数为2时 达到了最优性能，这也与图4-6得到的结果一致，本文将注意力头数量为2作为 模型的最优参数选择。从整体上来看，相较于原始的UNet语音增强网络，基于 独立自注意机制的SAUNet在各种评估指标上已经有了较为明显的提高。

图4-7不同注意力头的三种指标得分

本组消融实验将探究在信噪比水平为-5dB和OdB的条件下，局部区域大小 对SAUNet增强性能的影响。本实验将STOI作为评估指标，选择了 4种不同的 局部区域大小，每一种都代表一个训练完备的SAUNet网络。综上，本组实验一 共测试了 4种SAUNet网络模型，除了局部区域大小参数丘不同外，独立自注意 机制的注意力头数为2,加入相对位置编码，不对值矩阵进行距离感知操作，实 验的结果如图4-8所示。
图4-8表示具有不同局部区域大小的SAUNet在两种信噪比水平（-5dB、
OdB）下的STOI得分。图中上方的曲线是OdB信噪比下局部区域大小与STOI得 分的关系，可以发现随着局部区域大小的扩大，STOI得分逐渐升高，但k=7时 STOI得分略有下降，k=9时的SAUNet模型得到最大得分，同样的情况也适用 于-5dB曲线，只不过在k=7的情况下，STOI的得分下降更加明显。综合来看, 这说明k=7的SAUNet的语音增强性能在训练过程中出现下降，本文分析可能是 模型的初始化过程出现问题，进而导致只得到局部次优解。但从总体趋势上来看， 随着局部区域的增大，独立自注意机制可以学到更多有用的信息，能获得更好的 性能。在此，本文将局部区域大小k=9作为模型的最优参数选择。
44


图4-8不同局部区域大小的SAUNet的STOI得分

本组消融实验将探究SAUNet在4种测试的信噪比水平(-5dB、OdB、5dB、
10dB)下，在独立自注意机制中嵌入的相对位置信息对SAUNet语音增强性能的 影响。本实验一共选择了 3种评估指标，分别从语音可懂度，语音质量以及整体 语音恢复水平上检验SAUNet模型的性能。综上，本组实验一共测试了 2种 SAUNet网络模型，除了相对位置信息参数不同外，独立自注意机制的注意力头 数量为2,局部区域大小均为5X5,不对值矩阵进行距离感知操作，实验结果如 下表所示。
表4-1相对位置编码的三种指标得分
SNR
STOI

PESC

OVL

no-position
position
no-position
position
no-position
position
-5dB

表4-1是在4种测试信噪比下，是否具有相对位置信息的SAUNet模型在 STOI, PESQ和OVL三种评估指标上的得分，SAUNet分为有相对位置信息 (position)和不加入相对位置信息(no-position)两种情况。从表4-1中可以观 察到，对于STOI—栏，具有相对位置信息(position)的SAUNet模型在所有信 噪比条件下，针对不可见的粉红噪声和工厂噪声两种噪声，可以更好地提升语音 的可懂度水平;对于PESQ 一栏，情况发生了改变，没有相对位置信息(no-position) 的SAUNet模型在所有信噪比条件下对语音质量的提高超过了有位置信息的情 况，且相较于STOI的结果，提升的效果更加明显，这一方面表明语音质量和可
45 懂度之间并不是正向的关系，即语音质量好并不代表可理解性强，反之亦然，另 一方面表明具相对位置信息的SAUNet网络更趋向于提升目标语音的可理解性, 对语音质量的提升有所欠缺。对于OVL 一栏，no-position的SAUNet模型在平 均条件下的得分依然好于position的情况，结合第三章得到的实验结果，本文可 以做出如下结论：不同于计算机视觉对注意力机制中位置信息的需要，在语音增 强领域，在注意力机制中加入位置信息并不能提高模型的去噪性能，特别是对基 于self-attention的注意力机制而言。

本组消融实验将探究具有距离感知能力的独立自注意机制对SAUNet语音 增强性能的影响。本组实验一共选择了 5种测评指标，在第三章中已经对这些评 估指标做了具体介绍，总而言之，每一种指标都代表着增强性能的一个方面的测 度。这里一共测试了 4种SAUNet网络模型，除了多值数不同外，独立自注意机 制的注意力头数为2,局部区域大小均为5X5,加入相对位置编码，实验结果如 下表所示。
表4-2有距离感知的全注意层的5种指标得分
多值数入
STOI
PESQ
SIG
BAK
OVL
Avg.
1

表4-2是在OdB信噪比条件下，基于距离感知独立自注意机制的SAUNet模 型在5种评估指标(STOI, PESQ, SIG, BAK, OVL)上的得分。多值数的概念在 4.2.1小节中已经给出了定义，是一种可调的超参数自变量，用于多值矩阵的生 成，多值数为1表示不具备距离感知能力，故表中一共有三种(2 = 4,5,6)不同 的具有距离感知能力的SAUNet模型。从表中可以观察得到，在多值数为6时， 在5种指标上都取得了最高的分数，相较于其他三种模型，提升的水平较为明 显，这代表着对语音增强性能的多角度的提高。而如果只看多值数为1和5的情 况，不具备距离感知能力的SAUNet模型分值反而略高一些，但从理论上来讲, 具备距离感知能力的模型应该会有更优的性能，本文分析，由于选取的样本数不 足，未能从中体现岀全部规律性，下一步可以扩大多值数的样本量，并且对所有 样本网络赋予相同的初始化权重，进一步分析变化规律，找到最优参数。

在本组实验中，本文将对不同的语音增强算法的性能进行对比与分析，一共 选取了 4种语音增强算法，包括OMLSA-IMCRA,UNet,AAUNet和SAUNet。本 文用OMLSA-IMCRA用作横向实验对比，在下述实验中将用简称OMLSA表示。 本组实验将重点放在纵向对比上，即对比传统UNet,经过注意力强化的AAUNet
46 以及进一步融合了独立自注意机制的SAUNet,由此来检验本文提出的两种语音 增强模型的去噪能力，与此同时给出模型的参数量比较。
为了便于比较，同第三章实验设置，本组实验在2种不可见噪声和4种信噪 比(-5dB, OdB, 5dB, 10dB)条件下进行，UNet和AAUNet的网络的参数配置 详见3.3.1节，SAUNet的注意力头数为4,局部区域大小为5x5,无相对位置信 息，多值数2 = 6O 4种算法的具体对比分析如下表所示。
表4-3含噪语音及不同增强算法在4种信噪比下的SIG, BAK和OVL得分
信噪迸标
SIG
BAK
OVL

表4-3表示含噪语音及4种不同增强算法(OMLSA, UNet, AAUNet, SAUNet) 在4种信噪比水平下SIG, BAK和OVL的平均得分。本组实验旨在进行模型的 横向对比和纵向对比，验证所提出模型SAUNet的语音增强性能。从表格中可以 观察到，在所有信噪比水平下，SAUNet在三个指标上的得分都明显超过了其他 三种方法，且超过了第三章提出的AAUNet模型，充分说明了本章提出的SAUNet 模型在语音失真程度，噪声去除程度以及整体语音质量上具备优异的表现。相比 于带噪语音，SAUNet的三种指标的平均信噪比分数分别提高了 40.36%, 52.35% 和44.64%；只看纵向方法，在语音失真SIG方面，SAUNet比UNet和AAUNet 的分数分别高出13」％, 7.99%；在抑制背景噪声BAK方面，SAUnet的分数则 分别提高了约11.43%, 6.46%；对于最后整体处理后的语音质量OVL, SAUNet 得分则比UNet得分高岀13.09%,比AAUNet得分高出&31%。实验结果表明， 基于独立自注意机制的语音增强算法SAUNet对未知信噪比和背景噪声具有更 好的泛化能力，可以更好地平衡噪声抑制和语音失真，具有较好的语音处理质量， 取得了比所有对比算法更好的性能。
表4-4含噪语音及不同增强算法在4种信噪比下的PESQ和STOI得分
借噪这标
PESQ
STOI


表4-4表示含噪语音及4种不同的语音增强方法(OMLSA,UNet, AAUNet,
SAUNet)在4种信噪比水平下的PESQ和STOI平均得分。从表中可以看出，不 论是PESQ得分还是STOI得分，在所有的信噪比条件下，本章提岀的算法模型
47
SAUNet对平稳噪声和非平稳噪声的抑制能力超过了所有其他方法。SAUNet的 平均PESQ和STOI评分与带噪语音相比分别提高了 38.51%和15.7%,与OMLSA 相比分别提高了 27.33%和23.55%,与UNet相比分别提高了 12.21%和5.82%。 与AAUNet相比分别提高了 7.93%和4.16%。结合表4-3和表4-4的结果表明， 基于独立自注意机制的SAUNet网络模型可以在语音质量，语音可懂度以及噪声 抑制程度等方面多角度地提升语音增强的性能。

语咅增强模型

图4-9语音增强模型参数量对比
如图4-9所示，图中展示了骨干5网络UNet,注意力强化卷积网络AAUNet 以及基于独立自注意机制的卷积网络SAUNet这三种语音增强模型的神经元参 数量对比，参数量的单位为“个”。AAUNet和SAUNet的区别仅在于应用了不 同的注意力机制（二维相对自注意机制和独立自注意机制），二者的网络深度、 通道数、卷积算子参数等其他条件保持一致。从图中可以轻易的观察到，作为骨 干网络，UNet网络的参数量为2015328个，AAUNet在此基础上网络参数增加 至3388720个，而SAUNet的网络参数仅仅增加至2562272个，就取得了比UNet 甚至AAUNet更加有效的语音去噪能力，由此证明了独立自注意机制相较于二 维相对自注意机制在模型性能和参数量上具有双重优越性，至此基本实现了本文 研究的初心：力求在增加少量训练参数的前提下提升原有全卷积网络的语音增强 性能。
4.4本章小结
本章在第三章的基础上继续探究了自注意机制在语音增强领域的应用。在第 三章的实验研究中，本文将二维相对自注意机制嵌入到基于UNet的全卷积神经 网络中，当这种注意力机制的通道数占比设为100%时，没有带来模型性能的提 升，效果反而出现了下降，针对这一问题，本章将一种新的独立自注意机制应用
48
到语音增强技术领域，提出了一种基于独立自注意机制的语音增强模型，这种注 意力机制完全替代了卷积运算，且只需要增加极少量的网络参数，就可以获得显 著的性能提升。本章首先介绍了卷积运算的基本原理，由此引出了独立自注意机 制，并重点阐述了该注意力机制的局部运算特性以及基于距离的感知能力。最后 本章提出了一种基于独立自注意机制的单通道语音增强模型SAUNet,将独立自 注意机制取代部分卷积层，融合到全卷积神经网络中。随后本章详细介绍了 6组 消融实验和对比试验，实验结果表明，本章提出的模型性能优于AAUNet在内的 所有比较算法，用最少的网络参数获得了最优的增强性能。
49

50


第五章总结与展望
5.1工作总结
语音增强是一种语音信号处理技术，是语音分离领域的一个主要分支，是说 话人分离的一种特殊情况。语音增强技术的目的是从一段被噪声源或者混响环境 破坏了的带噪语音中恢复出干净的说话人语音，即增强语音。在这个过程中做到 背景噪声完全去除同时增强语音不会失真、保证增强语音的恢复质量和可理解性 是本领域学者一直不懈追求的目标。基于数字信号处理技术的传统语音增强算法 经过许多年的改进和发展，在既定的假设域内取得了良好的效果，已经在手机终 端、降噪蓝牙耳机等商品上实现了落地实用。随着计算机算力的增强，基于大数 据和深度学习的语音增强算法近年来异军突起，取得了十分亮眼的成绩，无需任 何前提假设就能在极低信噪比和复杂背景环境下恢复出干净语音。其中，基于卷 积神经网络的语音增强模型，相比于传统算法，能更好地保证增强语音的质量和 可理解度，相比于其他神经网络，其独特的权值共享特性能在保证去噪效果的前 提下大幅度减少网络的参数量，符合神经网络轻量化发展的趋势，得到研究人员 的广泛关注。
然而，卷积运算受限于感受域的局部性，一次只处理输入特征图的一个局部 邻域，这种特性决定了卷积算子很难捕捉到特征图上长距离的上下文信息，难以 具备感知全局语境的能力，这将不利于更好地恢复目标语音。此外，在卷积网络 中每一个通道代表一种特征类型，随着通道数的增加，网络中会产生许多冗余的 信息，逐层传递之后无益于模型的训练和学习。基于以上分析，本文研究的重点 是通过自注意力机制来强化全卷积网络获取长距离上下文信息的能力，帮助卷积 网络强调有用的特征，抑制冗余的特征。本文所作的主要工作总结如下：
(1) 本文提出了一种用于单通道语音增强的注意力强化全卷积神经网络 AAUNeto本文设计的基于UNet架构的全卷积神经网络一共包含14个卷积层， 编码端和解码端各包含7个卷积层，特征图的频率维度在编码端逐层减半，通道 数以2的幕次增加，在解码端进行相反的运算，并通过跳跃连接机制将编码端的 特征图传递到对应解码端，在通道方向上进行拼接，有助于恢复目标语音的细节 信息。本文将一种新的二维相对自注意机制应用到全卷积神经网络中，具体的做 法是在编码端的最后三层和解码端的前两层进行注意力强化操作，将卷积运算与 注意力产生的输出沿通道方向拼接起来生成新的特征图，通过灵活调整注意通道 的比例，可以在卷积关注局部细节和自注意力获取全局语境之间找到最优的组合。
51
(2) 本文提出了一种基于独立自注意机制的单通道语音增强算法SAUNeto 上述AAUNet的核心思想是用自注意力机制去辅助和强化卷积运算，在第三章 的实验中发现，当自注意力机制的通道数占比为100%时，即全注意力机制，语 音增强的性能出现了下降。针对这一问题，本文对另一种独立自注意机制展开了 研究，希望其在语音增强领域能完全替代卷积而不是作为一种辅助手段。相比于 二维相对自注意机制，独立自注意机制可以自由设置运算区域的大小，通过多值 矩阵提升基于距离的感知能力，通过后续的一系列实验表明，基于独立自注意机 制的语音增强网络只需要增加十分少量的网络参数，就可以获得显著的性能提升。 本文目前的工作仅将独立自注意机制用作模型中的独立一层，在这一层中来完全 替代卷积层，而不是完全替代整个卷积网络，在未来的工作中，可以继续探究完 全抛弃卷积的基于纯粹注意力架构的语音增强模型。
(3) 本文在上述提出的网络模型中，采用Huber Loss作为损失函数。Huber Loss结合了 L1和L2损失函数的优点，通过合理设置超参数，可以调节Huber Loss对L1或者L2的侧重性，对噪声具有较好的鲁棒性，可以使网络模型更快 地收敛。
(4) 本文对二维相对自注意机制在语音增强卷积网络上的通用性展开了研 究。将二维相对自注意机制应用到其他基于卷积网络的增强模型中，并提高了模 型的去噪能力，证明了二维相对自注意机制可以作为一种插件应用于卷积网络， 以提升语音增强网络的整体性能。
5.2研究展望
本文对卷积神经网络和自注意机制在语音增强领域的结合与应用展开了深 入的研究，提出了一种注意力强化全卷积网络和基于独立自注意机制的语音增强 模型，二者都在原有卷积网络的基础上进一步多角度地提升了语音增强的性能， 然而由于自身研究水平和实验条件限制，仍有许多不尽完善的地方，现总结如下：
(1) 没有采用基于端到端的语音增强架构。本文网络模型的输入是二维的 带噪语音的对数功率谱密度特征，在输入到网络之前需要进行复杂的数字信号处 理过程，包括语音活动检测，分帧加窗，短时傅里叶变换，取对数幅度谱和保存 带噪语音相位等操作，这不符合实时性去噪增强的要求，只能用作后端处理，而 且需要将输出的增强对数功率谱和带噪语音的相位相结合，通过逆傅里叶变换得 到最终干净的语音时域波形，这对语音的恢复质量会有一定的影响。因此，在未 来可以改进网络的结构，实现输入时域波形、输出时域波形的端到端语音增强架 构°
52
（2）	没有研究完全抛弃卷积的纯粹注意力语音增强网络，没有研究独立自 注意机制的通用性。在5.1节的工作总结中已经提到，独立自注意机制已经可以 替代卷积运算，而不是作为一种辅助或者强化手段，然而受限于自注意力运算的 特点，输入特征图和输出特征图的时频维度需要保持一致，目前需要通过池化等 有损操作才能改变维度大小，不能完全替代整个频域缩放的卷积网络。在第三章 中对二维相对自注意机制的通用性进行了研究，但在第四章中并没有对独立自注 意机制进行此类研究，因此不能保证和其他卷积网络融合后具有相同的提升效果。 因此，在未来的工作中，可以进一步设计纯粹的注意力语音增强网络，并进行通 用性的实验。
（3）	语音数据仅采用了英文语料库且训练和测试的噪声种类不够丰富。 TIMIT数据集是全英文数据集,且在今天看来其包含的数据量已经不足以训练大 型网络，因此当模型的输入为中文语音时，模型的语音增强能力必然会出现明显 的下降甚至是不可用的情况。NOISEX-92噪声库包含的15种噪声显然无法覆盖 生活中绝大多数的噪声场景，本文为基础探究型研究，仅选取了其中4种噪声做 训练，2种噪声做测试，使得模型在具体的实际应用中泛化能力不强，因此在未 来的工作中可以考虑购买昂贵的中文数据库与英文数据库混合作为实验语音数 据集，并加入更多不同类型的噪声（如Nonspeech噪声库）用于网络模型的测试 和训练。
53
54


参考文献
[1] Markovich-Golan S, Gannot S, Kellermann W. Combined LCMV-TRINICON Beamforming for Separating Multiple Speech Sources in Noisy and Reverberant Environments卩].IEEE/ACM Transactions on Audio Speech & Language Processing, 2017,25(2): 320-332.
[2] Li X, Girin L? Gannot S, et al. Multichannel Speech Separation and Enhancement Using the Convolutive Transfer Function[J]. IEEE/ACM Transactions on Audio Speech & Language Processing, 2017.
[3] Wang J-C, Lee Y-S, Lin C-H, et al. Compressive Sensing-Based Speech Enhancement [J]. IEEE/ACM Transactions on Audio Speech & Language Processing, 2016: 1.
[4] Yee D, Kamkar-Parsi H, Martin R, et al. A Noise Reduction Postfilter for Binaurally Linked Single-Microphone Hearing Aids Utilizing a Nearby External Microphone [J]. IEEE/ACM Transactions on Audio Speech and Language Processing, 2018, 26(1): 518.
[5] Lim J S, Oppenheim A V. All-Pole Modeling of Degraded Speech[J] .IEEE Transactions on Acoustics Speech & Signal Processing, 1978, 26(3): 197-210.
[6] He Q, Bao F? Bao C. Multiplicative Update of Auto-Regressive Gains for CodebookBased Speech Enhancement[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2016, PP(99): 1.
[7] Paliwal K, Wojcicki K, Schwerin B. Single-Channel Speech Enhancement Using Spectral Subtraction in the Short-Time Modulation Domain [J], Speech Communication, 2010, 52(5): 450-475・
[8] Lu C T. Enhancement of Single Channel Speech Using Perceptual-Decisiom Directed Approach[J]. Speech Communication, 2011, 53(4): 495-507.
[9] Paliwal K, Wojcicki K, Schwerin B. Single・Channel Speech Enhancement Using Spectral Subtraction in the Short-Time Modulation Domain [J]. Speech Communication, 2010, 52(5): 450-475.
[10] Wang Y, Brookes M. Speech Enhancement Using an MMSE Spectral Amplitude Estimator Based on a Modulation Domain Kalman Filter with a Gamma Prior[C]//2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2016: 5225-5229.
55
[1 l]Chinaev A，Haeb-Umbach R. A Generalized Log-Spectral Amplitude Estimator for Single-Channel Speech Enhancement[C]//2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2017: 4980-4984.
[12] Chao L, Jiang T, Sheng W. Single-Channel Speech Enhancement Based on Adaptive Low-Rank Matrix Decomposition[J]・ IEEE Access, 2020, PP(99).
[13] Cohen I, Berdugo B. Speech Enhancement for Non-Stationary Noise Environments [J]. Signal Processing, 2001, 81(11): 2403-2418.
[14] Cohen I. Noise Spectrum Estimation in Adverse Environments: Improved Minima Controlled Recursive AveragingfJ]・ IEEE Transactions on Speech and Audio Processing, 2003, 11(5): 46175.
[1 习Liu J, Yang X, Zhu M, et al. Speech Enhancement with Stacked Frames and Deep Neural Network for VoIP Applications[C]//l 7th International Conference on Optical Communications and Networks (ICOCN2018). International Society for Optics and Photonics, 2019.
[16] Zhang Z, Geiger J, Pohjalainen J, et al. Deep Learning for Environmentally Robust Speech Recognition[J]. Acm Transactions on Intelligent Systems & Technology, 201 & 9(5): 1—2&
[17] Deng F, Bao C, Kleijn W B・ Sparse Hidden Markov Models for Speech Enhancement in Non-Stationary Noise Environments [J]. IEEE/ACM Transactions on Audio Speech and Language Processing, 2015,23(11): 1973-1987・
[18] Cooke M, Hershey J R, Rennie S J. Monaural Speech Separation and Recognition Challenge [J]. Computer Speech & Language, 2010, 24(1): 1—15.
[19] Veisi H, Sameti H. Speech Enhancement Using Hidden Markov Models in Frequency Domain[J]・ Speech Communication, 2013, 55(2): 205-220.
[20] Mysore G J, Smaragdis P・ A Non-Negative Approach to Semi-Supervised Separation of Speech from Noise with the Use of Temporal Dynamics[C]//ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings..
[21] Vu T T, Bigot B, Chng E S. Combining Non-Negative Matrix Factorization and Deep Neural Networks for Speech Enhancement and Automatic Speech Recognition[C]//ICASSP? IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings..
[22] Xie F, Van Compemolle D. A Family of MLP Based Nonlinear Spectral Estimators for Noise Reduction[J]. ICASSP, IEEE International Conference on Acoustics, Speech
56
and Signal Processing - Proceedings, 1994, 2: II53-II56.
[23] Hinton G E, Osindero S, Teh Y W・ A Fast Learning Algorithm for Deep Belief Nets.[J]. Neural Computation, 2006.
[24] 徐勇.基于深层神经网络的语音增强方法研究[D]・中国科学技术大学,2015.
[25] Xu Y, Du J, Huang Z, et al・ Multi-Objective Learning and Mask-Based Postprocessing for Deep Neural Network Based Speech Enhancement[J]. 2017・.
[26] Kolboek M, Tan Z H, Jensen J. Speech Enhancement Using Long Short-Term Memory Based Recurrent Neural Networks for Noise Robust Speaker Verification[C]//2016 IEEE Workshop on Spoken Language Technology, SLT 2016 - Proceedings..
[27] Sun L, Du J, Dai L R, et al. Multiple-Target Deep Learning for LSTM-RNN Based Speech Enhancement[C]//Hands-Free Speech Communications and Microphone Arrays (HSCMA), San Francisco, CA, USA, 2017..
[28] Pascual S, Bonafbnte A, Serra J. SEGAN: Speech Enhancement Generative Adversarial Network[J]. Interspeech 2017, 2017: 3642-3646.
[29] 叶帅帅.基于Wasserstein生成对抗网络的语音增强算法研究[D]・北京邮电大 学,2019.
[30] Park S R, Lee J. A Fully Convolutional Neural Network for Speech Enhancement[J]. Interspeech 2017, 2017: 1993-1997.
[31] Pandey A, Wang D. A New Framework for CNN-Based Speech Enhancement in the Time Domain[C]//IEEE/ACM Transactions on Audio Speech and Language Processing..
卩2]Pandey A, Wang D. A New Framework for CNN-Based Speech Enhancement in the Time Domain [J]. IEEE/ACM Transactions on Audio Speech and Language Processing, 2019, 27(7): 1179-1188・
[33] Fu S W, Wang T W, Tsao Y, et al End-to-End Wavefbnn Utterance Enhancement for Direct Evaluation Metrics Optimization by Fully Convolutional Neural Networks [J]. IEEE/ACM Transactions on Audio Speech and Language Processing, 2018, 26(9): 1570-1584.
[34] Taal C H, Hendriks R C, Heusdens R, et at An Algorithm for Intelligibility Prediction of Time-Frequency Weighted Noisy Speech[J]. IEEE Transactions on Audio Speech & Language Processing, 2011, 19(7): 2125-2136.
[35] Tan K, Wang D L・ A Convolutional Recurrent Neural Network for Real-Time Speech Enhancement[J]. Proceedings of the Annual Conference of the International
57
Speech Communication Association, INTERSPEECH, 201 & 2018-Septe: 3229-3233.
[36] Grzywalski T, Drgas S・ Using Recurrences in Time and Frequency within U-Net Architecture for Speech Enhancement]J]. ArXiv, 201& 6970-6974: IEEE.
[37] Vaswani A, Shazeer N, Parmar N, et al. Attention Is All You Need [J]. Advances in Neural Information Processing Systems, 2017, 2017-Decem(Nips): 5999-6009.
[38] Bello I, Zoph B? Le Q, et al. Attention Augmented Convolutional Networks[J]. Proceedings of the IEEE International Conference on Computer Vision, 2019, 2019Octob: 3285-3294.
[39] Ramachandran P, Parmar N, Vaswani A, et al. Stand-Alone Self-Attention in Vision Models[J]. NeurlPS, 2019.
[40] Xiang Hao, Hao X, Shan C, et at An Attention-Based Neural Network Approach for Single Channel Speech Enhancement[J]. ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings, 2019, 2019- May(61571363): 6895-6899.
[41] Lan T, Lyu Y, Ye W, et al. Combining Multi-Perspective Attention Mechanism With Convolutional Networks for Monaural Speech Enhancement[J]・ IEEE Access, 2020, & 78979-78991.
[42] Nikzad M, Nicolson A，Gao Y, et aL Deep Residual-Dense Lattice Network for Speech Enhancement[J]. The Thirty-Second Innovative Applications of Artificial Intelligence Conference (AAAI), 2020.
[43] Dou P, Jiang T, Li C. Monaural Speech Enhancement with Deep Residual-Dense Lattice Network and Attention Mechanism in the Time Domain[C]//2020 IEEE 5th International Conference on Signal and Image Processing (ICSIP). IEEE, 2020: 789793.
[44] Recommendation I-T. Perceptual Evaluation of Speech Quality (PESQ): An Objective Method for End-to・EIK1 Speech Quality Assessment of Narrow-Band Telephone Networks and Speech Codecs [J]・ Rec. ITU-T P. 862, 2001.
[45] Lecun Y, Bottou L. Gradient-Based Learning Applied to Document Recognition]J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324・
[46] Xu K, Ba J L, Kiros R, et al. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention[J]. 32nd International Conference on Machine Learning, ICML 2015, 2015, 3: 2048-2057.
[47] Luong M T, Pham H? Manning C D. Effective Approaches to Attention-Based Neural Machine Translation [J]. Computer Science, 2015.
58
[48] Ronneberger O, Fischer P, Brox T. U-Net: Convolutional Networks for Biomedical Image Segmentation]J]. International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2015, 9351: 234-241.
[49] Ioffe S5 Szegedy C・ Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift [J]. International Conference on Machine Leaming,2015., 2015: 448—456・
[50] He K, Zhang X, Ren S, et al. Deep Residual Learning for Image Recognition[C]//Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition・・
[51] Huang C-Z A, V as ward A, Uszkoreit J, et al. Music Transformer [J]. ArXiv, 201 &
[52] Huber P J. Robust Estimation of a Location Parameter[M]//Breakthroughs in Statistics. Springer, 1992: 492-518.
[53] Hu Y, Loizou P C. Evaluation of Objective Quality Measures for Speech Enhancement[J]. IEEE Transactions on Audio, Speech, and Language Processing, 2007, 16(1): 229-238・
[54] Xiong R, Yang Y? He D，et at On Layer Normalization in the Transformer Architecture[C]//Intemational Conference on Machine Learning. PMLR, 2020: 1052410533.
59




























































60


