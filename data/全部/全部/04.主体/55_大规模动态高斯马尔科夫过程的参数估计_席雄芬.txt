第一章绪论
1.1选题背景与研究意义
物联网13是当前国内外的研究热点之一，正在给人们的生产和生活方式带 来深刻的变革，其深远的社会价值与潜在的应用价值已经成为学术研究的重点。 将传感器嵌入到各行各业的系统中，比如，智能家居，智能电网，社交软件等， 。现有的互联网连接起来，实现人与物、物V物的连接。。此同时，随着数据采 集技术的发展，物联网的出现不仅加速了大数据时代的到来，更是推动了大数据 的产生。
与一般的大数据相比，物联网产生的大数据有以卜6种不同的特点：（1）复 杂化，复杂的物理环境，比如，自然灾害监测、战场监控等，导致了物联网的网 络结构呈现异构、多样的特点，从而产生了复杂的、多样的非结构化的数据形式。
（2）规模化，物联网的核心仍然是传感器，随着传感技术的发展以及日渐低廉 的传感器价格，实际中往往大规模地部署传感网络，其传感节点的数量常常在千 万级以上，必将产生GB、TB甚至PB级别的数据量。（3）颗粒化，物联网可以 感知的数据类型非常广泛，除了连续的时间序列外，因GPS定位技术的普及， 也可以获取空间地理位置、行为等信息。在这个前提下，物联网感知结果可以同 时带有时间、位置、环境、行为等多重属性。（4）速度快，物联网感知的数据每 时每刻都在实时地变化，其变化的速率远远超出了肉眼所能观测的变化速率。（5） 质量低，由于大规模感知网络的数据传输延迟较大，很多基于感知数据做出的决 策与处理都是过时的、不可行的。另外，由于复杂的网络环境以及噪声干扰的存 在，物联网产生的数据常常会不精确、不完整、不一致。（6）社交数据与感知数 据的结合。物联网连接的不仅仅是物，还是物与物的连接，人与人的连接。可以 理解为，物联网是人与机器组成了庞大的社会网络，这种混合式的物联网数据， 通过感知的数据与社交媒体的数据结合，更加有利于科学的决策。
物联网实现了人与人、人与物、物与物的简单连接，这种连接是浅连接，或 者说，物联网为人与人的联系、人与物的连接搭建了一个简单的应用平台。物联 网下的大数据分析与处理实现了物联网的深连接叫这种数据处理通过隐藏信息 的挖掘、分析与预测实现，已经变得日益重要。本研究课题的选题背景是将大规 模物联网收集的数据建模为一阶动态高斯马氏过程并进行参数估计，同时针对大
规模物联网数据的规模化、速度快、类型多等特点以及实际大数据分析和处理中 遇到的挑战，提出相应的解决算法，旨在高效、准确地挖掘出大规模数据背后的 隐藏关系。
物联网（IoT）、在线社交媒体、金融市场、科学技术的发展驱动着信息呈现爆 炸式地增长，数据的产生、获取、测量、存储正以以惊人的速率在许多行业中也 应运而生，同时从海量的、复杂的数据中学习有效的数据拓扑结构也变得日益重 要。
物联网大数据的每一个特征都对大数据分析的系统设计和实施构成了挑战， 主要表现在以下5个方面：（1）数据的表示形式。传统的数据处理，比如时间序 列，图像或视频数据，通常定义在规则的欧式空间。这种定义在规则域的数据通 常用矢量形式表示，然后采用经典的降维处理方法，比如，主成成分分析（PCA）、 奇异值分解（SVD）,这些方法只适用于小数据集上。而物联网产生的“大数据” 通常定义在复杂的拓扑域中，比如网络结构、流形或不规则几何域中、云数据域 中，其数据结构通常是非结构化的，而且这种在空间上、时间上同时具有某些信 息结构关系的空时数据，如果使用向量的数据表现形式，也就是将一段空时的数 据块进行矢量化，将会破坏空时数据内在的流形结构关系。而且由于矢量化后的 数据将会产生高维向量，其在小样本数据集上会产生过拟合现象。（2）数据规范 化。由于物联网感知的数据类型非常丰富，在处理不同的变量时，常常因为具有 不同的单位、不同的变异程度使得系数在实践解释时非常困难，因此需要将带有 单位的变量转换成标量形式。（3）数据预处理难。物联网产生的数据噪声大，延 迟长，数据不准确，而且经常因为突发事故，导致感知器失灵等，使得数据在某 一时间段、空间段大面积缺失，需要同时探索数据在空时上规律，进行数据补缺。 （4）数据维度大。传感器可以感知各种各样的数据，包括自然界中电磁、温度、 湿度、噪声、光强度、压力、土壤成分、移动物体的大小、速度和方向等，身体 域的心跳、血压、血液等多种类型数据。社交领域中Facebook、推特等每时每刻 的发帖内容、评论数、粉丝数等。当数据维度超过3000维度时，计算机在进行 矩阵求逆时就变得非常困难。（5）数据处理计算复杂度高。在进行数据预测时， 往往需要迭代处理达到收敛的状态，其千万次的迭代次数通常导致计算机处理的 复杂度高，难以适应流系统场景下的实时预测。
矢量数据结构的表示形式，无法表示数据的空间关系。基于图拓扑关系的矩 阵数据结构，可以很直观地表示事物之间的联系⑶。图节点之间边的权重反映了 同一时刻时间序列的相互关系以及不同时刻时间序列间的内部关系。
基于图结构⑸的数据分析是当前大数据集处理中最热门的技术之一，主要通 过权重矩阵将不同数据点的相似程度紧密联系。图信号处理为大数据处理提供了
2
一种新的范例、技术和算法，是传统信号处理的一个延伸。尽管其技术还不太成 熟，仍给大数据处理提供了一种新的方法和视野。
但是，在现代许多应用中，比如，计算机网络网络、无线传感网络社交网络、 金融市场，通常用图来建模，将每个实体（计算机、传感器、人、股票）表示为 图的节点，实体与实体之间的相互关系或影响（路由协议、位置关系、人物关系、 市场作用力）表示为图节点边的连接或权重。当前许多研究仍致力于先验已知的 图数据分析和处理上⑹，比如，传感网络中，通常根据传感器的物理位置来建模 为图，距离近的传感器产生的数据具有较强的相关性，而距离远的传感器产生的 数据具有微弱的相关性。但是，按照这种方式建模出来的图，有时并不能反映数 据之间的内在联系，而且在实际应用中，通常没有随手可得的图可供处理，比如， ■市场中，在同一板块中股票与股票之间的价格具行较强的相关性并相"■ 处理这样的大规模股票的价格，就没有现成的图可供狈测。因此，很有必要从有 限的样本中学习有效的图拓扑结构，而且错综复杂的数据类型，庞大的数据量， 高速的数据产生速率等特征无疑加大了图拓扑结构预测的难度，如何利用大数据 的特征，提出快速高效低复杂度的估计模型也是本课题的研究意义所在。
1.2研究内容与创新
本文的研究领域主要集中在空时信号的图结构建模与参数估计领域，主要涉 及非凸函数的优化，稀疏惩罚方法与图结构的分解以及流信号场景下实时更新图 结构参数的方法。理论部分的研究主要分为3方面：（1）将空时信号建模为,阶 高斯马尔科夫图过程并使用联合图结构进行参数估计，（2）基于空时信号结构的 '块'特征与谱聚类技术实现信号空间结构的分解，（3）基于空时信号结构的，流' 特征与迭代最小二乘方法实现信号结构在时间域的迭代求解。实践部分主要将模 型与参数估计算法应用于美国S&P500股票市场，给出股票与股票之间的相关性, 从而有助于研究人员进一步探求不同板块行业间的股票相关关系。主要的研究内 容如下：
（1）基于一阶高斯马尔科夫过程的联合图结构参数估计
在进行多个图结构参数估计时，联合正则技术可以筛选掉共同孤立的节点， 并检测出共同存在的边，从而提高网络的拓扑识别率。本文从联合图结构模型C 出发，C = [q7] e Rpxp, , Cij = Cji = J%+品十202竭,。是权重参数，B = 也JcRpxp, n = [^j] e rpxp,在原有联合图结构模型C基础上，研究图结构 B与Q的相关关系和权重参数©对性能的约束，从而定量地确定巾的取值范围。对
分组阈值q算法GTQ进行收敛性分析并通过实验验证其收敛性。最后针对不同 的稀疏惩罚进行性能对比，选出适合本文模型的最优惩罚或阈值函数。
（2）基于聚类的一阶高斯马尔科夫过程的图结构参数估计
在实际大规模空时信号的图结构中，网络结构往往是‘分块'特性，使用聚 类算法将网络结构进行分解，然后对各个子网络分别进行估计，有助于减少复杂 的计算量，减少参数估计所需的样本数。本文从谱聚类算法出发，将聚类嵌入动 态线性系统中，并提出确定聚类数K的算法。通过仿真研究不同网络规模对聚 类性能的影响，阈值q对聚类性能、聚类数K的影响以及算法复杂分析，同时 通过不同的图模型对比GTG、CDG、MRCE、JGSE在模型拓扑识别率与模型估 计准确率方面的性能，最后将其运用到真实世界中S&P500股票市场的收盘价价 格数据。
（3）基于稀疏自适应的迭代最小二乘图结构参数估计
在实时大数据处理场景中，所需的数据量很多，很难将所有的计算资源加载 到计算机内存中，计算复杂度高，需要设计简单有效的框架实时估计海量的图结 构。本文从批-最小二乘出发（B-LSM）算法出发，提出迭代最小二乘法（ILSM） 算法，利用先验估计与新息信息，在线估计图结构；同时在误差可控的范围内利 用信号结构的共稀疏性，提出稀疏自适应-迭代最小二乘（ASP-LSM）算法，提 高拓扑识别的能力，最后通过实验仿真验证ASP-LSM算法的性能，并将其运用 与真实世界中S&P500股票市场的收盘价价格数据。
1.3结构安排
后续章节安排如下：
第2章介绍大规模空时信号结构建模的基础知识以及现有的图结构参数估 计方法和稀疏惩罚方法、参数调整方法。
第3章主要介绍高斯马尔科夫过程图结构参数估计包括联合图结构的构造、 分组阈值q算法、参数调整。
第4章主要从空时信号块的特征出发，将谱聚类算法嵌入到线性动态模型 中，对联合图结构进行谱聚类并确定聚类数K,图结构精准估计。
第5章主要从流信号的角度出发，推导流处理场景下参数的迭代公式，并给 出稀疏自适应的图结构估计方法，在误差可控的范围下实现拓扑识别率的提高。
第6章总结本文研究的优缺点，并对动态高斯马尔科夫过程图结构建模进行 展望。
第二章大规模空时信号图结构建模与参数估计
2.1	引言
随着信息和通信爆炸式的增长，信号(数据)以史无前例的速率增长，包括 社会网络、生物、物理场。与时间序列不同的是，这些信号有复杂的、不规则的 结构，需要新的处理技术，导致了图信号处理领域的出现。“大数据”集具有复 杂的类型和庞大的体积等特点，然而在具体的应用中这些数据的产生会呈现一定 的结构关系。图是描述数据结构关系的•种方式，通过图的邻接矩阵权电灯■ 自观地表示顶点域数据结构的概率依赖关系，因此成为大数据集处理中最热门的 技术之»
通过现实对象的信息建立的图结构模型可以描述系统的因果关系与相乜依 赖关系，然后实现对数学模型的参数求解，从而更深入地理解数据背后产生的机 制。经典的参数估计方法有⑺：矩估计，最小二乘估计，极大似然函数估计。矩 估计是一种估计总体各阶原点矩参数的方法，比如随机变量的期望，其利用样本 期望代替总体期望估计、也就是£= 1/nNL阳-E(X),由此得到的估计量成 为矩估计量。最小二乘是回归分析中一种标准方法，用来求解超定系统或方程(方 程的个数比未知参数的个数多)的近似解。在不知道变量的原点矩以及相应的概 率概率密度情况下，可以使用最小二乘最大限度地减少每个样本的残差平方和， 其残差备二% -火工的差异是由所观测到的值和模型拟合值确定。极大似然估计 是在已知条件概率密度p(y|乃的情况下，求解使条件概率密度p(y|x)达到极大的 那个工值，作为参数估计的最优值。基于似然函数的拓展估计方法还有极大后验 估计，最小风险估计和极小极大估计法等，在一定的条件下，他们都与极大似然 估计相同。寻求最小二乘估计和极大似然估计最优解的常用方法是将目标函数对 估计的参数进行求导，计算梯度，因而需要使用优化方法⑻：梯度法，单纯形搜 索法，网格搜索法，牛顿-拉夫森等。此外，为了减少计算量，便于参数的在线估 计，通过利用先前时刻t的参数估计和新息信息t+1时刻的输入量，递推公式计 算新的参数值，因而使得每一步的计算时间要比求解一个线性方程的计算复杂度 要少很多同时所需的时间也要少得多。根本上，本文所涉及的图结构参数估计也 是从最大似然函数和最小二乘法估计进行相应的参数求解，但是也会带来相应的 问题，比如在应用最小二乘法求解图结构参数时候，未知参数的个数往往大于观
察样本的个数，容易产生过拟合现象等，需要使用新的技术手段来解决这些问题， 这也是本文研究的重点。总体上，本章将简要介绍空时信号的图结构建模，图结 构参数估计和参数调整相关重要技术，为后续行文打下基础。
2.2	空时信号与图模型
在处理许多基于图描述的算法中，利用结构化的数据构建有意义的图结构非 常重要，尤其是在新兴的图信号处理领域。数据分析的首要任务是获得数据的低 维描述，图结构或者离散流模型，可以很好地描述同一时刻时间序列的相互关系 以及不同时刻时间序列的内部关系。下面将阐述空时信号以及图的相关概念。
图可以很直观地表示事物与事物之间的联系，其数学表述为：G = {V,E}, V = {1,2，…，P}表示图上的顶点集，|V| = P, E =	表示图上的边，顶点
I与顶点/相连，也)表示变的权重。当亚={%,/}为对称的权重邻接矩阵时表示无 向权重图表示。
一般来说，在大规模网络中我们面对的图结构都是稀疏的，即当前节点i不 可能与其他所有的节点/O e {V\i})有直接的联系，对应邻接矩阵的权重系数也/为 0,即使是在小范围内或在子网络内，网络关系呈现紧密连接状态，网络中也会 存在节点与节点之间没有连接的情况。因此，定义图的稀疏度q = ||W||o/p2 = abs59九(％/)) ”2,即邻接矩阵W = {W"}中非零元素所占的比例来表示网 络连接的稀疏情况。
本文所指的空时信号是指在时间域上无穷无尽平稳变化的信号，在空间域上 可以将信号定义在具有权重的、有向的或无向的图G上，信号值对应的顶点上携 带了样本中有意义的信息。定义顶点域到实数域映射x:V-R,矢量x的第i个函 数值表示顶点i的实数值，一旦图节点的顺序固定，那么图信号可以写成矢量形 式：% =[腐ecpo用/表示P维随机矢量代表某一时间点上图 顶点对应的信号值，Xt = [%t,xt+1，…,Xt+N_1]T表示第t至t+N-1个时间片段内P 个节点所有信号值，记为Xt & NNxP,那么Xt+1 = [xt+1,Xt+2 ...,Xt+N]T表示第t+1 到t+N个时间片段内P个节点所有信号值，则Xt+1与Xt为空时信号在当前时刻与 前一时刻的矩阵表示形式。
在图信号处理框架(DSPg)中⑼，基于图上信号处理的相关技术：拉普拉斯矩 阵L、全变差、图平移、图滤波，可以用来描述图与信号之间的关系。在无向图 中最重要的一个算子是拉普拉斯矩阵L = D - W, W = {她才是对称的权重邻接 矩阵，D = diag{di，d2,…dp},是度矩阵，L是所有边到顶点i的权重之和。L是实 对称矩阵，有完整的正交基和对应的特征值，即有P个实的、非负特征值b(G) =
■i=o,LP-i，对应地P个完全正交的特征矢量3 = ｛先｝『0,1,41，写成矩阵形式： L = xAxT, A对角化的特征值矩阵，其特征值按照从小到大排列，X是特征矢量矩 阵。最小的特征值为0,且特征值为0的个数表示网络(图)连通的个数。通过 上面的拉普拉斯矩阵L谱分解，产生了频率和图信号傅里叶变换的概念。由拉普 拉斯矩阵产生了图信号的傅里叶变换：今=＜羽为＞=221久Ox；。)，其对应的 逆图傅里叶变化：x(z)= s^WXi(0»图的傅里叶变换利用图的拉普拉斯矩 阵的特征矩阵将信号与图谱联系在一起。
利用拉普拉斯算子，还可以用来定义图的全变差，用来表示信号在图结构的 平滑性。定义图G上信号x的平滑性，可以使用L的二次形式来衡量：xtL% = 力〜jWij® —%2/2,好和引是节点/与节点./匕的恰号值。也观卜一，给定权电为 /负值，如果强连通的顶点(顶点之间有很大的权电)行相似的值那么认为图信 号光是平滑•，特别地，广以的值越小，图信号值越平猾,。平滑的图信号模型在许 多学习问题中被广泛使用，比如图正则，半监督学习。
而在有向图中使用图邻接矩阵亚=即非对称的权重邻接矩阵来表示图 顶点间的结构关系，Wnm可以是任意正数、负数、实数、复数值。需要注意的是， W不一定是实对称矩阵，那么对W做谱分解时有可能不存在完全特征集“叫可 考虑对W作Jordan分解：W = VJV-1。
一般地，与经典信号处理类似，定义图滤波为系统H。，将空时图信号勺作 为输入，产生新的图信号欠= H(x)作为输出。我们可以认为图移是一个局部乘法 算子,将顶点%的信号值&，使用顶点Vn邻节点信号值的线性加权和来代替：石= £mevWn,mSm，因此，图滤波的输出可以看作是给定输入信号与邻接矩阵W的 乘积：元=[/,…,4口 = W%。在DSPg框架中线性移不变图滤波是邻接矩阵W 的线性权重和：秋W) = /ioI + /hW +…+即WL,信号经过图滤波后无= H(s) = h(x)x„线性移不变图滤波拥有一些有用的特性，当Nw = degniw(x)时它至少有 LWNw跳系数%, degmwO)是W的最小多项式mw(x)的度；如果线性移不变 图滤波算子/i(W)是可逆的，那么其逆算子g(W) = /i(W)T也可以应用于相同的 图G上。最后，图滤波空间是线性代数空间，这些特性保证了任何非零的常量乘 以邻接矩阵W不改变相应的线性、移不变图滤波集【川。
拉普拉斯矩阵L描述了信号与图谱之间的关系，全变差描述了信号在图结 构的剧烈变化程度，图平移和图滤波描述了节点与节点之间的信号关系。总之， 这些概念与对应的技术可以有效地将图结构与信号联系起来，可为我们的空时信 号图建模提供灵感与设计技巧。
2.3	空时信号图建模
目前，关于从收集的复杂的数据中构建或学习图拓扑结构这方面的研究还相 对较少。当前图结构估计的主要构造模型有三种：因子模型A1，因果图过程模型 口叫一阶高斯马尔科夫线性动态模型Ml。因子模型是将信号与信号的图谱通过图 结构联系起来，因果图过程模型可以说是一阶马尔科夫模型的拓展将信号建模为 当前信号不仅与前一时刻有关系而且还与前面多个时刻有关系。一阶高斯马尔科 夫线性动态模型是将信号建模为当前信号只与前一时刻有关系，而与其他时刻没 有关系。这三种模型都能有效地将图结构与信号的结构关系紧密联系在一起。
2.3.1	因子模型
因子模型是一类通用的线性统计模型，它试图用较少的未观测的隐变量值来 解释给定维度下的样本值。因此，对于输入的图信号考虑下面的描述模型：
x = \h + ux + e	（2-1）
久是某一时刻观察的图信号，/icrp是隐变量，通过特征矢量矩阵控制图信 号龙，也是信号犬的均值。我们采用各向同性噪声模型，假设e服从均值为0,方 差为Mln的多元高斯分布，即e的概率密度函数为：e〜N（O,虎0）。这个模型可以 认为是图信号的经典因子模型，但是，其描述矩阵的选择是拉普拉斯矩阵L的特 征矢量矩阵X。X将图信号与隐变量关联起来。描述矩阵反映了图的拓扑结构，那 么图的构建可以直接与图信号的表示联系，L的特征矢量矩阵是一个很好的基， 提供了图顶点的图嵌入解释。
在经典的因子模型中，假设隐变量力高斯先验已知，特别地，假设隐变量九服 从退化的零均值多元高斯分布且密度矩阵为特征矢量矩阵A,即八的概率密度函 数为：/〜N（0,A+）, A十为A的伪逆。八的假设暗含了信号的能量主要集中在低频部 分，从而保证了图信号的平滑。基于公式（2-1）,给定人下的x的条件概率密度， 和工的概率密度分别是：
x\h - N（x% +以,位In）
x 〜N（〃x，L+ + 虎（2-2） 从式（2-2）中可以看出，在没有噪声场景下％ = 0, x也服从退化的高斯分布。 而且，无可以看作是对应图结构G的高斯马尔科夫场，其密度矩阵（即协方差的 逆矩阵）定义为图拉普拉斯矩阵L。高斯马尔科夫场是非常通用的模型，其密度 矩阵可以自由定义，只要它的非零元素与随机变量之间的部分相关性编码对应, 以及它们的位置正好对应图的边。
8
2.3.2	因果图过程模型
对于时间序列数据，而不是估计逆协方差的矩阵结构，稀疏矢量自回归 (SVAR)可以估计多元变量过程的稀疏矩阵结构。根据马尔科夫场(MRF), SVAR模型假设通过邻接矩阵Ae｛O,"PxP,每个节点的时间序列条件依赖于其 他节点。那么空时信号的动态演变过程可以表示为：x'[k]=2giA⑴久，伙一”+ w[k]
是随机噪声过程，对于任意时刻t丰j, 与w⑺相互独立。A①有相同 的稀疏结构，也就是说，对任意M有A'=00用? = 0。然而，集合｛A。)｝在单 ・重邻接矩阵中很难解释和分析,如果使用无权中矩阵A将工充了时代和， ■。因此，因果图过程模型使用权重图A,和其对应的时间滤波作为图滤波模 型，其动态演变过程如下：
L
x'[k]=[ A(D£[/c — i] + w[k] i=i
=S ( V ) x'[k - i] + w[k]
i=i \7=o	/
=(ciqI + c11A)x/[k- 1]
+ (。201+ C21A + C22A2)%'[k - 2] H-
+(Cl(J + —卜 CllAL)xI1< - L] + w[k] (2-3)
R(A)是A的矩阵多项式，也可以看作图A的时间滤波,c〃.是标量的多项式系数， 有C = (clo Ji …Cll),。
因果过程模型并不一定假设节点与其相邻的节点具有马尔科夫特性，它强调 信号在一个节点上的当前时刻受网络的影响。矩阵多项式R(A)有最小阶 min(i,NA),反映了x'[k]不受/阶时刻以前的网络影响，并且受限于Na，山为A 的最小多项式的度。通常，模型的阶取值为L« Na。
2.3.3	一阶高斯马尔科夫线性动态模型
马尔科夫随机场可能仅仅被研究人员应用于空间统计和图像分析中，但是， 高斯马尔科夫随机场(GMRF)还有其他广泛的应用[功，比如，结构化时间序列 分析，空时统计，图模型，参数统计等。GMRF在空时模型描述时，通常认为在 时间域上是自回归模型，在空间域上是条件回归模型。
假设存在P个节点来表示图，用下面的一阶高斯马尔科夫过程来表示线性 动态模型(LDN)：
9
xt+1 = Axf + et, et〜N（0,£）	（2-4）
机是P维随机矢量，代表某一时间点上图顶点对应的信号值，J是P维系统 噪声。A是过度转移矩阵，决定了当前状态是如何从过去先前状态演变过来的， 表明了节点之间的因果关系，因此也称为因果转移图（GTG）。是高斯密 度矩阵，决定节点之间的条件依赖关系，如果34 =3。= 0,表明节点i与节点J条 件独立，因此也称为无向条件依赖图（CDG）。从系统模型中，还可以看出对于 任意图结构顶点，当前时刻的噪声会影响下一时刻的图节点上的信号值，无向条 件依赖图，也就是噪声矩阵Q,从信号的空域关联关系上影响着空时信号的演变 过程。因果转移图A中对角线上元素表示自身节点在当前时刻与前一时刻的关 系，而非对角线上的元素表示自身节点与其他节点在当前时刻与前一时刻的关系。 这两个图结构A和。反映了图节点在时空演变上的一阶和二阶关系。
针对不同的应用场景，不同的数据集，不同的模型有不同的优点，只有模型 适不适合数据，根据数据假设的模型符不符合实际的应用场景，此外，根据奥卡 姆剃刀（Occam*Razor）原理，模型越简单越好，能用简单的模型表述数据集的 尽量用简单的模型。因子模型中图信号的估计可以看作图结构G的高斯马尔科 夫过程，上要研究了静态信号的空间结构关系，不能反应信号的时间属性。而因 果图过程模型主要考虑图结构上顶点间信号值的时间变化的马尔科夫过程，利用 图滤波思想，当前节点的信号值不仅与其他节点的前一时刻有关系还与前面多个 时刻有关系，但是它认为每个时刻之间噪声是独立的，可以说是高斯马尔科夫时 间过程的一般通用公式。一阶高斯马尔科夫线性动态模型是GMRF的一个特例， 主要考虑图结构上顶点的信号值与前一时刻自身顶点和其他顶点的信号值有关 系，体现了 GMRF在时间上的自回归特性，而节点与节点之间的关系体现在噪 声密度矩阵上。一阶高斯马尔科夫线性动态模型虽然简单但是却将节点与节点的 关系，节点上信号值的关系都有机地联系在一起，巧妙地包含了因子模型中所反 映的空间关系和因果图过程模型的时间关系。
2.4	图结构参数估计方法
最大似然估计是数据挖掘、信号处理中一个非常有用的参数学习工具。它是 一个方法体系，试图解决两件事：首先，当你想要从数据中学习一些模型，它是 一种相当好的原则性方法，帮助你计算你应该做什么。其次，它往往是计算高效 简便的。最重要的是，许多复杂的模型诸如多项式回归，神经网络，混合模型， 隐马尔科夫模型，最大似然估计（MLE）的思想可以帮助你理解I］和分析问题。 对于许多估计问题，最小方差无偏（MVU）是不存在的，即使存在也没有相应的
10
系统程序找到他的最优解，因此，通常使用最大似然估计来代替MVU。MLE不 需要满足任何最优判别准则，其独特的特点在于“转动摇摆的方法”，使得它可 以很快地实现对复杂估计问题的有效求解。粗略地讲，一组数据的似然函数是在 给定概率分布模型下获取特定数据集的概率。这个表达式包含了未知模型参数， 而参数的取值是样本的似然最大。也就是给定n个独立同分布的样本值 打,久2，…,xn,这些样本来自于同一个分布但是不知道概率密度函数0（•），推测函 数%属于某个家族分布｛f（? |。）,0 6 9｝, 6是这个家族的参数矢量，称为参数模型， 因此，f0 =	1%），0。未知且认为是参数矢量真正的值，目标是找到理想的估计
值品尽可能逼近真实的6。值。为了使用最大似然估计，首先需要写Hl所有观察样 本的联合密度函数…。⑼=f（Xi|0） x f（x2|0） X ...X f（xn|e）,可以看出观 …凡依赖于参数仇反过来,8可以看作是关广观察值对,孙，…
数，那么似然函数可以写成：£（0；%1…,0）=©1，%2,…如⑻=IK"（阳|6），； 表示两个输入参数的分割。在实际中通常转化为对数似然函数，即 ln£（6;xi，..,xn） =2kJn/5|0）,最大似然估计是分析最大化的过程，通过找到 品值使得也£（&%1，..,0）最大化的过程，其数学表达式为：｛0m/e） £ ｛argmax In £（0;, %„）｝o如果最大值存在，无论是最大似然函数还是对数似 Ges
然函数其MLE解释是相同的，因为log函数是单调递增函数。
对于许多模型，最大似然估计可以是观测样本巧,一今的显式函数，然而也 有许多模型，没有封闭形式的解，不能求出解析求解；还有对于一些问题，最大 似然存在多个估计，而对于另外一些问题，最大似然估计不存在（即对数似然函 数值一直增加没有极值）。因此，数值优化技术比如梯度下降，牛顿下降口A网 格搜索法陷、评分方法网等被广泛使用。牛顿法、得分法等迭代方法，仅在网格 搜索法失去作用时才使用，但是不能保证MLE收敛性。对于绝大多数使用的最 大似然估计，MLE具有渐进无偏特性，可达到Cramer-Rao下限（CRLB）,并 且具有高斯概率密度函数（PDF）,是一种渐进最优的估计。
优化问题是应用数学和数值分析的一个分支，由最大化或最小化一个实函数 构成，通过在可行解中系统地选择输入值并计算该输入值的函数值。其数学描述 可以表示为，给定函数f:A- R, f是集合A到实数集的映射，对于A中的任意一 个x,寻求A中的元素X。使得f（x（）） < f（x）（最小化问题）或者f（x（）） > f（x）（最大 化问题）。A是欧式空间R"的子集，具体为一些约束条件，即A中的元素满足等 式或不等式约束。f的域A称为搜索空间或选择集，而A的元素称为候选解或可 行解。函数f称为目标函数或损失函数或成本函数。可行解是使目标函数最小（最 大）的解。在数学上，经典的优化问题通常表示为最小化，包括不同类型的目标 函数和不同类型的可行域。许多现实世界的理论问题都可以建模成这个框架，比
11
如，最大似然函数的参数求解。
费马和拉格朗日提出微积分的公式来确定最优解，而牛顿和高斯提出了迭代 方法使得所求解逐步逼近最优解。拉格朗日乘法从理论上，比如KKT条件，来 确定凸问题的解，在实际中用的比较多的还是基于牛顿的迭代梯度下降法。最速 梯度下降法是逐步最小化损失函数的过程，沿梯度下降的方向求解极小值（或沿 梯度上升的方向求解极大值），其迭代公式为：ak+1=ak + pfesW,其中6（的代表 梯度负方向，Pk表示梯度方向上的搜索步长。一般步长的确定是通过搜索方法来 确定，也就是将下一个点的坐标aa］看作是。人的函数，然后求满足f（ak+i）的最小 值，这种方法简单明了，易于实现，但是收敛速度不尽如意，在最小值附近以一 种取着的形式慢慢逼近最小点。牛顿法是在当前点用二次泰勒展开，令其导数为 0,近似最小化目标找出极小点，然后进行线性搜索。这种方法有很好的收敛速 度，但是需要付出计算代价，每次需要计算二阶导而且需要求逆。拟牛顿法（DFP） 是在k次循环时，在上一个循环中的海森矩阵（Hessian）基础上得到在当前点的 Hessiano这种方法省去了重新计算Hessian矩阵，仍然需要存储并更新Hessian, 还有求逆的过程。BFGS方法是通过直接近似Hessian矩阵的逆，省去了求牛顿 方向中需要的矩阵逆运算，从而达到既不需要每步重新计算Hessian,又不需要 求逆的效果。这种方法在每次迭代时仍然需要存储更新矩阵，当矩阵维度很大时 非常占用内存空间。L-BFGS在每一个循环都保存之前步骤的相关信息直接近似 计算出牛顿方向，从而不仅像BFGS一样省去了单个循环计算Hession矩阵并求 逆的运算，而且也省去了存储Hession的必要。这种方法是一种并行化计算，在 有限的内存中存储计算，省去了很大的内存，现实中许多大规模的可微的约束问 题都可以通过此方法来解。由此可见，基于迭代的一系列牛顿方法已经很成熟， 也有很多统计软件包［2。］可以拿来直接使用。
一般情况下，除非目标函数和约束条件都为凸的情况下，其他情况都有可能 存在局部最优解。在最小化问题中，局部最小解无*定义为，存在3 > 0, ||%-%*||, 所有的x满足f（x*） <f（x）,也就是说，在％*的周围区域，所有的函数值都大于或 等于改点的函数值。虽然局部最小至少和附近的一样好，但是全局最小值至少和 每一个可行点一样好。在凸优化问题中，如果存在局部最小点，也是在可行域的 内部，而不是可行的点集边缘，那么这也是全局最小点，但是在非凸问题中可能 存在多个局部最小点，都不是所需的全局最小。在许多问题中，也会经常碰到非 凸的问题，目前关于非凸问题的求解主要还是采用迫近法mi或将问题转化松弛 凸问题［22］、局部凸化［23］的手段。实际中也提出了大量的算法求解非凸问题，包括 商业可用的求解器，大多数都不能区别是局部最优解还是全局最优解，通常是将 前者作为原问题的解。
12
这里主要介绍了求解参数估计以及优化当中的一些基本的方法，这些方法也 是最重要的方法，很多复杂的问题都可以通过这种思路得到求解。在高维信号的 统计参数估计中比如本文的大规模数据的图建模，仍然可以延伸最大似然估计、 梯度求解的思想，但是要复杂的多，未知参数的个数要远远大于样本的个数，稀 疏假设的合理性等，下面将介绍本文需要采用的图结构参数估计方法。
2.4.1	高斯图结构学习
高斯图结构的基木模型是假设观察样本服从均值为山协方差为£的多元高斯 分布[241, X = (X1…Xp)〜这个模型也包含高斯线性模型，比如，X1是 响应变量，Xk(2 WkSp)是预测变量。假设£非奇异，且条件独、九£的分布以 方便的表示成•个图模型G = (V,E),如果I1的第ij个兀素是0,那么变吊:”j变 最/条件独立。令。= £-i, S是经验协方差矩阵，这个问题的最大似然函数对数 形式：
log det® - tr(S。)-	(2-5)
假设均值H已知。0T是非负定矩阵，tr是矩阵的秩，II创11是k范数,即£T中每 个元素的绝对值之和。
公式(2-5)是凸问题，已知均值日下的高斯最大对数似然，只需考虑£或XT, 令亚是£的估计值，使用块坐标下降法，通过优化W的每一行和对应的列来求 解问题。分割W和S：
必2的解满足：
%2 = argmin{yTW#v： ||y - sRL < p]	(2-7)
y
这是一个箱约束二次规划问题(QP),可以用内点法来解决，置换行和列，那么 目标列总是在最后，对于每一列在每个阶段更新W的估计值，重复操作指导收 敛。使用凸对偶，公式(2-7)的原优化问题可以写成对偶问题：
1	2
min{| Wf^-b +川BI|J	(2-8)
其中，b = W；1s3, 0可以通过上式(2-8)求解获得，那么Wi2=Wi$就可以 解决原问题(2-7),公式(2-8)与lass。回归特别像。我们可以证明公式(2-5)
和公式(2-8)的解是等价的，且关系为W0 = L具体的表现为：
13
现在对公式(2-5)求子梯度：
w-s-P-r = o	(2-10)
10gdet G)的微分是= w, rt7 e sign(e>ij),也就是如果日4中0,坛=sig九⑼)， 如果= 0, Lj e L-1,1]O
公式(2-10)中矩阵右上角元素满足：
W12 - S12 _ P . 712 = 0	(2-11)
公式(2-8)的子梯度：
WiiS - s12 + p , v = 0	(2-12)
其中v esign(6)，假设(W,r)是公式(2-10)的解，(w12,y12)> (2-11)的解， 那么0二W1W12，V =-匕2是公式(2-⑵ 的解。任何符号项从(2-9)中可知 W11012 + @12^22 — °，那么有= -G22^11w12^ 因为。22 > °，那么Sign(B]2)= -signtW^w^) = -sign(P),因此公式(2-5)与公式(2-8)的解等价。公式(2-8)的优化问题可以认为是L正则的最小二乘问题。事实上，如果W"=S11，8的 解可以很容易地看作是第p个变量的lass。估计。一般地，W11芋S",使用快速 坐标下降算法可以使得lasso问题的解。根据内积的概念，第P个变量的lasso估 计将Su和Si2作为输入，更新w并循环所有的变量直到收敛。从公式(2-10)可以 看出，对于任意"优化问题的解wn = sa+p。因为0“>0,所以0 = 1,为了 方便我们称这样的算法为图lassoo图lasso的具体算法步骤如下：
(1)初始赋值为W = S + pl,在任何情况W的对角线元素保持不变。
(2)对于'每个变量j = l,2,…,P,使用lasso求解公式(2-8)问题，输入为W* 和Si?的内积，即lasso(Wu，Si2，P)，输出8的前P-1个矢量值，使用Wi2=Wi/ 填补W中对应的行和列。
(3)循环迭代知道收敛。
值得注意的是公式(2-5)的优化问题并不是p个独立的正则回归，而是p个 耦合的lasso问题，它们有相同的W和。=W-i,用Wii代替Su共享问题之间 的信息，是一种比较受欢迎的方法。在步骤(2)中对于每次迭代周期置换相应 的行和列使得目标列总是在最后一列，其lass。问题也可以使用坐标下降法有效 的计算得出，令丫 = Wii，u = s12> 0的更新形式：
印—S。/*&舟户	C2-13)
其中,Soft是软阈值，Soft(x,t) = sign(x)(\x\ — t)+=最后，当W的平均变化 值小于t,ave|S-diag|停止迭代，S-diag是经验协方差矩阵，是S的非对角线上的 元素，t是固定的阈值，默认为0.001。
14
2.4.2	因果图结构学习
在新兴的网络科学领域中，网络节点的演变不仅与自身节点有关，而且与其 他节点有关。多元时间序列正好包含了网络拓扑和动态性等重要信息、，矢量自回 归(VAR)1251是一种最常用的模型来刻画时间序列之间的关系，在这个模型中， 每个节点的状态是由一个时间序列来刻画。在某一时刻一个节点的值是过去世界 自身节点和其他节点值的线性组合，一般把这种关系称作Granger因果关系。通 过估计模型的过度转系矩阵，有助于理解节点之间的Granger因果关系。
因果转移图过程模型：
xt = Axt_x + £t, 4〜N(O,EJ	(2-14)
工是p维矢吊:，何:个元素对应动态网络中一个节点的时间序列,p是网络的节点 个数，A是转移矩阵，j是随机噪声。广义的VAR模型对应着m阶，当前.状态 ■ m个状态的线性组合。另一方面,通过重定义恰当的节点变吊:，任何■ VAR模型都"以转换成一阶VAR模型，因此我们更专注于m=l的情况。
给定网络的n个样本Xi，…,xn, A的最大似然估计为：
L(A|x1(..,xn) = n?=2	(%1
=	(2-15)
最大似然估计需要解决非线性优化问题，为了简便，研究人员经常使用条件似然， 即久1的初始状态假设固定。由于正态分布的特性，条件似然可以写成：
Lc(4) =	= 口之2(21)-P/2 &|T/2exp{—一
—i)T4|T(Xt——.1)1 (2-16) 那么，A的估计可以转换为：
呼扛屋区 一5-11|：	(2-17)
令丫=[嬉，居…，媒]。X=[xT)xTi xT_i]T)b = A\那么优化问题的矩阵形式 为：
Bml = argmin L(B) =|||Y-XB||；	(2-18)
实际上，X通常是高度共线性的，尤其是当一些节点有相似的动态行为而观 察样本的个数是有限的。单纯的最大似然估计并不产生稀疏的解，因此求得的模 型很难解释。为了提高预测的准确性和模型的可解释性，增加一个惩罚项或约束 项，惩罚最大似然函数(PML)可以写成：
Bpml = argmin L(B) +	P(%,旬)	(2-19)
B
15
bjj描述了节点i与节点j之间的有向连接强度,P。是B中每个元素的惩罚函数， 人,是对应的正则参数。比较受欢迎的是Lasso方法，其使用的是。范数，那么上 述优化问题是凸的，可以使用相应的Lasso统计优化软件包因］求解得到。
2.4.3	稀疏惩罚方法
高维数据广泛存在于人们的日常,，远远不是某种特殊现象，比如信息科技， 生物，航天科技产生的数据维度都很高。这里“高维”所指的是所需要估计的未 知参数个数远远大于数据的样本个数，甚至是一个或者几个数量级。经典的统计 推断并不能直接用于高维问题。比如，线性最小二乘拟合中，未知参数的个数远 大于观测个数，对应的标准误差和测量的意义都有可能是病态的。不难看出，没 有额外的假设或者限制应用到某一特定的模型，高维统计是不可能的。平滑函数 的估计，使得基于结构平滑的假设可以用来拟合许多参数的情况。随着方法论、 计算数学的进步，另一种基于稀疏假设的高维数据统计推断得到了肯定。从平滑 到稀疏约束，或者两者结合，打开了复杂数据应用领域的新路径。比如，稀疏假 设允许一个病人的健康状态取决于几千个生物标签中少数几个，要比在平滑假设 中所有的生物标签都对病人的健康状态有贡献更有实际和显示意义。此外，稀疏 假设［27］不仅可以简化模型还可以保留数据中比较重要的信息，使得数据有更好 的解释效果。在上面的高斯图结构估计和因果图结构学习中都对此进行了相应的 稀疏假设，因为实际中图的节点不可能跟其他所有的节点都有关联。稀疏假设的 方法有很多，这里将做一些简单的分类介绍，以便在后面的模型中更好地嵌入。
在正则化稀疏模型中具有开创意义的方法是Lass。的提出，Tibshirani使用，1 范数替换岭回归中的G范数，得到了 Lasso估计阳。%惩罚在估计和预测准确率 方面有明显的优势，并在平滑的标准方法中，比如，Newton-Raphson有广泛的应 用。21惩罚在零点处不可微，这个特性在高维模型选择中也非常有用，因为通过 LASSO估计得到的零解可以丢弃一些不重要的特征。在不相干设计中，不可表 示的条件、压缩感知RIP【29】规则等有较好的性能。Lasso对应的求解算法LAR (Least Angle Regression)提出后，稀疏正则模型才引起了图像处理和机器学习 等相关领域研究人员广泛关注与深入研究。
假设线性回归模型：y = Ha + s,其中，y CRN是因变量，H e R^p是观测 矩阵，a CRP是回归系数，ee RN是高斯独立分布的误差向量。
(1)基于G岭回归的正则模型：
arg嗽-	+ 期(2-20)
G范数有平滑回归系数a的作用，对回归系数有一定的压缩，在一定程度上
16
避免了过拟合，但是不能产生稀疏解，使得预测变量的待估系数接近于0,从而 给模型的解释性做成了困难。
(2)基于匕的Lasso正则模型：
argmin|||y - Ha\^+A\\a\\i	(2-21)
入2 0是调整参数，|[a||] =?Mi|ap|,也就是说Lasso惩罚是对回归系数的 匕范数进行压缩惩罚，使绝对值较小的回归系数变为0,从而产生稀疏的解。与 岭回归不同的是，Lasso无法得到理论解析解,它是通过数值优化里迭代下降法， 比如坐标卜降法，不断迭代收敛得到。其回归系数即在每次迭代中的更新过程为：
&P = sign(%)(M| -入)+
( afp - A f afp > A
二1	0,	< afp < A	(2-22)
(	&fp + 尢	p V -A
今p为最小一二乘估计的解，可以看出，落在[-入，入]区间内的系数都被降为0, 而这部分系数所对应的变量不参与模型的拟合，从而实现了对量的选择。
(3)基于Lasso的SCAD稀疏惩罚模型：
argmin|||y - Ha\^ + Ep=i<PA,y(«P)	(2-23)
aERp 乙	'
p e {L …,P}, W儿y(?)是 SCAD 惩罚
'A|e|,0< |0| <A
(|6|2-2yA|e|+A2)
W尢y(6)= <	2(y-i)	, A < |6| < yA	(2-24)
空严，|6| >yA
I 2
y和4一般默认取值为丫 >24 2 0, SCAD模型对回归系的绝对值数落在 [0,为区间部分倾向于压缩为0,这和Lass。的作用相同。对于回归系数的绝对值 落在[人,丫刃部分，随着回归系数绝对值的增大惩罚程度减小，而对于回归系数的 绝对值落在区间小尢+8],不再进行惩罚。
Wang和Li的文章的中建议参数y = 3.7比较合适，另夕卜，当观测阵列正交 时，SCAD在每次迭代中的更新过程为：
(	sign("p)(|"p _/l|)+ ,	\a'p\ < A
即=，	((y - l)ap - sign(a,p)yA)/(y - 2),	2 < \a'p\ < yA
(	即,照|<必
(2-25)
SCAD方法的优势在于回归系数对于数据是是有连续性的，因而比较稳定。
17
(4)基于Lasso的MCP稀疏惩罚模型：
argmin|||y-Hcr|P 4-Sj=i<PA,y(ap) aeRp /
%,yC)是MCP惩罚：
(2-26)
W儿y（e）=
4|6|一喏,|0|<yA |6| > yA
(2-27)
y和2一般默认取值为y > 1,2 > 0,可以看出，MCP模型对回归系的绝对值 数落在［0/刈区间部分倾向于压缩，当y— co时，MCP惩罚逐步趋向于基于范 数的Lasso惩罚，回归系数的稀疏性也变得越来越小，而对于回归系数的绝对值 落在区间卜尢+②］,不再进行惩罚。当了一1时，MCP惩罚逐渐趋于（°范数，回 归系数的稀疏性也变得越来越大。
SCAD和MCP稀疏惩罚模型都是一类近似无偏稀疏模型。在模型选择中， 我们可以把自变量分为两种，一种是目标变量，其与因变量密切相关，在求解过 程中是期望得到的解，另一种是噪声变量，其与因变量无关，是目标变量的干扰， 在求解过程中是希望抑制的解。Lasso模型在进行稀疏惩罚时对所有的回归系数 都进行了相同程度的惩罚，因此对期望变量对应的回归系数也会进行相应的压缩, 导致了对目标变量回归系数的有偏估计。而SCAD和MCP模型有选择性地对回 归系数的变量进行压缩，在一定程度上克服了 Lasso有偏估计的缺点，是一种近 似无偏稀疏模型。其他的近似无偏稀疏模型还有自适应Lasso》1,松弛Lassos1,， 桥回归网模型等。自适应Lass。，松弛Lass。,，桥回归惩罚函数是凸的，SCAD和 MCP惩罚函数为非凸的。他们都各自有各自的优缺点的，非凸惩罚在变量选择 的一致性有较好的效果，但是也可能会导致全局最优解不存在。
（5）基于Lass。的分组稀疏模型：
分组稀疏惩罚是指将某些变量作为一个整体同时选中或同时不选中进行模 型的构造，也就是说，将回归系数绝对值几乎相等的那部分，所对应的变量彼此 之间相关度非常高，将他们作为一个组同时选中或同时移除。分组稀疏模型可以 分为三类：（1）通过对岭回归施加惩罚，（2）通过惩罚系数之差（和），（3）通 过两两无穷范数惩罚。通过岭回归施加的自动分组惩罚包括迹Lasso3］、弹性网 3】、弹性SCAD1361等，弹性网这种方法对全部变量都施加同等程度的岭惩罚，自 动分组比较不适应，而迹Lasso和弹性SCAD会根据变量间的相关系数的自适应 的进行分组；通过惩罚系数之差（和）的自动分组惩罚包括融合Lasso,加权融合 Lasso、弹性相关网等。融合Lasso是所有其他回归系数惩罚分组的基础，其他的 融合技术均受融合Lasso启发。加权融合Lasso和弹性相关网可以通过对变量之 间的正负相关系数自动分组。通过两两无穷范数的分组惩罚，使用无穷范数来约
18
束变量间回归系数的最大值，可实现正相关与负相关的自动分组。
(6)基于2。的非凸稀疏惩罚
两个最基本的惩罚% (岭惩罚)和乙惩罚(LASSO),都是凸惩罚并且都是计 算方便的，但是％实际上并不产生稀疏解，L受限于变量选择的不一致性，使得 在处理回归中的共线性问题中准确率大大降低。比如说，在高分辨率光谱估计中 需要足够多的过完备字典来表示信号特征，而许多正弦原子的分辨率是高度相关 的，类似这种共线性问题的回归使得匕惩罚甚至比％惩罚的性能要差。而11范数是 %范数的严格凸松弛，为了保持准确率和稀疏性，必须考虑类如“2。+ %”的非 凸稀疏惩罚。然而没有哪个技术直接应用离散惩罚，比如％和/%，或分组惩 罚，大多数都是将非凸惩罚转换成凸松弛的形式:
argmin^ ||y -Ha\f.+y la^0	(2-28)
aeRp /
为了解决共线性和噪声污染的问题,相对应的“2。+ %”的惩罚形式为: arg吧 n：||y — ”团1： +薪(2-29)
仇是追求稀疏的理想表示形式，然而1的参数调整却不能忽略，大多数参数 调整策略，比如K折交叉验证，是非常耗时的。YiyuanSheR]提出了基于2。的稀 疏约束的阈值筛选技巧|[a||o < m,与惩罚参数/I相比，m更具有意义和可定制性， 可以通过先验的稀疏假设很方便地设置，而，2范数惩罚参数是不敏感参数的，不 需要进行大量的网格搜索，许多研究者网已经给出了最佳的默认值(比如，le-3),可以有效地减少预测误差。同时，他还证明了其迭代的收敛性与一致性。
2.4.4	模型选择方法
模型选择是从多个候选模型中选择最佳的一个，也就是从包含所有变量的模 型中选取信息量最大的子集进行建模。大体上模型选择的目标有两个侧重河，第 一个侧重是模型预测的有效性，比如在分类问题中，往往不关心有哪些变量影响 模型以及模型的回归系数是多少，而是关心模型能不能适用于新的样本点即能不 能正确地分类；第二个侧重是模型的相合性，也就是选择的模型是否跟真实的模 型一致。通常真实的模型并不存在于候选模型中，而是由候选模型中最接近真实 的模型替换。一般模型的有效性和相合性无法同时满足，不同的模型选择有不同 的目标，需要我们根据实际情况和研究目标自己确定。由于不知道真正的模型长 什么样，训练得到的模型都可以认为是真实模型的一个近似，模型评判的标准是 用了某个模型后相对真实模型的信息损失最小，其主要包括AIC准则，BIC准 则，HQ 准则等，AIC =-21n(L)+2 *k, BIC = -21n(L) + ln(n) * k, HQ =
19
—21n(L) + ln(ln(n))*k, L是似然函数，k是参数的个数。当似然函数的差异比 较显著时，说明模型之间的差异比较大，选择模型比较重要；而当似然函数的差 异不明显时，那么模型之间没有什么区别，模型的复杂度起作用，选用参数个数 少的模型。BIC对样本数量的惩罚力度比较大，可避免模型精度高而模型度也过 高的情况，因此BIC侧重于模型相合性的选择，而AIC更侧重于模型预报有效 性的选择。模型选择的新方法主要包括：基于惩罚因子的模型选择，基于降维的 模型选择，Dantzing Selector选择器。基于惩罚因子的模型选择方法在上一小节 已经着重描述过了，这里不再赘述，Dantzing Selector选择器［4。］有比较好的理论 性质，参数估计与真实参数的J范数保持在log(P)之内的误差范围，而基于降维 的模型选择方法网是通过主成分分析(PCA)或主成分回归(PCR)尽可能多地 提取变量的信息，选取相关变量的数目。此外，在实现模型选择时还需要经过的 一个重要步骤：参数调整。参数调整对模型的选择起着非常重要的作用，常用于 模型拟合度与模型复杂的折中平衡。不用的参数调整方法也有不同的侧重，有的 倾向于模型预测的有效性，有的侧重于模型的相合性。常用的参数调整方法有： 交叉验证网，误选率法画、网格路径法网等。交叉验证的思想是将数据集分为n 份，轮流将其中n-1份用作训练，剩下的1份用作验证，最后将n次结果的均 值作为参数估计值，因此这种方法更适合模型预测的有效性；误选率法的思想是 在给定的变量下，将不在模型的候选变量与隐变量建立回归并做显著性检验，在 保证模型选择误选率不超过设定误选率的前提下，将相应的变量放入模型中，这 种方法强调的是模型的相合性。网格路径法是将变量看作参数调整系数的一系列 路径，而路径是对样本进行二重抽样，将抽样时每个变量被选入模型的概率与不 同的调整参数对应所形成的路径。有了路径之后，选取模型的方法变成了在路径 中选取概率最大的变量放入模型，可以明显地区分有信息变量和无信息变量的路 径，因此这种方法可以提高已有模型选择方法的相合性。
2.5本章小结
本章系统地介绍了动态空时信号的图模型与参数估计的相应背景知识，包括 动态空时信号与图模型的定义，空时图建模的方法以及本文所选用的模型，还有 相应的参数估计方法：包括高斯图结构学习，因果过程图学习，常见的稀疏惩罚 方法和模型选择方法。本章介绍的几种参数估计方法是后续研究的基础。
20
第三章大规模空时信号联合正则图结构估计
3.1	引言
在第二章中，讲述并对比了空时信号图建模的三种方法。其中，一阶高斯马 尔科夫线性动态模型不仅考虑图结构上顶点的信号值与前一时刻自身顶点有关 系，还与其他顶点的信号值有关系，体现了 GMRF在时间上的自回归特性，而 节点号节点之间的关系体现在噪声密度矩阵ho由于本文主要所采用的实际数据 美国股票市场S&P500的452只股票从2003/1/1至2008/1/1的收盘价数据，不难 想象的是同板块之间股票与股票应该有较强的联系，而板块与板块之间的联系应 该没有板块内的股票之间联系那么强，因此，股票数据之间的关系不仅具行时间 的相关关系还具有空间的相关关系空间，本文将主要采用一阶高斯马尔科夫线性 动态模型来对S&P500的数据进行建模并对其进行图结构的参数估计。•阶高斯 马尔科夫线性动态模型是勺+1 = A/ + e「et〜N(0,E), 以是系统噪声，fl = I-1 是密度矩阵，A是过度转移矩阵。
现有的大部分方法，假设q是高斯独立分布的，比如，Cov(%tWt-i)正比于单 位矩阵4,从有限的观察样本中方,….，亏,估计出A。这种方法对应着第二章节讲 述的因果图结构学习(GTG),在小样本情况下，当前的挑战的是AeRPxP中未 知变量的个数p2》n,经典的方法会产生A的过拟合。在实际应用中，存在许 多只有少部分重要的节点直接影响其他给定的节点的情况，也就是说A是稀疏的。 从统计的角度，可以使用shrinkage estimation"］稀疏正则图A。但是，这完全忽 略了图节点之间的二阶统计关系。另外，静态网络研究中，通常假设A已知，图 的结构关系研究通过稀疏高斯图学习方法获得，这种方法对应着第二种讲述的高 斯图结构学习(CDG)o但是高斯图学习的方法，并不能直接应用于动态模型的 学习，因为估计A的任务和估计E的任务一样重要，并且当矩阵A很大时用样本 均值代替真正的均值也不合适。为了全面理解动态网络的结构，也有一些方法提 出了联合正则稀疏预测两个矩阵A、Q,已有的方法MRCEI46】、BDSR147］算法， 这种方法交替使用CDG和GTG方法，从而达到了很好的预测效果。但是，当维 度p>120时，未知变量p2+p(p + i)非常多，导致计算量大，处理速度慢，而且 很难可靠地识别稀疏网络的拓扑结构，从而不能准确地估计出参数。DaPengMJ等 提出了联合图稀疏正则可分解网络算法，这种方法假设图A、。是稀疏，联合图
21
C(A,I1) ( C = [c(7] e Rpxp, Cij = Cji = J峪 + 城 + 202M,。是权重参数，B = [bij] e Rpxp, n = [%] e rpxp)也是稀疏的，也就是说，许多节点并没有直接的 影响，因此，在运用CDG或GTG算法前可以提前筛选出没有关联的边，以提高 整体网络的识别和预测的准确率。本章在联合图模型C的基础上，研究图结构B 与Q的相关关系，及权重参数。对性能指标的约束，通过实验仿真，从而定量地 确定中的取值范围。在稀疏惩罚方面，使用非凸稀疏惩罚嵌入联合图结构，证明 其收敛性，并通过实验仿真对比几种稀疏惩罚的性能，证实了迭代阈值q稀疏惩 罚的有效性和计算简便性。
3.2	联合正则图结构估计
在介绍联合正则图结构估计框架之前，这里先描述联合正则网络学习与联合 稀疏正则的必要性。
使用高斯马尔科夫链的规则，可以写出A和Q的联合对数最大似然：
max{争og(2Tr)-/logEI -a上式乙+1 -	-A*	(3-1)
令Y = [%2, ...xn+i]T, X =	...xn]T, B = At, ML 问题的矩阵形式：
minB,neRPxP)n>0 L(B, H) = |tr{(Y - XB)£1(Y - XB)T} - ^log |£1|	(3-2)
Q > 0意味着Q是对称正定的。
为了加强图的稀疏性，通常使用惩罚函数，即使用Pb(B)b)、由添加 到上式中的损失函数后面，Pb和%可以是A或其他形式，这里使用联合正则B和Q 的惩罚函数，即使用Pc(C(B,Q)"c), C的构建基于B和Q。因此联合优化问题可 以转换为：
minBnL(B,n)+ Pc(C(B,£l); Ac) + Pb(B;Ab) + Pn(H;An) (3-3)
在动态网络中，通常假设图结构稀疏或接近稀疏有如下原因：(1)在许多真 实世界的动态网络中确实存在稀疏，比如在调控网络中，一个基因只受其他几个 基因的调控。(2)在高维数据统计中，样本的数量远小于未知变量的个数，稀疏 假设减少了模型参数个数，使得估计系统参数成为可能。(3)从压缩感知的角度 来思考，假设信号是稀疏的，那么可以通过有限的测量样本去恢复原始信号。对 应到我们的一阶高斯马尔科夫过程模型中，我们可以通过有限的多元时间序列去 估计(恢复)稀疏的图结构，因此对B和1a进行稀疏假设是合理的。(4)从客观上 讲，稀疏模型与Occam* razor原则一致，并且在实际中很容易解释。因此，如 果B和。是稀疏假设的，那么它们的联合图结构仍然是稀疏的。也就是说，事实上
22
许多节点是没有直接的影响，使用的设计可以用来捕获GTG和 CDG的联合结构，加强共同边的检测，从而使得在早期阶段就能筛选出有用的 边，使得估计问题的维度大大减少。下面我们使用S&P500能源类的股票数据来 说明联合图结构的必要性。
图3-1 S&P500能源类股票的GTG与CDG图1叫
图3-1 (a)是单独使用因果图结构学习(GTG)得到的有向图结构B,其忽略 了节点之间的二阶关系，图3-l(b)是单独使用高斯图结构学习(CDG)得到的无 向图结构C,其忽略了一阶因果关系。他们中共同孤立的节点已经移除了，只要 B或0的权重系数非0,那么两个节点就会用线连起来。两个图中共同存在的边， 或者只有一个图的节点有连接关系，联合图结构可以有效地筛选出它们中的孤立 节点，并检测出共同存在的边。事实上，从统计的角度来讲，即使两个图结构的 相似性不是很明显甚至不存在时，在高维参数估计中联合图正则也有助于检测提 高整体整体的估计准确性。
3.2.1	联合图模型与学习
一阶高斯马尔科夫过程模型表明了网络的演变是通过节点之间的一阶和二 阶统计关系组成。为了捕获联合结构，引入联合图结构C的概念，C是无向图， 如果GTG或CDG中有任意的一条边权重不为0,那么C中这两个节点之间也 相连。节点i与节点j之间的关联强度(权重)可以表示为：
ctj = cji= J 蛤 + 说 + 202%	(3-4)
。是权重参数(比如，0 = 1), C = [%] G RPXP表示联合图结构C。
如图3-2所示，使用了一个很小的例子来形象地解释联合图结构C,图3-2(a)表示GTG,图3-2(b)表示CDG,图3-2 (c)表示联合图结构C, C构造是由 上式(3-4)获得。可以看出，GTG和CDG共享许多共同的边，并且都具有子网络
23
结构。另外这两个图在某些重要的方面也存在很大的不同之处，比如，在GTG 中节点9和节点10是不相连的，而在CDG中它们是相连的，联合图结构通过 整合GTG和CDG的连接关系提供了一个综合的网络拓扑结构。
(a)	(b)	(c)
图3-2联合图模型的简单示例”用
事实上，GTG和CDG是未知的，是需要估计的参数。现在可以设想一下， 如果在学习图结构之前先得到联合图结构C, C可以用来进行图结构筛选帮助提 高B和II的估计，在图3-2中，节点4和节点5是不相连的，设置b45 = 854 = w45 = W54 =。有助于网络的估计和识别。
根据式(3-2),联合图结构C的网络结构识别可以通过求解联合正则问题： minB>nL(B, ft) + Pc(_C(B,0;Ac)	(3-5)
其中，惩罚形式Pc可以是：
Pc(B, Q; Ac) = Yi<i<j<P P(J- + 屐 + 202蝠；死)	(3-6)
也就是说，使用(瓦〃填入相同的组中并在相同的组中再使用稀疏惩罚。分 组稀疏确保只要节点i与节点j之间存在任何类型的连接，分组将保持并对应着联 合图结构C中边的连接关系。分组变量可以是任意的，如果我们先验的知道一些 节点可以形成一个簇，可以将B和C中对应的元素放入一个组中，而公式(3-6) 提供了更一般的情况，在先验未知情况下B和。对应元素的分组情况。
3.2.2	分组阈值q稀疏惩罚
公式(3-5)的目标函数是非凸的且是非光滑的，而且有大量的未知变量的个 数。一种常用的方法是交替梯度下降法，在每一个迭代步，固定一个变量，使用 梯度下降法求解处另一个变量。这里借助交替梯度下降的思想，将损失函数 L(B,。)分别对B和Q的梯度：
VbL = (XTXB - XTY)fi q Gb
24
将B和Q中的变量划分成K = p(p + 1)/2个组。在位置(/J)和位置< i < j < p)处的变量属于第 k 个组 k=(/")。令n = [B,4)n] e rpx2p, l(b,q)2 l(k), 则Rn)的子梯度可表示为：
外E = [Gb，0-1Gq]三 G	(3-8)
迭代算法得到公式(3.2.4)的分组阈值估计形式：
N'+i <— E((l —	—	A(；)	(3-9)
s是松弛参数。在所有的稀疏惩罚中，毫无疑问，。稀疏惩罚是追求稀疏形式的理 想形式。然而，参数调整也是不容易的，大部分的调整方法，比如，交叉验证， 在大规模网络应用中变的不可行。使川分组约束来代撤0惩罚：
Sl<i<p	—血
m表示联合图结构筛选(瓦〃瓦，包,)丰0的上界，那么卜约束的局部最小问题：
min L(B,O) s.t \\C\\^f < Q(p2 -p)	(3-11)
||C||；"表示C中非对角元素中非零元素的个数，q是分位参数，表示网络稀 疏程度的上界，可以根据先验的知识或具体的应用由用户自己定制。迭代分位阈 值收敛，并且约束问题在每次迭代中的形式：
出+i — 那((1 — 3)田一bG。m)	(3-12)
那是多元分位阈值算子。对于任意NE RPx2P被定义成一个新的矩阵&,如果 ||Nk12在前m个最大的范数值集中，那么& =心，否则为0。
因此，分组阈值q稀疏惩罚的思想是首先计算联合图结构C,对于任意的 iH/使用公式(3-4)获得,所有的对角线元素设为0,然后对C中每个元素实 行硬阈值，筛选C中前(2m+l)个最大的值作为阈值集，最后将N或(B,Q)中较小 的值置为0,具体算法流程，见算法1。
3.2.3	收敛性分析
梯度下降法是沿着梯度下降的方向求极值，是逐步最小化损失函数的过程, 在正常情况下梯度下降是迭代收敛的。而在分组阈值q稀疏惩罚算法中，在迭代 梯度下降过程中将每次迭代过程中求得解进行分组阈值q惩罚从而得到一个稀 疏的解，然后应用于下一次迭代过程中。本文将证明这一过程是迭代收敛的。
在证明收敛性之前先介绍阈值规则E(:;入)的相关特性。阈值规则4:;人)是奇
25
函数、非递减的无界收缩函数网。比如，软阈值Es(t") = sgmt)(|t|—/L)l|g 和硬阈值函数Eh«；Q = 口出加sgn。是符号函数，如果t > 0, sgn(t) = 1,反 之t<0,则sgn(t) = —1。E的多元变量形式记为弓(t;Q,定义为：弓(t;入)= 「吃(||川2；入)，当t=0时，t° = t/||t||2,否则t° = 0。文献网中的定理描述了对 于任意给定的阈值算子7,…,为，N(。)是任意矩阵值。N。)。= 1,2,...)是通过公式 (3-9)迭代产生的连续序列，定义<k< K)是任意给定的阈值，A = {bN。)+ (1 一	C (0,1), j = 1,2,…}和 p = sup||7(g)||2 ， 如 果 p < max(l,2 -
Q
]嚅£女)，那么对于任意的惩罚函数也，有.：
Pfc(t；4) - Pk(0；Ak) = ["(sup{s:Ek(s;4” 比} — u)du +	(3-13)
对于任意的s,某些非负4晨1；4)满足q/cRkG；4);儿)=。。
联合图结构目标函数是L(B,Q) + Pc(C(B,Q)Bc) = L(K) + P(K;A)q F(N)。 为了证明，迭代过程的收敛性，构造YS&N的能量函数：
E(y，q&,N) = L(y) + P(Y；A) + 1(y- &)% - K)(y - K)
+ (q - N)r(/ — K)T(q - N) +	[Y+(/- KylXTY
Zb	z
-(I - K)Tn]T(/ — K)[y + (1 — K)-1XtY - (/ - K)-1N] 1 Z / f	T
+ —^― [(;-(/- K)& - XTr] (/ - K)T [q - (/ - K)& - xTr]
-[N — (/ — K)& - XTY]r(l - K)T[N -(7 - K)N - xTr]
(3-14)
从公式(3-14)中可以看出，E(y，g，Rn)等式右边除了L(y) + P(Y；入)部分，其实 所有项的和是正定的，因此E(Y，q&N)总是大于或等于目标函数F(y),如果能量函 数EC)收敛，那么目标函数也将收敛。
给定我和N,能量函数E关于(％。的最小问题可以简化为：
min^||Y — nj(l - K)K — wXTY - (1 — w)x| + L(y) + P(y； A)
]—'CQ	t
rnin —- 卜一w(I — K)N — bX，Y — (1 — gj)n] (I — K)一1[q — 3(I — K)N
—bX，Y — (1 一 r)N]	(3-15)
26
基于文献【49】中的定理，最优解是：
(yn t = S(cj(/ — K)N + cjX'y + (1 — w)N + G;4)
\ P	、〜 T	(3-16)
I %pt = b(J — K)N + wX 7 + (1 — gt)N + G
因此，我们可以获得：
E 印+i),N(j+i),&(，N(j))
< E(&(2nS,&0),N(S -^^伊。+1)—	— K)T
2w
(3-17) 另一方面，给定(丫y), EM以表示为K或N的正定二次形式。将能量函数E分别对 我和N求导:
VE& - gj(/ — K)(N - 丫) + (1 — gt(N — 0)
VEr =詈(1 - K)T 旧(/ — K)(& - 丫)+ (1 - b)(N —©-18) 因此，E可以写成;Q(/ — K)(& - 丫)+ (1 — s)(N -	- K)TQ(/- K)(我 -
Y)+ (1 - s)(N 一 0]还有只包含丫机的项。因此&0川=&, (pt = G处取得最小值, 注意，这个最小值有可能是局部最小值，并不唯一。因此可以获得
E(&0+i),N("i),氏 0+i),N(j+D)
<	E(&0+i),N(j+i),&0),N。))
-	- [b(1 - K)g)- N(/+D) + (1 - b)(N。)一 N(J+D)「(/
-	K)T@(I 一 K)(&。)— n0+D) + (1- b)(N。)一 N("i))]
(3-19) 假设当t T 8时有：
E(&("), N(m, N(m)— E(&5+1), N("+1), &3+1), N5+1)) - 0 (3-20) 则连续序列&(")一部，淖是阈值规则E的一个值，从而有 % E(&gN((t), &(=)") = F(K°)O
l0°上面从理论上证明了使用分组阈值稀疏惩罚的收敛性，在后面3.3节中，将 通过仿真分析的方式来证明其收敛性。等式(3-5)是非凸的，求得的解有可能是局 部最优解，也就是说分组阈值思想也有可能产生局部解。事实上，通过等式(3-13) 基于阈值构造的任何惩罚函数，都可能会得到局部最小值包括2o，%SC4D,，p等。 这个问题现在归结于选择合适的惩罚形式，在仿真3.3节中，将通过仿真分析的 方式来说明最佳的惩罚形式。
27
3.2.4 参数调整
另外一个问题参数调整是不能忽略的，这在非凸惩罚中是不容忽略的。经常 使用的方法是交叉验证，网格搜索等，但这些方法在大规模网络中计算量非常高 变得不可取。本文使用四提出的异步Armijo线性搜索方法，这种方法简单却高 效，保证了解的收敛并且满足◎ >0。
Armijo线性搜索方法的思想是沿着梯度下降的方向选择合适的步长，对于 公式(3-11)满足Armijo步长：
< 工3') +。百{3+1 — N')Tg'}
(3-21)
如果条件满足，将在本次迭代中接受并继续进行下一次迭代，否则，线 性搜索松弛参数在本次迭代中继续更新加=X/10,直到的值满足条件(3-21)或者加很小，小于阈值C2。q, C2的值可以自己设置，一般地默认设置为J = 10-4, C2 = IOS
经验表明Gb和Gq在幅度上有不同的阶次，所以使用相同的步长来更新知和 立都是不合适的，另外如果只设置一个步长参数，也很难找到合适的凉来满足 公式(3-21),因此需要对Gb和Gq使用不同的步长。异步Armijo线性搜索更新公 式为：
日刈	if I is odd
[0,	if I is even
(3-22)
对于任意的非正定Q, log|fl| = -8,而无法满足公式(3-21)，非正定的。将不 被系统接受，因此异步Armijo线性搜索可以保证C正定。
如下，算法1是完整的联合图结构参数估计算法流程图。
算法1联合图结构参数估计算法____________________________
迭代分组阈值q稀疏算法(GTQ)__________________________
Input：数据矩阵X, Y,协方差矩阵分位数q，异步Armijo线性搜 索非零元素C> C2,最大迭代次数/误差容忍率2，联合图结构权重参数。
Initialization：图结构B° = 0,图结构= /,
初始迭代次数，=0，初始损失函数f - L(B°,fl°)
while(|尸一尸「> 女 or 1 < 为
<- 1
及二0
while(尸+i > fl + QAZ or gj > c2)
(1)更新B和。
If mod。, 2):
g4-(ZxxB'—功丫加
B'+i - (1	- wlGlB
6+1 - 6
K- tr{(Bl+1 - B】)TgA}
else:
Gn -久丫 - XBlV(Y-XBl)-式明
fl'+i — (1 一 gj()(1z —
B'+i - Bl
△'- tr[(£ll+1 - Uz)tG^}
end
(2)联合图结构■
C,+1 - [c『i]，对角线兀素满足c4+i = 0(1 < i < p), 非对角线兀素满足C俨=或1:](咐1)2 + 3仍)2 + 2e(卬犷1)2
(3)联合图结构筛选
壮+i ― d+i中第(2[q(p2 — p)] + 1)个最大元素所对应的系数
(4)阈值规则，为可以是硬阈值规则，。是哈达码积
S — sgn(EH(C"i；入”1) + 1)
Bl+1 一 BIoS
n;+1 - nZos
(5)下一次迭代的损失函数
fl+1 - L(Bi+1,nz+1)
J GJ'/IO
end
/ <- Z + 1
end
Results：联合图结构r = C】_____________________________
该算法包括两重循环，第一重循环的终止条件是松弛参数b满足异步Armijo 线性搜索条件(3-21),用于为梯度下降法中合适的步长，第二重循环的终止条件 是损失函数/的值收敛，用于求解联合图结构参数估计C。迭代分组阈值q稀疏 算法是一种易于执行且运行速度非常快的算法，其速度高效地功劳主要在于异步 Armijo线性搜索可以很快的找到合适的步长，要比交叉验证、网格搜索的方法要 经济许多。此外，迭代分组阈值q稀疏使用联合图结构C可以快速的筛选出图
29
结构的节点与边，如果我们的衡量指标更注重于模型的相合性，也就是想要快速 得到收敛的稀疏图结构而不是预测的准确性，迭代分组阈值q稀疏只要迭代稳定 就可以终止算法，能得到相对评分较高的稀疏图案，并且其稳定性要比GTG和 CDG要高很多。
3.2.5数值分析与仿真
本节中，我们将通过相应的实验仿真结果来对迭代分组阈值q稀疏算法的3 个方面进行实验分析：（1）图结构权重参数分析。。的取值会影响联合图结构的 构造，极端地来讲，如果e = 0,那么联合图结构C的估计将严重依赖于有向图 结构B,如果0 = 8,那么联合图结构C的估计将严重依赖于无向条件依赖图结 构C,因此，单独基于GTG或CDG联合图结构的构造是不可靠的，我们需要确 定一个最佳的取值空间合理地构造联合图结构；（2）收敛性分析。分组阈值q稀 疏惩罚是在梯度下降迭代过程中，对每次迭代所得的解使用分组q阈值进行筛 选，将筛选后的解作为下一次迭代的起始解。在323已经证明了这一过程的收 敛性，这里将通过实验仿真的方式来验证其迭代过程的收敛性；（3）稀疏惩罚分 析。在非凸非光滑的优化问题中，可能存在多个局部最小点，都不是所需的全局 最小，即使是一些商用非凸问题的估计器中，大多数都不能区别是局部最优解还 是全局最优解，因此这个问题将归结于选择合适的惩罚形式。本实验主要对小
“办+，2”、人、“"+不'、SCAD五种不同的稀疏惩罚进行对比分析。
在此之前，我们需要对稀疏网络图模型B和Q的构造、以及多元时间序列的 生成做相应的描述，以及对评价指标做相应的定义。图结构B的稀疏规则是给定 图结构B的任意节点3其稀疏度服从二项分布B（n,p）,也就是节点与节点之间 边的权重以概率p出现，其对应的权重值服从高斯分布N（O,1）,为了保证系统的 稳定性，对图矩阵B进行特征分解，判断最大的特征值是否小于1,如果大于1, 对图矩阵B进行尺度缩小操作。图结构口的构造与图结构B的稀疏规则设计类 似，但是还需要添加两个约束条件：对称和正定。对称很容易满足，判断矩阵的 正定性可以使用Chollesky分解,如果存在下三角实矩阵L的对角线元素为正数， 那么矩阵是正定的，如果不存在，可以稍微增大矩阵对角线元素的值，继续使用 Chollesky分解判断正定性直到矩阵满足正定为止，最后再对矩阵对角线上的元 素值归一化。根据上面的规则，生成了一个网络大小为P=40的图结构B和Q, 每个网络中有两个子网络，每个子网络的稀疏度是0.1,如图3-3和图3-4分别 为相应的生成图结构矩阵形式与网络形式，在两张图中，左边的图表示图结构B, 右边的图表示图结构。，从图中可以看出他们有相似的网络结构，为联合图结构
30
的构造提供了便利。
True B	True Omega
图3-4生成图结构的网络形式	,
根据图结构生成一阶高斯马尔科夫过程时间序列，初始时刻序列为无。= randn(l, P),根据 xt+1 = Axt + et, et -N(0, fl-1)生成相应的时间序列 Xi，%2, ...xn,由于噪声是多元高斯分布的随机噪声，为了保证时间序列的稳定性 可以选取第1000时间点以后的时间序列。将样本数据进行分割，70%的数据长 度作为训练样本，20%的数据长度作为验证样本，10%的数据长度作为测试样本。 最后对生成的时间序列进行标准化处理珀=(%一可)/肉i = 1,2 ...n； j = 1,2 ...p,弓和目是图结构中每一个节点的时间序列的均值和方差。
评价指标的定义，联合图结构C的作用是检测出共有的边并筛选孤立的节 点，因此侧重于考虑模型的相合性，并且在第四章中图结构还将作为聚类的相似 矩阵，因此注重考虑图结构中有权重的位置的正确性，而那些没有权重的位置如 果被误判为1可以看做是噪声，在聚类时可以通过一定的办法抑制，这里作为评 价指标的参考。定义正确率PR = |{(ij)：% = 1冏=l}|/|{(i,j)： Cij = 1}|,也就 是图结构有权重的位置被正确预测的概率。Pmiss = 1-PR为相应地错误率，即
31
图结构中有权重的位置被遗漏的概率。
（1）图结构权重参数分析
在仿真中，设置样本大小n=50,最大迭代次数乡=le3,误差容忍率（c = le -3,每个网络包含两个大小均等的子网络，每个子图中B和Q的稀疏度为（Pb，Pa）， 在不同稀疏程度（Pb，Pa）下的改变图结构的权重参数中，重复运行50次。图3-5（a） 是网络大小p=80的PR对比图，图3-5（b）是网络大小p=160的PR对比图，横坐 标是权重参数中以2为底的对数值。纵坐标PR是图结构B和Q中各自有权重的 位置被正确预测的概率值除以2o
0.65 ,-上_一 _ _	:	_	-	- --- -	------	-----
0	2	4	6	8	10	12
log 体）
图3-5不同网络模型下的对数权重参数log@）与正确率PR关系图
从图3-5中可以看出，在图结构不同的稀疏图案下，1。8（0）的值在［2,6］之间 PR的值相对比较稳定，当log（4））的值大于6时，PR值急剧波动下降，这严重依 赖于图结构。，也间接地说明了对单独使用CDG估计的图结构进行阈值q筛选 得到的稀疏图结构的正确率，要比使用联合图结构C估计的图结构进行阈值q筛 选得到的稀疏图结构的正确率要低。当log（4）的值在0到2之间时，如果图结构 B和Q的稀疏度相等或者图结构Q的稀疏度比较大时，即它们有相似的稀疏图案 或者B的连接结构要比C的连接结构稀疏，log（a）的值在［1,4］之间，联合图结构 加入了Q的信息，使得在这两种情况下仍然有相对稳定且较高的PR值，而如果 图结构C的稀疏度比较大，即Q的连接结构要比B的连接结构稀疏，联合图结构加 入了。的信息，会变成噪声其干扰B估计的稀疏图案的正确性。因此，如果我们
32
设定的B没有较强的稀疏能力，使用联合图结构会干扰整个估计的性能。由于Q 是对称正定性，一般地，(Pb<Pq)，Q没有B的稀疏能力强，使用联合图结构可 以有效地检测出他们共有的边并筛选出孤立的节点，从而提高整体的正确率PR 值，另外，实验表明在联合图结构的权重参数log"))也不能过大，在我们的线性 一阶高斯马尔科夫过程模型中取值为［2,6］比较合适。
(2)收敛性分析
在仿真中，设置样本大小n=50,网络大小p=40。网络的稀疏概率0.25,图 3-6(a)是阈值q=0.2下的损失函数值变化图，图3-6(b)是不同的阈值q下错误率 Pmiss的变化图，图3-6(c)是不同的阈值q下迭代收敛终止所需的迭代次数。
10000
(a)
5000
从图3-6(a)中可以看出，在单次迭代阈值q=0.2下，使用交替梯度下降法， 并且使用阈值q对每次迭代求得的图结构进行阈值筛选，并作为下一次迭代的初 始解这一过程中损失函数的值是收敛的，图3-6(b)可以看出阈值q的收敛性，也 说明了使用阈值q筛选图结构邻接关系的合理性。当阈值q到达0.35以上时， 错误率Pmiss呈现收敛状态，也就是为了保证图结构中有权重的位置被正确预测 的正确率，可以适当地提高阈值。当阈值q为0.9时，图结构邻接矩阵中几乎有 90%的位置上都有值，不难理解真正的图结构中有权重的位置被正确预测概率很 高，但是这样导致图结构中许多没有权重的位置被错误的置为1，我们把它当作 噪声，为了减少噪声的干扰，在不影响正确率的情况下适当的进行阈值筛选降低 噪声的干扰。当阈值q降到0.35以下时错误率急剧增加，当网络过于稀疏时， 会影响图结构中有权重位置被正确预测的概率。图3-6(c)可以看出，阈值q设置 为很小时，设定的网络过于稀疏，会增加迭代收敛的次数，从而增加了计算的复 杂度。因此选择合适的q值,可以在不影响正确率PR的情况下适当地降低噪声。
(3)稀疏惩罚分析
33
在仿真中，设置样本大小n=50,最大迭代次数乡=le3,误差容忍率（c =他一 3,每个网络包含四个大小均等的子网络，在不同的稀疏惩罚2。、“2。+ 12”、。、 “卜+）"、SCAD下,改变网络大小40,80,160,重复运行50次。如图3-7所示， 在使用不同的惩罚时需要进行参数调整,本仿真提前产生一个n=1000的验证集, 所有的正则参数调整在这个独立的验证集上进行，参数调整利用网格搜索在一定 范围内使得模型在验证集上的BIC最大为最佳参数。但是在，o + G”惩罚中， 为了提高效率，并没有运行二维网格搜索以寻找最佳的的参数，而是每个T1在网 格｛0.5暝,0.05日,0.005限｝,限是最优岭参数，寻找人（n）最小化交叉验证误差，然 后将入固定为最优值，然后寻找最优的T1最小化交叉验证误差。
图3-7不同的网络大小下的稀疏惩罚分析
图3-7仿真对比了稀疏网络图结构的5种不同惩罚函数阈值估计的错误率。
L离散非凸惩罚P（t;入）=X/2 • 1忤。对应的阈值®hSQ =	h凸惩罚
P（t;入）=人|国|对应的阈值：
= s^n（t）（|t| -A）l|t|>a	（3-23）
'1 + %"非凸惩罚P（t；入,n）=/产+ |击I/。对应的阈值：
（o, |t| < 入
入,n）=（上，用 > 入	（3-24）
凸惩罚P（t；人,"）= .
'人间|, ??2t2+A2 、24~~，
Itl < —
e：对应的阈值: iti>4
— eta
34
(	0,	|t| < A
0(t;X,r|)=卜一	4 W \t\ < A + A/t]	(3-25)
(卷，|t| > a + 入m
H|t|,	0 < |t| < 2
(|t|2-2?Mlt|+A2)
SCAD非凸惩罚P(t;入，n)= <	布奇—	"W |t| <娠对应的阈值:
”史，Itl > M
(	0,	|t| < 加I
0(t;A，n)谢九⑴ E「sg鸣皿 < |t| < a	(3-26)
I	I?
I	t, |t| > A
匕凸惩罚使用经典的LASSO估计，尽管LASSO会根据偏差矫正lasso estimator选择参数入，但是由F木文知阵X是马尔科夫过程时间序列，存在共线 性问题，受限于变量选择的不•致性，导致错误筛选的概率很大，尤其是在网络 大小p很大而样本大小n不变时、错误率急剧上升。'4 + G"凸惩罚是在k惩罚 的基础上对估计系数做了不同权重的修正，但是通过权重带来的改进往往是有限 的，尤其是在预测一些相关的问题，所以它的性能只比匕稍微好一点。非凸SCAD 是匕的变体，其阈值函数中当0 W 1.阈值形式退化成4。“3元)，接近于，。惩 罚，其性能跟，。一样在变量选择方面有先天的优势，此外，其在迭代初始点为零 并且在网络规模p很大时性能也好。2。非凸产生于受限制的ML估计问题，在零 点不可微分的部分，将估计系数强制惩罚为0,从而达到稀疏解，在变量选择中 做的很好。从图3-5中可以看出非凸'4+ %”使用参数人和参数T]不仅可以同时 进行变量选择而且还可以收缩系数，在稀疏恢复并且在大规模网络情况下有明显 的优势，其中，。部分处理共线性问题并且自适应各种噪声，同时，o部分，比，1凸 函数罚执行更强稀疏惩罚。毫无奇怪，非凸惩罚需要更多的计算时间，但是我们 使用阈值估计并以一定的概率进行筛选其计算速度是可以接受的。
3.3本章小结
本章主要涉及一阶高斯马尔科夫过程图结构估计问题的研究与仿真。首先, 针对联合图结构的构造，研究了图结构B和Q不同的稀疏连接结构，以及不同的 权重参数对评判指标的影响，定性地确定了中的最佳取值范围。然后，针对分 组阈值q算法的收敛性进行分析，并通过仿真验证了整个迭代过程以及阈值q的 收敛性。最后，针对不同的稀疏惩罚形式进行对比，实验表明“L + %”的惩罚
35
形式是本实验稀疏模型的最佳选择，当然稀疏惩罚或阈值函数在具体的实际问题 中需要根据实际情况自己确定，不一定是本仿真的，o +，2”最优。
36
第四章大规模空时信号结构的聚类算法
4.1	引言
大规模的数据量是现代网络分析的一大挑战，使得许多方法在计算上变得不 可行。幸运的是，许多大型网络都表现出子网络的结构特性，例如，从图3-1中 还可以看出一个更加有趣的现象，网络可以分解成更小的子网络包括孤立的节点 在内，在大脑连接网络和微观和济领域,也灯以看到相似的分解思想。如果这样 的网络分解能够在早期阶段被检测到，那么复杂的学习方法，比如MRCE和高 斯图学习，将会应用于类如并行计克等更仃效的求IW方式。使用GTG和CDG学 习的图结构除了共享很多共同的边，而R他们都具仃F网络结构。在图3-2中可 以看出在节点1-4形成了一个簇。通过使用合理的联合图结构权重参数，构造联 合图结构C,在经过矩阵排列和置换后，具有块对角结构diag{Cu，…，Cdd}，那么 B和C也有相同的块对角结构diag{Bu，…，Bd/和diag{%i，…，ildd],不难看出这 样的网络结构可以分解成d个独立的子网络而且动态性能完好无损。基于估计的 联合图结构G应用Dulmage-Mendelsohn分解来检测。中是否存在块对角形式。 然而由于噪声污染使得完美的分解几乎不可能。因此，把C看做是相似矩阵，对 应的权重吃看作节点7与节点./的相似程度，那么追求近似的块对角矩阵形式变 成了一个对节点聚类的问题。本章将谱聚类算法嵌入到大规模动态高斯马尔科夫 过程图结构模型中，也就是将估计的联合图结构r进行谱聚类，将原有的网络结 构进行分解，然后对各个子网络进行精准估计，研究不同的网络规模、分组阈值 q对聚类性能的影响，算法时间复杂度的分析以及该算法与GTG、CDG、MRCE 算法估计性能的对比。
4.2	聚类算法
聚类是探索性数据分析中一种应用广泛的技术工具，其应用范围从统计学、 计算机科学、生物学到心理学等。几乎每一个科学领域的数据处理，人们都试图 通过数据中相似行为的分组来获得数据的直观印象。
37
4.2.1	谱聚类
近年来，谱簇聚类已成为现代聚类算法中最流行的算法。它实现简单，可以 有效地被标准线性代数软件求解，而且能在任意形状的样本空间上聚类，并收敛 于全局最优解，其效果往往优于传统的聚类算法，如k-means算法。谱聚类算法 中根据使用拉普拉斯矩阵的不同，可大体分为三种，但他们的算法流程都是相似 的，第一步，根据相似矩阵计算拉普拉斯矩阵L,包括非归一化的Lunorm，归一 化的对称Lsys，归一化的非对称Lrw）；第二步，对L进行特征分解，将L的前K 个特征矢量组成矩阵U；第三步，将U的每一行5 6/?生2 = 1,2,...看作数据点， 使用k-means算法分成k个簇g,…,C”
一般地，聚类有两个目标：（1）我们想要一种图的分割方式使得不同的分 组间有较低的权重（也就是不同簇间的数据点极其不相似），也就是希望最小化 簇间的相似性，用数学优化问题来描述也就是minmize cut（A,A）, A是图顶点集 V的子集AuV, A是A的补集｛V\A｝。（2）我们想要一种图的分割方式使得在相 同簇内的数据点有很强的相似性，也就是最大化簇内的相似性，用数学优化问题 表示maxmize W（A,A） + W（A,A）。文献网表示选用归一化L进行谱聚类可以同 时满足上面两个目标，而选用L_unorm进行谱聚类只能满足第一个目标。因此， 在某种程度上，选用归一化的L要比Lunorm在平衡簇大小方面要好一些。在归一 化L中，Lrw的特征矢量是聚类指示向量，而Lsym的特征矢量需要额外的相乘度 矩阵的平方根D1/2,可能会产生不必要的噪声，而且没有计算优势，因此推荐使 用Lrw。此外，我们还可以通过观察相似矩阵的度分布来确定选用那个L,如果 相似图是规则的，所有顶点有相似的度分布，那么三种L彼此非常相似，其聚类 的效果都很好，然而相似图的顶点度分布非常广泛，那么L的差别会很大。
4.2.2	聚类数K的确定
根据谱图理论，在无向非负权重图中，对拉普拉斯矩阵L进行分解，特征值 为0的个数K对应着图结构中连通图的个数。假设K=l,即图是全连通图，f是 特征值为0的特征向量：
2
0 =尸4=2上1也/（力一力）	（4-1）
叫,是权重，非负。如果要想上面等式的和为0,那么所有的卬〃•（方-方）必 须为0,因此如果两个顶点巧和好相连，那么那么/的值在所有的顶点上 必须是常数，这些连接的顶点在图中形成了一个路径。因此，如果一个图只由一 个连通集元素组成，那么L的特征矢量基中只有一个常矢量为1,对应的特征值
38
为0。现在考虑K=4,也就是一个图中有k个连通图，不是一般性，假设顶点的 顺序是按照他们属于哪个连通集元素的位置排序的。在这种情况下，相似矩阵有 块对角形式，相应的L也是块对角形式：
£=r - j （4-2）
每个子块乙是L对应的第，个子图的元素，那么L的谱也是由各个子块及的 谱组成。L对应的特征矢量是〃的特征矢量，在其他块的位置为0。每个〃是一 个连通图的拉普拉斯矩阵，且只有一重特征值为0的根，对应的特征矢量在第z 个连通集上是常数。因此L的特征值为0的个数对应着图连通的个数，对应的特 征矢量是连通集元素的指小矢埴。因此，如果我们要判断一个图中连通的个数或 可以聚类的个数，可以观察期为特征值为0的个数，或者看其对应的特征矢量是 否是常矢量。
受特征值和特征向量的启发，可以利用特征值距离来确定聚类数K。我们的 目标是选择合适的K,使得特征值入1，…,儿非常小，而4+i相对比较大。也就是 说，在正常有噪声干扰下，我们不可能得到特征值的K重根，我们希望特征值距 离& -七+i|越大越好。在联合图结构估计出的C可以看作顶点与顶点之间的相 似程度，通过寻找2的拉普拉斯矩阵的最大特征值距离|儿-4+/来确定聚类数 Ko
而r可能受噪声影响，使得।儿一4+ii的最大值不明显，庆幸的是，我们可以 通过阈值q筛选来控制图结构的稀疏度从而控制图结构的噪声干扰。因此，聚类 数K的算法如下算法2,聚类数K的确定通过控制分位数q,使用分组阈值q算 法（GTQ）下得到联合图结构估计G然后计算其拉普拉斯矩阵的特征值及相邻 特征值之间的差|4-4+il，最大的特征值差对应的聚类数K,就是当前阈值q 下的最佳的类数K,调整不同的阈值q,观察特征值及聚类数K的变化情况，直 到聚类数K变化稳定为止。
算法2联合图结构谱聚类聚类数K确定算法_____________________
自动确定聚类数K的谱聚类算法__________________________
Input：数据矩阵X, Y,阈值q, GTQ算法 Initialization： q=0.9
While q>0:
1）使用GTQ算法，得到联合图结构C;
2）将C作为相似矩阵，计算归一化拉普拉斯矩阵L;
3）计算L的特征值，按其降序排列入2的…2
4）计算特征值差 gi，g2,	其中段=7-4+1，
5）计算 K,找到& = 4li+1 > 3 令6 = [g2,…，gm]，K = argmaxG;
39
更改q值，q = q —△,重复上述操作，直到达到稳定的q值为止;
Result：聚类数K
4.3	联合图结构分解与精准估计
如果网络是可分解(接近可分解)的，系统可以重新写成城= 4*_］ + 电e；~N(O,£&),i = 1,	d是子网络的个数，,表示对应节点属于第，•个子网
络。因此，我们可以以并行计算的方式对每一个子网络进行B”和期的精准估计。 如果每个子网络的网络规模相对很小，可以使用精准估计算法，而且公式(4-3)中 的约束可以丢弃。在这种情况下2仅仅用来显示矩阵的块对角结构。
在联合图结构分解成多个子网络图结构的情况下，图结构的估计问题变成了：
L(B, (1) +	+ Pq(C;/)
b,q>o s. t. Eb u E& Eq u Eq,
(4-3)
出表示r的非零边集，类似的琮和Eq也分别表示B和Q的非零边集。约束保 持了©的稀疏结构，但是有时候这种筛选约束可以被丢弃。那么估计优化问题转 换为：
jnm + Pb(B,Ab) + Pn(Q;A。)
(4-4)
其中Ab = Ub由］和Aq=Mq』/］是正则参数矩阵。为了加强筛选的约束，如果二 0，可以设置它用=8,否则凝刀=入8,如果d=0,可以设置=8,否则 %,以=Z1。为了求解B，固定Q,问题优化为：
minB /bCBMb) =|tr{(Y-XB)fi(Y-XB)T } + Pb(B;Ab) (4-5)
然后，固定B,使用CDG方法估计Q,问题优化为：
minn>0 %(。劣)=|tr{(Y - XB)n(Y - XB)T} - ^log|n| + Pn((l;2n)
(4-6)
幸运的是，322节中算法1提出的算法，当。固定于当前迭代的估计在初 始值为1 = 0,a = LB，=月，分组阈值q稀疏算法仍然可以适用于求解B的优化 解。对于Q的预测，使用给定采样协方差(Y —XB)(Y —XB)T/n,高斯图学习graph lasso算法解决。Pb、P0为k惩罚。MRCE算法也可以用来解决公式(4-4)相似的学 习问题，使用权重惩罚，但是没有稀疏筛选约束。这两个算法都是用交替坐标下 降，但是在优化B时，有更高的复杂度。⑴与，而本文图结构精准估计(GFE)优化 B的复杂度是0(p2),这个复杂度来自于计算梯度Gb时pxp的矩阵相乘。在后面 实验仿真分析中可以看出图结构精准估计在相同误差容忍率下和最大迭代次数
40
下，要比MRCE计算高效。综合前面的使用联合图结构进行分组阈值q (GTQ) 估计出C,使用C作为谱聚类的相似矩阵进行聚类，将一个大网络分解成多个子网 络，对每个子网络进行精准估计(GFE),这一过程记为JGSE算法。JGSE算法 与MRCE算法相比，构造了联合图结构，筛选出网络中共有的信息，对其进行 网络分解，从而将大规模的网络问题转化为多个子网络估计的问题，在计算效率 上要比MRCE高效很多；与CDG和GTG算法相比，不仅估计模型的一阶关系 同时估计模型的二阶关系，比单独使用CDG或GTG,由于模型过于简单造成的 低拓扑识别率要好很多。
4.4	数值分析
4.4.1	仿真分析
本节中，我们将通过相应的实验仿真结果来对联合图结构分解。粘准估计算 法的4个方面进行实验仿真分析：(1)模型拓扑以别率与模型估计准确率对比； (2)网络规模对聚类性能的影响；(3)阈值q对聚类性能、聚类数K的影响； (4)算法复杂度分析。GTG使用坐标下降法算法假设QocL只估计稀疏图结构 B； CDG算法使用图lasso在中心化数据后假设A = 0,只估计稀疏密度矩阵。； MRCE算法联合估计B和Q,但各自使用自己的惩罚。
现在定义相关指标：(1)分类评判指标CL CI = (TP+TN)/(TP+TN+FP+PN), 其中，TP表示同一标签的数据被分到同一个簇，TN表示不同标签的数据被分到 不同簇，FP表示不同标签的数据被分到同■个簇，FN表示同• label的数据被 分到不同簇。(2)模型拓扑识别率评判指标TPR和FPR, TPR = |{。,/):电=
= 1}|表示图结构有权重的位置被正确预测的概率，FPR = |{。,力：%=0冏=l}|/|{(iJ)：Qy = 0}|表示图结构没有权重的位置被错误预测 为有值的概率。(3)模型估计准确率MEb，MEb =	Exx(©—B)},当
只有Q需要估计时，使用ME。= 11^-< (4)预测准确率 TPo TP = (length (sgn(Y) — sgn(XR ) == 0))/(Zen^th(Y))
(1)不同的网络规模对聚类性能Cl的影响。
在仿真中，固定样本大小n=200,阈值q设置为0.3,每个网络中10个均等 的子网络，每个子网络的稀疏度设置为0.3,改变整个网络的大小p,重复运行 50次。
41
图4-1不同的网络规模对聚类性能CI的影响
从图4-1中可以看出，GTQ更适合于大规模网络的分解，使用联合图结构 的网络进行聚类对网络规模具有很强的鲁棒性，也就是说即使阈值q对单独的图 结构B或。进行有错误地筛选稀疏图案，但是他们的联合图结构对他们原有网络 中的子网络结构没有影响，使得网络中的子网络结构更加明显。而GTG和CDG 仅仅是单独对B或。进行阈值筛选，阈值q的错误筛选可能会破坏原有网络的子 网结构，而且随着网络规模的增大错误，而样本的大小不会因此而变化，过拟合 的现象愈加明显，阈值q错误筛选的概率更加高，破坏子网络结构的可能性更 大，聚类性能CI下降。
（2）不同的阈值q对聚类性能CI和聚类数K的影响。
在仿真中，固定样本数n=200,网络大小设置为100,包含4个子网络，每 个子网络的大小分别为10,20,30,40,网络稀疏度为0.2,改变阈值q的大小，重 复运行50次。
42
81值4
助丧0
图4-2不同的阈值q对聚类性能CI和聚类数K的影响
从图4-2(a)中可以看出，在不同的阈值q下，GTQ使用联合图结构进行网 络分解更具有鲁棒性，抗噪性能较好。当阈值q=0.2对应着实际网络的稀疏度时， 有较好的聚类性能，而当阈值q设置为小于0.2时，估计的网络结构过于稀疏， 图结构中真正有权重的位置被准确预测的概率急剧下降，导致聚类性能急剧恶化, 当阈值q设置为大于0.2小于0.7时，由于筛选阈值大于实际网络结构的稀疏度， 会有一些噪声干扰，但是这个噪声干扰并不影响聚类和聚类个数的确定，说明了 谱聚类具有一定的噪声抑制功能，而当q大于0.7后，噪声干扰会继续增加，已 经会影响聚类性能和聚类个数的确定。从图4-2(b)中还可以看出，使用联合图结 构估计要比单独使用GTG和CDG在聚类指标CI和聚类数K确定上更稳定，具 有很强的抗噪性。
(3)模型拓扑识别率与模型估计准确率对比
本次试验使用四种不同大小的网络规模和拓扑结构来对比不同算法在模型 准确率上的性能：(l)Exl：网络规模p=80,样本大小n=200,三个子网络大小 分别为：40, 20, 20； (2) Ex： p=160, n=300,网络由4个相等的网络组成；(3) Ex3： p=20, n=50, H = I, B 没有子网络结构;(4) Ex4： p=20,n=50,B=0,。是非 对角矩阵。
表4-1模型拓扑识别率与模型估计准确率对比
网络	评判标准	GTG	CDG	MRCE	JGSE
Exl	TPR	0.76	0.64	0.87	0.94
FPR	0.02	0.17	0.08	0.12
ME	1021.2	N/A	733.7	623.8
TP	0.59	0.6	0.63	0.73
Ex2	TPR	0.56	0.36	Infeasible	0.95
43
FPR	0.01	0.1	infeasible	0.13
ME	2243.6	N/A	Infeasible	745.3
TP	0.56	0.53	Infeasible	0.69
Ex3	TPR	0.73	0.67	0.88	0.87
FPR	0.2	0.46	0.29	0.1
ME	20.98	N/A	196,6	130.2
TP	0.67	0.60	0.69	0.68
Ex4	TPR	0.15	0.91	0.78	0.87
FPR	0.06	0.38	0.20	0.24
ME	53.1	3.5	27.3	20.6
TP	0.66	0.56	0.67	0.69
表4-1中，Infeasible表示在网络大小p=160的情况下，使用MRCE不可取。N/A 表示在CDG算法下假设B=0,只需要估计Q,而在前三个例子中，假设B=0, 明显的与模型不符合，所以空缺。从Exl和Ex2的TPR值可以看出GTG （假设 （loci,只估计B）和CDG （假设B=0,只估计fl）模型过于简单不能准确地识别 网络的连接结构，另外从FPR的值可以看出CDG算法估计的图结构许多没有权 重的位置被错误地预测为有值，并不产生足够充分的稀疏图结构，这可能是因为 CDG试图将网络的一阶动态性转变为节点之间的相互关系从而导致了一个密集 的二阶网络拓扑关系。GTG的TPR值偏低，丢失了图结构中很多真正的连接关 系，因此GTG在Ex3中有较好的性能而CDG在Ex4中有较好的的性能。MRCE 可以预测网络的一阶和二阶统计关系，相比于GTG和CDG也有较好的估计性 能，但是它的计算成本太高，在大规模网络中计算不可行，在Ex2中需要花费40 分钟跑一次实验。完整的JGSE学习算法非常高效，在第一阶段利用GTQ进行 图结构筛选之后进行网络分解，然后使用GFE对每个子网络进行精准估计。更 重要的是，几乎所有的情况JGSE都有很好的估计。
（4）复杂度分析
每个网络的大小p,每个子网络的大小均为ps，阈值q设置为0.3样本大小 为200o Tjgse表示先使用GTQ然后再使用GFE算法学习所需要的时间，T品弼表 示不使用GTQ而是对整个网络直接使用GFE算法学习所需要的时间。实验对比 不同（P, Ps）组合下Tjgse/下限的性能。
表4・2不同网络大小下的复杂度分析
(p, Ps)	(400,200)	(400,80)	(400,40)	(800,400)	(800,160)	(800,80)
T	/q^total Mgse/lGFE	0.454	0.287	0.156	0.427	0.218	0.124
44
从表4-2可以看出，在大型网络中先使用GTQ进行分解可以节省一半以上 的时间，而且p/ps越大，也就是网络规模p越大或者子网络规模Ps越小，可节省 的时间越多，效率越高。因此如果对多个子网络使用并行计算的话，那么计算效 率会有质的提升。这里并没有采用MRCE算法进行对比，因为他在大规模数据 下运行速度实在是太慢了。
4.4.2真实数据的应用
这部分使用股票市场的数据进行分析，收集美国S&P500指数⑪中10种不同 的行业类别的452只股票的收盘价,其时间跨度从2003/01/01-2008/01/01共1258 个时间样本。对其取对数做差分变换处理，计算对数收益率作为实验信号。
设置q=0.1,先使用GTQ进行网络分解，尽管没有真实的类标签来衡量聚类 性能，但是通过GTQ得到了 10个子网络这正对应S&P500的10个板块，如图4-3所示，因此我们使用10个板块所处的行业作为正确类标签基准，以此求解CI 用来评价聚类性能。同时，使用MSE来衡量预测准确率，假设滑动窗大小为W, 起始点为3 那么使用过去最近的W的观察样本｛xJ3°_w+i估计图结构瓦那 么可以预测时间序列Xt+h：骞+h = Bf和+重复运行程序进行预测直到滑动窗 滑动整个时间序列最后一个样本，则预测误差MSE = Jw.决阖|与+八一
71—fl—W+1	1
45
图4-4 S&P500中不同阈值q下的聚类性能
从图4-4中可以看出，当q=0.1时，GTQ的分类指标CI达到0.88,说明这几乎 跟S&P500指数官网上的行业分类标准一致，而且CI的值不会随着q值的变化而 剧烈变化，反应了 GTQ的鲁棒性。
JGSE对S&P500的预测能力主要体现在MSE上，设置h=L窗长W=0.8n。 在每个分类中对比GTG、MRCE和JGSE算法的性能。由于有限的样本大小，在 合成数据中使用验证集来进行模型选择的方法变得不可行，这里使用BIC进行 参数调整，如果同时估计B和Q,自由度的个数为巳,/1加产。+£引1小尸。，如果 只估计B,那么自由度为11产。。
表4-3 S&P500用每个行业类下不同算法的预测误差
类1	类2	类3	类4	类5	类6	类7	类8	类9	类10
GTG	1559.1	883.5	546.6	554.8	443.5	401.2	237.3	236.6	159.3	70.2
MRCE	531.1	783.3	150.1	92.3	87.6	93.4	28.4	7.9	3.4	2.5
JGSE	12.6	10.9	7.9	7.5	5.4	5.6	4.2	3.7	2.8	1.4
从表4-3中可以看出10个类的MSE分布,JGSE平摊到每个类的MSE要比GTG 和MRCE小很多。
4.5本章小结
本章主要讲述了两个方面的内容，一是联合图结构的分解（GTQ）,将谱聚 类算法嵌入到一阶线性动态高斯马尔科夫过程模型，二是对聚类的每个子网络结 构实行图结构的精准估计（GFE）,这两者合称为JGSE。并通过实验仿真研究GTQ 对聚类的影响，以及JGSE算法与GTG、CDG、MRCE算法性能对比，最后将 其应用于实际的S&P500金融股票市场验证。
46
第五章大规模空时信号结构的稀疏自适应估计
在许多实时大数据处理场景中，由于数据体量大、速度快等特点，使得图结 构估计算法碰到了许多技术问题。比如金融市场交易中，股票市场由多种类型的 股票构成，它们以TB每秒甚至更高的速率产生数据并且相互影响，除了异常或 极端事件的发生，这种邻接关系随时间而缓慢地演变。实时处理并预测这样的大 型网络结构，所需的数据量很多，也很难将所有的资源加载到计算机内存里，而 且计算复杂度也很高。因此设计简单而有效的框架来实时地估计海量的图结构连 接模型是具有实际意义的。也就是说，一旦仃新息信息进入，系统可以利用先验 的估计，自动地做出简单更新，处理飞前决策的过程。本也针对勺、:时数据处■ 场景，提出了迭代最小二乘法(1LSM),灯以根据当前状态和新息信息，更新对 下一刻图结构进行估计。Yiyuan She1川提出了其广阈值筛选的算法，暴干约束 筛选出图中前M个最大的数作为稀疏正则，M表小网络的稀疏度，可以人为FL 接控制。但是在实际应用中，由于网络随时间的演变而变化以及噪声的干扰，无 法确定真实的稀疏度。本章还提出了一种自适应稀疏度估计-最小二乘法(ASP-LSM),利用滑动窗前后估计的图结构具有共同的稀疏性，能够自适应地确定稀 疏度和抑制噪声。最后通过仿真分析研究B-EST、ILSM以及ASP-LSM三种算 法性能的对比。
5.1迭代最小二乘方法
为了加强图的稀疏性和能量平滑性，借用“％ + %”类似的惩罚，同时为了 控制误差范围，对QT进行约束，定义：err = ||Y-XB||^,巧合地是，误差err等 于QT对角线元素之和，优化问题可重新描述为：
2	7
s.t.||B||o<M1,||n-1||o<M2
%	(5-1)
公式(5-1)中入4 = 1,2)是正的正则参数，用来约束能量的平滑性，因而是不 敏感参数，不需要进行很大范围内地网格化线性搜索，通常取值为le-4。/II。 是图矩阵中非零元素的个数。第一项L(B,Q)是目标函数，其余的是正则函数以去 除一些不必要的解，|卜|信用于抑制噪声，控制非对角线上的元素，也就是图节点
47
之间边的权重，从而提高估计的准确性；INI。用于直接控制图结构的稀疏度，也 就是B和Q中非零元素的个数上界Mi和M2,从而提高拓扑的识别能力；2L跖1 用于控制误差精度，约束非对角元素QT。
公式(5-1)的优化问题是联合非凸且不可微，求解这样的问题是非常困难的， 采取松弛凸优化的方法，包括两个过程：(1)迭代最小二乘法(ILSM),利用新 息信息和先验估计更新迭代过程;(2)自适应稀疏度估计-最小二乘法(ASP-LSM), 根据时间窗前后共享的信息块和图结构的稀疏度缓慢变化的特性，通过能量检测 自适应地确定稀疏度。
这一小节主要推导ILSM更新图结构的公式，为了简化问题，首先不考虑约 束项求解目标函数以实现迭代更新过程。L(B,O)是联合非凸函数，经典的方法是 交替梯度下降法，如果有足够的样本，B,C的最优解将在各自的微分等于0处取 得：
B = (XTX)-1XTY
。-1="(展 X 针(丫― XR)]	(5-2)
公式(5-2)中的形式与最小二乘法(LSM)相似，上面描述的方.法是批处理预 测(B-EST),在获得一批训练集后集中处理。这种技术占用计算机很大的存储 空间，不能应用于在线估计。在实际数据处理中，数据往往是按时间顺序逐步给 出的，可以先获得一批数据松，得到图的近似估计，来了新数据后建立时间序列 前后的联系，利用共享的信息块再对原先的估计进行修正。1LSM的思想是利用 先验的估计瓦，同丁和血+「Xk+i获得新的估计及+i,标，。
假设初始时间序列样本大小为k,令丫人=[x2, . . ■, xfc]T, Xk =	…,X/liF，
全部k次测量的马尔科夫过程的矩阵形式：
Yk = XkB + Vk	(5-3)
公式(5-3)中，Vk = M，.»以],以〜N(O,E),此优化问题可以转化为公式(5-1)中的 优化问题，得到前k次测量B,QT的最优解：
.=—飞丫女
航1 =3[(Yfc- XkBk)T(Yk - XkBk)] (5-4) 现在假设获得第k + 1次测量值：
yk+1 = Axk+1 + vk+1	(5-5)
将新的测量值添加到先前的样本中，那么全部k + 1次测量值的矩阵形式：
Yk+i = Xk+IB + Vk+i	(5-6)
公式(5-6)中，Yk+1 = [Yk ： yk+1]T,
X/c+1 = [Xk : X「+1]T，廉+1 = Wk 为:+l]T	(5-7)
48
下面将推导为+1和瓦，。武1和的关系，令能量密度矩阵限二 (X£XQT,则：
Pfc+i = (xj+1xfc+1)
二(Xf Xk + X/c+i蛀+工)i
=(P/?i + 冲+i 邸+i)t
Pfc+l ~ [I ~ Pk%/c+i(x£+iPze%Zc+i + l)T%A+i ]Pfc (5-8)
由于(其+14+1々4+1 + 1)-1是数值，而不是矩阵，因此对它的求逆是不复 杂的。进而得瓦+i：
B/c+i = P/c+iX$+iYz+i
=P/c+l(X(Y/c + ^k+lYk+l)
=fk+l(P/c+l^k — X/c+lX^+lBk + 孔+1久+1)
二 B% + Pkxk+1(yJ+1 -xJ+iBj (5-9)
类似地，可以得到噪声协方差矩阵。连1：
1
二.二彳〔(丫土+1 — X/c+iBQTlY^+i - Xk+iBQ] rv i- 1
1	t
二时^丫人 一 X逮。丁(丫/<—XkBQ
+(7fc+i - Bjxk+i)(yk+1 - B1%k+i)T)]
=.+ 1 — J + . + ] (y.+i - B以k+D , (y〃+i — Bf%k+i)
(5-10) 上面B, Q-i的迭代过程是计算简洁的，没有矩阵求逆过程，因此适合流信号的在 线估计。
下面将目标函数加入F范数约束，在前k次测量中，分别对B和。微分，令 其微分为0：
XTXB = *T丫 —2 入iBQT
Q-i = ](丫- XB)T(Y-XB)+(/12。-3	(5-11)
明显地，不能得到B, 11T的闭式解，假设B和QT收敛有界，在多次迭代后有 Bk = B”i，贝帕和◎一1在k处的迭代解：
Bk =(X风尸(X- — 2%By Q/)
=1(Yk-XkBk)T(Yk-XkBk) +之为2口之1	(5-12)
与公式(5-12)类似，在k+1处迭代有：
B/c+1 = Bk + PfcXfc+i(yJ+i -超+1BQ - 2X1(Bk - Sfc-i)^1
49
/c	]	T
"Vi= k +1 °1 +1(y”+i —	”(,"+i — ^kxk+i)
+ 4入2(。/—。己)
(5-13)
5.2稀疏自适应估计
ILSM算法会产生过拟合，导致图节点之间密集连接，而实际中确实存在一 些重要的节点只影响其他的节点，因而在估计的图结构过程中需要进行稀疏假设。 下面将在迭代过程中加入不等约束进行稀疏约束与误差控制。
本文借用阈值筛选的思想［13］，在预测的图结构中抽取前M个最大的值作为 稀疏正则，也就是，一旦有更新，对取+1排序并截取前Mi个最大的值作为下次迭 代的初始值。将这个筛选过程嵌入到更新过程：
B/c+i _ 6h(B/c+i； Mi)
(5-14)
公式(5-14)中阈值筛选函数0Hs勾=t/|t| > A,/lt| > 2为指示函数，即当t > |入|时值为1，否则为0。入是W+i中第Mi个最大的值。同样对。武1采用相似的操 作。
在许多现代大数据研究中，预测估值技术希望在可容忍的误差精度范围下使 用简单的方法快速有效得估计。也就是说，允许在牺牲一定的准确率情况下来获 得计算速率的提高。在本文中估计误差err恰好等于IT】的对角线元素之和。令 权重算子77=£/甲］口二1，则在迭代过程中QT可以修订为：
为L —辿之1
(5-15)
然而，在大多数实际应用中，由于噪声干扰或者图结构的稀疏度也会随时间 而缓慢变化。有时，很难确定M的大小，用相同的M值来描述整个迭代过程中 图结构的稀疏度也是不合适的。从统计地角度来讲，在滑动窗前后每次估计的图 结构共享许多相似的信息并且有相同的稀疏度。下面提出ASP-LSM算法来自适 应稀疏度，控制M的变化。
假设稀疏图结构可以看作模型：z = s + w, s表示信号，在图结构中表示真 正有权重的位置，w表示系统噪声或者由于过拟合而产生的不必要的权重关系， 在图结构中表示没有权重连接的位置。具体地，信号s可表示为vecB = Rk+i，噪 声w可表示为vecBn = Bk+i -瓦+i。基于能量的确定信号检测问题可以使用下面 两个假设来描述：
Ho: z[n] + w[n], n = 1,2,N
Hi：z[?i] = s[n] + w[Xl，n = 1,2,N
(5-16)
在公式(5-16)中，信号协方差戊，噪声协方差在山条件假设下，信号服从高 斯分布：z〜N(0《2/),在用假设下信号服从高斯分布：z〜N(0,(o2相应
地似然比检验函数:
』(z)二
p(z|Hi)f> Y，Hi
p(z|h0)(< y, Ho
(5-17)
使用最大似然法求解，可获得能量检测函数:
T(x) = 2kz2 四过 Y'
(5-18)
最后，比较统计量TQ)与V的大小,当T(x) >/时，接收%,认为在％条件下， 协方差增加到/+武，否则接收H。假设，认为协方差减少到小。
■动窗滑动过程中,噪声的幅值在较大范围内波动，但是估计的图结构稀 疏度缓慢变化，信号有权重位置的能量以很大的概率大F噪声权用位置，的力■ ■始阶段，任意设置M的值，微断前M大个值作为信号，其余的作为口■ 连续观察N。次时间窗，计算所有节点的能量和记为T(x),噪声能吊:记为V。则支 撑集位置：S = supp(T(x) >/),如果想要加速算法收敛速度，可以对参数V微 微调整。对统计量的值筛选确定稀疏度大小M： M = length^。如卜算法3所 示是ASP-LSM详细算法流程，每隔I%次时间窗'，检测统计量与阈值Y'的关系， 确定稀疏度M,并作为下一次迭代的参数，在多次观察迭代后，M达到了稳定 的值，并接近真实的图结构稀疏度，终止迭代过程。
算法3 ASP-LSM详细算法流程_____________________________
ASP-LSM 算法____________________________________
Input：时间序列样本覆
Initialization：初始计数器i = 1,初始稀疏度M；
初始时间窗长M样本矩阵H = [x2,...xk]r,Xk =	刈_JT,
初始能量密度矩阵Pk =仆风尸;
初始估计瓦，际I根据式(5-12)计算得到； 统计时间窗大小No,全部时间窗大小N； for i=l,29...N
= i + 1；
2)根据式(5-8), (5-13)更新 Pk+i，Bk+i，一3;
矢量化矩阵，vecB = Vec(Bfe+1), vecO = Vec(。逢力；
稀疏惩罚与误差精度约束，根据式(5-14), (5-15)更新瓦+「航，；
矢量化噪声矩阵uecBn，vecOn
3)一 (i > No)
3.1)	根据前1-此+ 1个时间窗到到前i个时间窗更新稀疏度：
Tb(九)=Ei-No+1 vecB(n)2, T0(n) = E/-n0+i vec0(n)2；
3.2)	计算阈值Y1和％,与TB(n)方法类似；
3.3)	计算支撑集位置：St = supp(TB(n) > y1); S2 = supp(T0(n) > 丫外；
3.4)	确定稀疏度：M] = lengthiSj), M2 = length(^2)i
3.5)	比较稀疏度变化情况并更新，如果Mi，M2达到稳定值迭代终止。 end for
Results：估计的图结构H-1
5.3数值分析
5.3.1仿真分析
在这节实验中，将ASP-LSM算法与ILSM算法和B-EST算法进行比较，同 时，使用两个评价标准：误差率(Err)和准确率(AR)评估三种算法的估计性 能。定义ErrB =|| B - B |||/P ,用于评价图的估计精度；定义ARb = length(sgn(^) - sgn(B) == 0)/P,其中sgn。是符号函数，用于评价图的拓扑 识别能力。值得注意的是，B和的估计是有偏的，如果时间序列样本足够多， 月和0T越接近真实的值，Err指标也渐进趋近于0。
图5-1和图5-2使用了一个小的例子直观地说明了 ASP-LSM算法的优越 性。其中，图节点的个数是20,全部时间窗长(T) 300个时间样本，初始时间 窗长(”) 20个时间样本，图结构B和QT的稀疏度分别为0.1。
图5-1 ASP-LSM算法恢复的图结构B
(d)ASP-LSM
图5・2 ASP-LSM算法恢复的图结构QT
52
图5-1和图5-2中子图（a）为真实的图结构，子图（b）为使用B-EST算 法估计的图结构，子图（c）为使用ILSM算法估计的图结构，子图（d）为使用 ASP-LSM算法估计的图结构。从图中可以明显地看出，由于没有稀疏约束，使 用B-EST算法和ILSM算法估计的图矩阵出现了过拟合现象，无法识别出图节 点之间正确的邻接关系。而ASP-LSM算法能够有效地抑制噪声，检测出绝大多 数图节点的邻接关系。
理论地，如果有足够多地样本，经典的B-EST算法能够趋近真实的图结构， 而使用ASP-LSM算法可以大概知道在300个时间样本后能接近真实的图结构。 纵观图5-1和图5-2, QT的估计效果要比B的估计效果要好，其检测出的正确 的边的连接关系要比B检测出的正确的连接关系要多。
图5-3和图5-4使用了较大的网络拓扑图结构具体地量化ASP-LSM算法 的性能。在仿真中，图节点的个数为100,全部迭代窗长（T）为900个时间样 本，初始时间窗长（t°）为50个时间样本，B-EST算法使用4000个时间样本作 为基准。
图5-3不同算法下估计的图结构B的En•和AR对比关系
如图5-3和图5~4所示，子图（a）为B-EST, ILSM, ASP-LSM三种算法 分别估计B和QT的误差随时间变化图，子图（b）为三种算法分别估计B和Q-i的 拓扑识别准确率随时间的变化图，子图（c）是ASP-LSM算法分别估计B和QT 的稀疏度随时间的变化图。直观地，基准B-EST有很好的估计性能但拓扑识别 能力很差，ASP-LSM算法误差收敛速度比ILSM算法收敛速度快，而且拓扑识 别能力要比ILAM算法高。横轴为时间，则在第t个时间点，ASP-LSM算法与 ILSM算法所需的时间序列样本为t + t0,
53
图5-4不同算法下估计的图结构IT】的Err和AR对比关系
从图中可以看出，ASP-LSM算法只需要950个时间序列样本就能收敛到基
准的误差，而基准需要4000个时间样本。在950个样本情况下，ASP-LSM算法 所估计的图结构稀疏度也达到收敛并接近于真实的图结构稀疏度，同时拓扑识别 能力也达到了稳定状态。ASP-LSM算法在较少的样本情况下，却有较好较快的 估计效果，说明ASP-LSM算法比经典的批处理算法有较低的复杂度和较快的收 敛速度。实际上，B-EST和ILSM算法的AR性能相等的，因为都没有对图矩阵 进行稀疏度约束。
5.3.2真实数据应用
这部分使用股票市场的数据进行分析，在金融分析中，经常需要寻找不同股 票的相互关系，以设计新的策略。回归分析是一种简单而有效的寻找相关性的方 法，常用的方法是通过暴力搜索寻找每两只股票的相关性，这种做法是耗时的且 需要较高的机器性能。通过本文提出的模型将所有的股票用图结构描述，每天的 股票价格看作图信号，建立空时马尔可夫过程，从整体上估计所有股票之间的相 关关系，可供进一步研究。同样使用S&P500数据，对其取对数做差分变换处理， 计算对数收益率作为实验信号，并应用于ASP-LSM学习算法中。由于没有真实 的B和CT可供验证，设置£ = 1,也就是在每次迭代中模型容忍误差是1,那么 本实验主要关心的股票节点之间边的连接关系。
结果表明在500次迭代后，B和QT的稀疏度达到0.1和0.2并收敛于稳定状 态。在大多数情况下，来自不同行业的的股票有一些联系而来自相同行业内的股
54
票未必有联系。图5-5画出了估计452只股票的邻接关系，其中筛选了权重比较 大的边。节点越大说明节点的度越大，与其连接的边越多。从图5-5中可以看出， 估计的图结构连接关系具有聚类特性。
图5-6列出了使用ASP-LSM算法其中YHOO这只股票与其他股票估计的 连接关系。实线表示正的相关，虚线表示负相关关系，同时线条越粗相关性越强。 众所周知，YHOO是一家信息科技公司，除了与NVDL、AAPL等信息科技公司 有联系外，还与消费行业，如TJX, GT,金融行业，如SLM, PGR,有较强的 联系。图 5-7 画出了 YHOO 与 TJX、AAPL 从 2003/01/01 到 2008/01/01 真实的 股票走势价格。从图中可以看出YHOO和TJX在三个时间段呈现相同的价格涨 跌波动趋势。而YHOO与AAPL的价格走势几乎相反呈现负相关，有趣的是， 这个事实与图5-6使用图模型估计的结果相吻合。总之，ASP-LSM算法可以帮 助研究者进一步探索不同行业股票的相关性。
图5-5 S&P500中使用ASP-LSM算法对其聚类的效果图
55
图5-6 S&P500中使用ASP-LSM算法YHOO与其他股票的连接情况
图5-7 S&P500中YHOO与其他股票的价格走势图
56
5.4本章小结
本章提供了从收集的大规模数据中学习图拓扑结构的在线学习框架，算法假 设动态空时信号是由静态的网络图结构生成，并基于最小二乘法自适应地学习图 结构的稀疏度。该算法可以快速有效地估计大规模信号结构的连接关系，进而可 以从海量的数据中挖掘有效的信息。实验结果表明提出的ASP-LSM算法可以有 效地推断出图拓扑结构，该算法比经典的离线估计算法复杂度要低月收敛速度要 快，但是所估计的图B在拓扑识别能力方面没有Q-i好，还有待进一步研究。同 时，针对动态信号是由动态网络图结构生成的图信号学习算法还有待进•步研究。
58
第六章全文总结
6.1本文研究内容与创新
本课题基于空时信号的一阶高斯马尔科夫过程，研究静态场景下联合图结构 的参数估计，以及大规模网络下基于聚类的图结构参数估计和流信号场景卜的图 结构参数估计问题。根据联合图结构的阈值q,提出了聚类数K的确定方法，以 及在流信号场景中，根据流信号的前后状态转移，推导用I 了图结构参数的状态转 移过程，并结合能量检测，提出了自适应稀疏度的图结构参数估计方法，并将共 应用于实际的S&P500数据中。
结合本课题的主要研究内容，本文的特色与创新之处如下：
1	.基于一阶高斯马尔科夫过程的联合图结构参数估计
联合图结构C的构造可以有效地筛选出它们中的孤立节点，并检测出共同 存在的边，并且为大规模网络谱聚类提供了相似矩阵，本文研究了联合噪声图结 构构造的权重参数，提出了不同网络类型以及不同网络规模下权重参数的确定范 围。并使用分组阈值q(GTQ)算法作为图结构的稀疏惩罚，证明其迭代过程的收 敛性并通过仿真验证其收敛性。同时针对不同的稀疏惩罚，研究不用类型的惩和 约束对模型相合性的影响，通过仿真验证了 “仇+%”稀疏约束的优越性。
2	.基于聚类的一阶高斯马尔科夫过程的图结构参数估计
使用谱聚类可以将大规模网络图结构进行分解，对每个子网络使用并行的方 式进行图结构参数估计，从而降低计算的复杂度。本文根据阈值q筛选图结构的 情况，提出了聚类数K的确定方法，然后对其聚类，对每个子网络进行精准估 计，对比不同网络模型与规模在JGSE、MRCE、GTG、CDG四种算法下的性能， 通过仿真雁阵了 JGSE在估计准确率、拓扑识别率以及计算性能方面的优势。
3	.基于稀疏自适应的迭代最小二乘图结构参数估计
利用时间序列前后共享的信息，对前一时刻的图结构估计进行修正，得到新 一时刻下的图结构估计，可以有效地解决在线估计问题同时解决批处理下数据不 能全部加载的内存问题。本文利用新息信息以及先验的估计，推导出图结构的状 态转移关系，同时根据能量检测，推导出流场景下稀疏度自适应的图结构估计算 法。
59
6.2未来工作展望
本文研究了空时信号一阶高斯马尔科夫过程的图结构参数估计问题，针对空 时信号的“块”、“流”特点提出了相应的聚类算法与迭代最小二乘算法，以提高 参数估计的拓扑识别率与估计的准确性。基于本文的研究内容，未来的研究可以 从以下几个方面进行开展：
（1）针对空时信号的建模部分，本文侧重于一阶高斯马尔科夫过程模型， 对于其他模型，比如，多阶因果过程模型，因子模型等也同样适用于空时信号， 我们需要对同一个空时信号做不同模型的对比，因为没有绝对好坏的模型，只有 模型是不是适合数据。同时，本文以及先前的图结构模型中，均假设噪声是高斯 独立的或高斯有色的，但是在实际的空时数据中，往往存在极值的情况，比如， 交通流量的高峰期估计，此时并不能假设噪声是高斯的，需要考虑其他的假设, 比如泊松过程分布等。
（2）针对空时信号模型的参数估计部分，在高维数据下，往往样本数量远 远小于需要估计参数，需要对参数估计的解作稀疏假设，根据压缩感知理论，假 设信号是稀疏的，那么可以通过有限的测量数恢复出原始信号。在实际中根据先 验知识我们可以知道解的稀疏情况，往往不知道所需要的样本的数量，我们需要 研究高维信号处理下，不同的稀疏情况所需的最佳样本个数。
（3）实际的空时数据往往存在许多缺失情况，比如中国股票市场经常会由 于涨停板出现大量的缺失数据，如何利用空时数据的相关关系建模来对缺失数据 的填补也是今后研究的重点。
60
参考文献
[1]	Mollersen S, Sexton H C, Holte A. Big Data and the Internet of Things[J]. Journal of Marketing Analytics, 2015, 3(l):l-4.
[2]	Ding G, Wang L, Wu Q. Big Data Analytics in Future Internet of Things[J]. Computer Science, 2013, 9:430 - 434.
[3]	Katai A, Wazid M, Goudar R H Big data: Issues, challenges, tools and Good. practices[C]// Contemporary Computing (IC3), 2013 Sixth International Conference on. IEEE, 2013:404-409
[4]	Shuman D I, Narang S K, Frossard P, et al The emerging field of signal processing on graphs:Extending high-dimensional data analysis to networks and other irregular domains]”. IEEE Signal Processing Magazine, 2012, 30(3):83-98.
[5]	Nisar M U, Fard A, Miller J A. Techniques for Graph Analytics on Big Data[C]// IEEE International Congress on Big Data. IEEE Computer Society, 2013:255-262.
[6]	Dong X, Thanou D, Frossard P, et al. Learning Laplacian Matrix in Smooth Graph Signal Representations[J]. Computer Science, 2015:1-1.
[刀凯(美).统计信号处理基础：估计与检测理论[M].电子工业出版社, 2003.
[8]博伊德.凸优化[M].清华大学出版社,2013.
[9]	Sandryhaila A, Moura J M F. Discrete Signal Processing on Graphs [J]. IEEE Transactions on Signal Processing, 2012, 61(7):1644-1656.
[10]	Sandryhaila A, Moura J M F. Discrete signal processing on graphs: Graph fourier transform [C]// 2013:6167-6170.
[11]Chen S, Sandryhaila A, Moura J M F, et al. Signal denoising on graphs via graph filtering[C]// Signal and Information Processing. IEEE, 2014:872 - 876.
[12]	Zhou D, Scholkopf B. A Regularization Framework for Learning from Graph Data[J]. Icml Workshop on Statistical Relational Learning, 2004:132—137.
[13]Mei J, Moura J M F. Signal Processing on Graphs: Modeling (Causal) Relations in Big Data[J]. Statistics, 2015.
[14]	She Y, He Y, Li S, et al. Joint Association Graph Screening and Decomposition
61
for Large-scale Linear Dynamical Systems[J]. IEEE Transactions on Signal Processing, 2014, 63(2):389 -401.
[15]Rue H, Held L. Gaussian Markov Random Fields[J], Chapman & Hall/crc Boca, 2005, 49(3):xii,263.
[16]Dutilleul P. The mle algorithm for the matrix normal distributionfj]. Journal of Statistical Computation & Simulation, 1999, 64(2):105-123.
[17]李阳.利用优序列方法证明牛顿下降法在一般条件下的收敛性[JL渤海 大学学报(自然科学版),2004, 25(4):342-345.
[18]温蓉胜，吴衍智.峰值网格搜索法[J].河北工程大学学报(自然科学版), 1993(1):6-10.
[19]陶菊春，吴建民,综合加权评分法的综合权重确定新探[J].系统工程理 论与实践,2001, 21(8):43-48.
―20] http :〃 cvxr. com/cvx/
[21]杨洋,一类非凸非光滑约束优化的束方法[D]大连理工大学,2012.
[22]贲树军.秩优化问题的多阶段凸松弛法研究[D].华南理工大学,2014
[23]滕岩梅，高月娟,局部凸空间中的向量值强扰动优化定理[J].哈尔滨师 范大学自然科学学报,2008, 24(6):4-6,
[24] Witten, Daniela M. New Insights and Faster Computations for the Graphical Lasso[J]. Journal of Computational & Graphical Statistics, 2012, 20(4):892-900.
[25]He Y, She Y, Wu D. Stationary-sparse causality network leaming[J]. Journal of Machine Learning Research, 2013, 14(1):3073-3104.
[26]	http:〃cran.r-project.org/web/packages/lasso2/index.html
[27]Buhlmann P, Geer S V D. Statistics for High-Dimensional Data[J]. Journal of the Japan Statistical Society Japanese Issue, 2011, 44(10):247-249.
[28]刘建伟，崔立鹏，刘泽宇，等.正则化稀疏模型[J].计算机学报， 2015(7):1307-1325.
[29]路畅，刘玉红.压缩感知理论中的RIP准则[J].自动化与仪器仪表, 2015(8):211-213.
[30]	Wang L, Chen G, Li H. Group SCAD regression analysis for microarray time course gene expression data,[J]. Bioinformatics, 2007, 23(12):1486-94.
[31]	Huang J, Ma S, Zhang C H. Adaptive LASSO for sparse high-dimensional regression[J]. Statistica Sinica, 2006, 18(4):1603-1618.
[32]Meinshausen N. Relaxed Lasso[J]. Computational Statistics & Data Analysis,
62
2007, 52(1):374-393.
[33]Knight K. Asymptotics for lasso-type estimators[J]. Annals of Statistics, 2000. 28(5):1356-1378.
[34]Grave E, Obozinski G, Bach F. Trace Lasso: a trace norm regularization for conelated designs[J]. Advances in Neural Information Processing Systems, 2011:2187-2195.
[35]Zou H, Hastie T. Regularization and variable selection via the elastic net[J]. Journal of the Royal Statistical Society, 2005, 67(2):301-320.
[36]Xie J. Group variable selection via SCAD-[J].
[37]She Y, Thresholding-based Iterative Selection Procedures for Model Selection and Shrinkage[J]. Electronic Journal of Statistics, 2009, 3(1):384-415.
[38]She Y, He Y, Wu D. Learning Topology and Dynamics of Large Recurrent Neural NetworksfJ]. IEEE Transactions on Signal Processing, 2014, 62(22):5881-5891.
[39]李根，邹国华，张新雨.高维模型选择方法综述[J].数理统计可管理, 2012, 31(4):640-658.
[40]Candes E, Tao T. The Danzig selector: statistical estimation when p is much larger than n. Ann Stat [J]. Annals of Statistics, 2005, 35(6).
[41]Jong S D. SIMPLS: An alternative approach to partial least squares regression[J]. Chemometrics & Intelligent Laboratory Systems, 1993, 18(3):251-263.
[42]Xiang D, Wahba G. A Generalized Approximate Cross Validation for Smoothing Splines with Non-Gaussian DatafJ]. Statistica Sinica, 1994, 6(3):675-692.
[43]Wu Y, Stefanski L A. Controlling Variable Selection by the Addition of Pseudovariables[J]. Journal of the American Statistical Association, 2007, 102(477):235-243.
[44]Meinshausen N, Btihlmann P. Stability selection[J]. Journal of the Royal Statistical Society, 2010, 72(4):417-473.
[45] Stein C. Inadmissibility of the usual estimator for the mean of a multivariate normal distribution[C]// Berkeley Symposium on Mathematical Statistics & Probability. University of California Press, 1956:197-206.
[46]Rothman A J, Levina E, Zhu J. Sparse Multivariate Regression With Covariance EstimationfJ]. Journal of Computational & Graphical Statistics,
63
2010, 19(4):947-962.
[47]Mazumder R, Hastie T. Exact Covariance Thresholding into Connected Components for Large-Scale Graphical Lasso.[J], Journal of Machine Learning Research Jmlr, 2012,13(1):781-794.
[48]	She Y Thresholding-based Iterative Selection Procedures for Model Selection and Shrinkage[J]. Electronic Journal of Statistics, 2009, 3(1):384-415.
[49]	She Y. An Iterative Algorithm for Fitting Nonconvex Penalized Generalized Linear Models with Grouped Predictors [J]. Computational Statistics & Data Analysis, 2011, 56(10):2976-2990.
[50]Luxburg U V A tutorial on spectral clustering^]. Statistics and Computing, 2007, 17(4):395-416.
[51]	http://finance.yahoo.com/.
64
