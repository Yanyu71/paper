
第一章绪论
1.1引言
随着计算机科学技术的不断发展，虚拟现实(VirtualReality, VR)技术以及 增强现实(AugmentedReality, AR)技术已经进入到我们的日常生活。虚拟现实 技术被誉为“下一代互联网”和“下一代计算平台”⑴，综合了计算机图形技术、 计算机仿真技术、显示技术、传感器技术等多种学科技术，通过运用计算机图形 渲染能力制造三维虚拟世界，同时使用多维的人机交互界面提供包括听觉、视觉、 触觉等在内的全方位感官感受，使用户可以自由地浏览虚拟世界并与其互动，获 得身临其境之感。
目前，VR/AR技术已经应用在电商行业的AR试穿，虚拟看房、在线家装、 网络游戏等各行各业。其中，精细的三维模型成为了各种虚拟现实应用的重要媒 体承载形式。相比于传统的二维场景，基于网格模型的三维场景可以使用户更好 地得到沉浸式的体验，用户可以在终端上完成更多的交互功能。例如移动端AR 游戏“我的世界”，游戏玩家可以和游戏场景中的模型完成多种交互功能，相比 于普通的游戏具有更高的可操作性。三维场景给用户带来更优的沉浸式体验的同 时，高质量三维模型和纹理图片的数据量也是巨大的。因此，将高质量的三维场 景快速传输给用户以便实时浏览是一个巨大的挑战。
1.2研究背景及意义
在流媒体出现之前，人们只能将视频或者音频文件下载到本地才能浏览，不 仅浪费时间还占用大量本地存储空间。随着流媒体技术的发展，用户体验音视频 内容的方式也有了质的飞越，可以一边下载一边观看。这一过程又很好的契合窄 带互联网时期到宽带互联网时期的移动通信技术的发展。当前的虚拟场景以及其 中的三维模型这种媒体文件仍停留在先下载到本地才能浏览的阶段，而伴随着 5G时代的到来，这种媒体形式是否也会加入流媒体的行列呢？
近年来，快速发展的VR/AR技术不断地改变人们的生活。VR/AR相关产品 也在大量涌现，例如VR/AR头戴式显示设备、虚拟现实拍摄设备、VR/AR内容 创作平台和不同平台的SDK等一系列产品。其中VR/AR头显设备已经出具规 模,Facebook 的 Oculus 系列、HTC 的 Vive 系列等 VR 头显 >Microsoft 的 HoloLens 系列、Magic Leap等AR眼镜Pl。同时，Google和Apple公司也申请了多项AR
1 眼镜相关技术的专利，大力布局相关产业，计划推出他们的AR头显产品。随着 5G技术的真正落地，也让VR/AR的未来变得更加光明。基于低时延、高带宽的 5G技术，将会出现真正的杀手级应用，将VR/AR的发展推向新的高度。
当前，通常需要提前将数据下载到本地，而这个过程需要花费很长时间，并 且占用了大量的本地存储空间。随着三维场景的数据规模和复杂程度的急剧增加, 实时下载三维模型的需求与有限的带宽的矛盾、庞大的数据量和用户有限的存储 空间之间的矛盾成为了制约三维场景在网络中实时传输进一步发展的关键问题。 因此，将三维场景数据转换成流媒体表现形式将会显著提升用户浏览虚拟场景的 体验。
1.3国内外研究现状
目前，在三维场景中使用的模型文件有两种类型，分别是网格模型和点云模 型。网格模型由明确指定拓扑结构的三角形网格构成，点云模型则是基于点的结 构形式。基于三角面的网格模型是目前应用范围最广的一种三维模型，特别是在 纹理贴图、光照材质等技术应用下，网格模型能够高质量的模拟现实世界的物体， 并具有高复用的特点。基于点描述表示和渲染的点云模型是Levoy首次提岀⑶， 这种基于点的描述方式特别适合现实物体的三维重建工作，而且不需要记录顶点 间的几何连接和拓扑结构关系，节省了储存连接关系的信息，便于对模型进行表 示、处理和渲染。网格模型以及点云模型都可以用来完成渐进式加载，而且二者 之间也可以互相转化。但是就应用层面来说，网格模型复用率高、灵活性强，极 大的减少了开发、传输、存储等各种成本，当前市场上绝大部分应用都使用的网 格模型，所以本文设计方案中将重点放在三维网格模型上。
为了在移动设备上体验大规模虚拟场景，现有的解决方案是基于云服务器的 视频传输，即在云端完成客户端应用内容的渲染，将视频传输到客户端⑷。这种 方案虽然避免了在客户端上存储大量数据以及客户端本身的性能限制，但很难保 证高实时性应用的稳定性和流畅性。一般来说，动态场景让画面看起来流畅，画 面的刷新率至少要保证60fps,也就是16ms完成一次刷新。即使在5G网络环境 下，也很难在这么细粒度的时间内完成信号传输、视频压缩、解码、渲染等一系 列工作。另一种可行的方案就是通过渐进式的方式传输大规模的虚拟场景⑸。在 三维场景中，用户所看到的网格模型数据以及场景相关数据能够实时下载到本地, 用户就可以实现实时漫游，并且轻松的完成场景的转换，而无需等待漫长的下载 时间。同时，该虚拟场景应用也不会占据大量的本地存储空间。
渐进式传输三维场景的关键技术是将三维媒体流式传输。在三维场景流中， 三维模型经过预编码，被分为一个基础层及一系列的优化层。在下载了基础层之
2 后，用户就可以查看模型，并随着优化层的下载逐步细化模型并精确恢复原始模 型。Hoppe用渐进网格(ProgressiveMesh,PM)来表示模型的多个层次向，其核心 思想是通过一系列边缘折叠操作之后减少其顶点和面的数量来简化3D模型，将 三维模型用一个基础信息网格和一系列的增量信息网格存储，从而实现模型的渐 进式加载。在三维场景中，用户由于受到视野范围、可视距离、物体遮挡关系等 限制，在场景中的任一位置上都只能看到诊场景的部分内容。因此只需为用户提 供当前视野范围内可视对象的集合，然后经过渲染管线，在客户端绘制三维场景 后，用户就可以进行体验。用户在客户端输入旋转或移动等操作，依据视点的变 化更新可视对象的集合并完成下载。因此，三维场景流通常被分为两个阶段，模 型集合选择和模型数据传输。其中第一个阶段，当前主流的办法是通过兴趣管理 技术(interestmanagement)来确定用户的可见对象⑺，一旦确定了相关对象进行 传输，就通过模型的传输完成场景的更新。用户可以用一个兴趣区域(Area of Interest, AOI)来确定场景对象的可见性冈。在实现兴趣区域管理中，首先要进行 视椎体剔除以及遮挡剔除，即将不再视椎体内的模型，以及由于遮挡关系，在视 椎体内却因为空间位置关系而看不到模型，剔除在当前的传输列表中。然后则需 要对在传输列表中的模型进行分辨率的选择以及传输顺序的排序，来实现网格模 型渐进式传输。
为了能够让用户实时浏览三维虚拟场景，许多研究将渐进式传输作为虚拟场 景的传输方案。三维场景的渐进式传输主要体现在三个过程：(1)可视内容的 确定。根据用户视野范围的限制性，只需逐步获取在用户视野范围内的内容，对 于视野范围外的场景则无需立即下载。(2)场景中三维模型的渐进式传输。通 过三维模型多分辨率建模技术，再根据三维模型与视点的距离、模型自身的尺度 等因素，在不降低漫游视觉效果的同时，按需下载具有不同分辨率的模型数据， 从而减少场景下载的网络延时。(3)场景中纹理图片的渐进式传输。在传输时， 依据网格模型当前的分辨率层次选择最佳采样率的纹理图片，完成网格模型和纹 理图片的联合优化。渐进式传输通过实时传输场景中的有效数据，减少了用户每 次下载请求的数据总量，也大大降低应用对客户端存储空间的需求。相较于一次 性下载完整质量对象的策略，渐进式传输策略更易于用户实时的完成和三维场景 的浏览和交互，灵活性和传输效率得到了很大的提高。
1.4本文工作和主要创新点
三维流是三维场景内容连续、实时的传输，包括网格模型、纹理贴图、骨骼 动画、音频文件等等，让用户不需要下载完成场景就可以实时浏览。本文主要根 据主流三维流中三维网格模型和纹理图片占据主要传输带宽这一特点，对网格模
3 型和纹理图片的渐进式传输进行理论研究及优化。在对三维网格模型渐进式传输 过程中，根据人类视觉系统的视觉分辨率的限制以及自下而上的视觉注意机制， 提出一种模型的失真估计算法，帮助完成用户在三维场景中实时浏览系统中的场 景更新策略。综合考虑场景中模型距离、尺度和用户观察角度等因素，使得用户 实时浏览场景过程中能够得到更优的体验。在对纹理图片的渐进式传输过程中， 依据网格模型的简化信息，在额定总采样像素数下，对纹理图片的不同区域计算 出该区域最优的降采样系数，从而实现纹理图片的降采样，完成渐进式传输。
本文针对大规模三维虚拟场景的实时浏览所存在的问题，对目前已有的三维 虚拟场景渐进式传输方案中的兴趣管理算法及三维模型最优分辨率计算算法进 行了分析和改进，并将之前研究中忽视的纹理图片加入三维虚拟场景渐进式传输 系统，使得在下载相同数据量的情况下，用户的视觉内容以及视觉呈现的体验更 好。通过将三维虚拟场景中用户行为特点、三维模型的视觉特征有机地结合起来， 依据用户的视觉质量，通过数学建模和理论推导，完成三维虚拟场景的更新策略。
对基于视觉分辨率和视点显著性的模型失真评估算法进行创新。改进基于模 型到视点距离和相对视线中心偏转角度这两个维度的失真评估算法，增加基于距 离和尺度的视觉分辨率作为评价标准，让模型失真评估算法更加精确。同时加入 了视点显著性信息，使得评估方法更加符合人类的视觉特征。改进后的算法，减 少了对用户视觉质量贡献较低的模型传输，提升了对传输带宽的利用率，将更多 的带宽分配给那些能够提升视觉画面质量的模型，同时，更加看重当前视角下显 著性高的模型，从而进一步提升画面视觉质量。
基于纹理图片和网格模型的联合优化进行创新。纹理图片所代表的属性信息 在网格模型的传输中占据了大部分的带宽，对纹理图片做整体的降采样会忽视网 格模型的细节特征。本文结合网格模型的特征对纹理图片不同区域采用不同的降 采样系统，完成渐进式压缩，使得客户端仅下载低分辨率版本的纹理图片即可应 用于模型的纹理贴图，并与渐进式压缩的多分辨率网格模型进行匹配组合，实现 最优的搭配结果。
在模型失真评估算法的基础和纹理图片的渐进式压缩的基础上，对用户相关 场景中三维模型的兴趣区域管理方法进行改进，使得用户的兴趣区域的划分更加 满足真实的体验场景。改变了以往兴趣区域的视距限制，让用户在视觉内容上的 体验更优。同时，基于失真评估、兴趣区域、纹理图片渐进式压缩等因素，对三 维场景中模型和图片的更新策略进行创新，保证用户浏览三维场景的体验。通过 数学模型的建立及问题的求解，完成场景中三维模型的最优分辨率及优先级的确 定，从而在有限的带宽下，为用户提供最优的体验。
1.5论文组织结构
根据本文的研究内容，论文的章节结构安排如下：
第一章为绪论。介绍本课题的研究背景，分析基于三维网格模型的虚拟场景 的相关技术背景和发展状况，以及当前所需解决的问题及本文的中心解决思想， 最后对论文的结构和创新点进行了阐述。
第二章为三维场景渐进式传输技术。主要包含了三维模型相关概念，包括网 格模型、点云模型和三维流，渐进式传输中网格模型的渐进式传输技术、场景渐 进式传输技术、纹理图片压缩，及三维场景的渐进式传输方案的相关介绍。
第三章为基于渲染管线的三维场景渐进式传输优化。从渲染管线出发分析渐 进式传输的优化方向，优化内容主要包含网格模型重要程度计算方式（基于视觉 感知的模型重要程度，基于视点的网格显著性），网格模型和纹理图片的联合优 化，场景传输中的最佳更新策略。
第四章为三维虚拟场景传输系统设计、方案仿真及性能评估。通些渐进式传 输方案的设计，搭建仿真环境，并通过模拟三维场景渐进式传输对象亦画面质量 的改变，对本文提出的方案中画面视觉质量结果进行性能评估和分析。
第五章为总结和展望。对本文的整体结构和内容进行总结，并分析本文的后 续工作以及三维场景渐进式传输的未来展望。
第二章三维场景渐进式传输技术
上一章介绍了三维场景渐进式传输技术的发展背景以及现实意义，并针对当 前传输技术所存在的问题进行了分析，在此基础上，阐述了本文的主要研究内容 并且介绍了本文的组织结构。本章首先介绍了三维模型和三维场景渐进式传输的 相关技术，并在此基础上提出了三维场景的渐进式传输的设计方案。
2.1三维模型
目前三维模型的建模方式主要有三种，分别是通过三维软件数字建模、3D扫 描建模、多图建模。数字建模是最常见的建模方式，常见的工具有Maya、3DS Max等。通过对一些基本的几何元素（如球体、立方体等）进行平移、旋转、缩 放等操作，辅助纹理贴图和模型表面的材质信息来构建复杂的三维模型和场景， 主要用于影视、游戏等领域虚拟角色和虚拟场景的创作上。常见的扫描工具有深 度相机、激光扫描、结构光设备等，利用3D扫描建模能够快速的将现实世界的 物体空间和颜色信息采集成能被计算机直接处理的数字信号。多图建模是通过多 组高清相机拍摄物体的多角度图片，推算出多张图片中同一顶点的位置，从而生 成点云模型。常用的多图建模软件有Reality Capture、Autodesk 123d等。
常用的三维模型有两种描述方式，一种是需要明确指定拓扑结构的三角形网 格描述，另一种是基于点信息的描述，如图2-1所示。基于三角面的网格模型是 目前应用范围最广的一种三维模型，尤其是在纹理映射、光照计算等技术应用下， 网格模型能够高质量的模拟现实世界的物体，并具有高复用的特点。Levoy首次 提出基于点描述表示和渲染的点云模型。这种基于点的描述方式特别适合现实物

图2-1网格模型和点云模型〔27]
体的三维重建工作，并且不需要记录顶点间的几何连接和拓扑结构关系，节省了 储存连接关系的信息，便于对模型进行表示、处理和渲染［9〕。
2.1.1网格模型
三维网格模型由多边形网格组成，最常用的是三角形，本文所指的网格模型 都是基于三角面的。一个三角形网格模型一般由三部分数据组成，1）几何数据, 是顶点的空间位置坐标信息。2）拓扑数据，记录顶点集合中每个顶点的连接关系, 组成三角面，以及所有三角面的连接关系。3）属性数据，一般的网格模型还会包 括纹理集合，记录顶点通过纹理映射到贴图的位置坐标。除了模型的三维信息（也 就是网格模型，纹理信息），还需要光照材质信息，光照材质信息包括粗糙度， 光泽度，菲涅尔发射系数等。这些信息共同构成了三维网格模型。
随着三维模型采集技术和计算机软件硬件的快速发展，制作三维模型的方式 变得更加便捷，而存储和处理的网格模型数据量也越来越大。例如，由Stanford 大学完成的“数字米开朗基罗工程其中数据量最大的David模型，该三维模 型中含有二十亿个三角面，数据量所占的存储空间达到32Gbyte,如图1所示。 由于三维网格模型能够高保真的还原现实世界的物体，基于三维网格模型的三维 场景可以使用户更好地得到沉浸式的体验，应用的场合也越来越多。但是精细的 三维模型意味着庞大的数据量，而三维场景中又包含了大量的高精度模型，这对 计算机的存储空间、处理器的计算能力以及网络带宽也提出了更高的要求。

图2-2 David模型⑷

网格模型分为单分辨率压缩和多分辨率压缩两种压缩方式，其中采用单分辨 率压缩的模型需要客户端完整的下载模型数据才能绘制，而多分辨率压缩的模型 在完成最低分辨率模型下载时即可绘制模型，如下图所示，这种多分辨率的模型 压缩方法给三维场景的渐进式传输提供了可能。

图2-3网格模型多分辨率压缩

2.1.2点云模型
点云是在同一空间参考系下表达目标空间分布和目标表面特性的海量点的 集合，在获取真实物体表面每个采样点的空间坐标后，得到的是点的集合，称之 为“点云”(Point Cloud)〔11】。制作点云模型可以通过3D扫描建模和多图建模两 种方式，但两者建模得到的点云模型包含的数据信息有所区别。通述3D扫描设 备(例如激光扫描仪)建模得到的点云，包含的数据信息有三维坐标和激光反射 强度，强度信息与物体表面的材质、粗糙程度、入射角方向、探测设备的发射能 量、激光波长相关，但是强度信息只能反映在该探测角度下光线的反射强度，并 不能反推出物体表面真实的材质信息和粗糙程度，当光照角度发生变化时，该强 度信息也将失去参考价值。另一种则是通过多图建模得到点云模型，包含的数据 信息有三维坐标和颜色信息。将两种方式结合才会得到具有完整属性信息的点云 模型。另外，通过测量得到的点云模型将包含大量的噪声，需要对噪声处理后才 会得到可以使用的点云模型。
点云模型同样可以采用渐进式的简化算法，通过在编码过程中将产生一系列 不同水平的细节层次(Level of Detail, LOD),来适应实时传输带宽的限制和客户 端处理器的能力。常用的简化算法可以分成两类：误差驱动和点数驱动。误差驱 动算法在降低原始模型的点数时，要求每个点的误差不超过给定值QI。点数驱动 算法则要求简化后模型的点数不超过给定值，并最大化保持简化模型质量［⑶。
2. 1.3三维流
三维流(3DStreaming)指的是通过网络实时和连续地传输三维内容。类似于 音视频流媒体，使用三维场景流能够大幅度缩短启动延时，减少用户的等待时间。 用户无需等待整个下载过程的完成，可以在仅接收部分数据时立即渲染三维场景。 但是，在三维场景流和音视频媒体流之间也存在差异。例如，音视频流根据时间 序列发送数据内容，因此媒体内容的传输顺序是固定的。另一方面，三维场景流 会根据用户的视角和位置信息的改变，从而产生不同的传输序列。
9
目前三维流可被分成四种类型：对象流，场景流，可视化流和图像流〔23】。其 中可视化流和图像流都将传输介质变成了视频流，例如云游戏，即在云端完成客 户端应用内容的渲染，将视频传输到客户端。这种方案虽然避免了在客户端上存 储大量数据以及客户端本身的性能限制，但很难保证高实时性应用的稳定性和流 畅性。一般来说，动态场景让画面看起来流畅，画面的刷新率至少要保证60fps, 也就是16ms完成一次刷新。即使在5G网络，也很难完成这么细颗粒度的时间 内完成信号传输、视频压缩、解码、渲染等一系列工作，所以本文不考虑这两种 三维流。
场景流的基本单位是对象流，每个三维场景都是由多个模型对象构成，场景 流是本文的研究重点。在对象流中先进行预编码操作，三维模型会被分为一个基 础层及一系列的增强层。客户端下载了基础层之后，就可以渲染模型，并随着增 强层的不断下载逐步提高模型质量。场景流是对象流的集合，三维场景的传输是 不断增强多个对象流的过程。在三维虚拟场景中，用户受到视野范围、物体遮挡 等限制，在空间的任一位置上都只能看到场景的一部分，因此只需要传输当前视 点下的可见对象集合，经过渲染管线在本地绘制虚拟场景后，用户就可以进行漫 游。随着用户位置和姿态的改变，会改变视点内场可视内容，再根据场景模型数 据的变化逐步下载和绘制新的三维虚拟场景。
2.1.4小结
目前，在三维场景中使用的模型有两类，分别是网格模型和点云模型。网格 模型以及点云模型都可以用来完成三维场景渐进式加载过程，而且二者之间也可 以实现互相转化。因为三维重建相关领域的兴起，使得点云模型有了一定的应用 舞台。但是就应用层面，由于三维网格模型的模型复用率很高，极大的减少了开 发、传输、存储等成本，当前市场上绝大部分3D类应用都使用网格模型。相较 于点云模型，网格模型另一个主要优势是可以真实的还原物体信息，实现高保真 建模。因为点云模型的辅助信息都存储在顶点中，对于没有面结构的点云模型来 说，难以还原现实世界物体的光照材质信息，包括反射面的粗糙度、光泽度、菲 涅尔发射系数等。因此本文的研究重点放在三维网格模型上。
2.2三维场景渐进式传输技术
三维网格模型数据量的激增，已经限制了图形处理效率、实时漫游等技术的
发展。要从根本上解决这些问题，必须降低三维模型的数据量，而模型的数据量
10 又是三维虚拟场景视觉质量的保障。仅仅依靠提高计算机的处理速度和能力和单 纯增加网络带宽等硬件方面的措施是远远不够的。为了能够让用户实时浏览虚拟 场景，许多研究将渐进式传输作为虚拟场景的传输方案。三维场景的渐进式传输 主要体现在三个方面：(1)可视内容的确定。根据用户视野范围的限制性，只 需逐步获取在用户视野范围内的内容，对于视野范围外的场景则无需立即下载。
(2)场景中三维模型的渐进式传输。通过三维模型多分辨率建模技术，再根据 三维模型与视点的距离、模型自身的尺度等因素，在不降低漫游视觉效果的同时， 按需下载具有不同分辨率的模型数据，从而减少场景下载的网络延时。(3)场 景中纹理图片的渐进式传输。在传输时，依据网格模型当前的分辨率层次选择最 佳采样率的纹理图片，完成网格模型和纹理图片的联合优化。
渐进式传输通过实时传输场景中的有效数据，减少了用户每次下载请求的数 据总量，也大大降低应用对客户端存储空间的需求。相较于一次性下载完整质量 对象的策略，渐进式传输策略更易于用户实时的完成和三维场景的浏览和交互， 灵活性和传输效率得到了很大的提高。	;
2.2.1网格模型渐进式压缩
Hoppe首次提出了将网格模型简化成渐进式网格的方法【6][⑸，即 PM(Progressive Meshes)算法。通过边折叠(Edge-Collapse )和点分裂(Vertex-Split) 这两个基本操作，实现模型简化和恢复，边折叠和点分裂的过程如图2-2所示。 基于Hoppe的成果,Taubin等人提出了渐进森林分裂表示算法(Progressive Forest Split,PFS)【⑹，森林分裂操作是对点分裂的优化，会获得更大的压缩比，更适合 对网格模型进行压缩编码。为了在渐进式压缩中更进一步的压缩几何数据， Pajarola和Rossigna提出了一种改进的PM算法，称为压缩的渐进式网格 (Compressed Progressive Meshes, CPM)呵。该算法扩展了边折叠操作，提出了 通过半边折叠的方式，这种方法是将边折叠至该边的一个顶点而不是重新生成一 个新点。
本小节选取经典的PM算法做详细介绍。PM算法在渐进式压缩中使用的操 作被称为边折叠，即通过折叠一条边，用一个新的顶点来代替，并用这个新的顶 点继承原来这条边的拓扑结构，渐进式传输的增强信息就是折叠的这两个点的空 间坐标信息和拓扑结构信息。在一次的边折叠的过程中，减少了 1个顶点，2个 面以及3条边，从而实现了模型的简化。边折叠的过程如图2-2所示。在图中可 以看到在本次边折叠过程中，折叠了由顶点班和顶点Vs组成的边，将顶点*和顶 点Vs合并为Vs。同时，由于边结构的消失，原拓扑结构也发生了改变，顶点V]和 顶点Vr与新的顶点Vs连接，三角面(V],Vt，Vs)和在这个过程中被简化。
11

PM算法通过点分裂操作完成了网格模型从基础网格到原始网格的恢复，是边折 叠的逆过程。该过程将一个顶点分裂为两个点，形成了新的边结构，并对分裂后 的边的拓扑结构进行恢复，该过程如图2-2所示。在点分裂的过程中，通过渐边 折叠的过程存储的空间坐标信息和拓扑结构信息，由顶点Vs分裂为顶点％和顶点 Vs，并恢复出了这两个顶点的拓扑结构，从而准确的对模型进行了恢复。

图2-4通过点分裂操作进行三维网格模型的恢复
2.2.2三维场景渐进式传输
三维场景渐进式传输过程通常被分为两个过程，传输内容的确定和传输过程。 相较于视频流媒体通过时间序列确定传输内容，三维场景则需依据当前用户视点 确定所需传输的对象。当前主流确定传输内容的方案是使用兴趣管理技术，通过 表示场景中需要被关注的兴趣区域AOI,确定基于视点的传输内容并通过数据传 输完成场景更新。兴趣区域一般为圆形或者扇形区域，存储着在三维场景内沿Y 轴投影落在AOI内的对象。用户在客户端通过改变自身的位置和姿态漫游场景， 对应用户视点会发生旋转和平移操作。当视点进行旋转操作时，AOI内的对象一 般不需要重新获取。发生平移操作时，只需传输新加入AOI的模型。这不仅降 低了用户在实时浏览时对带宽和存储空间的要求，而且大大减少了图形处理器实 时计算的数据量。相较于兴趣区域外的模型，兴趣区域内的模型拥有更高的传输 优先级，而兴趣区域内的模型由于其相对视点的位置和相对视线中心的偏转角度, 传输优先级也会有所差异。
当前AOI的基本类型主要有三种，如图2-3所示。(1)圆形区域。通过计 算用户与虚拟环境中的每个三维模型之间的欧式距离与可视距离的关系来确定 该模型是否在用户的兴趣区域内，由此构成了一个圆形的兴趣区域，如图2-3(1) 所示。以用户在三维场景中的坐标位置作为兴趣区域的原点，以用户的可视距离 作为兴趣区域的半径。用户不会接受距离大于可视半径的模型信息，灰色区域为
12
用户的相关区域，白色区域为非相关区域。(2)扇形区域。扇形区域主要考虑 了用户在客户端中存在的FOV限制。由于客户端渲染管线的相机内参中FOV — 般为60°到90° ,扇形区域一般采用120°到180°的设计。如图2-3	(2)所
示，当三维模型与用户之间的欧式距离小于可视距离并且偏离用户视线中心的角 度小于扇形角度的一半时，认为该三维模型为相关模型。相比于圆形区域，扇形 区域明显地减小了兴趣区域的范围和相关模型的数量。但是用户视点在大范围旋 转时(偏转角度大于扇形区域角度)，由于客户端内容的缺失，会岀现视觉断层 现象，从而影响用户体验。(3)组合区域。组合区域是通过多个兴趣区域的叠 加，尽量减小相关区域的面积。在文献［18］中提出了一种将圆形区域和扇形区域 结合的兴趣区域管理算法A3,弥补了扇形区域的缺点，如图2-3 (3)所示。该算 法结合了前两种算法的优点，以用户视点位置为圆心定义了一个圆形的临近区域, 在此基础上叠加扇形区域。圆形兴趣区域距离用户更近，比扇形区域有着更高的 相关度。通过这种方法，在减少兴趣区域面积的同时，还保证了用户视点在大范 围旋转时，不会出现视觉内容断层的情况。在文献［19］中提出了一种新的兴趣区 域组合方式，由两个扇形区域。相较于A3算法，更进一步减少了兴趣区域的面 积。
文献［18-21］都详细介绍了兴趣区域管理方案，并都在一定程度上定义如何确 定对象在兴趣区域内的重要程度。在兴趣区域中，根据对象位置与用户视点距离 的远近来确定相关度，与用户距离越远，相关度越小。另一方面根据对象位置与 视点中心的偏转角度大小来确定相关度。与用户视点中心的偏转角度越大，相关 性越小。

图2-5圆形兴趣区域、扇形兴趣区域、A?兴趣区域和组合兴趣区域

2.2.3纹理图片压缩
网格模型的属性信息在三维场景的传输占据了很高的比重。在文献［22］进行 的相关研究表明大型MMORPG游戏，Second Life中，纹理图片贡献了网络传输 数据量的61%-88%。这一结果非常符合开发者的习惯，因为开发者会大量复用
13 网格模型素材，通过替换纹理图片实现场景的构建以及内容的更新。因此，对纹 理压缩方法的探讨是非常有必要的。
Beers等人在论文中列举了四项纹理压缩与普通图像压缩算法的区别。1) 解压速度。为了不影响处理器实时渲染的性能,纹理图像的渲染需要满足实时性， 最好能够不解压直接渲染。2)图像质量和压缩率。由于纹理图片映射的网格模 型并不一定都是高精度或者不需要使用高精度纹理图片，纹理图片的质量可以稍 微降低来换取更高的压缩比，节省更多的带宽资源，提升系统的传输效率。3) 编码速度。纹理图片一般都是通过压缩存放在服务器端，跟传输是两个阶段，因 此纹理图片的压缩编码效率并不影响系统效率，降低编码速度而提升其他几个因 素的性能是个不错的选择。4)随机访问。这是纹理图片与普通图片之间最大的 差异。由于纹理图片映射到网格模型这个过程，导致纹理图片中像素被访问的顺 序是不可控的，因此要求纹理图片中的像素都能够被随机访问。正是这个原因， 常用的纹理压缩标准都采用了基于块的框架，方便像素的读取和解压。ARM公 司设计的自适应可伸缩纹理纹理压缩方法(Adaptive Scalable Texture Compression, ASTC)〔24］成为OpenGL的正式扩展标准，与DXTC(DirectX纹理压缩)和ETC (爱 立信纹理压缩)一起成为目前主流的纹理压缩标准，均采用了基于块的框架，支 持在图形处理器渲染时随机访问纹理图像。因此在设计纹理图片压缩算法时，设 计方案必须符合上述三种纹理压缩标准。目前主流的纹理压缩方法都是借鉴Delp and Mitchell等人〔幻提出的块剪裁编码(Block Truncation Coding, BTC)。最流行的 方法是Iourcha等人a】提出的S3TC纹理压缩方法，S3TC被使用在微软的多媒 体组件开发接口 DirectX中，因此也被称为DXTC,同时在OpenGL中也有使用， 它被默认为纹理图像压缩事实上的标准［27】。
在生成一系列LODs网格模型的渐进式传输系统中，纹理图片同样可以通过 简化来匹配不同层次的网格模型。其中，最直接的方式是根据网格模型的简化率， 将纹理图片均匀地降采样到与之匹配的简化率，系统只需要知道所需的像素预算 即可。但是纹理图像的细节特征分布往往是不平均的，即细节特征被定义在几个 小区域中，而平滑的特征或者没有特征往往分布在大区域中。这促使研究人员通 过变形纹理图片的不同区域来优化纹理空间，使得具有更多特征细节和更高失真 的区域能分配在更多的纹理空间，这个优化过程也被称为纹理变形，或者纹理曲 翘。Sloan等人SI提出的算法考虑用户指定的权重和图像本身的失真情况，对纹 理图像进行多级形变处理。Hunter和CoherB】从纹理图像中的频率分布出发，图 像经过傅里叶变化，通过分段线性形变平衡图像频谱。因此，在纹理图片简化时 应充分考虑纹理图片中不同块的细节特征，并对不同细节特征的块采用不同的降 采样系数。
14
2.3三维场景渐进式传输方案
在本章的前文中介绍了三维场景渐进式传输方案涉及的技术内容，通过网格 模型渐进式压缩得到多分辨率模型，是三维场景流的基础。通过兴趣区域的管理 确定渐进式传输所需的内容。同时，由于纹理图片占据了三维场景传输中大部分 的带宽资源，需要协同多分辨率网格模型做对应的简化处理。兴趣区域的管理机 制一方面明确了所需传输对象的集合，另一方面要求依据模型的视觉重要程度对 集合的对象进行优先级排序。常用GarlandPO］提出的二次误差度量(QEM, Quadric Error Metrics)算法计算模型的失真情况。可以将三维场景渐进式传输问题简化 成传输队列确定以及传输优先级两个子问题。传输队列确定是指需要传输的场景 信息，包括模型信息、音频、光照等。由于模型是三维场景的基本构成单位，也 占据了最大比重的数据信息，本文将场景信息简化为模型信息。常用的传输队列 内容确定方式就是划分兴趣区域，只传输兴趣区域内的模型。由于三维模型固有 的空间特征，兴趣区域内不同位置以及处于用户不同视点下的模型为朋户提供的 视觉内容也不尽相同，因此传输优先级问题就是将兴趣区域内所需要传输的模型, 按照视觉贡献程度划分为不同的优先级。同时，由于渐进式场景中模型都是通过 渐进式编码，还需要确定传输过程中每个模型不同的细节程度。最后，根据网格 模型的简化，纹理图片同样需要进行多分辨压缩，匹配对应的网格模型。本文在 第三章中将从渲染管线出发，详细介绍兴趣区域的管理机制、模型优先级的计算 方式等内容。
当前三维场景渐进式传输常用的网络框架有P2P网络框架【9］卩1］和客户端/服 务器(C/S, Client/Server)框架。相对复杂的P2P网络能够扩大用户获取所需数 据的来源，而C/S框架胜在结构和实现更加简便快捷。为了简化实验环境的搭建 过程，本文在第四章中采用了 C/S框架。
15




























































16


第三章基于渲染管线的三维场景渐进式传输优化
本章主要内容是从渲染管线出发，基于渲染管线中物体消除、背面剔除、 Mipmap等技术特点，提出了网格模型重要程度的计算方式。这一算法主要用于 结合用户的视点特征，基于人类的视觉感知和网格显著性信息来评价三维场景中 模型的重要程度，使得兴趣区域管理机制中模型的质量评价指标更符合视觉机制; 网格模型和纹理图片的联合优化中通过分析纹理图片在不同块区域的特征差异， 将纹理图片的简化与网格模型特征结合；更新策略则是在前两个模块的基础上进 一步规定如何确定不同网格模型和纹理图片的不同增强层之间的传输优先级。
3.1渲染管线
由于三维虚拟场景的复杂程度很高，直接面向三维虚拟场景的处理较为困难。 为了能够更加简单有效地处理三维虚拟场景渐进式传输中相关场景的拾取的问 题，提出了预处理器算法。预处理器主要包含“场景描述”、“三维模型渐进式压 缩”和“兴趣区域算法”三个部分。通过预处理器中的场景描述和兴趣区域算法， 可以非常快速高效的完成相关场景的拾取。并且在该模块中完成了三维虚拟场景 内三维模型的渐进式编码。该部分在用户和场景交互之前完成，不会占用用户浏 览场景的时间开销。
渲染管线是图形处理器将三维场景转换成2D图像，并最终在显示器上显示 的过程，可以总结为应用阶段、几何阶段和光栅阶段。本文的重点不在对顶点着 色器和片元着色器的编程过程，而是希望通过渲染管线理解渲染过程，因此本文 不考虑光照计算、着色处理和纹理映射等流程，只考虑几何变换的情况， 3D渲染管线中的坐标变换的流程如下：
局部坐标系也称模型空间坐标系，渲染管线中的第一步是进行局部坐标到世 界坐标的变换。世界坐标系是虚拟空间的参考系，可以假定物体默认在世界坐标 原点，3D模型上的点相对于模型锚点的位置即是世界坐标系下的(Xw, yw, zw)o 当拿到3D模型在世界坐标系下的坐标后，会有两步可选操作，分别是物体消除 和背面消除。在可选的物体消除跟背面消除后，进行了世界坐标到相机坐标的变 换、透视变换、空间剪裁、屏幕投影这几个主要过程。简单的可以理解为物体坐 标在三个坐标系间的转换。世界坐标系是虚拟空间的参考系，可以假定物体默认 在世界坐标原点，3D模型上的点相对于模型锚点的位置即是世界坐标系下的 (Xw, yw, Zw)。相机坐标系是从虚拟相机中看到的参考系，相机坐标系(Xc, Yc, Zc)
17

中，原点为相机透镜的中心，坐标轴Xc轴与X轴平行，Yc轴与Y轴平行，Zc轴与相 机光轴重合，一般来说为了方便计算，常将相机放置在世界坐标系的原点或者Z 轴上。图像坐标系是在成像平面内，以二维图像为基准所建立的坐标系。一般可 以理解为（U,v）,原点为图像左上角点，坐标轴为U轴和V轴，表示物体所在的行 数和列数。屏幕投影就是模型的三维坐标到平面二维坐标的转换过程。




3.1.1物体消除
如图3-1所示，在可选操作中首先执行的是物体消除，可以使用包围球或者 包围盒测试是否消除物体，如图3-2所示。为每个对象创建一个球体将其包围, 并判断球体是否位于视锥体内。可以通过计算离物体中心最远的顶点与物体中心 的距离，得到包围球的半径。


视锥体在渲染渲染管线中扮演重要的作用，相机坐标系就是指物体在视锥体 中的坐标，起到承接世界坐标系和屏幕坐标系的作用。由视点相机、近平面、远 平面构成，视线被近平面和远平面剪裁成一个“梯体”，被称为视锥体。
远剪裁平面

图3-3视椎体

在得到包围球半径后，就可以通过平行土X轴，土Y轴，土Z轴的球心连线定 义6个顶点来描述包围球。当y=0时，得到2D包围球的平面俯视图，如下图所 示：

x +y

图3-4视椎体中Y=0平面
其中，Pi是包围球的球心，坐标为（Xi，zj, P2是+Z轴方向的最远端点，坐标为 （Xi，zi + r）, P3是+z轴方向的最近端点，坐标为（Xi，Z]-r）, P4是+x轴方向的最 远端点，坐标为（Xi + r,z） P5是+x轴方向的最近端点，坐标为（X] - r,zj。至
19

此得到了 Y平面内包围球上所有关键点的坐标。物体消除遵循的原则是当关键 点都位于视锥体外时，认为包围球在视锥体外。Z轴方向物体消除的条件为：
(Z］十 r < far_Z)||(Zi — r< near_Z)	(3-1)
X轴方向则需要通过平面方程和P4, P5两个端点的位置来判断，其中视锥体 右平面可以表示为：
a
左平面可以表示为：
w/2
X —	Z
a
其中W为近平面的宽度，d为视点到近平面的距离。
X轴方向物体消除的条件为：
(x1-r>^z1)||(x1+r < -~Zr)
同理，将球心的坐标扩展为(xi,yi,zj), y轴方向物体消除的条件为：
O1 - r > 竽 zJIOi + r< 一竽 Z1)
在判断物体消除时，只要满足任意一轴的消除条件，即可判断包围球在视锥 体外，综上，给定物体包围球球心坐标(x1,y1,z1)>和相机参数(视平面宽度w, 视距d,近平面距离near_z和远平面距离far_z,物体被剔除的条件为：
(3-6)
物体消除的过程跟文献［18］［20］的兴趣区域中判断对象是否剔除的过程完全 相同，然而渲染管线中使用了大量相机的内参作为参数计算，而兴趣区域方案中 使用的均为人为设定的系统参数。比如，在渲染管线中使用近平面和远平面作为 剪裁平面，而文献［18］［20］中则会系统设定一个兴趣区域的半径，该参数如果跟 远平面不匹配，将会造成传输数据的浪费或者显示内容不完整。因此，基于上述 对渲染管线中物体消除计算方式的分析、与兴趣区域方案中物体消除方式对比， 本文提出了一种结合渲染管线物体消除的兴趣区域确定方式，具体实现见本章第 二节。
3.1.2背面消除
如图3-1所示，在物体消除后下一步进行的是背面消除。在3D场景的渲染 过程中，由于用户视角的限制，同一时间能看到的模型区域是有限的，可以分成 可见区域和不可见区域。不可见区域的渲染并不会增加用户获取的信息量，也就
20

没有绘制的必要。所以在渲染管线中增加了单独的一个流程来管理是否启用背面 消除。背面消除是指删除绘制模型背向视点(相对于相机视点)的三角面，减少 不必要的三角面进入渲染管线,提高图形处理器的运算效率【32】。常用的背面消除 算法⑴］是通过叉乘运算计算三角面的法向量,然后通过视线向量与三角面法向量 的点乘运算计算出该三角面的绕向，以此判定是否消除该三角面。如下图3-5所 示，其具体的工作流程为：
网格模型的所有三角面的三个顶点以统一的方式进行标记，例如顺时针，可 以得到以(vo, Vi，v2)表示的三角面。
根据三角面的两个方向向量％1，%2的叉乘运算，计算出三角面的面法线 (surface nomial)：
ns = v01 x v02	(3-7)
计算观察向量E也就是从相机出发的视点向量。假设相机坐标为Pc，观察向 量可以表示为：
v = pc - v0	(3-8)
计算面法线和观察向量的点乘运算得到res：
res = ns ■ v
若res>0,说明夹角小于90° ,该三角面为可视平面；若res <0,说明夹
角大于90。，则标记多边形为背面。在渲染管线后面的流程中，将会剔除有背面

从渲染管线背面消除这个过程可以发现，3D模型在虚拟场景中包含了大量
的信息冗余，背面消除的三角面并不会提升用户的视觉质量，还会占用图形处理
器的计算资源，这为三维模型渐进式传输提出优化方案提供了可能。在三维场景
21
中用户看到的视觉内容与观看视点密切关联的，视点的不同会影响图形处理器的 绘制内容。经常使用相机坐标来代表用户的视点，相机在空间中的坐标位置以及 观看方向的不同导致了模型在屏幕上尺度和姿态的不同。研究者们也看到了视点 对三维内容的影响，将重点放到了如何度量以及快速选择三维模型的最佳视点和 最不利视点［珂［辺。然而，在三维场景中用户往往不会在特定的位置浏览，而是 能够自由移动，这时只是判断最佳视点和最不利视点就远远不够了。结合渲染管 线背面消除的特点，本文在本章第四节中详细介绍了如何能够在渐进式传输的三 维场景中计算不同视点间重要程度的差异，本文从多个角度对模型进行观测，依 据网格模型在不同视点下显著性的差异，作为评价网格模型重要程度的指标。
3.1.3 Mipmap 技术
Williams卩5最早提出了 Mipmap的概念，这一技术目前已广泛应用于三维场 景应用中。Mipmap技术通过降采样将纹理图片预加载成不同的版本，表示纹理 的不同LODs,它们通常被存储在一系列不断缩小的纹理对象中，其中每一级别 的分辨率都是上一级别的四分之一，这些纹理集合称为Mipmap链，如图3-6所 示。Mipmap技术的应用场景当视点与模型之间的距离改变时，随着模型离视点 越来越远，模型本身与它的纹理在屏幕上的分辨率不断缩小，这意味着使用高精 度的纹理会有大量的信息冗余，占用图形处理器的资源。客户端可以使用Mipmap 技术，实现随着模型和视点之间距离的变化而在Mipmap链中切换不同的纹理图 片，提高了系统的缓存效率。缺陷是完整的Mipmap链将额外占据33%的存储空 间，但相较于绘制速度的提升，往往会忽略存储成本，是一种以空间成本换取时 间成本的方法。同时，Mipmap可以在离线和运行两种状态创建，这取决于离线 创建的存储成本和运行创建增加的计算资源消耗的平衡，一般情况下，都采用离 线的创建方式。参考Mipmap技术的实现过程，纹理图片在渐进式压缩和传输将 依据绘制的模型所占屏幕分辨率的大小而选择与之匹配的分辨率。

图 3-6 Mipmap 链
22

3.1.4 AR应用中的姿态求解
AR应用的渲染流程与VR、3D游戏等三维场景应用相同，但是显示过程有 所差异，因为AR应用需要通过对模型的姿态求解来确定与现实世界的联系，才 能准确定位在现实世界的空间。因此，针对AR类应用，需要额外关注三维模型 的姿态求解的过程，并依据定位结果计算模型的重要程度。
在了解姿态求解过程前，需要了解相机的成像过程，前文已经介绍了具体的 坐标转换过程。现在将三个坐标系中坐标的变换过程抽象成一个公式，它的输入 是模型在空间中的顶点位置(xw,yw,zw),输出是二维图片上的位置信息(u,v),中 间需要两次投影变换，姿态矩阵变换和投影矩阵变换。模型上所有的顶点都会经 历这样一个从三维的世界坐标系投影到二维平面的投影变换过程。

其中，R为旋转矩阵，T为位移矩阵，f、uo、Vo分别代表相机焦距和主轴偏移, 虫、dy为相机视角宽髙。整个姿态求解的过程就是寻找3D模型从世界坐标系的 原点如何移动到一个特定的位置，使得模型在相机坐标系中符合需求。移动的过 程可以使用一个姿态矩阵表示，可以分为位移矩阵和旋转矩阵。位移矩阵T是相 对X轴、Y轴、Z轴的位移距离，旋转矩阵R是相对X轴、Y轴、Z轴的旋转 角度。
rll r12	r13
R T] = W r22 r23
0T 1」r31 r32 r33
姿态求解也被称为PNP(Perspective-N-Point)问题，通过现实空间中的N个特 征关键点与图像成像中的N个成像点计算出其投影映射关系，从而解决相机或 物体位姿的问题。当选择三组图像中可见的关键点(2D/3D),结合公式3-2和 3-3组成了三组投影矩阵方程，每个矩阵方程可以拆解成两个方程组，最后就得 到六个方程组。而姿态的关键变量就是平移矩阵的三个变量和旋转矩阵的三个变 量，通过六个方程组就可以求解出这六个变量。由于图像识别以及固定模型之间 存在的误差，所以常需要大于三组的关键点进行拟合运算，求出误差最小的解。 如果计算的模型是非刚体模型，计算过程会变得更加复杂，比如人脸，需要考虑 56+组的FACS系数，为了简化计算过程，本文中所指的3D模型都是刚体模型。
23
3.2网格重要程度
渐进式传输三维场景包含了模型简化编码、传输保护、场景重建和兴趣区域 管理等众多相关内容。E1 - SanaJ等人⑶】提出了基于观察视点的网格模型简化算 法，LiuY等人㈤］提出了基于UEP-LTCode的非对等差错保护算法对不同重要程 度的网格模型进行传输保护，Liu E S等人卩9】在场景重建中兴趣区域的划分和模 型传输顺序的确定等中对比和分析了几种兴趣区域管理的算法，其中计算模型视 觉重要程度的算法也是简单的通过计算视点距离的反比例函数来确定，以上问题 都避免不了对场景中模型传输优先级的计算。一般来说，模型传输优先级的确定 方式是根据场景中模型重要程度来计算的，这里的重要程度评价可以有很多维度。
在大多数基于兴趣区域的模型渐进式传输的文章中都提出了模型重要程度 计算的相关算法。在文献［20］中在圆形的AOI计算模型在场景中的重要性时，使 用了视点到模型的距离以及相对视线中心偏转角这两个维度来计算FOV内模型 的视觉重要程度，类似的，在文献［21］中将AOI划分成宽度相同的环，把FOV 内的环划分成扇区，处于不同扇区的模型的重要程度的权重不同。在文献［13］中 提出了一个新颖的AOI的划分方法A3,将用户的兴趣区域划分成一个半圆的 FOV和一个近距离圆。除此以外，还有其他的学者从视觉方面来衡量模型的重 要程度。Teler等人在文献［40］中使用网格分辨率和屏幕分辨率比值来确定模型的 视觉质量。
Leea］等人提出了一种基于高斯权重的中心-周围机制的图形网格划分方法， Feixas等人［旳提出了一种基于多边形互信息提出了一种新的显著图计算方法， 并针对视点选择和三维网格显著图建立了统一的信息论分析框架。Kim等人IM 等人提出了基于视觉显着性中心-周围机制启发的新型可视化增强运算符的方法。
本节在分析总结当前三维场景渐进式传输策略的基础上，基于模型内容视觉 感知提出了一种渐进式传输三维场景的解决方案。该方案主要贡献包括：提出了 一种基于视觉感知的计算模型重要程度的算法，包括屏幕分辨率的视觉感知和模 型多姿态的视觉感知；提出了基于中心-周围机制的视点显著性计算方式，通过 该算法可以更加准确地评价场景中模型的视觉质量。最后基于上述算法提出了一 种网格模型重要评价方式，依据场景内模型的重要程度对三维场景实时更新。
3.2.1基于视觉感知的模型重要程度计算
目前绝大多数应用中使用的三维模型都是基于三角形网格表示的，其表示精 度取决于三角面和顶点的数目。类似于纹理贴图的MipMap技术［殉，Y.Pan和 I. Cheng等人的视觉感知实验表明【42】［43］,由于人类视觉系统(Human Visual System, HVS)视觉分辨率的限制，当其顶点数超过一定的数目后，这些多余
24

的三角形顶点所表示的模型的几何信息对于HVS是不可感知的。
当观察不同简化率下的网格模型在不同视距时，其对应的关系结果如图3-7 所示，表示在不同视点距离处简化的3D对象的视觉退化情况，其中§是模型的 边界框的对角线长度。
三维网格模型简化引起的视觉质量的下降是视距、简化率的函数。设VI丘 [0,1)表示三维网格的视觉重要程度，则可用式(3-12)来表示：
VI=f(D,R)	(3-12)
D e [0,+8)表示视点与观测三维模型包围盒中心之间的距离，R G [0,1] 表示三维网格简化模型的简化率。VI - 1表示模型的视觉质量不断的增加，当 VI=1时，此模型达到最佳的视觉质量，可以认为不在需要对这个模型继续进行 更新。
可以用下面的公式来计算LOD模型的视觉质量：

其中，area表示在屏幕上模型边缘盒的像素面积。F代表未简化的模型的三角面 的个数。f代表LOD模型的三角面的个数。通过模型的简化率可以计算f：
f = R*F
精度由完整模型中的平均面部大小与LOD中的平均面部大小之闻的比率确 定，其中F和f是这些的估计值。忽略一个像素以下的面的大小，而是将其视为 一个像素，因为这种高精度将不再提升视觉质量，如图3-7所示，随着对象在屏 幕上变小，整个模型的面的精确度在减小，当LOD的面部区域的精确度低于1 像素时，该模型就会被认为具有完整的质量。
相机的投影过程分为透视投影和正交投影。透视投影常用于模拟人类的视觉 系统，在3D渲染中被普遍使用。透视投影的效果非常依赖相机内参，包括相机 的焦距、成像平面的宽高比、相机中心轴向偏移等。
25



1	3	5	7	9
视距⑻
图3-7不同简化率下的网格模型在不同视距下的关系
为了将三维模型在2D屏幕上显示，需要经历世界坐标系、相机坐标系、投 影坐标系到屏幕坐标系的一系列变化，这里仅为了计算投影后模型在屏幕上的像 素数，将问题简化成从相机坐标系到投影坐标系以及从投影坐标系到屏幕坐标系 这两个过程。OpenGL以及D3D等3D APIs都提供了函数为用户提供快捷的透 视矩阵生成方法，可以实现从相机坐标系到投影坐标系这一过程。本文以OpenGL 中的方法gluPerspective(fov, aspect, near, far)为例，该方法中有四个参数，其中fov 为视场角，是视锥体在yz平面的开角角度，aspect为投影平面的宽高比，near是 视点到近裁剪平面的距离，far是视点到远裁剪平面的距离。area的计算公式如 (3-15):
26


其中Pscr代表显示屏幕的像素数，area°bj表示对象在近裁剪平面上的面积, areanear表示近裁剪平面的面积。areaobj可以计算为：
(3-16)
areanear可以计算为：
areanear = aspect * (2 tan |£>near)2
假设在相机坐标系中，对象边缘盒顶点坐标分别为(Xi, y13 Dobj), (x1; y2, D°bj),(X2, y13 Dobj), (x2, y2, D°bj),那么在相机坐标系中对象的面积为：
areacamera = |(衍 一 x2) (y1-y2 )1	(3-18)
根据视点与观测三维模型包围盒中心之间的距离D、模型简化率R以及相 机参数和显示设备分辨率等相关参数，能够计算出该LOD模型的视觉感知质量。 3.2.2基于中心-周围机制的网格显著性计算 '
在三维网格模型的视觉感知处理上，视觉注意机制是最广泛使用的一种视觉 感知特征，包括自下而上的视觉注意机制和自上而下的视觉注意机制这两个方面。 ITTi等人〔的提出了最有效的自下而上的显著性计算方法，本文依据他们的中心- 周围机制来提取特征，选择使用Lee等人〔34］的方法计算三维网格的显著性。
曲率是用来描述网格变化情况的一个维度，用C(v)来表示均值'曲率，该计 算方式选择文献［34］中的方法。假设N(v, o)为到顶点v的距离小于o的所有点 的集合，N(v, o)可以表示为公式3-19。o的取值为{2£,3E,4E,5E,6E}, £为模型边缘 盒对角线长度的0.3% ,本文这里o的取值为牡。
N(v, = /x|||x- v|| < o, x is a mesh point}	(3-19)
用G(C(v), o)表示均值曲率C(v)的平均高斯权重，可以通过下面的公式计 算：



中心-周围机制使用不同的尺度分别计算特征，通过中心区域以及周围区域 的差异判断显著值。上面的公式我们选择的距离为6假设截止尺度的距离为26 令S(v)表示在粗细两个尺度上顶点V的平均高斯权重的差值，认为S(v)即该 点的显著性值。
S(u) = |G(C(v),o-) - G(C(v),2(r)|
27
计算模型网格上每个顶点对应的网格的数值S(u),得到Armadillo模型基于 中心-周围机制的显著图如3-8所示。高亮(浅色)区域为高显著性区域，主要部 分为耳朵、手、脚等变化显著部位。深色区域为低显著性区域，主要部分为大腿、 后背等平滑部位，符合人类的视觉机制。

图3-8 Armadillo模型的网格显著性

3.2.3基于视点的网格显著性
在三维场景中模型的视觉内容是与用户的观看视点密切关联的。经常使用相 机坐标来代表用户的视点，相机在空间中的坐标位置以及观看方向的不同导致了 模型在屏幕上尺度和姿态的不同。
研究者将重点放到了如何度量以及快速选择三维模型的最佳视点和最不利 视点［29］卩0］。然而，在三维场景中，用户往往不会在特定的位置浏览，而是能够自 由移动，这时只是判断最佳视点和最不利视点就是远远不够的，为了能够在渐进 式传输的三维场景中计算不同视点间重要程度的差异，从多个角度对模型进行观 测，并计算当前视点下显著值的大小，并指定特定个数的视点作为基视点。其中 基视点集合v包括26个球坐标系的坐标，每个坐标由方位角和仰角构成，距离 为模型包围球的半径，这里省略了归一化后距离坐标。通过3-21中的方法计算 从集合v的角度观察模型得到的显著值，统计图片上可见顶点显著值S(v)的总 和，表格1为视点集合v包括的方位角、仰角以及计算的显著值。
28

表3-1观察视点坐标以及对应的显著值

Azimuth
Elevation
Saliency
Azimuth
Elevation
Salie ncy
1
45
0
1502
U
180
-45
781
2
45
45
674
15
225
0
^ggg
3
45
25
1111
16
225
45
336
4
45
90
344
17
225
-45
493
5
45
-90
911
18
270
0
643
6
90
0
852
19
270
45
869
7
90
45
882
20
270
-45
1294
8
90
-45
1392
21
315
0
1069
5
135
0
1797
22
315
45
721
10
135
45
376
23
315
-45
1107
11
135
-45
439
24
360
0
2105
12
ISO
0
341
25
360
45
1101
13
180
45
364
26
360
-45
1990
图3-9为表3-1中坐标对应的按顺序排布的显著图，通过表3-1中显著值的 大小，可以发现当前角度下可见像素的多少以及高显著性区域的大小决定着该视 点下显著值的多少，这一信息可以作为判断模型在三维场景中重要程度的一个主 要因素。在三维空间中，模型可以有不同的位置和姿态，当用户从空间中不同位 置观察同一个模型时，获得的信息量是不同的。为了将这个信息量量化以及跟模 型的LOD对应起来，本文将从表3-1的视点集合观察得到的这26个显著性的结 果进行归一化。从图3-10中可以发现，该模型在26个视点下观察得到的显著值 有明显的差异，符合预期。


图3-9多视点Armadillo模型的网格显著性
29
25GO


计算三维网格模型26个视点下显著性的平均值pis, Nv表示观察视点的个 数，勺表示第i个视点的显著值。
"=盘墨2	(3-22)
计算三维网格模型26个视点下显著值的标准差os:
处=(盘"216 —少尸)亍	(3-23)
利用式(3-24)描述的非线性映射将各个视点下的显著性si从[a, b]到si， 映射至单位区间[0, 1]，其中a和b分别为所有显著值中的最小值和最大值。
(s-a)
s' = X(瓷),s G [a, b]	(3-24)
1—e 2*es
图3-11展示了 Armadillo > Bunny > Dr agon > Angel这四个模型在所有观察视 点下的归一化后的显著值，并按照显著性降序排列的结果，y轴为归一化得到的 s'的值。从图中观察到显著值的排序结果为线性相关，为了简化显著值计算的这 一过程，通过对曲线拟合，得到式3-25,其中n为整数，代表显著值降序排序后 的顺序。
s' = 1 — 0.04n,n 6 [0,25]	(3-25)
30

&	W	15	2Q
x
图3-11网格显著性归一化结果

3.2.4网格重要程度
前文对本文涉及到的模型视觉重要程度计算方式进行了说明，本节将结合上 述的方法，为仿真场景应用做准备。为了能够确定不同视点下的模型显著性级别, 新增一个模型描述文件(MPD),有三个描述变量，分别是ID、Az和El。其中ID 为0到25,是根据视点集合观察模型得到的显著值的降序排列，Az和E1分别代 表对应的方位角和仰角。
通过用户在三维场景中的位置坐标(默认为相机坐标系)，需要计算出当前位 置与模型之间的方向向量与集合views中26个方向向量最接近的一个，从而计 算当前视角的视觉重要程度。因为集合views中是方位角和仰角坐标,通过式(14) 将这些坐标变换成笛卡尔坐标。
Xi = cos^elj) * cos (azi)	(3-26)
= cos(elQ * sin^azi)	(3-27)
Zi = sin(eZi)	(3-28)
集合views中的方向向量可以表示为$ = (Xj.ypZj),通过世界坐标系中的相 机坐标Pc以及模型坐标Pm，可以得到从相机位置看向模型位置的方向向量3：
C = Pm - Pc	(3-29)
假设方向向量3 = (xv,yv,zv),il过向量的点积公式，可以求出两个方向向量 的夹角cos 8严爺,筛选出集合views中所有方向话与3的最小夹角所对应的ID no
在3.2节中我们用VI表示网格的视觉重要程度，在3.3、3.4节中对基于集 合views的观察视点的显著性进行排序，场景中模型的重要程度MI可以表示为式
31
(3-30) o
M/(Q = (1 - 7/(0) * (s() + a)	(3-30)
VI表示当前LOD模型基于屏幕分辨率的视觉感知程度，s'为用户视角下归 一化到的网格显著性，为了网格显著性信息对视觉重要程度贡献的比重，a的取 值为｛0.05,0.25,0.5,0.&1｝。
在实际传渐进式传输的过程中，我们会先将模型文件进行多分辨率编码，生 成一个基础层和若干个增强层。计算当前视角下场景内所有模型的重要程度MI, 根据场景内所有模型MI的大小可以确定当前情形下的模型传输顺序，每次更新 当前场景中MI最大模型的一个增强层，完成后更新场景MI»
3.3网格模型和纹理图片的联合优化
Liang等人在文献［22］中经过研究表示大型MMORPG游戏Second Life中， 纹理图片贡献了网络传输数据量的61%-88%o这一结果非常符合开发者的习惯， 因为开发者会大量复用网格模型素材，通过替换纹理图片实现场景的搭建以及内 容的更新。面对庞大数据量的纹理图片，三维场景渐进式系统中对纹理图片的优 化是必不可少的。
本节提出了一个联合优化网格模型和纹理图片的算法，将两者之间的简化过 程联合进行，通过网格模型的简化信息指导纹理图片的简化。该算法的核心思想 是通过纹理图片本身的特性和简化的网格信息，在额定总采样像素数下，对纹理 图片的不同区域计算出该区域最优的降采样系数。基于前文研究的当前用于纹理 图片的压缩编码标准，本节设计的纹理图片渐进式压缩编码符合纹理压缩编码标 准。
本文通过纹理映射到三维模型表面后的采样点的比较衡量简化纹理与原纹 理之间的差异。假设两个有纹理映射的模型为S =< M,I >和5' =< M\T >,其中 M和M，分别是网格模型，I和I'分别是对应的纹理图片，那么两个模型之间的纹理 差异可以表不为：
d(S,S‘)=易“刘“川⑹)-『(P')ll	(3-31)
其中p和p'分别是网格上的顶点，1(?)表示模型顶点与纹理图片之间的映射关系， 这个函数没有具体的表达式，要从网格模型的属性信息中查表得到。
对上式继续优化，因为相同尺寸的图片区域映射到网格模型时，由于网格模 型在场景中位置的差异，显示时的屏幕屏变率有很大的差异，这一点与前文介绍 的Mipmap技术类似，参考Mipmap链的实现方式，在误差计算中引入权重W(), 该权重系数可以使用前文公式3-30计算的模型视觉重要程度表示，公式3-32改
32
进为:
d(S,S? =》w(p) X ||/(卩)一/'(矿)||	(3-32)
公式3-30就是简化模型M，与原始模型M的外观误差。
本节使用比率-失真度计算纹理图片不同块的最佳降采样率。假设有K个纹理 块，对第i(i = 1,2，…,K)个纹理块，计算降采样率为琉X咅时剩余像素数Gg和误 差口珥。目标是找到一组采样点以最小化总误差丫釘。®,并且满足iXiGg < Gtotalo可以通过最小化拉格朗日代价函数解决这个带约束的最小化问题：
厶U) = 丫角囚伽+祐伽]	(3-33)
通过对比取不同的值，以获得第i个纹理块的比特率-失真度(R-D)曲线。
3.4更新策略
三维场景中的网格模型和纹理图片经过渐进式压缩编码后，都会被存储成一 个基网格以及一系列的增强层数据,，通过上一节网格模型和纹理图并的映射关 系，将产生一系列一一对应的模型和纹理层次。我们将基础层的编号定义为0, 增强层的编号按照顺序依次递增。因此模型Mi和纹理心都可以通过一个基网格以 及多个增强的集合表示，该模型信息集合可以用£表示：
Si=<M』i>	(3-34)
Mi = {弘°0, RM”I，加：,2,…，加"}	(3-35)
k = {%0,R“,2, •••, R/i，n}	(3-36)
其中BM“O表示模型岡的基础网格，B“,o表示纹理人的最低分辨率，RM〃表示模型 的第丿•个增强层，R如表示网格厶的第丿个分辨率。
用户当前可视区域的三维模型信息集合S =他』2，…,SN}，每个模型都包含 了网格和纹理，所以可以使用一个基网格集合、一个网格增强层集合、一个基纹 理集合以及一个纹理增强层集合来表示：
S = {BM，B[,RM，RI}	(3-37)
其中B表示当前兴趣区域内所有三维模型的集合，其中BM和E分别代表模型的网 格信息和纹理信息。同样，R表示当前可兴趣区域内所有三维模型的增强层的集 合，RM和&分别是模型网格和纹理的增强层信息。
通过渐进式网格编码，网格数据和纹理数据之间存在很强的相关性，基网格 与增强层又存在的极强的依赖性。一旦某一部分数据在传输中丢失，将导致与其 相关的网格或纹理信息数据的无效，并且由于依赖关系，无法正确解码在错误接 受编号后面的所有信息。考虑到实时性要求，无法正常解码的数据将被丢弃，这 将浪费带宽资源。因此，为了在实时性和可靠性之间取得平衡，我们使用传输控
33
制协议TCP传输更重要的数据，而通过用户数据报协议UDP传输的次要数据则 可以最大程度地减少延迟。
通常，三维模型的基础网格和最低分辨率纹理图片的数据都很小（通常小于 原始质量的5%）,而增强层占据了大多数数据大小。但是，基础层是所有后续 细化层的基础，因此基础网格和基础纹理是3D模型中最重要的部分，应使用可 靠传输（TCP）进行传输。这样，客户端在接受到数据后，可以的渲染模型和绘 制纹理。增强层则可以通过不可靠通道（UDP）传输以减少传输延迟，提升传输 效率。
经过第二节网格重要程度计算后，得到了当前视点下用户兴趣区域中每个三 维模型的视觉重要程度，以及当前的网格层次和纹理层次编号，并对模型按照视 觉重要程度降序排列。本文的核心思想是保证用户的视觉质量最佳，因此将会优 先更新对画面视觉提升更多的模型。当视觉重要程度等于0时，意味着当前模型 网格和纹理质量的提升不会对画面质量有所贡献，在用户视点信息下一次改变前, 将不再考虑视觉重要程度等于0的模型。视觉重要程度高的模型往往意味着当前 网格和纹理的LOD低，使用较少的数据量将会给场景的画面质量带来较大的提 升。在完成一次数据请求后，等待用户输入以及数据下载，这两点都将触发场景 视觉排序描述的更新。
34
第四章	系统设计和仿真实验
上一章从渲染管线出发，对三维场景渐进式传输中兴趣区域管理、网格模型 视觉重要程度、网格模型和纹理图片联合优化几个方面进行算法优化。本章将根 据上一章的三个方面提出传输系统具体的设计方案，接着通过搭建仿真环境对该 设计方案进行仿真实验，最后对仿真结果进行分析。
4.1系统设计
本章提出了一种基于渲染管线的三维场景渐进式传输的具体设计方案。本方 案基于兴趣管理机制确定三维场景渐进式传输的具体对象，利用用户的视觉特点, 确定用户兴趣区域，每次只对兴趣区域内的场景进行渲染，从而减少，簣次请求场 景的数据量；基于渐进式网格技术和渐进式纹理完成场景三维模型和：纹理图片的 多分辨率编码，并基于用户的视觉特点计算网格模型的视觉重要程度，完成兴趣 区域内三维模型传输优先级的确定，最后通过混合传输协议，完成三维场景的传 输，达到实时性与可靠性间的有效平衡。
4.1.1传输方案的总体架构
本文提出的三维场景渐进式传输方案是基于服务器/客户端框架的，图4-1描 述了本方案的整体架构设计。
服务器	客户端

图4-1三维场景渐进式传输设计框架

35
服务器端包含数据预处理、传输队列、信道编码这几个流程，其中每个子模 块又包含了几个部分实现不同的功能。客户端的主要工作是对网络模型和纹理图 片的解码和渲染，依据用户输入计算兴趣区域内的所有模型的视觉重要程度，向 服务器端发送请求数据。
系统框架的三个主要过程分别为：
(1) 数据预处理：在数据预处理器中，首先会通过渐进式编码处理三维网格 模型和纹理图片，并将视点的显著性信息于模型文件绑定。当客户端根据请求队 列请求数据时，便会从预处理好的文件中选择合适细节层次的网格模型和纹理图 片，加入到传输队列。
(2) 传输队列：传输队列会加载请求队列的内容，依据请求数据中模型重要 程度的排序。传输队列的内容跟网络状况密切相关，当网络情况波动时，传输队 列会动态调整队列的大小以及更新的细节层次的多少，避免网络拥塞。选择好合 适的细节层次模型和纹理后加入到信道编码。
(3) 视觉重要性：用户作为视觉重要性计算的输入，客户端会根据当前用户 的视点位置，对兴趣区域中所有模型计算其视觉重要程度，并根据当前视觉质量 进行请求数据的排序，模型的排序方式是更新内容对场景视觉贡献提升程度的大 小。
4.1.2方案描述
本文所提出的渐进式传输方案可以分为两个阶段，第一个阶段通过基于兴趣 管理机制确定渐进式传输的具体对象，依据用户的视点位置计算模型的视觉重要 程度，并在兴趣区域中挑选模型和纹理最佳的细节层次在场景进行渲染，从而减 少每次请求场景的数据量，第一阶段包含了计算模型视觉重要性和创建请求队列 这两个过程；第二个阶段为在数据预处理模块完成场景三维模型和纹理图片的多 分辨率编码，通过结合请求队列内容和当前的网络状况完成传输队列的选择，最 后通过混合传输协议，实现三维场景的传输，达到实时性与可靠性间的有效平衡。
图4-2给出了本文所提设计方案一次数据请求的详细流程。首先当用户在场 景中漫游时，兴趣区域管理机制将划分出于用户相关性高的区域，并基于当前视 点下各个模型的重要程度对兴趣区域内所有模型进行重要程度排序，最后向服务 器端发出数据请求。在服务器端通过数据预处理模块，完成了网格模型和纹理图 片的渐进式编码，同时将模型视点显著性的描述文件上述文件一同压缩，存储在 数据库中，此部分是在客户端与服务器交互之前离线完成的，不占用用户浏览的 时间开销。服务器端将客户端的请求数据加入的传输队列中，由于网络状态是实 时变化的，而用户的数据请求也是动态的，经常会出现上一个传输队列的内容还
36

没有传输完，请求队列就发生了变化。所以当请求内容数据量与当前带宽不匹配, 或者用户新的请求数据有更新时，将重新规划传输队列。最后，通过混合传输协 议对网格模型、纹理图片的基础层和增强层采取非对等错误保护编码，因为基网格传输错误将导致整个模型无法加载，因此比增强层具有更高的优先级，完成这 次请求过程。

4.2仿真实验
上一节描述了三维场景渐进式传输的具体设计方案，其中主要的模块是数据 预处理、传输队列和更新策略。整个算法基于渲染管线展开，对兴趣区域管理、 模型视觉重要程度计算、网格模型和纹理图片联合优化进行了详细的分析和研究。
在仿真实验搭建中，本文通过基于WebGL接口，在浏览器上模拟了渐进式 更新三维场景这一过程，使用了本文提出的场景内模型更新策略以及模型视觉重 要程度计算方法。我们首先构建了一个服务器/客户端模型，在服务器端先进行模 型相关文件的预处理工作，通过PM算法对网格模型进行渐进式压缩，结合第三 章中网格模型和纹理图片联合优化算法，对纹理图片进行多分辨率处理，并在预 处理过程中完成网格模型多视点的显著性计算，将上述三种信息统一称为模型的 辅助信息。通过Node.js搭建服务器，并制作出基于three.js的web网页以及用 于存储辅助信息的数据库。在本实验中选择了 Stanford模型数据库中的Angek
37
Armadillo、BunnyDragon这几个模型作为实验数据，如表4-1所示。客户端则 使用PC或者移动设备访问web网页即可。
表4-1数据库三维模型顶点和三角面数目
模型
Angel
Armadillo
Bunny
Dragon
顶点数
237018
172974
35974
437645
三角面数
4747048
345944
69451
871414
本章先介绍渐进式传输方案对整体画面视觉质量的提升。为了简化传输过程, 本实验在仿真场景中使用了 Armadillo模型，因为其具有复杂的形状，而且粗糙 区域较多，网格显著性在不同视点下差异更明显，与应用于游戏等领域的模型类 似。为了使用多分辨率网格模型进行渐进式传输，实验中模型的简化率以及数据 量等信息见表4-2,在客户端即各种浏览器访问我们的场景。
表4-2 Armadillo模型的简化率以及数据量

简化率
Model size(MB)

首先需要完成客户端场景的初始化，包括web网页中模型对象大小位置以 及用户视点的控制。本文使用第一人称角色控制器模拟用户在场景的移动，认为 相机坐标为用户视点坐标。在场景中随机摆放5个Armadillo模型，包括位置、 姿态、尺度的维度均随机设定。场景初始化的详细参数见表4-3,包括相机内参 的远近剪裁平面、视野范围、视点位置、投影方式以及每个模型对应的尺度、旋 转和位置，并将网络速率设定为4MB/S。我们在客户端得到的随机摆放的五个模 型的场景如图4-3所示，右下角为该场景的俯视图。
38

表4-3场景初始化数据
参数
值
可视距离（uni⑸
(0.1,1000)
相机位置
(0,0,400)
相机方向
(0,0,0)
模型数量
5
相机视场角
45
投影方式
透视投影


Model(i)的位置
(x,y,z)
Model(i)的旋转
(r,y,p)
Model(i)的大小
(a,b,c)




图4-3仿真环境示意图

图4-4给出了在当前场景参数下，a取值为｛0.05,0.25,0.5,0.8,1｝时，客户端画 面质量的变化情况，其中x轴代表时间，y轴代表当前帧画面跟5个模型均是全 分辨率模型的PSNR值。可以看到a取值越大，画面的整体质量越高。但是a取值 的增加，降低了网格显著性对画面质量评价的权重，PSNR并不是唯一的画面视 觉评价指标，还应从HVS出发评价。因为本文选择a = 0.5,认为是最合适的值。
39


图4-5给出了使用本文模型更新算法和GUOU4］提出的方法的对比情况。
GUO在文献中提出的方法是根据模型和用户之间的距离、偏离视线中心的角度 以及当前LOD的程度这三个维度计算。从实验结果可以看到，在前两秒有一段 时间对比方案的曲线要高于本文的方案，原因是对比方法对场景内模型的重要程 度的区分不明显，对所有模型均进行一次更新，会得到较好的PSNR结果。之后 的画面质量本文的结果要明显高于对比方法，并且本文方案会在12S处完成下 载，而对比方法要下载到16S,原因是本文会根据屏幕分辨率计算模型细节失真 程度，如图4-3中的模型5,在简化率为30%的时候就不在有画面质量的提升， 即不再需要对这个模型进行更新，而对比方法并没有考虑视觉感知限制，需要将 所有的模型更新到完整分辨率。同时，模型5距离相机最近，在对比方法中计算 的模型视觉重要程度最高，这显然是不可取的。本文的方法，能够在保证画面质 量的前提下，最大程度上减少了传输的数据量。图6为使用表4-1中四个模型数 据在仿真环境中完成传输所需时间的对比，可以看到下载时长明显小于对比方案。




图4-6实验结果对比
图4-7是根据相机坐标以及模型在场景中的旋转坐标计算观察方向，并参照 媒体描述表格中相关视点坐标选择出来的观察视点，并依据该视点计算该场景下 每个模型的显著性信息，右下角为该场景的俯视图。可以看到3号模型拥有最高 的网格显著性（更大区域的白色面积），同时屏幕分辨率也更高。而相对的，4 号模型的显著性最低，屏幕分辨率也低于3号模型。场景描述文件发现，4号模 型与视点的距离要小于3号模型距离视点的距离，这也验证了本设计方案的算法 在实际应用中要优于使用距离参数的模型重要程度计算方法。计算得到的4号模 型MI值最小，本文在场景中更新的优先级同样是3号模型最高,4号模型最低， 符合ITTi等人提出的自下而上的视觉注意机制。	*

图4-7视觉质量评价

41
4.3总结
本文基于模型内容视觉感知提出了 一种渐进式传输三维场景的解决方案，该 方案主要贡献包括：提出了一种基于视觉感知的计算模型重要程度的算法，包括 屏幕分辨率的视觉感知和模型多姿态的视觉感知，通过该算法可以准确地评价场 景中模型的视觉质量。提岀了一种以模型视觉质量最优为目标的更新策略。仿真 实验结果表明，在进行三维场景渐进式传输时，本文的模型重要程度计算方法以 及模型更新策略明显优于当前方法，本文的模型重要程度计算方式可以广泛扩展 到模型简化编码、传输保护、场景重建、兴趣区域管理等多种领域中。
42
第五章总结与展望
5.1论文总结
随着VR/AR技术和移动端硬件等相关产业的快速发展，三维多媒体将在多 媒体领域占据越来越高的比重。网格模型的快速传输和加载是用户能够漫游虚拟 场景的前提。通过基于网格模型和纹理图片渐进式编码的三维场景渐进式传输方 案己经在很大程度上缓解了三维场景海量数据与有限带宽的矛盾。然而当前主流 的兴趣区域管理以及模型视觉重要程度等计算指标都是从服务器端进行优化，并 不是最优的解决方案。本文着重从基于渲染管线的客户端出发，对目前已有的三 维虚拟场景渐进式传输方案中的兴趣管理算法及三维模型最优分辨率计算算法 进行了分析和改进，并将纹理图片的压缩和传输加入三维虚拟场景渐进式传输系 统，使得在下载相同数据量的情况下，用户的视觉内容以及视觉呈现的体验更好。 本课题通过将三维虚拟场景中用户行为特点、三维模型的视觉特征有机地结合起 来，依据用户的视觉质量，通过数学建模和理论推导，完成三维虚拟场景的更新 策略，达到最优化视觉质量和最少传输数据之间的平衡，为用户提供更高的视觉 体验质量。
本文基于视觉分辨率和视点显著性设计了新的模型失真评估算法。修改原有 的失真评估算法，放弃使用相对视线中心的偏转角度这个维度，取而代之是基于 距离和尺度的视觉分辨率，使得模型失真评估算法更加精确，同时加入了视点显 著性信息，使得评估方法更加符合人类的视觉特征。并从渲染管线出发对用户相 关场景中三维模型的兴趣区域管理方法进行改进，使得用户的兴趣区域的划分更 加满足真实的体验场景。改变了以往兴趣区域的视距限制，让用户在视觉内容上 的体验更优。通过改进后的算法，避免了不对用户视觉质量有提升的模型的传输， 减少了对带宽的浪费，将更多的带宽分配给那些能够提升视觉画面质量的模型上, 同时，更加看重当前视角下显著性高的模型，从而提升用户的体验。
其次，本文研究了当前用于纹理图片的压缩编码标准，为后续设计纹理图片 的渐进式压缩编码做好基础，分析了直接根据网格模型的简化率，将纹理图片均 匀地降采样到与之匹配的简化率，系统只需要知道所需的像素预算即可这种方式 的不足。并据此设计了网格模型和纹理图片的联合优化方案，在纹理图片简化时 应充分考虑纹理图片中不同块的细节特征，并对不同细节特征的块采用不同的降 采样系数。本文通过在服务器端对纹理图片进行渐进式压缩编码，使得客户端能 够依据模型的简化程度选择合适的纹理图片，实现最优的匹配结果。
43
最后，基于模型失真评估、兴趣区域管理、纹理图片渐进式压缩等方式，设 计了从服务器端到客户端完成的三维场景渐进式传输框架。通过Node.js搭建服 务器端，客户端选择使用浏览器，基于WebGL实现三维模型的渲染，网格模型 的渐进式编码通过MeshLab平台实现，完成实验环境的搭建，并通过主观实验 对实验结果进行对比分析。验证了本方案能够^£相同时间内给用户提供更高的观 看质量。
5.2研究方向展望
本文设计并实现了一套基于渲染管线的三维场景渐进式传输方案，实现了更 符合用户视觉感知的场景失真评估算法，并通过网格模型和纹理图片的联合优化 实现网络传输的数据量和用户视觉质量的有效平衡。在后续工作中将从三个方向进行优化。
首先，本文的传输方案采用了标准的TCP协议进行传输，使用TCP协议保 证了所有数据信息能够可靠交付。但尚未考虑针对新的应用场景在传输层做出优化。未来工作中，本文将考虑设计合适的信源和信道的编码对抗可能的网络损伤，通过TCP/UDP混合协议传输来提升传输效率，并通过应用层的反馈信息指导传输层的重传机制，进一步提升带宽的利用率。
其次，中心-环绕算法中计算顶点曲率的距离，在本文中选取的是一个固定 值，为当前模型的最优解，但是随着多分辨率网格模型的渐进式传输，顶点数目会发生变化，在固定距离半径内的顶点数也会随之改变。因此，未来将会从距离 参数出发，寻求一个动态方法计算应用于多分辨率模型的顶点曲率计算，不同顶点密度下距离参数的最优解。
最后，为了简化实验环境的搭建，本文采用客户端/服务器系统框架进行实验 验证，仿真环境的网络拓扑结构也非常简单。然而实际的网络环境要复杂很多， 除了多用户之间存在的竞争，还存在着延时、丢包、抖动等弱网环境。因此在后 续工作中，将从网络拓扑结构进行优化，并进行弱网环境下的测试来发现传输框 架中存在的不足，从而获得更真实的实验数据，优化设计方案。




















































