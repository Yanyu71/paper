
第一章绪论
1.1研究背景
随着互联网的出现并以惊人的速度在全球范围内日益普及，越来越多的社会成员已经踏入了这张超级大网，可以说是对人类社会的又一次重大变革。互联网是人类智慧与创新的象征，是科技发展的重要标志。它不仅改变了人们获取各种信息的方式，让人们的生活变得密不可分，而且还让许多人实现了创业梦想。互联网不仅给人们带来了精神上的享受，还在慢慢的改变着人们的生活方式。互联网在现实生活中的应用很广泛，人们在互联网上可以聊天、购物、游戏、炒股,也可以搜寻学术上、工作上所需的信息。在互联网不断的发展过程中，不仅仅只可以通过计算机来访问互联网，各种移动设备如手机、平板电脑也可以随时访问互联网，使得互联网的应用更加方便。伴随着各种各样的应用和越来越多的人们加入到这张巨大的互联网中，我们也渐渐的走进了一个新的时代一大数据时代。
根据《第35 次中国联网络发展状况统计报告》中的数据统计，截止2014年 12 月底，中国网民规模已达到 6.49 亿，全年共计新增网民3117 万人。互联网普及率为 47.9%。这充分说明互联网的发展已变得更加深入，已经成为人们日常生活中不可缺少的一部分，并逐渐渗透到人们生活的方方面面。随着科技的进步，移动互联网也在快速的成长，对比于传统有线互联网而言，移动互联网有着灵活性更大、便捷度更高的优点，因此移动用户数逐年高速增加，各种各样的移动应用也层出不穷。
随着科技互联网的快速发展，互联网已经融入到人们的日常生活之中，也使得人们摆脱了原本信息匮乏的时代，进入了信息爆炸的时代。现如今，网络数据的增长引起了人们的重视，各种各样的应用层出不穷，代表不同使用人的虚拟信息也随之剧增，信息的总量激增，单单是每天增加的新信息，也是没有任何一个人有足够的精力去一一了解的，这使得人们在大数据时代面前显得不知所措。为了解决这个难题，就需要我们对用户行为进行分析，挖掘出用户的兴趣喜好，从而有针对性的为用户推荐他感兴趣的信息，帮助用户有选择性的获取信息。通过对用户行为进行分析,无论是从用户角度还是从信息提供者的角度都是非常有利的。因为，从用户的角度来看，减少了用户筛选信息的工作量，能够直接获取到想要的信息，符合用户体验:从信息提供者的角度来看，有针对性的向相关用户推送信息，而不是毫无选择的海量推送，降低了信息推送的成本。
不论是用户行为的分析，还是进一步向用户做出兴趣推荐，都会涉及到海量的数据处理和分析。传统的单个计算机已经不能有效的处理这些数据，因此需要引入快速有效的方法进行处理。目前，受到业界追捧的处理超大数据量的应用为Apeache 提出的 Hadoop 分布式系统。Hadoop 分布式系统是基于 MapReduce 编程框架的系统，它最核心的组成模块为 MapReduce 计算框架和 HDFS(HadoopDistributed File System)。Hadoop 系统是一个并行处理系统，有多个服务器并行的执行一项作业，这样每一个服务器上的压力就会很小，面对海量数据也是游刃有余。而 HDFS 是一个分布式文件系统，并且是元余存储，数据文件会以块的形式存储在多个节点服务器上，每个数据文件默认存储 3 份，这样可以保证当存储该数据的那个节点出现故障时数据不会丢失，这使得 Hadoop 得到广泛的应用。
1.2研究现状
1.2.1网络虚拟身份
身份是指社会群体中个体成员的标识和称谓,也可以看作是一种人与人之间进行联系和交流的关系定位。在现实生活中人的年龄，性别，生活角色，兴趣爱好等各种因素都会影响到人的身份，而这些影响因素一般很难被任意更改。作为社会群体中的一员，社会身份已经在一定程度上被设定好了，我们必须遵守道德规范、增强社会意识、约束行为准则，同时还要履行我们应尽的权利和义务14.而在互联网时代，人们借助互联网平台构造出一个包罗万象，令人眼花缭乱的虚拟世界。在这个虚拟世界里,种类繁多,层出不穷的应用服务以及数量众多、不同人群的网络用户构成了整个互联网大家庭，在这个虚拟社会里人们的语言表情、动作等将会以各种数字化代码和符号来代替。其中会有聊天、交友、论坛游戏等各种应用，并且这些应用必须要求人们注册一个能够代表自己的独特的用户名或ID 才能登录，随之，这种匿名的、流动的虚拟身份就自然出现了，这就为本课题的研究提供了丰富的宝贵资源。这些虚拟身份通常可以由人们自由、随意地构造，并能隐藏自己的一些真实属性。在这个虚拟社会里人们可以利用各式各样的工具，如文本、图像、视频等来任意地创建一个或者多个虚拟身份，通过这些虚拟身份人们可以展现给他人多方面、多角度的自我。在这个崭新的，可以隐藏真实自己的社会里，人们通过各种各样的虚拟身份进行前所未有的释放。现如今，对网络虚拟身份的研究并不是很多，而且通过阅读相关文献可知，大部分研究都是对某一个或多个虚拟身份进行分析来研究使用人的心理。文中结合传播心理学对网络时代的虚拟身份的特征进行了分析,来阐述网络虚拟身份对现实生活的影响[4，文中研究了虚拟身份的数据特点及存储模型[S]。
然而，我们可以注意到的是，虽然一个人可以随意创建多种多样的网络虚拟身份，但是这些虚拟身份之间还是存在一定关系。本文就是来分析挖掘出这些虚拟身份之间的关系，从而找出哪些虚拟身份对应属于同一使用人，从而对用户行为进行相应的分析。本课题所进行分析的虚拟身份是指那些原则上只属于某一使用人的，如QQ，邮箱，微博帐号及游戏帐号等等。像那种多人使用的公共账号，正是对本文分析造成干扰的噪声，后面的分析会详细介绍如何过滤掉这些干扰的虚拟身份。
1.2.2网络用户行为
网络用户行为分析概述
随着互联网的高速发展以及迅速普及，人类社会已在不知不觉中迈入了大数据时代。在这个信息爆炸的时代，海量的网络数据如潮水般向人类涌来，当然在这些海量的网络数据中也所蕴含着无比珍贵的财富。百联网的普及使得越来越多的人进入到互联网的世界，随着互联网用户的不断增加，越来越多的的电商企业也开始着手分析这些网络用户的上网数据，从而对网络用户的行为习惯和兴趣爱好作出分析，以满足他们不同的网络需求。
网络用户行为分析是指对网络用户的上网数据进行统计、分析，从中找出他们在访问互联网过程中的规律性,这些规律性可以用一些特定的数学公式来表示也可以通过可视化工具将其表现出来[6-8]。对网络用户行为的分析可以很好的应用到许多购物网站,这些电商通过分析用户的浏览习惯能够有效的预测出该用户的当前需求，接着向该用户进行推荐所需的类似商品，这样不仅节约了网络用户的浏览时间，也增加这些电商企业的营销利润[9。
以团购网站举例，可以从以下几个方面对用户行为进行分析:1) 看客户过去是否有点击: 统计客户是否购买、购买频率、购买商品种类以及最近一次购买时间等属性，然后对推荐给用户的商品进行优先级评估，从而提高用户的购买率。
2)从多维度对客户进行分析:统计客户的性别、年龄、访问时间、访问该商品时所处的地理位置等信息，从而可以在不同时间不同地域对他们进行商品推
荐，提高推荐准确率。3在给用户推荐的商品周边添加似于“喜欢”“”“不喜欢”之的按钮:分析用户点击这些按钮的信息，从而能更有针对性的为客户进行商品推荐。
上述以团购网站的例子体现了网络用户行为分析对电商网站的重要性。通过对网络用户行为的分析，电商企业可以很好的对客户做出相应的推荐，减少客户的流失，发掘可发展的客户。然而，到目前为止通过阅读关于用户行为分析的文献可知大多的用户行为的研究都是基于网络用户的购物数据。有的是通过用户访问一个指定网站的来获得用户的有效数据从而分析用户的行为;有的是通过用户浏览网页的内容和日志来计算用户的喜好从而进行用户行为分析[2]还有的是通过单纯的分析单个虚拟身份的特征来猜测用户的行为[3]。而基于企业网络数据的对网络用户行为的分析较少，一定程度上是因为企业的网络数据很难去获取，企业数据也不会对外公开，就算能够获取到得到的数据也不全面，得出的结果也不具有普遍性，相应的研究也就不具有说服性10]。但是本文所分析的企业用户的网络数据，是用自主研发的设备采集到的包含各种类型大中小企业的网络出口的数据，数据广而多，分析出的企业网络用户行为具有普遍性和说服力。本文是提取出企业网络流量中包含有虚拟身份的有效字段，来分析这些海量的不同类型的虚拟身份哪些是属于同一使用人，从而对用户行为进行分析。
网络用户行为特征变化
伴随着互联网新技术的出现、各种网络应用的不断涌现、互联网用户的不断增加，使得网络用户的行为特征也发生了一些改变。根据中国互联网络信息中心发布的《中国互联网络发展状况统计报告》从2011 年第27 次报告到2014 年第35 次报告可以看到互联网规模、网络用户属性、网络用户上网习惯等的变化。在互联网规模上，网民总数从2010年的4.57亿增长到2013 年的6.49 亿，互联网普及率从 34.3%扩展到47.9%:在网络用户属性方面，网络用户的生活和职业所需以及收入水平的提高使得网络用户的平均上网时间有所增加并且其网络行为也变得多种多样。在互联网出现的早期人们大多只会通过网络进行聊天、发邮件或者知识搜索，而现如今，人们可以通过互联网进行国内外购物、看网络视频直播、炒股等等，用户的网络行为变得复杂多样化。以下从不同的方面描述了网络用户的行为变化:
1) 沟通交流
人们最早是通过论坛以及电子邮件这种非即时的通讯手段来进行网络交流的，随着人们对沟通交流要求的不断提高，出现了许多即时通信工具，如微信QQ、MSN、Line 等这些即时通信工具，因为这些应用能实时的收发信息有的还可以视频聊天，所以受到网络用户的喜爱!]。此外，像博客、微博等沟通平台的出现也进一步促进了沟通交流的多样性，尤其是微博，刚出现就迅速成为了极具影响力的媒体。
2)信息获取
最早人们在网络上获取信息的途径是通过百度等搜索引擎,利用这些搜索引警网络用户可以快速准确的搜索到自己想要的信息，但是一般搜索到的信息大都是之前的。网络新闻的出现满足了人们想要获取实时新闻的需求，解决了人们信息滞后的苦恼。此外，地图搜索的出现给人们出行带来了极大的方便，无论你通过哪种交通工具(驾车、公交、步行)去一个陌生的地方，地图搜索都能给你规划好准确的路线。
3)休闲娱乐
在互联网的开始阶段，大部分的电脑游戏都是单机版或局域网内的游戏，如抢滩登陆、红警、CS 等，人们也只能跟局部一小部分人对战。随着技术的进步，越来越多的网络游戏开始出现，人们可以在任何地方跟任何人一起对战。随后网络视频和网络音乐的出现又丰富了人们的休闲娱乐项目。
4)生活服务
一提到网络上的生活服务就会自然的想到网络购物，人们可以在购物网站上浏览生活中的各种所需品，还可以选择海外购物，满足了网络用户足不出户的购物需求。网上炒股、网上教育等生活服务也受到了广大用户的青睐。
总而言之，网络内容的丰富增加人们对互联网的使用率，也改变了网络用户的上网行为。这也使得网络流量不断增加且网络流量的组成也越来越复杂,因此对网络用户行为的分析不仅能更好的了解网络用户的兴趣爱好，也能为商家带来丰厚的利润。
网络用户行为分析方法
每个网络用户的上网目的不同，其在互联网上的行为必然不同，并且每个人都有一些自己的上网习惯。商家通过分析用户的上网行为，可以向其推荐可能感兴趣的商品，因此若想其对推荐的商品感兴趣，选择合适的分析方法显得尤为重要。传统的数据分析方法包括相关分析、主成分分析等，现在流行的分析方法有聚类分析、决策树、时间序列分析等。
聚类分析是数据挖掘中一种常见的分析方法，它通过多次选代将海量数据中的类似对象组合成一类。聚类分析根据不同的聚类变量可能得到不同的解，根据自己的判断和后续的研究需要选择适合的结果。聚类分析最大的缺点就是不会自动给出准确的最佳的解。K-means 聚类算法是比较经典的聚类算法，其基本过程是逐个扫描样本，并计算这些样本的平均值，然后计算新样本与已知样本平均值的距离，与已设定的闯值进行比较，判断新样本属于哪个类或生成一个新的类直到所有的样本均被扫描。由此可见，最终的结果与初始的样本选择有关，所以聚类分析可能会得到多个不同的解。
决策树方法是一种分类算法，利用树的思想先从根节点对样本进行判断，即先从大的类别进行分类，根据所属的类别选择不同的路径到下一节点，然后在这一节点再进行判断分类，如此一层一层进行下去直到当前节点不再有子节点，则该样本找到了所属的类别。相比聚类分析方法，决策树方法是从数据对象中归纳出一种可读的且比较准确的分类规则，其效率和结果准确率都比较高时间序列分析是一种动态数据处理的方法,通过分析该数据的过去和现在来预测数据的未来走向，即预测事物的未来发展趋势[8]
总之，在大数据背景下，对于网络用户行为分析至关重要，不仅能够了解这些用户上网行为，更重要的是能够在分析的结果中找到商机。我们对已有相关文献进行查找，发现通过对虚拟身份的分析以及对企业员工的网络行为分析的比较少，因此，本文在已有企业员工上网数据的基础上，通过对其中的虚拟身份进行分析研究来挖掘出企业网络用户的上网行为习惯。
1.3论文结构
本文用到的数据主要是从分布在全国的网络监控平台的两千多家不同类型企业的网络数据中获得。本课题从企业的报文数据中提取出网络虚拟身份等其他重要信息，对同一使用人的虚拟身份进行合并分析，研究企业网络用户的行为特征。本文共六章，各章节主要内容如下：
第一章，绪论。主要介绍了本课题的研究背景以及研究现状，最后介绍了本文的论文结构。
第二章，相关分析技术介绍。本章介绍了 Hadoop 运行机制和MapReduce的编程模型以及 HBase 分布式存储系统。并对实现本系统的核心算法中用到的有关图论及图论中的经典算法作了必要的介绍。
第三章，网络虚拟身份分析系统的框架结构。本章详细介绍了该系统框架各模块的设计，包括数据采集模块，数据预处理模块，数据分析模块第四章，网络虚拟身份分析系统的算法实现。面对海量的数据传统的计算机是不可能完成的，本章详细介绍了在 Hadoop 技术的基础上对该系统的实现。第五章，同人关系传播算法在 Hadoop 中的设计与实现。详细的介绍了本文在实现该分析系统中的关键算法一同人关系传播算法,该算法是基于图论中的标签传播算法，对其进行了自己的改进，使其能很好的适合本文研究场景，并成功的在Hadoop平台上实现了该算法。
第六章，总结与展望。本章对本文做了一个总结，最后对网络流量分析和海量数据处理领域的技术发展进行了展望。

第二章相关分析技术介绍
2.1 Hadoop原理
Apache Hadoop 是一种开源的、基于 Java 语言的编程框架，可以运行在一台或多台物理计算机上来并行的处理海量数据。当某个节点发生故障时，Hadoop集群可以从一个或更多节点的故障中恢复，实现了高可用性。Hadoop 框架主要包括:Hadoop Common、HDFS与MapReduce。Hadoop Common 为其他两个提供常用工具，主要包括系统配置工具 Configuration、抽象文件系统 FileSystem远程过程调用 RPC和序列化机制等。HDFS(Hadoop Distributed File System)是Hadoop 系统的存储模块，它以流式方式来访问应用程序的数据，因此大大提高了整个系统的吞吐量112MapReduce是一种可以处理海量数据的并行处理框架采用“分而治之”的思想将输入数据进行分块，并采用键值对的形式对数据进行并行快速处理。图2-1 为一个Hadoop 集群的部署结构图及工作流程示意图。
2.1.1 HDFS组件
NameNode
NameNode是HDFS系统的管理者主要功能是管理文件系统和控制对文件的访问。它维护着整个文件系统和文件夹的元数据(metadata)。这些信息分别存放在名为命名空间镜像文件和编辑日志文件中，且被缓存在 RAM 中，当然，这两个文件也会被永久存储在本地磁盘上[13]。除此之外，NameNode 中还存放着数据块的位置信息,以便于查找所需的文件数据,但是这些信息并不会永久的被存储因为这些信息会在Hadoop 集群启动时从 DataNode重建。
Secondary NameNode
在 Hadoop 集群中，一般只会配置一个 NameNode 节点，由上述所说的NameNode 的重要性，一旦其发生故障整个集群就将会受到影响，这就是常说的单点故障。为了解决此问题实现高可用，增加了Secondary NameNode 节点，它并不是NameNode的热备份,它真正的意义是定期保存NameNode 中的 Metadata信息，所以SecondaryNameNode 并不能分担NameNode 上对HDFS交互性操作的压力。它一般运行在一台单独的物理机器上，当NameNode 出现问题时，可以从保存的Metadata 快照恢复以重新启动NameNode，因此实现了高可用。2.1.1.3 DataNode
DataNode是Hadoop 集群的数据存储和工作节点，主要负责大量的计算和数据文件的存储，它还会定期的向 NameNode 发送存储的数据块block)的列表信息。HDFS 的文件通常是以余备份的形式存储在多个 DataNode 节点中，默认的备份数是 3。所以当某一个 DataNode 节点宕机后，数据也不会丢失，增加了数据的可靠性。
2.1.2 MapReduce组件
JobClient
JobClient 主要作用提交MapReduce作业。2.1.2.2 JobTracker
JobTracker 运行在Master 节点，主要负责接收提交的Job，然后将 Task任务分发到相应的 TaskTracker 上，并实时报告它们的运行情况，如果有任务失败就重新运行。此外，JobTracker 一般部署在单独一台机器上，且每个Hadoop 集群中只有一个JobTracker。
TaskTracker
TaskTracker 运行在 Slave 节点，主要功能是执行 JobTracker 分发的任务TaskTracker 通过心跳(HeartBeat)主动与JobTracker进行通信，以维护整个集群的运行状态。
2.1.3工作流程
1)客户端 JobClient 提交一个MapReduce 作业
2) JobClient 向 JobTracker 申请一个 Job Id;
3)JobClient根据配置文件信息将输入数据进行分块并同时把执行作业所需要的资源存放到HDFS 上，HDFS 上会有一个以此JobId 命名的文件夹，有的文件可能不止存放在一个节点上。
4)JobClient 调用JobTracker 的 submitJob0方法，此方法会将此作业提交到集群。
5)作业提交后，JobTracker 会将其放入一个作业队列中，通过调度器配置的调度算法对其进行初始化调度。调度器有三种: FIFO 调度器、公平调度器(FaiScheduler)和计算能力调度器(Capacity Scheduler)，默认为 FIFO 调度器，即先到先处理。TaskTracker 会定期给 JobTracker 发送一个心跳，告诉JobTracker 它的运行状态，同时心跳中还包含其他有用的信息，比如是否可接收新任务、当前任务的进度等信息，JobTracker 可以凭借这些信息来更好地分配 MapTask 和ReduceTask。
整个过程如果有一个任务失败了(或某一个数据节点坏了)，Hadoop 集群会重新读取该任务的数据(因为默认的数据备份是3份)将其分发到新的正常工作的节点。所以 Hadoop 系统的可靠性是很强的。
2.2 HBase原理
HBase 是一种基于 Google BigTable 的开源的、非关系型数据库。它是Apache 软件基金会 Hadoop 项目的一部分，基于 Hadoop 分布式文件系统(HDFS)运行，为 Hadoop 提供与 BigTable 相似的功能。HBase 是基于列的存储方式，查询、插入、删除等操作的效率特别高。
HBase 可与 Hadoop 无缝配合，从而共享其文件系统并用作 Hadoop 作业的直接输入和输出端。
所谓非关系型数据存储就是说 HBase 是基于列的而不是基于行的模式，列存储的好处包括以下四点:
1) 查询快:不像关系型数据库，若要单独查询某一列，必须要把全部数据取出再从中选取，而列存储可以直接取出要查询的列，不仅减小了 I/O 次数，而且把随机读取变为了连续读取;
2) 提高压缩率:同列数据具有很强的相似性且列值为空的也不再对其存储会提高压缩效率;
稀疏数据:列为空就不存储数据，节省存储空间;3
结构灵活:不需要指定特定的列数，列可以动态增加，而且对于列数也4)没有限制。
在整个Hadoop 体系中HBase 位于结构化存储层，其底层是利用HDFS作为其文件存储系统，利用 Zookeeper 作为协同服务，主要用于实时随机读/写大规模数据集，并且利用 MapReduce 框架来处理存储在其中的海量数据。HBase 的架构图如图2-2所示。
2.2.1HBase使用场景
HBase 可以与 Hadoop 和 Hive 直接集成并且可以快速访问存储数据因此它可用于存储多项 Hadop 任务或多个 Hadoop 集群使用的引用数据该数据可直接存储在运行 Hadoop 任务的集群上，也可以存储在独立的集群上。分析类型包括需要快速访问人口数据、IP 地址地理位置查找表和产品维度数据的分析
HBase 可优化顺序数据、高效存储稀数据且具有高写入吞吐量，因而是实时引入日志数据的极佳解决方案。同时，它还可与 Hadoop 集成并可优化顺序读取和扫描，因而同样适用于对引入后的日志数据进行批量分析。常用案例包括，引入和分析应用程序日志、点击流数据和游戏使用数据计数器增量不只是数据库写入，而是读取 - 修改  写入，因此，关系数据库的这一操作成本非常高。然而，因为 HBase 是非关系型分布式数据库所以它可支持更新率非常高的操作，且 HBase 采用的是一致性读取和写入方式，因而可即时访问已更新的数据。此外，如果要对数据运行更为复杂的汇总(如最值、平均值和分组计算)，您可以直接运行 Hadoop 作业，然后将汇总结果反馈到 HBase 中。
2.2.2 HBase组件
HBase Client
HBase Client 主要负责与HMaster 和 HRegionServer 之间的通信，主要是通过RPC(远程过程调用)机制实现。
ZookeeperZookeeper 是 HBase 的协同管理者，它可以将 HRegionServer 的运行状况上报给HMaster，使HMaster 及时发现故障，更好地维护集群。Zookeeper Quorum中还会配置 Zookeeper 管理的节点，一般配置奇数个，避免了 HMaster 的单点问题。
HMaster
HBase 集群中可以启动多个 HMaster，所以HBase 不存在单点故障，并且作为协同管理者的 Zookeeper 也会保证总有一个节点在运行1141。HMaster 的主要功能是管理数据库表的增、删、改、查操作，负责任务的分配和资源调度2.2.2.4 HRegionServer
HRegionServer 是用户对数据库表的各种请求具体执行的部分，而其最底层的存储单元 HFile 就是基于 Hadoop 的 HDFS 来把 HBase 数据库表以一些KeyValue对的形式来存储[15]2.2.3物理存储
虽然 HBase 的数据模型可以采用与传统关系型数据库类似的数据行表的形式表示，但实际上这些数据在进行物理存储时是以列族为单位的。Table 到HRegion
首先，HBase 表(Table)中的数据在行上会按 RowKey 进行排序，并被分为多个HRegion存储单元存储在 HRegionServer 上。对表进行分割的目的是为了能够应对大表存储的情况。每个表在创建开始时只有一个HRegion，随着数据量不断的增加，HRegion会越变越大，当超过一个阙值时，这个 HRegion 会被等分为两个HRegion。这个过程会不断重复，HRegion 数量也随之不断增加。HRegion 是最小的存储单元，即不同的 HRegion 可以存放在同一个HRegionServer 上，但个HRegion 不可被拆分到多个HRegionServer 上。这种存放方式也很好地实现了数据管理的负载均衡。
HRegion 到 Store
HRegion 是 HBase 中的最小存储单元，但并不是物理存储的最小单元。在物理存储时,HRegion被划分为若干个Store,每个Store 保存了一个列族的数据[16]Store 到HFile
Store由两部分组成，MemStore 和 StoreFile。MemStore是HRegionServer 上的一段内存空间。写入的数据会最先存入 MemStore，当MemStore 中的数据量达到一定的阙值后会转存到 StoreFile 中。HRegionServer 借用了HDFS DataNode的功能，StoreFile 实际上是 HDFS 中的一个 HFile。
2.2.4读写流程
HBase的数据是以HFile的形式存储在 RegionServer 中的，因此对HBase数据表(Table)进行读写的关键就是如何通过表名和行关键字(RowKey)找到所对应的 RegionServer。在这里先介绍 HBase 中两张最关键的表:-ROOT-表和META表。
-ROOT-表
正如它的名称所示，-ROOT-表是 HBase 中的根数据表，它存放了META.表元数据表)的 HRegionServer 信息。-ROOT-表是保存在 Zookeeper 服务器中。当HBase 客户端第一次向 HBase 读取或写入数据时，首先要访问 Zookeeper 以获取ROOT-表的位置并存入缓存，然后得到-ROOT-表。-ROOT-表的结构如表2-1 所
表2-1-ROOT表结构
Row Key
Columnl
Column 2
Column 3
.META. Region Key
info:regioninfo
info:server
info:serverstartcode
其中行 RowKey(行关键字)代表了每个META.表的 Region 索引，info:regioninfo 记录了该 Region 的一些有用信息，info:server 记录了该 Region所在的 RegionServer 的端口和地址，inforserverstartcode 代表此 RegionServer 拥有对应META.表的进程的启动时间。为了保证寻址性能，-ROOT-表的 Region永远不会被拆分，保证了最多通过三次跳转就能定位任意一个存储数据的RegionServer。
META.表
META.表保存了所有表的元数据信息，支持以表名和行关键字 RowKey(或关键字的范围)查找到对应的 RegionServer。.META.表的结构如表2-2 所示。表 2-2.META.表结构
Row Key
Column 1
<table, region start key, region id> info:regioninfo
Column 2
info:server
Column 3
info:serverstartcode
其中RowKey(行关键字)表示该表名及该Region起始关键字和Region的id,info:regioninfo 记录了该 Region 的一些有用信息，info:server 记录了该Region所在的 RegionServer 的地址和端口，inforserverstartcode 表示该 RegionServer 拥有对应 RegionServer 信息的进程的启动时间。为了能够实现快速访问，META.表的全部 Region会加载到内存中。
读数据流程
假设 HBase Client 要读取 Table 中的第一行数据，并且是第一次读取操作。HBase Client 会先从 Zookeeper 中得到存放-ROOT-表的 Region 服务器 S，并从Region 服务器S中根据表的名称索引找到META表所在的 Region 服务器R用户表 Region 服务器信息是以表和行关键字(RowKey)为索引创建的，且以 B+树的形式存放在META服务器中HBase Client 根据表名和行关键字(RowKey)找到相应的 Region 服务器后，使用对应接口直接从服务器中进行数据读取。
实际上，从 RegionServer 中查找并读取一行或几行数据的过程并非像描述的那样简答。因为RegionServer 中的数据还有可能存放在memStore或storeFile中所以除了需要根据行关键字(RowKey)找到对应的 HRegion 外，还要根据行关键字(RowKey)找到相对应的 memStore 或 storeFile。如果要读取的数据存放在memStore 中，则HBase Client 可以直接从中读取:如果要读取的数据存放在storeFile 中，RegionServer 中的 HDFS 客户端组件首先要从HDFS 文件系统中获取该数据。为了减少网络时延以加快读取速度，通常在实际应用中大都将 HDFSDataNode 与 RegionServer 部署在一起，这样可以充分利用 HDFS 的位置感知特性，将与某个 RegionServer 中存放的表和行相关的数据存放到本机的 DataNode中，从而提高读取效率。
写数据流程假设HBase Client 要向 Table 中写入数据，并且是第一次进行写操作，同样的，要经历与读数据相同的步骤以找到对应的 Region Server，如果不是第一次写操作则可以从缓存中直接获取要写入的地址。在HBase Client 向 RegionServe 发出写入请求后，RegionServer 会将该请求分发到对应的HRegion 上。在进行真正的写入数据操作之前，会根据用户自已设置的标志位来决定是否要写 HLOg。HLog可以在 Region Server 出现故障时进行数据回复，防止数据丢失，实现高可用。
在完成HLog记录后，数据会先被保存在 memStore 中，当写入全部完成后本次HBaseClient的写操作才算完成。接下来的数据文件持久化工作是由 RegionServer进行的，Region Server 会判断memStore 的存储量是否达到已定阙值，如果超出闯值则会触发一个请求，该请求会将缓存中的数据写入磁盘，该请求操作是由专门的服务器线程来完成的。写入数据的文件形式是 StoreFile，并且在写入时是以追加的形式进行的，所以 storeFile 数据文件会不断增大，直到超过一定的闯值会再触发合并操作。在多个 storeFile 数据文件进行合并的同时还会进行删除无效的数据等操作。
2.3图论
本章主要用到的知识是与图论相关的内容，同人关系传播算法是参考图论中的标签传播算法(LPA)来实现的，后面会详细介绍这两种算法。首先，先介绍图论的一些基本内容。
2.3.1图论中的图
在现实生活中，图的概念随处可见，比如人们常常用点来表示事物，用点和点之间的连线来表示事物与事物之间是否存在某种关系，由这样的点和线构成的图形就是图论中所讨论的图。在这些图中，人们往往只关心点与点之间是否有连线，而不关心点所处的位置以及点之间的连线的形状。这就是图论中的图和几何中的图的最根本的区别。因此在现实社会中，可以用不同的图来描述事物的不同状态，使其简单清晰，易于理解，便于分析，同时还可以根据图的特征，从不同的角度来对问题进行全面的分析。2.3.2图论综述
2.3.2图论综述
在图论的研究中，一般用一个二组 G=(V，E)来表示图，集合V中的元素称为图G的节点(或者点、定点)，而集合E 中的素称为边(或者线)。通常，描绘一个图的方法是把节点画成一个小圆圈，若两节点之间存在特定的关系就用一条线把这两个小圆圈连接起来，至于如何绘制这些小圆圈和连线都无所谓，重要的是要表现出哪些节点之间有边，哪些节点之间没有边。2.3.21有向图和无向图
有向图
若图G中的每条边都是有方向的，则称图G为有向图17。有向边的表示
在有向图中，一般用尖括号来表示有序对，如<Vi，V>表示一条有向边，Vi是有向边的始点，Vi是有向边的终点。所以，<Vi，V>和<Vi，V>是两条不同的有向边。
如图2-3 所示，此图G即为一个有向图，图中边的方向是用从始点到终点的箭头表示的，该图的节点集和边集分别为:
V(G)={V1，V2，V3)
E(G)={<V1,V2>，<V2,V1>，<V2,V3>!无向图
若图G中的每条边都是没有方向的，则称图 G 是无向图无向边的表示
无向图中的边都是节点组成的无序对，一般用圆括号来表示无序对，如(Vi,V)表示一条无向边，无序对(Vi，V)和(Vj，V)表示的是同一条边。
如图2-4 所示，此图G即为一个无向图，它的节点集和边集分别为V(G)=V1，V2，V3，V4
E(G)={(V1,V2)，(V1,V3)，(V1,V4)，(V2,V4)，(V3,V4)}节点的度
节点度是指与该节点相连的边的条数。特殊的，对于有向图还会有节点的入度和出度，所谓节点的入度是指进入(有向箭头指向)该节点的边的条数;节点的出度是指从该节点出发(有向箭头远离)的边的条数。2.3.2.2图的存储方式
图的存储方式有很多种，本章主要介绍最常用的两种方法:邻接矩阵表示法和邻接表表示法，根据不同的应用类型和进行的不同操作选择合适的存储类型邻接矩阵表示法
图的邻接矩阵存储方式一般用两个数组来表示。一个一维数组用来存储图中的节点信息，另一个二维数组用来存储图中的边(或弧)的信息。
假设图G中有 n个节点，则该图的邻接矩阵表示则为一个 nxn 的方阵，其定义式:
就对图2-4来说，节点数组(即一维数组)为:V1 V2 V3 V4边数组(即二维数组)为:
从上面的表示可知，无向图的边数组是一个对称矩阵，且两个节点间有连线的位置的元素值为 1，没有连线的位置的元素值为0。而且从此矩阵中可以得到以下信息:
1)根据对称矩阵中元素的值可以很容易的判断任意两节点是否有边2)想要计算某个节点的度，就把该节点 Vi在邻接矩阵中第i行(或第i列)的元素的值加起来，之和就是该节点的度;
3)阵中第i行的值为1的节点就是节点 V的所有的邻接点邻接表表示法
邻接矩阵是一种很好的而且是很常用的图的存储结构，但是，对于边数相对节点较少的图来说，这种结构就会对存储空间造成极大的浪费。因为矩阵中的大多元素的值都为0，此矩阵就变成了稀疏矩阵。因此为了弥补这个缺点，我们采用数组与链表相结合的存储方式来表示这种特殊的图，并将这种存储方法称为邻接表表示法。
邻接表的处理原理如下:
1)图的节点有两种存储方式，一个是用一维数组来存储，另一种是用一个单链表来存储，不过，对于较多的读取操作则数组更加方便
2)图的任意节点V的所有邻接点构成了一个线性表，因为邻接点的个数是不确定的，所以用单链表存储较好，在无向图中称为节点 V的边表，而在有向图则称为节点 V;的出边表。
如图2-4 所示，它的邻接表的结构可以表示为图2-5
从图2-5可以看出，节点表的各个节点由 data 和 firstedge 两个域表示，data是数据域，存储节点的信息，firstedge 是指针域，指向边表的第一个节点，即此节点的一个邻接点。边表节点由adivex 和next 两个域组成。adivex 是邻接点域存储节点的邻接点在节点表中的下标，next 则存储指向边表中下一个节点的指针对于带权重的图，可以在边表节点定义中再增加一个 weight 的数据域，存储权重值即可。
图的遍历
图的遍历是指从某一个节点开始,沿着某一路径对图中的所有节点进行全部且仅做一次访问。在众多的研究领域中被各大学者所青睐的遍历图方法为深度优先遍历和广度优先遍历。
Y深度优先遍历
其遍历过程为:选择一个被访问节点i并对其标记;然后从该节点开始选择条边(i，j)，如果节点j被访问过，则重新选择另一条边(i，k)，否则，对节点;进行访问标记;然后再从节点j选择一条边做上述操作;直到从j连通的节点全部遍历完;再返回到节点 i，选择另一条边做同样的操作，直到从点i出发的边全部遍历完遍历过程结束。基本思想是先深再广。如图 2-6 所示的图 G，其深度优先遍历得到的序列为:V1->V2->V4->V8->V5->V3->V6->V7。
广度优先遍历
其遍历过程为:在广度优先遍历中一般采用对列这种数据结构来保存已经访问的节点。假设节点i和i的邻接点分别记为i1，i2，·.，is和j1，j2，··，jt。遍历开始时，先将节点i和i按顺序存入队列，随后，节点出队列，并遍历其邻接点i1，i2，··，is，将其中未访问过的节点存入队列;接着节点j出列，并遍历其邻接点i1，i2，··,jt，将其中未被访问的节点存入队列。基本思想是先广再深。如图2-6所示的图G，其广度优先遍历得到的序列为V1->V2->V3->V4->V5->V6->V7->V8。
2.3.3图论的应用
图的概念在现实生活中很普遍，在互联网中亦是如此，并且图论中的算法在社交网络中有着广泛的应用，尤其是在处理人际关系方面的应用。因为本文的算去是基于图论中的标签传播算法，所以后面会对这一算法进行详细的介绍，这里只对图论中的常用算法的应用做一下简单的介绍。331最小生成树
假设图G=(V，E)是一个连通的无向图，则把它的所有的节点V和部分边E构成的一个子图G即G=(VE将图中所有的节点相连但又不形成回路，则称子图G是图G的一生成树。而对于带有权值的加权连通图，生成树的权值是将生成树中所有边上的权值进行相加，从定义知生成树不上一种，其中权值最小的生成树称为图的最小生成树。求图的最小生成树有两个经典的算法，分别为Prim算法和Kruskal 算法。
Prim法
O设置一个节点集合V和一个边集合E，V和E的初始状态都为空;@选定图中的一个节点i，从i开始生成最小生成树，将i加入到集合 V;O重复下列操作，直到选取了 n-1 条边:
1.选取一条权值最小的边(M，N，其中Mev，NEV
2.将节点N加入集合V，边(M，N加入集合 E;得到最小生成 T(V’，E)
2)Kruskal 算法
假设最小生成树为 T=(V’，E，设置边集合E的初始状态为空集。首先将图 G 中的边按权值从小到大进行排序，然后从最小的边开始选取，若选取的边使生成树T不形成回路，则把其加入集合 E中，作为最小生成树 T的一条边:若选取的边使生成树构成回路，则将其舍弃;如此进行下去，直到 E中包含了 n条为止。最后得到的生成树 T即为最小生成树。
最短路径
在带权值的图 G=(V，E)中，若节点 Vi，V是图G中的两个节点，从节点 V到V的路径长度定义为路径上所有边的权值的和。从节点V到V可能有多条路径，其中权值的和最小的那条路径就称为节点 Vi到V的最短路径。求最短路径的算法有多种，下面只简单的介绍其中的两种: Diikstra 算法(也叫 D算法)和Floyd-Warshal1 算法(也叫F算法)。
Diikstra 算法
Diikstra(迪杰斯特拉)算法大多用来用来计算一-个节点到其他节点的最短路径，是解决单源最短路径的经典算法[18-19。其主要思想是以始发点为中心向外层层遍历，直到访问到终点为止。
O算法思想
设 G=(V，E)是一个带权值的有向图，将其节点集合 V 分成两组，第一组为已遍历过的最短路径的节点集合，用 R 表示初始状态 R 中只包含一个始发点，以后每次计算出的一条最短路径就将其计入到集合 R 中，直到所有的节点都加入到R 中，算法停止:另一组为其余未被访问过的节点集合，用 W 表示，按照最短路径长度的递增次序依次把这一组的节点加入到集合 R 中。注意，在加入的过程中，要始终保持从始发点 V 到集合 R 中的每个节点的最短路径长度不大于从始发点 V 到集合 W 中任意节点的最短路径长度。另外，集合 R 和集合 W 中的每个节点对应一个距离，R 中节点的距离代表从节点 V 到此节点的最短路径长度，W 中节点的距离则代表从此节点只包括 R 中的节点为中间节点的当前最短路径长度。
O算法步骤
1)初始状态时，R中只包含始发点 V，即 R=V)，V 的距离为0。而集合w 包含除V以外的其他所有节点，即 W=其余节点，若V与W中的节点w有边，则<w，V>的权值为常量，若 w不是V的出邻接点，则<w，V>的权值为o;2)从W 中选取一个距离 V 最小的节点i，然后把节点i加入到集合 R中选定的该距离就是V到节点i的最短路径长度;
3)以节点i为新的始发点，更新 W 中各节点的距离。若从始发点V到节点w 的距离(经过节点i)比原来的距离(不经过节点i)短，则更新节点 w 的距离，更改后的距离为节点i的距离加上边的权值;
4)重复步骤2)和3)直到所有的节点都加入到集合 R 中Floyd-Warshall算法
Floyd-Warshal1(佛洛伊德)算法是处理任意两点间的最短路径的经典算法可以很好的处理有向图和带有负权值的最短路径问题。
1算法思想
Floyd-Warshall 算法其实是一个动态规划的算法。假设在图 G=(V，E)中，从任意节点i到j的最短路径不外乎有以下两种情况，一是从i直接到i:二是从i经过若千个节点到i。所以，我们假设 Distance(i，j)为节点i到节点的最短路径的距离,对于其余每一个节点n,我们验证 Distance(i,n)+Distance(n,j)<Distance(i.i)是否成立，如果成立，说明从节点i经过节点n再到节点的路径比从节点i直接到节点;的路径距离要短，所以我们修改节点i到节点的距离 Distance(i,i)=Distance(i，n)+ Distance(n，j)，如此进行下去，当我们遍历完所有的节点后Distance(i，j)中的值就是从节点i到节点i的最短路径的距离[2012算法步
1)选取图中的任意一条边路径，两个节点之间的距离即为边的权值，如果某两个节点之间没有边将它们相连，则权值记为o;
2对于给定的节点i和i，验证是否存在另外一个节点n，使得从节点i到节点n再到节点i的距离比已知的距离更短，如果存在则更新已知的距离,否则保留原来的距离。
2.4标签传播算法
2.4.1概述
在机器学习领域，主要有三种不同的学习方法:监督学习、非监督学习和半监督学习。所谓监督学习是指输入输出关系已知，然后找到一个对应的函数，将输入映射到合适的输出，例如分类算法;非监督学习是指样本之间没有确定的关系，直接对输入数据集进行建模，例如聚类算法;半监督学习是指知道部分输入输出的关系，生成合适的函数，来预测未标记数据的类别，然后归并到特定的已标记的数据集中。
标签传播算法(LPA，Label Propagation Algorthm)是一种基于图的半监督的机器学习方法，而且是一种高效准确的图结构检测算法。在所描述的图中，节点包括了有类标和没有类标数据，连接两个节点边上会标有的权值，代表两个节点之间的相似度，标签会根据相似度传播给其他的节点，节点间的相似度越大，标签就越容易在其之间传播。
2.4.2算法思想
标签传播算法的基本思想是，在图 G=(V，E)中，最初的每一个节点都会用有一个自己的标签，这个标签代表它属于哪个集合。在算法执行的过程中，该节点选择它的邻接点所在的最多的那个集合，相应的，把自己的标签修改成那个集合的标签。随着一步一步的进行，节点的标签不断的发生变化，紧密相连的节点可以很迅速的达到标签的一致。算法结束的标志是所有节点的标签都不再发生变化，且拥有同样标签的节点组成一个集合。图2-7 为标签传播的示意图。
综上所述，LPA算法的步骤如下:
1)给每一个节点设置好自己的邻居节点，并将邻居节点的信息存储在一个规模为 MXN的矩阵中。节点i的邻居为矩阵中的第i个元素，注意，这个元素也是一个矩阵，因为MxN的矩阵是由矩阵组成的矩阵，所以它的各个元素都是一个矩阵;
2)给每一个节点初始化一个自己的标签;
3)归循环。随机处理一个节点，假设对于节点i，第x 轮它的标签记为Li(x)，则 Li(x)=f(L1(x),,Lm(x),Lm+(x-1),Lk(x-1))，f 返回的值即为节点i的新标签。当图处于平衡状态，即该节点的邻居中，具有多个标签的邻居节点数相等或者值达到最大，则在其中随机的选取一个标签作为新的标签
4)当节点的标签不再发生变化时，则算法执行结束。在实际的应用中可以看情况而定，比如当标签不变的节点数目超过一定的阙值(90%)时，就可以让算法结束。
2.4.3 标签传播算法的特点
1)该算法步骤简单，操作容易且计算量小。LPA 开始时需要用到训练标签作为节点的初始标签,利用以标记数据和未标记数据之间的内在规律以及邻接点数据的标签，就可以预测和传播未被标记数据的标签，然后将其合并到对对应的标签数据集中[21]
2)该算法可移植性强，具有很高的扩展性[22]。因为只要要处理的数据在空间上的分布是相近的，我们就不用关心数据的具体分布形状，都可以通过标签传播的方法将他们归并到同一个集合中，所以不管是音频、视频、图像还是文本都可以对它们进行标注、检索及分类等操作。
2.4.4标签传播算法的应用
信息检索与文本分类
信息检索是对所拥有的资源和用户需求进行分别标记,然后对这两个标记结果进行匹配查询，并将匹配成功的资源作为最终结果呈现给用户。文本分类就是在指定了所划分好的的类别下，将用不同机器语言编写的文本文档，根据其内容来判断该文本属于哪一个类别。信息检索是将用户需求和资源进行匹配，而文本分类是将文本内容和类别进行匹配。而最终匹配的效果和使用的算法有直接的关系。
标签传播算法能够将用户需求或类别根据赋予它们的标签的相似度将标签传播到未被标记的内容，该相似度的值决定了邻接点之间传播的概率。2.4.42多媒体信息标注
多媒体信息标注的概念是将已经标注好的多媒体信息当作分类系统中的一种类标签，然后利用合适的算法从已被标注的信息中提取出有效的关系模型，从而对未被标注的多媒体信息进行类别标记，完成标注。
标签传播算法首先要将多媒体信息划分成多个子信息块,提取出颜色、大小位置等特征信息，然后找出各信息块间的关系模型，并计算各子信息块间的相似度，最后对其进行相应的标注和分类。2.4.4.3社区应用
本文用到的同人关系传播算法就是社区应用的完美诠释。标签传播算法应用于社区的整体思路是根据网络节点的结构来预测社区的结构,每个节点被初始化一个特定的标签，在循环迭代的过程中，连接紧密的节点会从一个被标有独特标签的节点变成公认的社区节点，那些被标有同种标签的节点便组成了同一个社区即属于同一个集合[23]。
第三章网络虚拟身份分析系统框架
3.1概述
本章描述整个网络虚拟身份分析系统，主要包括数据采集，数据预处理，数据分析三大模块，并分别对各个模块进行必要的描述，其中数据分析模块即同一使用人的网络虚拟身份合并算法的实现是本文的重点，将在下一章进行重点详细的介绍。因为所要分析的数据量很大，传统的计算机无法处理，因此本文的数据分析主要是基于上一章介绍的 Hadoop 平台。随着数据量的剧烈增长，基于Iadoop 平台的海量数据分析越来越受到学者的欢迎。本文使用的数据是两千多家企业的日常上网数据，数据真实可靠，能很好的保证研究的真实性。这些数据包含多种样式，例如HTTP 报文，TCP 报文等以下几节将对网络用户虚拟身份分析系统进行详细的分析，并对每个模块对应的架构进行介绍。
3.2网络虚拟身份分析系统的概述
本文使用的分析系统包括数据采集模块、数据预处理模块和数据分析模块
系统架构如图3-1。
3.3网络数据采集模块
企业网相当于一个局域网，同一个企业的所有员工都工作在一个局域网内。所有用户的上网数据都将通过一个网络出口向外传送，因此我们将采集数据的设备设置在这个网络出口处，就能获得该企业所有员工的上网数据，我们称这个设备为网络流量监测设备即网络探针。
网络探针不仅可以获取用户的上网流量,还可以对用户上网进行管理。该设备类似一个路由器，是由本实验自主研发的，整合了具有特定功能的业务到该设备的内核，当用户使用该业务时，该业务生成的数据报文将通过流量监测设备向外传送，若该报文与存在内核的特征相匹配，则丢掉该报文，其对用户产生的影响就是用户不能使用该业务,因为该业务的数据报文不能经过流量监测设备成功的发送到对方服务器，因此服务器就没有相应包回应。本文针对用户的网络虚拟身份进行分析，只需要带有虚拟身份相关信息的数据报文即可。
本研究课题分析的是网络用户的虚拟身份是否属于同一使用人，从而来分析用户的上网行为，单分析一个企业的数据信息不具有普遍性，因此我们将上千个网络流量探针部署在上千家企业的网络出口。除此之外，又建立了一个网络监控平台来管理这些流量监测设备，并通过建立 Postgresgl 数据来储存从各家企业获得的网络流量数据。目前这种网络监控平台已经形成，网络流量探针部署在不同类别企业的网络出口处，这些企业包括金融业，服务业等。我们在该网络监控平台上获取其中两千多家企业作为分析对象，这样可以保证研究的可靠性、真实性和合法性。网络监控平台如图 3-2 所示
3.4数据预处理模块
数据预处理模块是一个基于 hadoop 的处理架构。我们从网络监控平台将数据下载到本地，由于采集的数据包含两千多家企业以及半年的数据，所以数据量非常大，因此需要上传到我们搭建的 Hadoop 平台上。采集的数据包括 HTTP 报文数据、DNS 报文数据。由于是通过设备采集数据，不可避免的会受到人为或非人为的影响，因此需要对从网络监控平台采集到的数据进行预处理。
将采集到的报文数据上传到分布式存储系统 HDFS，通过 MapReduce 预处理报文数据，得到结构整齐的数据报文。预处理之后得到的数据报文字段如表 3-1 所示:
表 3-1 数据报文格式
名称
customer id
host name
description
user name
cert_type
cert code
org name
country
note
pinyin
netid type
netid account
netid pass
netid url
first time
last time
netid count
mac
类型
BIGINT
VARCHAR(128)
VARCHAR(128)
VARCHAR(128)
INTEGER
VARCHAR(36)
VARCHAR(140)
VARCHAR(128)
VARCHAR(2048)
VARCHAR(512)
INTEGER
VARCHAR(128)
VARCHAR(128)
VARCHAR(128)
INTEGER
INTEGER
INTEGER
VARCHAR(128)
数值
DEFAULT O
DEFAULT
DEFAULT
DEFAULT
DEFAULT 0
DEFAULT
DEFAULT
DEFAULT
DEFAULT
DEFAULT
DEFAULT O
DEFAULT
DEFAULT
DEFAULT
DEFAULTO
DEFAULTO
DEFAULT O
DEFAULT
说明
探针设备号
主机名
用户名
身份类型
身份号
组织名称
虚拟身份类型
虚拟身份号码
在一个上报周期内一小时)此虚拟身份第一次出现的时间
在一个上报周期内一小时)此虚拟身份最后一次出现的时
设备的MAC 值
3.5数据分析模块
数据分析模块是基于Hadoop平台的大数据分析是我们自己搭建的Hadoop集群，包含一个NameNode，一个 SecondaryNameNode 和十个 DataNode，每个DataNode可以存储3.5T的数据，性能足以分析 TB级的数据。在据预处理阶段，被预处理的数据报文会分别上传到数据库和 HDFS 上，因此数据分析时直接读取HDFS上的数据即可。数据分析后的结果首先保存在HDFS 上，然后根据需要再将数据上传到 Postgresql 或Hbase 上。想要查询结果时，可以直接从客户端连接数据库或HDFS，从而使结果有更好的可读性。
3.6系统工作流程
以某个正式上线项目的分析需求为例，系统的工作流程如下:网络流量探针设备实时收集链路上的流量信息，以流记录的形式储存每隔一段(一小时)时间，流量监测设备通过 FTP方式将流记录数据传输到网监平台的数据预处理服务器。数据预处理服务器对此段时间内的此类数据进行规定的分析处理，将处理后的结果分别转发存储到数据库和云计算平台中，为各种应用分析提供需要的中间结果。云计算平台根据需求对中间结果进行再处理，得到最终的结果并呈现给用户。

第四章 网络虚拟身份分析系统的算法实现
网络虚拟身份分析系统体系结构中的数据分析模块是该系统中的重点,也是本研究课题的重点。该系统是在 Hadoop 技术的基础上，通过编写MapReduce 程序，将原始无关联的海量虚拟身份处理成想要的数据结果展示出来，即将虚拟身份进行合并，分析出哪些虚拟身份对应着同一使用人。
4.1概述
近年来，随着互联网的高速发展，网络上的数据量早现爆炸性的增长，不同的应用程序要求对用户进行认证,即用户只有注册一定程度上可以标识自己的账号才可以登录。这样就在互联网上留下各种各样的海量虚拟身份。之前的研究只是单纯的提取出这些虚拟身份，通过这些虚拟身份来分析用户的行为习惯和兴趣爱好等。相比之前的研究，我们发现这些海量的虚拟身份之间存在一定的关系所以本文提出了一个基于海量虚拟身份的合并算法，分析出该用户对应的所有虚拟身份也就能知道其注册的各种应用，从而能更好的进行用户行为分析。这样能帮助企业更好的理解用户，挖掘用户的价值，提高服务质量，最终会给企业带来利益。
4.2数据采集
本章所用的流量数据是由本实验室自主研发的流量监控设备采集得到的。该设备部署在企业的网络出口处，监控上下行链路上的所有用户报文，并将报文以流记录的形式存储下来。为了保护用户的隐私，该网络探针过滤掉了所有与用户隐私相关的信息。
本章所有的流量数据采集自中国南方某省会城市的两千多家企业，并选择了2014年4月到2014 年8月的几亿条数据进行分析，保证了分析结果的普遍性
4.3算法描述
算法流程图
因为本算法是属于网络虚拟身份分析系统的数据分析模块，所以最初的输入数据就是数据预处理后的如表3-1的数据，每行数据记录包含18个字段该算法的总体思想是:当用户在上网时，在他们上网的这段时间内，他们会同时登录各种应用，使用各种虚拟身份。这样产生的结果就是，我们会在同一个设备(MAC)上很小的一段时间内看到多个虚拟身份同时出现。当多个虚拟身份同时出现的次数，即多个虚拟身份同时出现在不同的MAC 地址的数目，超过一定的闽值时，我们就有很大的把握认定这些同时出现的虚拟身份属于同一使用人4.3.2输入数据前期处理
去除用字段
根据我们的算法总体思路，对于数据预处理模块后的输入数据报文需要进行前期处理，只保留一些对于我们的算法有帮助的字段:customer-id、netid type、netid account、first time、last time、MAC。如表 4-1 所示:
去除公用账号
在许多企业内部普遍存在一些公用测试账号,这些账号也许会被不同的人使用进行一些必要的测试,也就会和不同的人的虚拟身份在很小的一段时间内同时出现在同一MAC 地址上。这样造成的后果就是，原本不属于同一使用人的虚拟身份通过这些同一公用账号被合并到一起，带来很大的干扰。这些公用账号具有如下几个特点:
1) 和许多虚拟身份同时出现;
2)出现在不同的 MAC 地址的数目远远多于一个正常的虚拟身份出现的不
同的MAC 地址数目。在本研究课题中，我们经过多次测试，根据特点2)就可以很好的去除公用账号。当某一个虚拟身份出现在不同的 MAC 地址数超过某一值时，我们就认为此虚拟身份即为公用账号，然后从输入数据中删除带有此虚拟身份的这一条记录
4.3.3虚拟身份合并
我们认为多个虚拟身份在很小的一段时间内同时出现在同-MAC地址上即属于同一使用人。所以我们设置一个跨度为一小时的时间窗口，然后出现在同时间窗口内的所有虚拟身份很可能属于同--使用人。但是,也会出现特殊的情况如图 4-2(a)。很有可能属于同一使用人的两个虚拟身份 A 和 B 被划到两个不同的时间窗口，造成的结果就是该属于同一使用人的虚拟身份没有合并到一起为了解决这个问题，我们可以将时间窗口移动半个小时，如图 4-2(b)。这样就不会漏掉恰好在时间窗口两边缘的虚拟身份组。最后，我们会在后面的步骤中将这两种情况进行合并。
时间口的确定
首先，对 first time 和last time 取平均值 avgTime=(first time+last time)/2然后将 avgTime 分别转换成半点时刻和整点时刻。
1.半点时刻的时间窗口(getHourHalfO)小时数:nHour=((avgTime-60x30)/(60x60))X(60x60)分钟数:nMinute=avgTime%(60x60)。如果nMinute小于等于30，返回nHour+60x30否则返回(nHour+1)+60x30
2.整点时刻的时间窗口(getHourTime0)小时数:nHour=((avgTime)/(60x60))X(60x60)分钟数:nMinute=avgTime%(60x60)。如果nMinute小于等于30，返回nHour，否则返回(nHour+1)
4.3.4合并条件
1)如上所述，出现在同一时间窗口内的虚拟身份很有可能属于同一使用人。但是怎么确认呢?我们的想法是，如果这些虚拟身份同时出现在同一时间窗口的次数超过一定的闯值，我们就认为同时出现在同一时间窗口内的这些虚拟身份属于同一使用人。
2)除此之外，还有另外一种情况。我们假设在同一时间窗口内有两个虚拟身份A和B，并且在另一个时间窗口内有两个虚拟身份 B和C，如图4-3 所示。那么，虚拟身份 A 和虚拟身份 C 是否属于同一使用人呢?因此，在两个虚拟身份之间我们设定了关联度 R，定义如下:
R=Q1xQ2
(4-1)
其中，Q1、Q2 分别代表两个虚拟身份之间的权重。
如表 4-2 所示，虚拟身份 A 和虚拟身份 B、虚拟身份 B 和虚拟身份 C、虚拟身份 C 和虚拟身份 D，它们之间的权重都是 0.5，那么，虚拟身份 A 和虚拟身份C之间的关联度 RAc 就为 0.25(0.5x05)，虚拟身份 A 和虚拟身份 D之间的关联度RAD便为 0.125(0.5x0.5x0.5)。如果设定值为0.2，则我们认为虚拟身份 A和虚拟身份 C 属于同一使用人，虚拟身份 A 和虚拟身份 D 就不属于同一使用人。
4.3.5后期处理
在我们的网络探针的前面也许会有 NAT(网络地址转换器)或者路由器，这样就会造成很大的错误，即把出现在这个 MAC 地址上的所有的虚拟身份都合并认为属于同一使用人，毫无疑问，这些虚拟身份有很大的概率不属于同一使用人。所以当我们分析出属于某一使用人的所有虚拟身份后，我们就会根据现实生活中一个自然人拥有的合理的虚拟身份数来判断统计出来的属于同一使用人的虚拟身份的个数是否在一个合理的范围内，如果统计出来的个数超出了合理的阙值，就认为此人的虚拟身份出现的 MAC 地址很可能就是一个NAT，接下来，我们就从原始数据中删除带有这些虚拟身份出现的MAC 地址的整条记录，然后再从头开始执行算法。如此往复，直到最终统计出来的结果在合理的范围内。
4.4基于Hadoop平台的算法实现
4.4.1 过滤公用账号
由于公用账号会被不同的人拿到不同的设备上进行测试使用，所以对虚拟身份出现的不同设备进行计数，如果出现在不同设备的数超过一定的闯值，我们就认为此虚拟身份即为公用账号。
1输入数据
网络流量探针采集到的上亿条数据，数据量大约有 100GB在数据库中的存储形式如图4-4所示
2伪代码
OMapper 阶段
以虚拟身份(类型+值)为 key，以某一台设备为value 输出。@Reducer 阶段
把相同 key对应的value放入到一个hashmap 中，然后判断这个hashmap的长度，即这一虚拟身份出现在多少个设备上，如果长度大于某一阙值，则就判定这一虚拟身份为公用账号，将其输出。
3输出结果
图 4-5 所列出的虚拟身份即为找到的公用账号，并保存到一个文件中。4.4.2统计相同设备上的虚拟身份
4.4.2 统计相同设备上的虚拟身份
首先，为了确定跨度为一小时的时间窗口，我们对first time和last time 取平均值，然后将计算后的值分别转换成离它最近的整点时刻 hourtime 和半点时刻 halfhour。这样就解决了虚拟身份出现在时间窗口两边缘的情况，即实现了时间窗口的半点移动。
其次，以custom idMAC hourtime作为 key，统计出在很短时间内出现在某设备上的虚拟身份，同样，对 halfhour 做同样的操作，后面会对这两个时间窗口的结果进行合并。而且我们会对这两个时刻打上标签，另外，在此过程中会对出现的虚拟身份进行去重。
1输入数据
这一步的输入数据包含两个文件:
1原始数据，数据量约为100GB;
2上一步(4.4.1)的输出数据，数据量约为100MB;
并将文件@作为分布式缓存文件。因为此文件比较小适合作为分布式缓存文件，这样会很好的提高运算速度。
2伪代码
在伪代码中可以看出:
O在Mapper 阶段首先对公用账号进行了分布式缓存，其次对不同的时间窗口进行了分开统计，并在虚拟身份后面打上标签加以区分。@在 Reducer 阶段对不合理的身份数进行过滤，只出现一个虚拟身份的肯定无法和其他虚拟身份进行合并;其次，对一个设备上出现的虚拟身份数过多的也进行剔除，因为这个 MAC 地址有可能是一台 NAT 设备，如路由器，会汇集不同人的虚拟身份，造成很大的噪声干扰。
3输出结果
由图 4-6 可以看出，同一设备上出现的虚拟身份已去重，且虚拟身份后面的“1”和“2”就是所打的标签，标识是属于整点的时间窗口还是属于半点的时间窗口4.4.3对相同设备上的虚拟身份组合计数
4.4.3 对相同设备上的虚拟身份组合计数
对出现在同一设备上的所有虚拟身份进行两两组合成对，并对虚拟身份对进行计数。在此步骤中需要注意两点:
0在组合虚拟身份对时，对两个虚拟身份按照大小进行排序，小的在前，大的在后，防止以后会重复计数。
@由于在虚拟身份中包含时间窗口类型信息，所以对同一个虚拟身份的整点时间窗口和偏移时间窗口会进行分别统计。
1输把上一步(4.4.2)的输出结果文件作为本步骤的输入数据，数据量大约为40GB。
2伪代码
在Mapper 阶段对同一设备上的虚拟身份进行两两组对并排序来作为 key以常数1作为value。
在Reducer阶段对虚拟身份对进行计数输出，类似于经典的 wordcount。
3)输出结果
由图4-7可知，不同的窗口类型进行分开统计，且最后一列即为虚拟身份对出现的次数。
4.4.4 统计单个虚拟身份
对出现在单个设备上已去重的虚拟身份进行单独计数，区分整点时间窗口和偏移时间窗口，统计其在所分析的整个时间内出现的总次数。
1输入数据
和4.4.3同样的输入数据，即4.4.2的输出结果，数据量约为40GB。
2伪代码
将输入文件的每一行以“t”进行分割，然后对每一个虚拟身份进行单独计数典型的 wordcount，就不再赘述
3)输出结果
如图4-9所示，虚拟身份后面会打上标签来区分不同的时间窗口类型，然后进行分别计数。
4.4.5过滤虚拟身份
对虚拟身份对中的前一个过滤
根据单个虚拟身份出现的次数以及虚拟身份对出现的次数对数据进行过滤排除掉单个虚拟身份出现总次数小于某一阙值的虚拟身份，若出现的次数太少则偶然性太大，失去了研究的普遍性，不具有说服力。并去掉虚拟身份对与单个虚拟身份出现次数比值小于某一闯值的记录，若虚拟身份对出现的次数小于单个虚拟身份出现的次数，则不足以说明这一虚拟身份出现另一个虚拟身份也会同时出现，即不能说明这两个虚拟身份属于同一使用人。
在此步骤中需要注意两点:O针对需要过滤的虚拟身份，处理之后删除该虚拟身份后面的时间窗口类型信息;
@将虚拟身份对的 key 和 value 交换，方便下一步进行处理。
1)输
本步骤的输入数据包含两个部分:
输出的虚拟身份对文件，数据量约为10GB;
输出的单个虚拟身份文件，数据量约为 2GB;
2伪代码
由伪代码可知，在 Mapper 阶段对不同的输入文件进行不同的操作用以区分。因为在后续的合并过程中不必要求知道该虚拟身份是出现在半点时刻还是整点时刻，而且还要将这两个时窗口的虚拟身份对进行去重合并，所以在 Redcuer阶段，对要过滤的虚拟身份所属的窗口类型进行移除。
在 Reducer 的输出可以看出，对虚拟身份对和单个虚拟身份的比值进行了条件过滤，说明第一个虚拟身份出现第二个虚拟身份也会同时出现，这样就在很大程度上说明这两个虚拟身份属于同一使用人。
3)输出结果
由图4-10可知，两个虚拟身份的顺序进行了对调;且第二个虚拟身份已经把时间窗口的类型信息去掉。
对虚拟身份对中的另一个过滤
和对虚拟身份对中的前一个过滤过程一样，但输入数据不同。
1输入数据
本步骤的输入数据包含两个部分
输出的虚拟身份对文件，数据量约为8GB;@4.4.4输出的单个虚拟身份文件，数据量约为2GB
2)输出结果
由图4-11 可以看出，虚拟身份后面的时间窗口类型信息都已经去掉;因为此步骤和上一步的程序是一样的，所以经过两次的虚拟身份的位置的对调，两个虚拟身份依然是按照从小到大的顺序进行排序。4.4.6去重整理
4.4.6 去重整理
首先，对上一步输出的结果进行整理，把最后一列的虚拟身份对出现的次数去掉
其次，对虚拟身份对进行去重
1输入数据
将4.4.5.2的输出文件作为本步骤的输入文件，数据量约为5GB
2)输出结果
由图4-12可见，输出的虚拟身份对已按照从小到大的顺序排好;又因为在上一步过滤虚拟身份中，对两个虚拟身份进行了相互过滤，条件也相当苛刻，所以一行记录中的虚拟身份对肯定属于同一使用人。
4.4.7合并所有记录
这一步是算法中的重点，借助图论的思想，用 MapReduce 实现了对整个文件取并集，完成了属于同一自然人的所有虚拟身份的合并。对上一步的输出结果进行取并集，得到的结果形式是文件的每一行的所有虚拟身份对应同一使用人将在下一章对此同人关系传播算法的实现进行单独详细的介绍
1)输入数据
步骤4.4.6的输出结果，数据量约为3.5GB
2)输出结果
这一步所得到的输出结果并不是真正的最终结果，下一步会对这一步的输出结果进行分析验证然后再做相关的处理，下一步骤会有相关说明，但是最终的结果形式是不会变的，如下所示:
如输出结果图4-13 所示,每一行记录中的所有虚拟身份即属于同一使用人，为了保护公司以及个人隐私，我们对敏感的信息进行了特殊处理(用*号代替)并且，在图 4-13 中进行特殊处理的虚拟身份是我们已知企业所用的邮箱，这样我们可以对分析出属于同一使用人的结果的正确性进行验证。对照分析出来的结果，然后询问该邮箱使用人的其他虚拟身份看是否吻合，经验证统计分析出来的结果正确率达 90%以上。
4.4.8结果再处理
虽然在前面的步骤中对相同设备上虚拟身份数过多的进行了过滤，这些设备有可能是 NAT 设备，但还会存在其他的NAT设备。在这一步对上一步输出的结果进行判断,我们就会根据现实生活中一个自然人拥有的合理的虚拟身份数来判断分析出来的结果是否在一个合理的范围内，如果统计合并出来的属于同一使用人的虚拟身份个数超出了合理的闯值，就认为这些虚拟身份出现的 MAC 地址很可能就是一个NAT，接下来，我们就从原始数据中删除带有这些 MAC 地址的整条记录，然后再从头开始执行算法。如此往复，直到分析合并出来的同一使用人的虚拟身份个数在合理的范围内。

第五章同人关系传播算法在Hadoop中的设计与实现
5.1概述
同人关系传播算法是启发于标签传播算法，是图论在社区应用中的完美体现在本文中它是将属于同一个人的所有虚拟身份归并成一个集合，即同一个人的虚拟身份拥有相同的标签，且两两集合之间没有任何交集。
这一步的输入数据是 4.4.6 去重整理过的输出数据，输入数据的形式是每一行记录为成对的虚拟身份。在图论中的表示应为每一个虚拟身份看作是一个节点V,每一行记录出现的虚拟身份对表明代表这两个虚拟身份的节点之间存在边E在本次研究课题中对标签传播算法先后进行了改进，相比第一次的不足，第二次的算法程序既合理又有效。
5.1.1同人关系传播算法初次实现
通过对标签传播算法的分析与理解，发现其比较适合本文对同一使用人的虚拟身份的合并，使得每一个人的虚拟身份共同拥有同一个标签，会形成一簇簇的虚拟身份组，每一簇即代表一个使用人。
算法设计
将每一个虚拟身份看作是图中的一个节点，节点的数据结构表示为:class nodef
nodeld
neighborNodes
oldLabel
newLabel
//节点Id，即虚拟身份
1/邻居节点
//1日标签
//老标签
1)算开始时，首先为每一个节点设置一个独有的标签 Label;
2)归迭代。在本文中我们将标签设置为从1开始的整数，通过节点之间的关系将标签传播到其他邻居节点，当每个节点收到多个标签时，选取数值最小的标签来更新自己的标签。
3)当图中所有节点的标签都不再发生变化时，程序运行结束。拥有相同标签的节点虚拟身份即属于同一使用人。
Hadoop实现
用MapReduce实现该算法需要两个 Job。Job1 是递归迭代，目的是更新节点的标签信息;Job2是用来断 Job1 是否代完成，判断依据是在 Mapper 阶段检查节点的新旧标签是否相等，若相等则输出<nodeld，0>，否则输出<nodeld，1>;在Reducer 阶段，将相同 key 值的 value 相加，若结果等于0，则选代结束否则继续进行下一轮迭代。伪代码如下:
5.1.2同人关系传播算法最终实现
算法设计
因为本文所要分析的数据量比较大，而第一次改进的标签算法初始时需要给每一个节点分配一个特有的标签,显然对于海量数据来说此算法显得比较笨拙也不太合理。
同人关系传播算法的最终实现初始时不再给每一个虚拟身份设置一个独立的标签，而是将每一个虚拟身份看作是不同的标签，然后将属于同一个使用人的虚拟身份关联起来，相当于对整个的输入文件的所有行进行了取并集操作，即属于同一使用人的所有虚拟身份出现在同一行。整个算法需要进行迭代计算，迭代结束的标志是当输出文件的行数不再发生变化。因为当行数不再发生变化时，说明每两行之间没有共同的元素，不同使用人的虚拟身份也就完全分开，程序实现也很简单，只需要判断文件的行偏移量就可以。过程原理图如表 5-1 所示从表 5-1 中可以看到当迭代进行到第四轮时，输出文件和第三轮的输出文件-·模一样，此时程序运行结束。所得到的结果即为每--行所列出的虚拟身份组分别属于不同的使用人。
Hadoop实现
该算法的MapReduce 实现也是需要两个 Job，两个 Job 串联执行且会循环多次。伪代码如下:
综合表5-1 原理图和伪代码进行具体分析，首先可以看到整个算法需要两个Job 串行执行，且执行的次数也会根据数据量的大小和数据之间的内在关系有所不同。
第一个Job的 Mapper 阶段是将两两出现的虚身份分别当作 key，这样能保证不会漏掉任何一个虚拟身份。而 value 值有所不同，排在前一个的 key 对应的 value 为整行，而排在后一个的 key 对应的 value 只是第一个虚拟身份(后续的暴力解决也可以将它的 value 设置为该整行)。这样如果某两行存在相同虚拟身份则在合并的过程中也不会丢失数据;在 Reducer 阶段对相同 key 的 value进行拼接合并，同时会对相同的虚拟身份进行去重。
第二个 Job 的 Mapper 阶段首先判断第一个 Job 输出的 value 中虚拟身份的个数，如果 value 中只有一个虚拟身份的话，就让其与它的 key 进行比较(compareTo)，如果小于 key 就将 key 和 value 交换位置，这样做的目的是防止产生多余的行而使得算法无限循环，导致程序崩溃:在 Reducer 阶段也是进行简单的 value 列表中元素的拼接合并，同样的，也会对虚拟身份进行去重，最后只将 value 输出接着进行下一轮的迭代运算。
随着算法的不断进行，文件的大小和行数不断的发生变化，而程序会对每次输出文件的行数进行判断，如果发现前后两次输出文件的行数相等则程序终止。因为如果某两行存在相同的虚拟身份，则程序会将它们合并成一行，使文件的行数发生变化。如果行数不在发生变化说明输出文件的每两行之间不再有重复的元素，不同行所列出的虚拟身份即属于不同的使用人。
5.2性能分析
通过表 5-2 对两种算法的性能分析可知，当数据量非常小的时候，初次实现的算法能够较好的完成任务，但是随着数据量的不断增加，达到海量数据时，因为初次实现的算法开始时要对每一个元素设定一个标签,这对海量的数据来说是不太合理的，而最终实现的算法不再对初始元素做任何操作，且算法时间复杂度也不会随数据量的增加有太大变化，能够很好的应用到本文所提到的场景。5.3总结
5.3 总结
综上所述，将图论的思想应用到本算法中，并借鉴其经典算法对本算法先后进行了两次不同的改进和调试后，最终实现的整个系统能很好的实现对属于企业某一用户网络虚拟身份的合并。最初的原始数据大小为 100G而最终的结果数据为800M 左右，约包含千万条记录，使得研究具有普遍性和说服性。结果的准确率也达到了 90%以上，符合预期的效果。

第六章 总结与展望
在互联网的普及率以及渗透率日益增强以及网民数量日渐增多的背景下，我们必然会走进信息爆炸时代一一大数据时代。大数据时代的到来意味着数据不再是MB、GB 级别，而将达到TB、PB，甚至 EB 级别。这些庞大的数据中往往院藏着有价值的信息，随着网络数据量的增加，这些隐藏的信息所带来的价值对推动当今时代的发展又是至关重要的。因此，如何从海量数据中挖掘出有价值的信息是当今时代的热门话题。现如今，大部分都是从电商、社交网站数据来分析用户行为，本文则从企业用户数据着手分析，分析企业用户的行为。本文使用网络流量采集探针采集的两千多家企业员工的上网数据作为分析的原始数据。接着，本文从用户使用的虚拟身份的角度来分析这些数据，通过对不同使用人的虚拟身份的合并来分析企业用户的一些行为习惯，具体来讲，本文主要完成以下几个工作:
1)了解当前的研究现状，学习数据分析的技术，设计出本文数据分析的整
个系统流程，所有流程均在 hadoop 平台上实现。
2)对采集到的数据进行分析，提取出对研究目的有用的字段，并对用到的字段做一些特殊的处理，以更好的实现虚拟身份的合并，如时间窗口的确定。
3)因为本系统的实现算法是借鉴于图论中的标签传播算法，所以对图论中的基本概念和基本原理做了深入的研究，对标签传播算法的应用场景、算法原理及代码实现也进行了深入的学习。
4)本文中重要的工作是对噪声的控制，采用别除公共账号和 NAT 的方式有效的降低了噪声干扰，使得结果比较干净，达到了理想的效果。
通过对企业用户的虚拟身份的分析，包括简单属性分析以及一些算法设计得到企业用户的行为习惯。但是在某写方面仍有不足，本人认为仍有以下方面可以进行扩展分析:
1)本文所得到的结果是存储在HDFS或HBase中,想要对结果进行查询是返回的结果都是些单纯的虚拟身份，界面不够友好，应在返回界面做一些必要的说明。
2)可以将所有合并出来的属于同一使用人的虚拟身份出现的地理位置标记出来，然后在地图上进行标注，最后根据虚拟身份出现的时间的先后顺序进行跳跃式的在地图上显示，这样就描绘出了该用户的运动轨迹，从而对该用户行为进行更好的分析。

参考文献
[1]中国互联网络中心(CNNIC)第35 次中国联网发展状况统计报告 2015.02http://www.cnnic.cn/hlwfzyj/hlwxzbg/201502/P020150203551802054676.pdf.[2] Jia LiResearch of Analysis ofUser Behavior Based on Web Log In Computationaland Information Sciences(ICCIS)June 21-232013Shiyang pp:601-604.[3] Jingling Zhao, Xia Wang, Yue Zhou.Study and Implementation ofUser BehaviourAnalysis In Advanced Communication Technology(ICACT)February 7102010Phoenix Park pp:692-695.
[4] 周帆，许永.网络时代的虚身份研究[D].南京艺术学院，2013.
[5]邓璐，韩伟红基于eID虚拟身份数据存储的研究D1国防科技大学2013[6] 吕诚，张春.手机上网用户行为分析的关键技术研究与应用[D].北京交通大学2013.
[7]刘鹏网络用户行为分析的若干问题研究D]北京电大学，2010.[8] Hao Wei,Xingyuan Chen, Chao Wang. User behavior analyses based on networkdata stream scenario[J].//Communication Technology(ICCT)，IEEE，2012.[9] 任思颖，何刚基于大数据的网络用户行为分析[D].北京邮电大学，2014.[10]杨铮，李双庆.基于流量识别的网络用户行为分析[D].重庆大学，2009.[11]付莎，楼新远基于XMPP 协议企业级IM的研究与实现D西南交通大学2009.
[12]张硕，杨洁基于 Hadoop 的网络流量数据处理系统的实现与应用D]北京邮电大学，2013.
[13]张勇勇，沙学军基于 Hadoop 自动文本分类的研究与实现[D]哈尔滨工业大学，2012
[14]邓祥，王备战基于Hadoop 的海量日志数据处理研究与应用D]厦门大学2013
[15]侯建，帅仁俊.基于云计算的电子健康档案存储方式与关联规则挖掘的研究[D].南京工业大学，2011.
[16王怡丰，臧斌宇面向非结构化分布式存储系统的性能分析系统研究ID1复日大学，2012.
[17]张建梅，金应烈最短路径算法分析与应用--城市公交网络咨询系统D].南开大学，2007
[18]刘茂华，王岩，周海壮D算法最短路径在数字校园中的应用研究D1沈阳建筑大学土木工程学院，东北大学资源与土木工程学院，2012.10.13.
[19]何晓涛，张军英典型复杂网络的最短路径统计特性分析ID1.西安电子科技大学，2013.
[20]邓礼礼，孙强求图中受限制的所有最短路径算法的分析与研究D1.华东师范大学，2009.
[21]张俊丽，常艳丽，师文.标签传播算法理论及其应用研究综述[D1.南京大学信息管理学院，2013.
[22]何国雄，徐泽明基于 MapReduce 的图聚类算法的研究与实现D1湖南大学2012
[23]信楠，郑小林基于标签传播的实时社区发现算法研究[D].浙江大学.2013.

