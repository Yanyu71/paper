摘要
智能语音客服是如今机器学习和人工智能算法研究的重点，对于 企业来说是节省人力回答高频重复性问题的必须，对于个人来说也希 望有拟人化的智能客服快速地解决实际问题，而如今的客服系统还存 在语义理解不足、多轮对话能力欠缺，语音对话不够拟人个性化等问 题。
本文设计了基于Rasa、React、Tacotron2> MelGAN等框架模型 的个性化智能语音客服系统，解决了单轮对话回复不精准，多轮对话 重要信息丢失，语音回复个性化能力弱等关键问题，完成点餐这个垂 直领域的多轮对话基本服务逻辑，而且能使用特色人声完成个性化的 语音服务，本文主要包含五个大模块，分别为前端交互模块、后端中 转请求处理模块、Rasa NLU语义理解模块、对话管理模块和语音合 成模块。
1•前端交互模块使用React框架中最新的前端函数式组件技术 React Hooks,在耦合度和扩展性上都能达到很好的效果，在用户呈现 上达到流畅、简洁和易使用的要求，同时也使用Ts编程语言规范编 写格式，实现了智能客服机器人的交互界面，完成了文本输入、语音 输入和转换文字、文本输出显示、语音输出显示、音色输出选择等主 要功能。
2•后端中转请求模块采用了轻量级的Python异步协程包Aiohttp 构建，负责接收前端的文本输入数据，并将数据信息与Rasa的NLU 部分以及对话管理部分进行交互得到文本的回复输岀，再与语音合成 模块进行交互将文本的输出回复转换为语音波形的输出，最后将信息 返回给前端模块。整体作为核心中转模块连接其他各个模块，在设计 上足够轻巧和易于扩展。
3. Rasa NLU模块负责单个句子的实体提取和意图识别，是语义 理解的关键模块，采用了 Pipeline的构建方式将功能分层，包含了分 词器、中文词向量转换、实体提取器、意图识别器等多个部分，利用 机器学习方法训练了高准确度的实体提取器模型和意图识别模型，并 配合同义词提取和正则化提取来优化实体提取，利用Spacy中文词向 量模型优化了中文分词和中文的向量化。同时采用了时间前回溯策略 增加了本轮对话的信息量，包含了前几轮对话的信息后大大提高了实 体提取和意图识别的准确度，采用数据增强策略解决了训练语料不足 的问题，采用动作选择策略实现了低置信度下的问题回滚，使问答更 加流畅。
4•对话管理模块是实现多轮对话的核心模块，本文搭建了 Action 服务器用于对话的逻辑处理，与Rasa NLU模块紧密配合使用插槽管 理对话上下文的关键信息，使用知识图谱管理基本的实体信息，并对 中文数字提取为阿拉伯数字进行了专门优化，针对未知关键信息具备 一定程度的推导能力，配合回复模板能生成拟人化的准确回复。
5.语音合成模块包含语音合成模型Tacotron2＞声码器模型 MelGAN、格林算法和声码器模型WaveFlow,结合语音克隆技术对 语音合成模型编码器部分进行了改造，解决了大量单人语音语料搜集 的困难，以多人语音训练的语音模型为基础，只用较少单人语音数据 通过迁移训练就得到了特殊音色的语音模型。本文自训练了声码器模 型部分通过比较分析选择最优方案，最终方案同时满足了生成语音质 量好和生成耗时低的要求。
本人独立完成了该系统所有模块的设计和实现，数据集上使用了 部分开源数据集，搜集了周星驰语音数据和自录音了本人音频数据作 为语音数据，点餐文本对话数据也由本人直接模拟生成。系统整体达 到了目标要求，并最终通过功能测试和性能测试验证了系统的核心功 能以及交互的实时性和系统稳定性。
关键词:语音合成;多轮对话;声码器;深度学习
DESIGN AND IMPLEMENTION OF PERSONALIZED VOICE CUSTOMER SERVICE SYSTEM
ABSTRACT
Intelligent voice customer service is the focus of machine learning and artificial intelligence algorithm research. For companies, it is necessary to save manpower and keep solving high-frequency repetitive problems. For individuals, it is also hoped that anthropomorphic intelligent customer service can quickly solve practical problems. However; today's customer service system still has problems such as insufficient semantic understanding, lack of multi-round dialogue ability, and insufficient anthropomorphic and personalized voice dialogue.
This paper designs a personalized intelligent voice customer service system based on framework models such as Rasa, React, Tacotron2, MelGAN, etc., which solves the key issues such as inaccurate responses in a single round of dialogue, loss of important information in multiple rounds of dialogue, and weak voice response capabilities. The basic service logic of multq)le rounds of dialogue in the vertical field of meal, and the ability to use characteristic human voices to complete personalized voice services, this article mainly includes five major modules, name仪 the front-end interaction module, the back-end transfer request processing module, and the semantic understanding of Rasa NLU Module, dialogue management module and speech synthesis module
l. The front-end interaction module uses tiie latest front-end functional component technology React Hooks in the React framework, which can achieve good results in coupling and scalability, and achieve smooth, concise and easy-to-use requirements in user presentation. Using the Ts programming language to standardize the format, the interactive interface of the intelligent customer service robot is realized, and the main functions such as text input, voice input and conversion text, text output display, voice output display, and tone output selection are completed.
2. The back-end transfer request module is constructed using the lightweight Python asynchronous coroutine package Aiohttp, which is responsible for receiving the text input data of the front-end, and interacting the data information with the NLU part of Rasa and the dialogue management part to obtain the text reply output. Then interact with the speech synthesis module to convert the output response of the text into the output of the speech waveform, and finally return the information to the front-end module. The whole is used as the core transit module to connect to other modules, which is light enough and easy to expand in design.
3. The Rasa NLU module is responsible for the entity extraction and intent recognition of a single sentence. It is a key module for semantic understanding. It uses the pipeline construction method to layer functions, including word segmentation, Chinese word vector conversion, entity extractor, and intent recognizer. And many other parts, using machine learning methods to train high-accuracy entity extractor model and intent recognition model, and with synonym extraction and regularization extraction to optimize entity extraction, using Spacy Chinese word vector model to optimize Chinese word segmentation and Chinese Vectorization. At the same time, the backtracking strategy before time is adopted to increase the amount of information in this round of dialogue, and the information from the previous rounds of dialogue has been included to greatly improve the accuracy of entity extraction and intent recognition. The data enhancement strategy is used to solve the problem of insuffic ient training corpus. The action selection strategy realizes the rollback of questions under low confidence and makes the question and answer more smooth.
4. The dialogue management module is the core module to achieve multiple rounds of dialogue. This article builds an Action server for the logical processing of the dialogue, and closefy cooperates with the Rasa NLU module to use the slot to manage the key infoimation of the dialogue context, and use the knowledge graph to manage the basic entity infoimation , And specifically optimized the extraction of Chinese numbers into Arabic numbers, and has a certain degree of derivation ability for unknown key information, and can generate anthropomorphic and accurate responses with the response template.
5. The speech synthesis module includes speech synthesis model Tacotron2, vocoder model MelGAN, Green algorithm and vocoder model WaveFlow, combined with speech cloning technology to transform the speech synthesis model encoder part, solving a large number of single-person speech corpus collection Difficulty, based on the speech model of multi-person speech training, the speech model of special timbre can be obtained through migration training with less single-person speech data. In this paper, the vocoder model is trained to select the best solution through comparison and analysis. The final solution meets the requirements of good voice quality and low time-consuming generation at the same time.
independently completed the design and implementation of all modules of the system. I used part of the open source data set on the data set. I collected Zhou Xingchfs voice data and self-recorded my own audio data as voice data. The order text dialogue data was also directly generated by my simulation. . The system as a whole has reached the target requirements, and finally verified the core functions of the system and the real-time interaction and system stability through functional tests and performance tests.
KEY WORDS:speech synthesis;multi-round dialogue;vocoder;deep learning
